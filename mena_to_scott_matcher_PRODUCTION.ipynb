{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mena to Scott Catalog Matcher - Production Version\n",
    "\n",
    "**Clean implementation with all fixes applied**\n",
    "\n",
    "## Features:\n",
    "- ✅ Multi-signal scoring (category, denomination, color, year, perforation)\n",
    "- ✅ Handles surcharges and overprints correctly\n",
    "- ✅ Compound color matching (e.g., \"yellow green / dark green\")\n",
    "- ✅ Category-aware matching (Surface Mail, Airmail, Official, etc.)\n",
    "- ✅ Unique Scott identifiers to handle duplicate numbers across years\n",
    "- ✅ Hungarian algorithm for optimal assignment\n",
    "- ✅ Color family similarity matching\n",
    "\n",
    "## Scoring System (100 points):\n",
    "- Category match: 10 points (or -50 if wrong)\n",
    "- Denomination: 35 points\n",
    "- Color: 30 points\n",
    "- Year: 25 points (exact match)\n",
    "- Perforation: 10 points\n",
    "- Surcharge mismatch: -10 points penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MatchResult:\n",
    "    \"\"\"Represents a match between Mena and Scott catalogs\"\"\"\n",
    "    mena_catalog_no: str\n",
    "    scott_number: str\n",
    "    confidence: str\n",
    "    score: float\n",
    "    signals: Dict[str, float]\n",
    "    breakdown: str\n",
    "    boost_reasons: List[str]\n",
    "    requires_review: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Color Normalization and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_ABBREVIATIONS = {\n",
    "    \"pl brn\": \"pale brown\", \"dk brn\": \"dark brown\", \"lt bl\": \"light blue\",\n",
    "    \"dk bl\": \"dark blue\", \"org\": \"orange\", \"grn\": \"green\", \"dk grn\": \"dark green\",\n",
    "    \"lt grn\": \"light green\", \"yel\": \"yellow\", \"blk\": \"black\", \"scar\": \"scarlet\",\n",
    "    \"car\": \"carmine\", \"vio\": \"violet\", \"pur\": \"purple\", \"brn\": \"brown\",\n",
    "    \"ol\": \"olive\", \"org red\": \"orange red\", \"red brn\": \"red brown\", \"gray\": \"grey\",\n",
    "}\n",
    "\n",
    "COLOR_FAMILIES = {\n",
    "    \"blue_family\": [\"blue\", \"light blue\", \"dark blue\", \"pale blue\", \"ultramarine\", \n",
    "                    \"blue violet\", \"blue vio\", \"pale gray violet\", \"gray violet\"],\n",
    "    \"red_family\": [\"red\", \"scarlet\", \"carmine\", \"rose\", \"vermillion\", \"crimson\",\n",
    "                   \"dark red\", \"rose red\", \"lake\"],\n",
    "    \"yellow_family\": [\"yellow\", \"orange\", \"lemon\", \"gold\", \"amber\", \"yellow green\"],\n",
    "    \"green_family\": [\"green\", \"light green\", \"dark green\", \"olive\", \"emerald\", \n",
    "                     \"yellow green\"],\n",
    "    \"brown_family\": [\"brown\", \"pale brown\", \"dark brown\", \"sepia\", \"chocolate\", \n",
    "                     \"red brown\"],\n",
    "}\n",
    "\n",
    "def normalize_color(color_string: str) -> str:\n",
    "    \"\"\"Normalize color strings to standard format\"\"\"\n",
    "    if not color_string:\n",
    "        return \"\"\n",
    "    color_lower = color_string.lower().strip()\n",
    "    if color_lower in COLOR_ABBREVIATIONS:\n",
    "        return COLOR_ABBREVIATIONS[color_lower]\n",
    "    return \" \".join(color_lower.split())\n",
    "\n",
    "def clean_scott_color(color_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove overprint notation suffixes from Scott color strings.\n",
    "    Examples: \"carmine (Bk)\" → \"carmine\", \"green (R)\" → \"green\"\n",
    "    \"\"\"\n",
    "    if not color_string:\n",
    "        return \"\"\n",
    "    # Remove overprint suffixes: (R), (Bk), (BI), (G), (V), etc.\n",
    "    cleaned = re.sub(r'\\s*\\([A-Z][a-z]?\\)$', '', color_string)\n",
    "    return cleaned.strip()\n",
    "\n",
    "def find_color_family(color: str) -> Optional[str]:\n",
    "    \"\"\"Find which color family a color belongs to\"\"\"\n",
    "    color_normalized = normalize_color(color)\n",
    "    for family, colors in COLOR_FAMILIES.items():\n",
    "        if color_normalized in colors:\n",
    "            return family\n",
    "    return None\n",
    "\n",
    "def calculate_color_family_similarity(color1: str, color2: str) -> float:\n",
    "    \"\"\"Calculate similarity between two colors based on color families\"\"\"\n",
    "    norm1 = normalize_color(color1)\n",
    "    norm2 = normalize_color(color2)\n",
    "    if norm1 == norm2:\n",
    "        return 1.0\n",
    "    family1 = find_color_family(norm1)\n",
    "    family2 = find_color_family(norm2)\n",
    "    \n",
    "    if family1 and family2:\n",
    "        if family1 == family2:\n",
    "            return 0.85  # Same family\n",
    "        else:\n",
    "            return 0.3   # Different families\n",
    "    \n",
    "    return SequenceMatcher(None, norm1, norm2).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Denomination Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_simple_denomination(denom_string: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a simple denomination string\"\"\"\n",
    "    if not denom_string:\n",
    "        return {\"value\": None, \"unit\": None}\n",
    "    \n",
    "    denom_string = denom_string.strip()\n",
    "    \n",
    "    # Handle ½\n",
    "    if \"½\" in denom_string:\n",
    "        value = 0.5\n",
    "        unit = re.sub(r'[½\\d\\s.]', '', denom_string)\n",
    "    else:\n",
    "        match = re.search(r'(\\d+\\.?\\d*)', denom_string)\n",
    "        if match:\n",
    "            value = float(match.group(1))\n",
    "        else:\n",
    "            return {\"value\": None, \"unit\": None}\n",
    "        unit = re.sub(r'[\\d\\s.]', '', denom_string)\n",
    "    \n",
    "    # Normalize unit\n",
    "    unit = unit.strip()\n",
    "    if unit == 'r':\n",
    "        unit = 'real'\n",
    "    elif unit == 'p':\n",
    "        unit = 'peso'\n",
    "    elif unit in ['c', 'ct', 'cts']:\n",
    "        unit = 'centavo'\n",
    "    \n",
    "    return {\"value\": value, \"unit\": unit}\n",
    "\n",
    "def parse_denomination_string(denom_string: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse Scott denomination strings including surcharges.\n",
    "    Examples: '½r' → {\"value\": 0.5, \"unit\": \"real\"}\n",
    "              '1c on 20c' → {\"value\": 1, \"unit\": \"c\", \"surcharge\": {\"on_value\": 20, \"on_unit\": \"c\"}}\n",
    "    \"\"\"\n",
    "    if not denom_string:\n",
    "        return {\"value\": None, \"unit\": None}\n",
    "    \n",
    "    denom_string = denom_string.lower().strip()\n",
    "    \n",
    "    # Check if it's a surcharge\n",
    "    if \" on \" in denom_string:\n",
    "        parts = denom_string.split(\" on \")\n",
    "        if len(parts) == 2:\n",
    "            new_denom = parse_simple_denomination(parts[0].strip())\n",
    "            orig_denom = parse_simple_denomination(parts[1].strip())\n",
    "            return {\n",
    "                \"value\": new_denom[\"value\"],\n",
    "                \"unit\": new_denom[\"unit\"],\n",
    "                \"surcharge\": {\n",
    "                    \"on_value\": orig_denom[\"value\"],\n",
    "                    \"on_unit\": orig_denom[\"unit\"]\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return parse_simple_denomination(denom_string)\n",
    "\n",
    "def normalize_denomination(value: float, unit: str) -> Dict[str, Any]:\n",
    "    \"\"\"Normalize Mena denomination to match Scott format\"\"\"\n",
    "    unit_normalized = unit.lower().strip()\n",
    "    \n",
    "    # Remove plural 's'\n",
    "    if unit_normalized.endswith('es'):\n",
    "        unit_normalized = unit_normalized[:-2]\n",
    "    elif unit_normalized.endswith('s'):\n",
    "        unit_normalized = unit_normalized[:-1]\n",
    "    \n",
    "    # Handle abbreviations\n",
    "    if unit_normalized in ['p', 'ps']:\n",
    "        unit_normalized = 'peso'\n",
    "    elif unit_normalized in ['r']:\n",
    "        unit_normalized = 'real'\n",
    "    elif unit_normalized in ['c', 'ct']:\n",
    "        unit_normalized = 'centavo'\n",
    "    \n",
    "    return {\"value\": value, \"unit\": unit_normalized}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Year Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_primary_year(issue_dates: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"Extract the primary year from Mena issue dates\"\"\"\n",
    "    date_priorities = ['placed_on_sale', 'probable_first_circulation', 'announced']\n",
    "    for date_key in date_priorities:\n",
    "        if date_key in issue_dates and issue_dates[date_key]:\n",
    "            match = re.search(r'(\\d{4})', str(issue_dates[date_key]))\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_scott_year(scott_stamp: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"Extract year from Scott stamp entry\"\"\"\n",
    "    if 'year' in scott_stamp and scott_stamp['year']:\n",
    "        return int(scott_stamp['year'])\n",
    "    if 'header' in scott_stamp and scott_stamp['header']:\n",
    "        match = re.search(r'(\\d{4})', str(scott_stamp['header']))\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scott Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_leading_zeros(catalog_no: str) -> str:\n",
    "    \"\"\"\n",
    "    Strip leading zeros from regular stamps for display.\n",
    "    Examples: \"021\" → \"21\", \"O21\" → \"O21\" (keep letter prefixes)\n",
    "    \"\"\"\n",
    "    catalog_no = str(catalog_no).strip()\n",
    "    prefix_match = re.match(r'^([A-Za-z]+)', catalog_no)\n",
    "    if prefix_match:\n",
    "        return catalog_no\n",
    "    return catalog_no.lstrip('0') or '0'\n",
    "\n",
    "def fix_scott_surcharge_data(scott_stamp: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fix Scott stamps where surcharge info is split between denomination and color.\n",
    "    Example: {denomination: \"1c\", color: \"on ½r ('82)\"} → {denomination: \"1c on ½r\", color: \"unknown\"}\n",
    "    \"\"\"\n",
    "    denom = str(scott_stamp.get('denomination', '')).strip()\n",
    "    color = str(scott_stamp.get('color', '')).strip()\n",
    "    \n",
    "    if color.lower().startswith('on '):\n",
    "        surcharge_part = re.sub(r'\\s*\\([\\'\"]?\\d{2}\\).*$', '', color)\n",
    "        full_denomination = f\"{denom} {surcharge_part}\"\n",
    "        fixed_color = \"surcharge color unknown\"\n",
    "        \n",
    "        return {\n",
    "            **scott_stamp,\n",
    "            'denomination': full_denomination,\n",
    "            'color': fixed_color,\n",
    "            'original_color_field': color\n",
    "        }\n",
    "    \n",
    "    return scott_stamp\n",
    "\n",
    "def enrich_variety_stamps(scott_stamps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Enrich variety stamps by inheriting data from base stamps in the same issue\"\"\"\n",
    "    base_stamps = {}\n",
    "    for stamp in scott_stamps:\n",
    "        if 'variety_of' not in stamp or not stamp.get('variety_of'):\n",
    "            scott_no = stamp.get('scott_number', '')\n",
    "            year = stamp.get('year')\n",
    "            header = stamp.get('header', '')\n",
    "            key = (scott_no, year, header)\n",
    "            base_stamps[key] = stamp\n",
    "    \n",
    "    enriched = []\n",
    "    for stamp in scott_stamps:\n",
    "        stamp_copy = stamp.copy()\n",
    "        \n",
    "        if 'variety_of' in stamp and stamp['variety_of']:\n",
    "            base_no = stamp['variety_of']\n",
    "            year = stamp.get('year')\n",
    "            header = stamp.get('header', '')\n",
    "            key = (base_no, year, header)\n",
    "            base_stamp = base_stamps.get(key)\n",
    "            \n",
    "            if base_stamp:\n",
    "                if not stamp.get('denomination') and base_stamp.get('denomination'):\n",
    "                    stamp_copy['denomination'] = base_stamp['denomination']\n",
    "                \n",
    "                if not stamp.get('color'):\n",
    "                    desc = stamp.get('description', '').lower()\n",
    "                    color_keywords = [\n",
    "                        'light blue', 'dark blue', 'pale blue', 'blue',\n",
    "                        'light green', 'dark green', 'green',\n",
    "                        'light brown', 'dark brown', 'brown',\n",
    "                        'light violet', 'dark violet', 'violet',\n",
    "                        'blue violet', 'gray violet', 'pale gray violet',\n",
    "                        'scarlet', 'red', 'carmine', 'rose',\n",
    "                        'yellow', 'orange', 'black', 'purple', 'gray', 'grey'\n",
    "                    ]\n",
    "                    for color in color_keywords:\n",
    "                        if color in desc:\n",
    "                            stamp_copy['color'] = color\n",
    "                            break\n",
    "                \n",
    "                if not stamp_copy.get('color') and base_stamp.get('color'):\n",
    "                    stamp_copy['color'] = base_stamp['color']\n",
    "                \n",
    "                if not stamp_copy.get('perforation') and base_stamp.get('perforation'):\n",
    "                    stamp_copy['perforation'] = base_stamp['perforation']\n",
    "        \n",
    "        enriched.append(stamp_copy)\n",
    "    \n",
    "    return enriched\n",
    "\n",
    "def flatten_and_enrich_scott_data(scott_grouped_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Flatten Scott data from grouped structure and enrich variety stamps\"\"\"\n",
    "    flat_stamps = []\n",
    "    \n",
    "    for group in scott_grouped_data:\n",
    "        header = group.get('header', '')\n",
    "        stamps = group.get('stamps', [])\n",
    "        \n",
    "        for stamp in stamps:\n",
    "            stamp_copy = stamp.copy()\n",
    "            stamp_copy['header'] = header\n",
    "            \n",
    "            # Normalize scott_number\n",
    "            scott_no = stamp_copy.get('scott_number', '')\n",
    "            stamp_copy['scott_number'] = strip_leading_zeros(scott_no)\n",
    "            \n",
    "            # Extract year from header\n",
    "            if header:\n",
    "                match = re.search(r'(\\d{4})', str(header))\n",
    "                if match:\n",
    "                    stamp_copy['year'] = int(match.group(1))\n",
    "            \n",
    "            # Fix surcharge denominations\n",
    "            stamp_copy = fix_scott_surcharge_data(stamp_copy)\n",
    "            \n",
    "            flat_stamps.append(stamp_copy)\n",
    "    \n",
    "    return enrich_variety_stamps(flat_stamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Category Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_catalog_number(catalog_no: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Normalize catalog number to (category, number, suffix) for sorting.\n",
    "    Examples: \"17\" → (\"\", 17.0, \"\"), \"O31\" → (\"O\", 31.0, \"\"), \"C164\" → (\"C\", 164.0, \"\")\n",
    "    \"\"\"\n",
    "    catalog_no = str(catalog_no).strip()\n",
    "    \n",
    "    # Extract category prefix (letters only)\n",
    "    category_match = re.match(r'^([A-Za-z]+)', catalog_no)\n",
    "    if category_match:\n",
    "        category = category_match.group(1).upper()\n",
    "        remaining = catalog_no[len(category):]\n",
    "    else:\n",
    "        category = \"\"\n",
    "        remaining = catalog_no\n",
    "    \n",
    "    # Strip leading zeros\n",
    "    remaining = remaining.lstrip('0') or '0'\n",
    "    \n",
    "    # Extract numeric part\n",
    "    number_match = re.match(r'^(\\d+)', remaining)\n",
    "    if number_match:\n",
    "        base_num = float(number_match.group(1))\n",
    "        remaining = remaining[len(number_match.group(1)):]\n",
    "        \n",
    "        # Extract suffix\n",
    "        suffix_match = re.match(r'^([a-z]+)', remaining, re.IGNORECASE)\n",
    "        if suffix_match:\n",
    "            suffix = suffix_match.group(1).lower()\n",
    "            for i, char in enumerate(suffix):\n",
    "                base_num += (ord(char) - ord('a') + 1) * (0.1 ** (i + 1))\n",
    "        else:\n",
    "            suffix = \"\"\n",
    "    else:\n",
    "        base_num = 999999.0\n",
    "        suffix = \"\"\n",
    "    \n",
    "    return (category, base_num, suffix)\n",
    "\n",
    "def get_stamp_category(stamp: Dict[str, Any], is_mena: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Get the category of a stamp.\n",
    "    For Mena: Use section field. For Scott: Use catalog number prefix.\n",
    "    \"\"\"\n",
    "    if is_mena:\n",
    "        section = stamp.get('issue_data', {}).get('section', '') if 'issue_data' in stamp else ''\n",
    "        section = section.lower().strip()\n",
    "        \n",
    "        section_to_category = {\n",
    "            'surface mail': '',\n",
    "            'airmail': 'C',\n",
    "            'air mail': 'C',\n",
    "            'official': 'O',\n",
    "            'telegraph': 'T',\n",
    "            'telegraphs': 'T',\n",
    "            'postage due': 'J',\n",
    "            'dues': 'J',\n",
    "            'special delivery': 'E',\n",
    "            'registration': 'F',\n",
    "            'guanacaste': 'G',\n",
    "        }\n",
    "        \n",
    "        for key, cat in section_to_category.items():\n",
    "            if key in section:\n",
    "                return cat\n",
    "        \n",
    "        return normalize_catalog_number(stamp.get('catalog_no', ''))[0]\n",
    "    \n",
    "    else:\n",
    "        return normalize_catalog_number(stamp.get('scott_number', ''))[0]\n",
    "\n",
    "def make_scott_unique_key(scott_stamp: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Create unique identifier for Scott stamps: \"number__year\"\n",
    "    Handles duplicate numbers across different years.\n",
    "    \"\"\"\n",
    "    scott_no = scott_stamp.get('scott_number', 'UNKNOWN')\n",
    "    year = extract_scott_year(scott_stamp) or 9999\n",
    "    return f\"{scott_no}__{year}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scoring and Matching Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_score(mena_stamp: Dict[str, Any], \n",
    "                         scott_stamp: Dict[str, Any], \n",
    "                         mena_issue_context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Calculate match score using multiple signals (100-point system)\"\"\"\n",
    "    signals = {}\n",
    "    total_score = 0.0\n",
    "    breakdown_parts = []\n",
    "    \n",
    "    # ========== CATEGORY MATCH (10 points, -50 if wrong) ==========\n",
    "    mena_category = get_stamp_category(\n",
    "        {'issue_data': mena_issue_context, 'catalog_no': mena_stamp.get('catalog_no', '')}, \n",
    "        is_mena=True\n",
    "    )\n",
    "    scott_category = get_stamp_category(scott_stamp, is_mena=False)\n",
    "    \n",
    "    category_compatible = False\n",
    "    if mena_category == scott_category:\n",
    "        category_compatible = True\n",
    "    else:\n",
    "        equivalences = [\n",
    "            ({'', 'C'}, {'', 'C'}),\n",
    "            ({'O'}, {'O', 'CO'}),\n",
    "            ({'E'}, {'E', 'CE'}),\n",
    "            ({'J'}, {'J'}),\n",
    "            ({'G'}, {'G'}),\n",
    "        ]\n",
    "        for mena_set, scott_set in equivalences:\n",
    "            if mena_category in mena_set and scott_category in scott_set:\n",
    "                category_compatible = True\n",
    "                break\n",
    "    \n",
    "    if not category_compatible:\n",
    "        signals['category'] = -50\n",
    "        total_score -= 50\n",
    "        breakdown_parts.append(f\"Cat: ✗\")\n",
    "    else:\n",
    "        signals['category'] = 10\n",
    "        total_score += 10\n",
    "        breakdown_parts.append(\"Cat: ✓\")\n",
    "    \n",
    "    # ========== DENOMINATION (35 points) ==========\n",
    "    mena_denom = normalize_denomination(\n",
    "        mena_stamp['denomination']['value'], \n",
    "        mena_stamp['denomination']['unit']\n",
    "    )\n",
    "    scott_denom = parse_denomination_string(scott_stamp.get('denomination', ''))\n",
    "    \n",
    "    # Check surcharge status\n",
    "    mena_has_surcharge = (mena_stamp.get('overprint', {}).get('present') and \n",
    "                          mena_stamp.get('overprint', {}).get('type') == 'surcharge')\n",
    "    scott_has_surcharge = 'surcharge' in scott_denom\n",
    "    \n",
    "    # Surcharge mismatch penalty\n",
    "    if mena_has_surcharge != scott_has_surcharge:\n",
    "        signals['surcharge_mismatch'] = -10\n",
    "        total_score -= 10\n",
    "        breakdown_parts.append(\"Surcharge: ✗\")\n",
    "    \n",
    "    # Denomination matching\n",
    "    if mena_has_surcharge and scott_has_surcharge:\n",
    "        new_match = (mena_denom['value'] == scott_denom['value'] and \n",
    "                     mena_denom['unit'] == scott_denom['unit'])\n",
    "        mena_orig = normalize_denomination(\n",
    "            mena_stamp['overprint']['on_denomination']['value'],\n",
    "            mena_stamp['overprint']['on_denomination']['unit']\n",
    "        )\n",
    "        scott_orig = scott_denom['surcharge']\n",
    "        orig_match = (mena_orig['value'] == scott_orig['on_value'] and \n",
    "                      mena_orig['unit'] == scott_orig['on_unit'])\n",
    "        \n",
    "        if new_match and orig_match:\n",
    "            signals['denomination'] = 35\n",
    "            total_score += 35\n",
    "            breakdown_parts.append(\"Denom: ✓\")\n",
    "        elif new_match:\n",
    "            signals['denomination'] = 20\n",
    "            total_score += 20\n",
    "            breakdown_parts.append(\"Denom: ⚠️\")\n",
    "        else:\n",
    "            signals['denomination'] = 0\n",
    "            breakdown_parts.append(\"Denom: ✗\")\n",
    "    elif (mena_denom['value'] == scott_denom['value'] and \n",
    "          mena_denom['unit'] == scott_denom['unit']):\n",
    "        signals['denomination'] = 35\n",
    "        total_score += 35\n",
    "        breakdown_parts.append(\"Denom: ✓\")\n",
    "    else:\n",
    "        signals['denomination'] = 0\n",
    "        breakdown_parts.append(\"Denom: ✗\")\n",
    "    \n",
    "    # ========== COLOR (30 points) ==========\n",
    "    if mena_stamp.get('color') and scott_stamp.get('color'):\n",
    "        mena_color_raw = mena_stamp['color']\n",
    "        scott_color_raw = scott_stamp['color']\n",
    "        scott_color = clean_scott_color(scott_color_raw)\n",
    "        \n",
    "        # Handle compound/variant colors\n",
    "        mena_colors = []\n",
    "        if '/' in mena_color_raw:\n",
    "            mena_colors = [c.strip() for c in mena_color_raw.split('/')]\n",
    "        elif ' & ' in mena_color_raw:\n",
    "            mena_colors = [c.strip() for c in mena_color_raw.split('&')]\n",
    "        else:\n",
    "            mena_colors = [mena_color_raw]\n",
    "        \n",
    "        # Take best match\n",
    "        best_similarity = 0.0\n",
    "        for mena_color in mena_colors:\n",
    "            similarity = calculate_color_family_similarity(mena_color, scott_color)\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "        \n",
    "        color_score = best_similarity * 30\n",
    "        signals['color'] = color_score\n",
    "        total_score += color_score\n",
    "        breakdown_parts.append(f\"Color: {int(best_similarity*100)}%\")\n",
    "    else:\n",
    "        signals['color'] = 0\n",
    "    \n",
    "    # ========== YEAR (25 points) ==========\n",
    "    mena_year = extract_primary_year(mena_issue_context['issue_dates'])\n",
    "    scott_year = extract_scott_year(scott_stamp)\n",
    "    if mena_year and scott_year:\n",
    "        year_diff = abs(mena_year - scott_year)\n",
    "        if year_diff == 0:\n",
    "            signals['year'] = 25\n",
    "            total_score += 25\n",
    "            breakdown_parts.append(\"Year: ✓\")\n",
    "        elif year_diff == 1:\n",
    "            signals['year'] = 15\n",
    "            total_score += 15\n",
    "            breakdown_parts.append(\"Year: ~1\")\n",
    "        elif year_diff == 2:\n",
    "            signals['year'] = 10\n",
    "            total_score += 10\n",
    "            breakdown_parts.append(\"Year: ~2\")\n",
    "    \n",
    "    # ========== PERFORATION (10 points) ==========\n",
    "    mena_perf = str(mena_stamp.get('perforation', '')).strip()\n",
    "    scott_perf = str(scott_stamp.get('perforation', '')).strip()\n",
    "    \n",
    "    if mena_perf and scott_perf:\n",
    "        mena_perf_num = re.findall(r'[\\d.]+', mena_perf)\n",
    "        scott_perf_num = re.findall(r'[\\d.]+', scott_perf)\n",
    "        \n",
    "        if mena_perf_num and scott_perf_num:\n",
    "            if any(m == s for m in mena_perf_num for s in scott_perf_num):\n",
    "                signals['perforation'] = 10\n",
    "                total_score += 10\n",
    "            else:\n",
    "                signals['perforation'] = -5\n",
    "                total_score -= 5\n",
    "                breakdown_parts.append(f\"Perf: ✗\")\n",
    "    \n",
    "    return {\n",
    "        'total_score': total_score, \n",
    "        'signals': signals, \n",
    "        'breakdown': \" | \".join(breakdown_parts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Candidate Pool and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidate_pool(mena_issue: Dict[str, Any], \n",
    "                         all_scott_stamps: List[Dict[str, Any]], \n",
    "                         year_tolerance: int = 2) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Build a pool of Scott stamp candidates based on year\"\"\"\n",
    "    primary_year = extract_primary_year(mena_issue['issue_data']['issue_dates'])\n",
    "    if not primary_year:\n",
    "        return all_scott_stamps\n",
    "    \n",
    "    candidates = []\n",
    "    no_year_count = 0\n",
    "    \n",
    "    for scott_stamp in all_scott_stamps:\n",
    "        scott_year = extract_scott_year(scott_stamp)\n",
    "        if scott_year is not None:\n",
    "            if abs(scott_year - primary_year) <= year_tolerance:\n",
    "                candidates.append(scott_stamp)\n",
    "        else:\n",
    "            no_year_count += 1\n",
    "    \n",
    "    print(f\"Found {len(candidates)} Scott candidates for year {primary_year} (±{year_tolerance} years)\")\n",
    "    print(f\"Excluded {no_year_count} stamps without year information\")\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def score_all_candidates(mena_issue: Dict[str, Any], \n",
    "                        scott_candidate_pool: List[Dict[str, Any]], \n",
    "                        min_threshold: float = 30.0) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Score all Mena stamps against all Scott candidates\"\"\"\n",
    "    scoring_matrix = []\n",
    "    \n",
    "    for mena_stamp in mena_issue['stamps']:\n",
    "        mena_row = {\n",
    "            'mena_catalog_no': mena_stamp['catalog_no'], \n",
    "            'candidates': []\n",
    "        }\n",
    "        \n",
    "        for scott_candidate in scott_candidate_pool:\n",
    "            score_result = calculate_match_score(\n",
    "                mena_stamp, scott_candidate, mena_issue['issue_data']\n",
    "            )\n",
    "            \n",
    "            if score_result['total_score'] >= min_threshold:\n",
    "                unique_key = make_scott_unique_key(scott_candidate)\n",
    "                \n",
    "                mena_row['candidates'].append({\n",
    "                    'scott_number': scott_candidate.get('scott_number', 'UNKNOWN'),\n",
    "                    'scott_unique_key': unique_key,\n",
    "                    'scott_year': extract_scott_year(scott_candidate),\n",
    "                    'score': score_result['total_score'],\n",
    "                    'signals': score_result['signals'],\n",
    "                    'breakdown': score_result['breakdown']\n",
    "                })\n",
    "        \n",
    "        if mena_row['candidates']:\n",
    "            scoring_matrix.append(mena_row)\n",
    "    \n",
    "    return scoring_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optimal Assignment (Hungarian Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_assignment(scoring_matrix: List[Dict[str, Any]]) -> List[MatchResult]:\n",
    "    \"\"\"Find optimal one-to-one assignment using Hungarian algorithm\"\"\"\n",
    "    mena_stamps = [row['mena_catalog_no'] for row in scoring_matrix]\n",
    "    \n",
    "    # Collect unique Scott keys\n",
    "    all_scott_keys = set()\n",
    "    for row in scoring_matrix:\n",
    "        for cand in row['candidates']:\n",
    "            all_scott_keys.add(cand['scott_unique_key'])\n",
    "    \n",
    "    scott_stamps = sorted(all_scott_keys)\n",
    "    \n",
    "    # Build cost matrix\n",
    "    n_mena = len(mena_stamps)\n",
    "    n_scott = len(scott_stamps)\n",
    "    max_dim = max(n_mena, n_scott)\n",
    "    \n",
    "    cost_matrix = np.full((max_dim, max_dim), 1000.0)\n",
    "    scott_to_idx = {scott_key: i for i, scott_key in enumerate(scott_stamps)}\n",
    "    \n",
    "    for i, row in enumerate(scoring_matrix):\n",
    "        for cand in row['candidates']:\n",
    "            scott_key = cand['scott_unique_key']\n",
    "            if scott_key in scott_to_idx:\n",
    "                j = scott_to_idx[scott_key]\n",
    "                cost_matrix[i, j] = -cand['score']\n",
    "    \n",
    "    # Find optimal assignment\n",
    "    mena_indices, scott_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Build results\n",
    "    assignments = []\n",
    "    details_map = {}\n",
    "    \n",
    "    for row in scoring_matrix:\n",
    "        for cand in row['candidates']:\n",
    "            key = (row['mena_catalog_no'], cand['scott_unique_key'])\n",
    "            details_map[key] = cand\n",
    "    \n",
    "    for mena_idx, scott_idx in zip(mena_indices, scott_indices):\n",
    "        if mena_idx >= n_mena or scott_idx >= n_scott:\n",
    "            continue\n",
    "        \n",
    "        mena_no = mena_stamps[mena_idx]\n",
    "        scott_key = scott_stamps[scott_idx]\n",
    "        key = (mena_no, scott_key)\n",
    "        \n",
    "        if key not in details_map:\n",
    "            continue\n",
    "        \n",
    "        cand = details_map[key]\n",
    "        score = cand['score']\n",
    "        \n",
    "        if score < 30:\n",
    "            continue\n",
    "        \n",
    "        confidence = \"HIGH\" if score >= 70 else \"MEDIUM\" if score >= 50 else \"LOW\"\n",
    "        requires_review = score < 70\n",
    "        \n",
    "        # Display with year\n",
    "        scott_display = f\"{cand['scott_number']} ({cand.get('scott_year', '?')})\"\n",
    "        \n",
    "        assignments.append(MatchResult(\n",
    "            mena_catalog_no=mena_no,\n",
    "            scott_number=scott_display,\n",
    "            confidence=confidence,\n",
    "            score=score,\n",
    "            signals=cand['signals'],\n",
    "            breakdown=cand['breakdown'],\n",
    "            boost_reasons=[],\n",
    "            requires_review=requires_review\n",
    "        ))\n",
    "    \n",
    "    assignments.sort(key=lambda x: normalize_catalog_number(x.mena_catalog_no)[1])\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Matching Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_mena_to_scott(mena_issue: Dict[str, Any], \n",
    "                       all_scott_stamps: List[Dict[str, Any]], \n",
    "                       year_tolerance: int = 2, \n",
    "                       min_score_threshold: float = 30.0) -> Dict[str, Any]:\n",
    "    \"\"\"Main function to match Mena issue to Scott catalog\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MENA TO SCOTT CATALOG MATCHING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build candidate pool\n",
    "    scott_candidates = build_candidate_pool(mena_issue, all_scott_stamps, year_tolerance)\n",
    "    \n",
    "    # Score all candidates\n",
    "    scoring_matrix = score_all_candidates(mena_issue, scott_candidates, min_score_threshold)\n",
    "    \n",
    "    # Find optimal assignment\n",
    "    assignments = find_optimal_assignment(scoring_matrix)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    statistics = {\n",
    "        'total_mena_stamps': len(mena_issue['stamps']),\n",
    "        'total_assignments': len(assignments),\n",
    "        'high_confidence': sum(1 for a in assignments if a.confidence == \"HIGH\"),\n",
    "        'medium_confidence': sum(1 for a in assignments if a.confidence == \"MEDIUM\"),\n",
    "        'low_confidence': sum(1 for a in assignments if a.confidence == \"LOW\"),\n",
    "        'success_rate': round(len(assignments) / len(mena_issue['stamps']) * 100, 1) \n",
    "                        if mena_issue['stamps'] else 0\n",
    "    }\n",
    "    \n",
    "    # Build result\n",
    "    result = {\n",
    "        'issue_match': {\n",
    "            'mena_issue_id': mena_issue['issue_data']['issue_id'],\n",
    "            'mena_title': mena_issue['issue_data']['title'],\n",
    "            'candidate_pool_size': len(scott_candidates)\n",
    "        },\n",
    "        'assignments': [\n",
    "            {\n",
    "                'mena_catalog_no': a.mena_catalog_no,\n",
    "                'scott_number': a.scott_number,\n",
    "                'confidence': a.confidence,\n",
    "                'score': round(a.score, 1),\n",
    "                'signals': {k: round(v, 1) for k, v in a.signals.items()},\n",
    "                'breakdown': a.breakdown,\n",
    "                'requires_review': a.requires_review\n",
    "            }\n",
    "            for a in assignments\n",
    "        ],\n",
    "        'statistics': statistics,\n",
    "        'scoring_matrix': scoring_matrix\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matching_results(result: Dict[str, Any]):\n",
    "    \"\"\"Print matching results in a formatted way\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MATCHING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not result['assignments']:\n",
    "        print(\"\\nNo matches found above the threshold.\")\n",
    "        return\n",
    "    \n",
    "    for assignment in result['assignments']:\n",
    "        confidence_icon = \"✓\" if assignment['confidence'] == \"HIGH\" else \"⚠\" if assignment['confidence'] == \"MEDIUM\" else \"!\"\n",
    "        print(f\"\\n{confidence_icon} Mena #{assignment['mena_catalog_no']} → Scott #{assignment['scott_number']}\")\n",
    "        print(f\"  Confidence: {assignment['confidence']} (Score: {assignment['score']}/100)\")\n",
    "        print(f\"  {assignment['breakdown']}\")\n",
    "    \n",
    "    stats = result['statistics']\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Total: {stats['total_mena_stamps']} | Matched: {stats['total_assignments']} ({stats['success_rate']}%)\")\n",
    "    print(f\"High: {stats['high_confidence']} | Medium: {stats['medium_confidence']} | Low: {stats['low_confidence']}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mena issue\n",
    "PATH = Path(\"results/parsed_catalogues/mena_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    mena_parsed_catalog = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Mena issue: Prospero Fernandez Issue\n",
      "Number of stamps: 5\n",
      "{'issue_data': {'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'section': 'Surface Mail', 'title': 'Prospero Fernandez Issue', 'country': 'Costa Rica', 'issue_dates': {'announced': None, 'placed_on_sale': '1883-01-13', 'probable_first_circulation': '1883-01-13', 'second_plate_sale': None, 'demonetized': '1889-10-31'}, 'legal_basis': [{'type': 'decree', 'id': 'Decree #17', 'date': '1883-01-13', 'ids': [], 'officials': []}], 'currency_context': {'original': 'c', 'decimal_adoption': '1864-01-01', 'revaluation_date': None, 'revaluation_map': {}}, 'printing': {'printer': 'ABNCo.', 'process': ['engraved'], 'format': {'panes': None}, 'plates': {}, 'notes': ''}, 'perforation': '12'}, 'production_orders': {'printings': [], 'remainders': {'date': None, 'note': '', 'quantities': []}}, 'stamps': [{'catalog_no': '12', 'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'denomination': {'value': 1, 'unit': 'c'}, 'color': 'yellow green / dark green', 'plate': None, 'perforation': '12', 'watermark': None, 'quantity_reported': None, 'status': 'regular', 'notes': '1c printed again Nov 1884 color states: yellow green (1882), dark green (1884)'}, {'catalog_no': '13', 'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'denomination': {'value': 2, 'unit': 'c'}, 'color': 'dark red / rose red', 'plate': None, 'perforation': '12', 'watermark': None, 'quantity_reported': None, 'status': 'regular', 'notes': 'color states: dark red (1882), rose red (1884)'}, {'catalog_no': '14', 'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'denomination': {'value': 5, 'unit': 'c'}, 'color': 'blue violet', 'plate': None, 'perforation': '12', 'watermark': None, 'quantity_reported': None, 'status': 'regular', 'notes': 'exists in different color shades'}, {'catalog_no': '15', 'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'denomination': {'value': 10, 'unit': 'c'}, 'color': 'yellow', 'plate': None, 'perforation': '12', 'watermark': None, 'quantity_reported': None, 'status': 'regular', 'notes': ''}, {'catalog_no': '16', 'issue_id': 'CR-1883-PROSPERO-FERNANDEZ', 'denomination': {'value': 40, 'unit': 'c'}, 'color': 'blue', 'plate': None, 'perforation': '12', 'watermark': None, 'quantity_reported': None, 'status': 'regular', 'notes': 'Unused copies of 40c usually lack gum (fiscally used?)'}], 'varieties': [], 'proofs': {'die_proofs': [{'code': 'DP12', 'denomination': '1c', 'color': 'green', 'die_no': 'C78', 'substrate': 'India paper or sunk on card', 'finish': ''}, {'code': 'DP13', 'denomination': '2c', 'color': 'carmine', 'die_no': 'C79', 'substrate': 'India paper or sunk on card', 'finish': ''}, {'code': 'DP14', 'denomination': '5c', 'color': 'blue violet', 'die_no': 'C77', 'substrate': 'India paper or sunk on card', 'finish': ''}, {'code': 'DP15', 'denomination': '10c', 'color': 'yellow', 'die_no': 'C83', 'substrate': 'India paper or sunk on card', 'finish': ''}, {'code': 'DP16', 'denomination': '40c', 'color': 'blue', 'die_no': 'C84', 'substrate': 'India paper or sunk on card', 'finish': ''}], 'plate_proofs': [{'code': 'PP12', 'note': '1c green, imperf on card or bond', 'items': [{'variant': 'PP12', 'denomination': '1c', 'color': 'green', 'plate': None, 'note': ''}]}, {'code': 'PP13', 'note': '2c carmine, imperf on card or bond', 'items': [{'variant': 'PP13', 'denomination': '2c', 'color': 'carmine', 'plate': None, 'note': ''}]}, {'code': 'PP14', 'note': '5c blue violet, imperf on card or bond', 'items': [{'variant': 'PP14', 'denomination': '5c', 'color': 'blue violet', 'plate': None, 'note': ''}]}, {'code': 'PP15', 'note': '10c yellow, imperf on card or bond', 'items': [{'variant': 'PP15', 'denomination': '10c', 'color': 'yellow', 'plate': None, 'note': ''}]}, {'code': 'PP16', 'note': '40c blue, imperf on card or bond', 'items': [{'variant': 'PP16', 'denomination': '40c', 'color': 'blue', 'plate': None, 'note': ''}]}], 'color_proofs': [], 'imperforate_proofs': []}, 'essays': [], 'specimens': [{'code': 'M12', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '1c', 'base_color': 'green', 'overprint_color': 'red', 'notes': ''}, {'code': 'M12a', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '1c', 'base_color': 'green', 'overprint_color': 'black', 'notes': ''}, {'code': 'M13', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '2c', 'base_color': 'carmine', 'overprint_color': 'black', 'notes': ''}, {'code': 'M14', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '5c', 'base_color': 'blue violet', 'overprint_color': 'red', 'notes': ''}, {'code': 'M15', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '10c', 'base_color': 'yellow', 'overprint_color': 'black', 'notes': ''}, {'code': 'M16', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '40c', 'base_color': 'blue', 'overprint_color': 'red', 'notes': ''}, {'code': 'M16a', 'applies_to': 'stamps', 'type': 'overprint', 'denomination': '40c', 'base_color': 'blue', 'overprint_color': '', 'notes': 'double overprint'}], 'postal_stationery': []}\n"
     ]
    }
   ],
   "source": [
    "mena_issue = mena_parsed_catalog[3]\n",
    "print(f\"Loaded Mena issue: {mena_issue['issue_data']['title']}\")\n",
    "print(f\"Number of stamps: {len(mena_issue['stamps'])}\")\n",
    "print(mena_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Scott catalog: 1083 issue groups\n"
     ]
    }
   ],
   "source": [
    "# Load Scott catalog (grouped structure)\n",
    "PATH = Path(\"results/parsed_catalogues/scott_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    scott_grouped = json.load(f)\n",
    "\n",
    "print(f\"Loaded Scott catalog: {len(scott_grouped)} issue groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed: 2462 total stamps\n",
      "\n",
      "Example enriched variety stamp (Scott #1a):\n",
      "  denomination: ½r\n",
      "  color: light blue\n",
      "  variety_of: 1\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL STEP: Flatten and enrich Scott data\n",
    "all_scott_stamps = flatten_and_enrich_scott_data(scott_grouped)\n",
    "\n",
    "print(f\"Preprocessed: {len(all_scott_stamps)} total stamps\")\n",
    "print(f\"\\nExample enriched variety stamp (Scott #1a):\")\n",
    "for stamp in all_scott_stamps[:10]:\n",
    "    if stamp.get('scott_number') == '1a' and stamp.get('year') == 1863:\n",
    "        print(f\"  denomination: {stamp.get('denomination')}\")\n",
    "        print(f\"  color: {stamp.get('color')}\")\n",
    "        print(f\"  variety_of: {stamp.get('variety_of')}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MENA TO SCOTT CATALOG MATCHING\n",
      "================================================================================\n",
      "Found 41 Scott candidates for year 1883 (±2 years)\n",
      "Excluded 355 stamps without year information\n",
      "\n",
      "================================================================================\n",
      "MATCHING RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Mena #12 → Scott #1 (1883)\n",
      "  Confidence: HIGH (Score: 85.5/100)\n",
      "  Cat: ✓ | Surcharge: ✗ | Denom: ✓ | Color: 85% | Year: ✓\n",
      "\n",
      "✓ Mena #13 → Scott #3 (1883)\n",
      "  Confidence: HIGH (Score: 85.5/100)\n",
      "  Cat: ✓ | Surcharge: ✗ | Denom: ✓ | Color: 85% | Year: ✓\n",
      "\n",
      "✓ Mena #14 → Scott #5 (1883)\n",
      "  Confidence: HIGH (Score: 85.5/100)\n",
      "  Cat: ✓ | Surcharge: ✗ | Denom: ✓ | Color: 85% | Year: ✓\n",
      "\n",
      "✓ Mena #15 → Scott #6 (1883)\n",
      "  Confidence: HIGH (Score: 85.5/100)\n",
      "  Cat: ✓ | Surcharge: ✗ | Denom: ✓ | Color: 85% | Year: ✓\n",
      "\n",
      "✓ Mena #16 → Scott #7 (1883)\n",
      "  Confidence: HIGH (Score: 90.0/100)\n",
      "  Cat: ✓ | Surcharge: ✗ | Denom: ✓ | Color: 100% | Year: ✓\n",
      "\n",
      "================================================================================\n",
      "Total: 5 | Matched: 5 (100.0%)\n",
      "High: 5 | Medium: 0 | Low: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the matching algorithm\n",
    "result = match_mena_to_scott(\n",
    "    mena_issue=mena_issue,\n",
    "    all_scott_stamps=all_scott_stamps,\n",
    "    year_tolerance=2,\n",
    "    min_score_threshold=60.0\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print_matching_results(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
