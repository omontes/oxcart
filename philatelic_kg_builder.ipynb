{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1454574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Costa Rica Philatelic Knowledge Graph Extractor - EXPERT VERSION\n",
    "Handles all Costa Rican denomination systems and catalog syntax\n",
    "By: Philately & Regex Expert\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd59eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install networkx matplotlib pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class PhilatelicNode:\n",
    "    \"\"\"Represents a philatelic entity node\"\"\"\n",
    "    catalog_number: str\n",
    "    node_type: str  # stamp, proof, specimen, essay, variety, error\n",
    "    sub_type: Optional[str] = None  # die_proof, plate_proof, color_variety, etc.\n",
    "    denomination: Optional[str] = None\n",
    "    color: Optional[str] = None\n",
    "    year: Optional[str] = None\n",
    "    issue_name: Optional[str] = None  # From most recent <sec> element\n",
    "    quantity: Optional[str] = None\n",
    "    page_number: int = 0\n",
    "    reading_order: int = 0\n",
    "    raw_text: str = \"\"\n",
    "    context_before: List[str] = field(default_factory=list)\n",
    "    context_after: List[str] = field(default_factory=list)\n",
    "    attributes: List[str] = field(default_factory=list)\n",
    "    reference_numbers: List[str] = field(default_factory=list)\n",
    "    base_stamp: Optional[str] = None  # For proofs/varieties: which stamp they belong to\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {k: v for k, v in asdict(self).items() if v not in [None, [], \"\"]}\n",
    "\n",
    "class CostaRicaCatalogParser:\n",
    "    \"\"\"Expert parser for Costa Rica philatelic catalog with full denomination support\"\"\"\n",
    "    \n",
    "    # COMPREHENSIVE DENOMINATION REGEX\n",
    "    # Handles: centavos(c), Colones(C/col), pesos(p), reales(r), fractions(½, 1/2)\n",
    "    # Full words: centimos, centavos, colones, pesos, reales\n",
    "    DENOMINATION = re.compile(\n",
    "        r'\\b('  # Captura grupo 1: el valor\n",
    "            r'\\d+(?:[/.]?\\d+)?'  # Números normales: 15, 1.5, 1/2\n",
    "            r'|½|¼|¾'            # O símbolos de fracción standalone\n",
    "        r')\\s*'\n",
    "        r'('  # Captura grupo 2: la unidad\n",
    "            r'c|C|col|colón|colones|p|peso|pesos|r|real|reales|'\n",
    "            r'centimo|centimos|céntimo|céntimos|centavo|centavos|céntavo|céntavos'\n",
    "        r')\\b',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Surcharge pattern: \"1c on ½ real\", \"5c on 2 reales\", etc.\n",
    "    SURCHARGE = re.compile(\n",
    "        r'(\\d+)\\s*c\\s+on\\s+([½¼¾\\d/]+)\\s*(real|reales)',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # More precise: only match denomination after catalog number, not standalone\n",
    "    DENOMINATION_AFTER_CATALOG = re.compile(\n",
    "        r'(?:DP|PP|S|E|I|OP|^|\\s)(\\d+[a-z]?)\\s+'  # Catalog number\n",
    "        r'(\\d+(?:[/.]?\\d+|½|¼)?)\\s*'  # Denomination value\n",
    "        r'(c|C|col|colón|colones|p|peso|pesos|r|real|reales|'\n",
    "        r'centimo|centimos|céntimo|céntimos|centavo|centavos)\\b',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Color patterns - comprehensive\n",
    "    COLOR_MODIFIERS = r'(deep|light|dark|bright|pale|dull|bright)'\n",
    "    COLOR_NAMES = r'(black|violet|blue|red|green|orange|brown|yellow|gray|grey|' \\\n",
    "                  r'scarlet|ultramarine|carmine|olive|purple|pink|rose|magenta|' \\\n",
    "                  r'turquoise|indigo|vermillion|sepia|slate|cobalt|crimson)'\n",
    "    COLORS = re.compile(rf'\\b{COLOR_MODIFIERS}?\\s*{COLOR_NAMES}\\b', re.IGNORECASE)\n",
    "    \n",
    "    YEAR = re.compile(r'\\b(18\\d{2}|19\\d{2}|20\\d{2})\\b')\n",
    "    \n",
    "    # Quantity: numbers with commas, but NOT single/double digit numbers\n",
    "    # Must have comma OR be 4+ digits OR have \"printed\"/\"issued\" keyword\n",
    "    QUANTITY = re.compile(\n",
    "        r'\\b(\\d{1,3}(?:,\\d{3})+)\\b|'  # Try comma pattern FIRST\n",
    "        r'(?:printed|issued|quantity)[:\\s]+(\\d{1,3}(?:,\\d{3})+)\\b',  # ← Añadir soporte para comas aquí también\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    REFERENCE = re.compile(r'#([\\w-]+)')\n",
    "    \n",
    "    ATTRIBUTES = [\n",
    "        'imperf', 'imperforate', 'inverted', 'double perf', 'triple perf',\n",
    "        'tete beche', 'tete-beche', 'téte-béche', 'shifted', 'gutter pair', \n",
    "        'sunk on card', 'no numeral', 'omitted center', 'inverted center', \n",
    "        'double op', 'horizontal pair', 'vertical pair', 'right margin', \n",
    "        'left margin', 'lower margin', 'upper margin', 'inverted op',\n",
    "        'misplaced', 'offset', 'printed on both sides', 'blind perf',\n",
    "        'photographic proof'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_issue = None  # Most recent <sec> element\n",
    "        self.current_sec = None          \n",
    "        self.current_sub_sec = None      \n",
    "        self.current_sub_sub_sec = None  \n",
    "        self.current_section = None  # Proof, Regular issue, etc.\n",
    "        self.current_year = None\n",
    "        self.stamps_seen = set()\n",
    "    \n",
    "    def clean_latex(self, text: str) -> str:\n",
    "        \"\"\"Remove LaTeX formatting and extract content\"\"\"\n",
    "        if '\\\\begin{array}' in text:\n",
    "            match = re.search(r'\\\\begin\\{array\\}[^{]*\\{(.*?)\\\\end\\{array\\}', text, re.DOTALL)\n",
    "            if match:\n",
    "                content = match.group(1)\n",
    "                rows = content.split('\\\\\\\\')\n",
    "                cleaned_rows = []\n",
    "                for row in rows:\n",
    "                    row = re.sub(r'\\\\text\\s*\\{\\s*([^}]*)\\s*\\}', r'\\1', row)\n",
    "                    row = re.sub(r'\\\\mathrm\\s*\\{\\s*([^}]*)\\s*\\}', r'\\1', row)\n",
    "                    row = re.sub(r'&', ' ', row)\n",
    "                    row = re.sub(r'\\\\[a-zA-Z]+', '', row)\n",
    "                    row = re.sub(r'[{}$\\\\]', '', row)\n",
    "                    row = re.sub(r'\\s+', ' ', row).strip()\n",
    "                    if row:\n",
    "                        cleaned_rows.append(row)\n",
    "                return '\\n'.join(cleaned_rows)\n",
    "        \n",
    "        text = re.sub(r'\\$\\^?\\{(\\w+)\\}\\$', r'\\1', text)\n",
    "        text = re.sub(r'\\\\text\\s*\\{\\s*([^}]*)\\s*\\}', r'\\1', text)\n",
    "        text = re.sub(r'\\\\mathrm\\s*\\{\\s*([^}]*)\\s*\\}', r'\\1', text)\n",
    "        text = re.sub(r'\\\\[a-zA-Z]+\\{([^}]*)\\}', r'\\1', text)\n",
    "        text = re.sub(r'\\\\[a-zA-Z]+', '', text)\n",
    "        text = re.sub(r'[{}$]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def normalize_denomination(self, value: str, unit: str) -> str:\n",
    "        \"\"\"Normalize denomination to standard format\"\"\"\n",
    "        \n",
    "        # CRITICAL: Check for capital C BEFORE any conversion\n",
    "        if unit == 'C':  # Capital C = Colones\n",
    "            unit_normalized = 'col'\n",
    "        elif unit.lower() in ['c', 'centimo', 'centimos', 'céntimo', 'céntimos', \n",
    "                            'centavo', 'centavos', 'céntavo', 'céntavos']:\n",
    "            unit_normalized = 'c'\n",
    "        elif unit.lower() in ['col', 'colón', 'colones']:\n",
    "            unit_normalized = 'col'\n",
    "        elif unit.lower() in ['p', 'peso', 'pesos']:\n",
    "            unit_normalized = 'p'\n",
    "        elif unit.lower() in ['r', 'real', 'reales']:\n",
    "            unit_normalized = 'r'\n",
    "        else:\n",
    "            unit_normalized = unit.lower()\n",
    "        \n",
    "        # Handle fractions\n",
    "        if value == '½':\n",
    "            value_normalized = '0.5'\n",
    "        elif value == '¼':\n",
    "            value_normalized = '0.25'\n",
    "        elif value == '¾':\n",
    "            value_normalized = '0.75'\n",
    "        elif '/' in value:\n",
    "            try:\n",
    "                parts = value.split('/')\n",
    "                result = float(parts[0]) / float(parts[1])\n",
    "                value_normalized = str(result)  # str(float) automáticamente pone 0.25\n",
    "            except:\n",
    "                value_normalized = value\n",
    "        else:\n",
    "            value_normalized = value\n",
    "        \n",
    "        return f\"{value_normalized}{unit_normalized}\"\n",
    "    \n",
    "    def extract_base_stamp_number(self, catalog_num: str) -> Optional[str]:\n",
    "        \"\"\"Extract base stamp number from proof/specimen/variety\"\"\"\n",
    "        match = re.match(r'[A-Z]*(\\d+)[a-zA-Z]*$', catalog_num, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return None\n",
    "    \n",
    "    def extract_stamp_color(self, line: str, catalog_num: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract color of stamp, avoiding colors of overprints, frames, values.\n",
    "        Expert strategy: Get color between denomination and first delimiter.\n",
    "        \"\"\"\n",
    "        # Find text segment after catalog and denomination\n",
    "        # Pattern: [catalog] [denom] [COLOR SHOULD BE HERE] [, or 'op' or other delimiter]\n",
    "        \n",
    "        # Escape special regex chars in catalog_num\n",
    "        cat_escaped = re.escape(catalog_num)\n",
    "        \n",
    "        # Try to find: catalog_num + any_denomination + color_text\n",
    "        pattern = rf'{cat_escaped}\\s+\\d+(?:[/.]?\\d+)?\\s*(?:c|C|col|p|r|centimos?|centavos?|colones?|pesos?|reales?)\\s+([^,]+?)(?:,|\\bop\\b|\\bimperf|\\bperf|\\bframe\\b|\\bvalue\\b|$)'\n",
    "        match = re.search(pattern, line, re.IGNORECASE)\n",
    "        \n",
    "        if match:\n",
    "            color_section = match.group(1).strip()\n",
    "            \n",
    "            # Stop at certain keywords\n",
    "            stop_words = ['op', 'specimen', 'frame', 'value', 'imperf', 'perf', \n",
    "                         'inverted', 'double', 'triple', 'sunk', 'with', 'hole',\n",
    "                         'margin', 'pair', '#', 'quantity', 'printed']\n",
    "            \n",
    "            color_parts = []\n",
    "            for word in color_section.split():\n",
    "                if word.lower() in stop_words:\n",
    "                    break\n",
    "                color_parts.append(word)\n",
    "            \n",
    "            if color_parts:\n",
    "                color_text = ' '.join(color_parts).strip()\n",
    "                # Verify it contains actual color\n",
    "                if self.COLORS.search(color_text):\n",
    "                    return color_text\n",
    "        \n",
    "        # Fallback: Get first color before comma or 'op'\n",
    "        text_before_delim = re.split(r',|\\bop\\b', line, maxsplit=1)[0]\n",
    "        \n",
    "        # But after the denomination\n",
    "        denom_match = re.search(r'\\d+(?:[/.]?\\d+)?\\s*(?:c|C|col|p|r|centim|centav|colon|peso|real)', \n",
    "                               text_before_delim, re.IGNORECASE)\n",
    "        if denom_match:\n",
    "            text_after_denom = text_before_delim[denom_match.end():].strip()\n",
    "            colors_matches = self.COLORS.findall(text_after_denom)\n",
    "            if colors_matches:\n",
    "                if isinstance(colors_matches[0], tuple):\n",
    "                    color_parts = [p.strip() for p in colors_matches[0] if p.strip()]\n",
    "                    return ' '.join(color_parts) if color_parts else None\n",
    "                return colors_matches[0]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_attributes(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract philatelic attributes including overprint colors\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found = []\n",
    "        \n",
    "        for attr in self.ATTRIBUTES:\n",
    "            if attr in text_lower:\n",
    "                found.append(attr)\n",
    "        \n",
    "        # Special: overprint colors (store as attribute, not as stamp color)\n",
    "        if 'op' in text_lower or 'overprint' in text_lower:\n",
    "            # Pattern: \"blue op\" or \"op in red\" or \"red overprint\"\n",
    "            op_color_patterns = [\n",
    "                r'(black|blue|red|green|violet|brown|orange|yellow)\\s+op\\b',\n",
    "                r'\\bop\\b.*?\\bin\\s+(black|blue|red|green|violet|brown|orange|yellow)',\n",
    "                r'(black|blue|red|green|violet|brown|orange|yellow)\\s+overprint'\n",
    "            ]\n",
    "            \n",
    "            for pattern in op_color_patterns:\n",
    "                matches = re.finditer(pattern, text_lower)\n",
    "                for match in matches:\n",
    "                    color = match.group(1)\n",
    "                    attr_name = f'overprint_{color}'\n",
    "                    if attr_name not in found:\n",
    "                        found.append(attr_name)\n",
    "        \n",
    "        return found\n",
    "    \n",
    "    def parse_catalog_entry(self, line: str) -> List[Dict]:\n",
    "        \"\"\"Parse line and extract catalog entries with proper denomination handling\"\"\"\n",
    "        entries = []\n",
    "        \n",
    "        # OCR CORRECTION\n",
    "        line = re.sub(r'\\b(DP|PP|S)I(\\d)', r'\\g<1>1\\2', line)\n",
    "        line = re.sub(r'\\b(DP|PP|S)I([a-z])', r'\\g<1>1\\2', line)\n",
    "        line = re.sub(r'\\b(S|PP|DP)l([a-z])', r'\\g<1>1\\2', line)\n",
    "        \n",
    "        # FILTERS\n",
    "        if re.search(r'Decree[s]?\\s*#\\s*\\d+', line, re.IGNORECASE):\n",
    "            return entries\n",
    "        if re.search(r'\\(Ref\\s+[A-Z]+\\s+\\d+', line, re.IGNORECASE):\n",
    "            return entries\n",
    "        if re.search(r'Accord\\s+\\d+', line, re.IGNORECASE):\n",
    "            return entries\n",
    "        \n",
    "        # Filter OCR corruption (2011 repeated 3+ times)\n",
    "        match = re.search(r'\\b(\\d+[a-zA-Z]*)\\b', line)\n",
    "        if match:\n",
    "            first_cat = match.group(1)\n",
    "            count = len(re.findall(rf'\\b{re.escape(first_cat)}\\b', line))\n",
    "            if count >= 3:\n",
    "                return entries\n",
    "        \n",
    "        # NEW: Handle bare numbers separated by newlines (e.g., \"5\\n\\n\\n6\\n\\n\\n7\")\n",
    "        bare_numbers = re.findall(r'^(\\d+)$', line, re.MULTILINE)\n",
    "        if bare_numbers and len(bare_numbers) >= 2:\n",
    "            for num in bare_numbers:\n",
    "                if int(num) <= 500:  # Reasonable stamp number\n",
    "                    entries.append({\n",
    "                        'catalog_number': num,\n",
    "                        'node_type': 'stamp',\n",
    "                        'sub_type': 'regular_issue',\n",
    "                        'base_stamp': None\n",
    "                    })\n",
    "            return entries\n",
    "        \n",
    "        # NEW: Handle concatenated M entries (M12M12a1c green...)\n",
    "        # Pattern: M## followed immediately by M##a or more M entries\n",
    "        m_pattern = r'\\b(M\\d+[a-z]?)\\b'\n",
    "        m_matches = list(re.finditer(m_pattern, line, re.IGNORECASE))\n",
    "        if len(m_matches) >= 2:\n",
    "            for m_match in m_matches:\n",
    "                cat_num = m_match.group(1).upper()\n",
    "                base = self.extract_base_stamp_number(cat_num)\n",
    "                if cat_num not in [e['catalog_number'] for e in entries]:\n",
    "                    entries.append({\n",
    "                        'catalog_number': cat_num,\n",
    "                        'node_type': 'specimen',\n",
    "                        'sub_type': 'specimen',\n",
    "                        'base_stamp': base\n",
    "                    })\n",
    "            # If we found M entries, return early to avoid duplicate processing\n",
    "            if entries:\n",
    "                return entries\n",
    "        \n",
    "        # NEW: Handle varieties with space after number (LaTeX cleaned: \"7 a surcharge...\")\n",
    "        # This handles the pattern after clean_latex converts \"${ }^{7} \\\\mathrm{a}\" to \"7 a\"\n",
    "        variety_space_pattern = r'\\b(\\d+)\\s+([a-z])\\b'\n",
    "        for match in re.finditer(variety_space_pattern, line):\n",
    "            num = match.group(1)\n",
    "            letter = match.group(2)\n",
    "            cat_num = f\"{num}{letter}\"\n",
    "            # Skip if this looks like a dimension or other non-catalog pattern\n",
    "            if int(num) > 2000:\n",
    "                continue\n",
    "            if cat_num not in [e['catalog_number'] for e in entries]:\n",
    "                entries.append({\n",
    "                    'catalog_number': cat_num,\n",
    "                    'node_type': 'variety',\n",
    "                    'sub_type': 'variety',\n",
    "                    'base_stamp': num\n",
    "                })\n",
    "        \n",
    "        # Die Proof: DP###\n",
    "        for match in re.finditer(r'\\bDP(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"DP{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'proof',\n",
    "                'sub_type': 'die_proof',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Plate Proof: PP###\n",
    "        for match in re.finditer(r'\\bPP(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"PP{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'proof',\n",
    "                'sub_type': 'plate_proof',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Color Proof: CP###\n",
    "        for match in re.finditer(r'\\bCP(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"CP{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'proof',\n",
    "                'sub_type': 'color_proof',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Specimen: S### (but not in concatenated M pattern already handled)\n",
    "        for match in re.finditer(r'\\bS(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"S{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'specimen',\n",
    "                'sub_type': 'specimen',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Essay: E###\n",
    "        for match in re.finditer(r'\\bE([I\\d]+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"E{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'essay',\n",
    "                'sub_type': 'essay',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Imperforate: I###\n",
    "        for match in re.finditer(r'\\bI(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"I{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'variety',\n",
    "                'sub_type': 'imperforate',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Overprint Proof: OP###\n",
    "        for match in re.finditer(r'\\bOP(\\d+[a-zA-Z]*)\\b', line, re.IGNORECASE):\n",
    "            cat_num = f\"OP{match.group(1)}\"\n",
    "            base = self.extract_base_stamp_number(cat_num)\n",
    "            entries.append({\n",
    "                'catalog_number': cat_num,\n",
    "                'node_type': 'proof',\n",
    "                'sub_type': 'overprint_proof',\n",
    "                'base_stamp': base\n",
    "            })\n",
    "        \n",
    "        # Base stamp with denomination\n",
    "        for match in re.finditer(\n",
    "            r'(?:^|\\s)(\\d+[a-zA-Z]*)\\s+(\\d+(?:[/.]?\\d+|½|¼)?)\\s*'\n",
    "            r'(c|C|col|colón|colones|p|peso|pesos|r|real|reales|'\n",
    "            r'centim|céntim|centav|céntav)\\b',\n",
    "            line, re.IGNORECASE\n",
    "        ):\n",
    "            cat_num = match.group(1).strip()\n",
    "            denom_value = match.group(2)\n",
    "            \n",
    "            try:\n",
    "                if int(denom_value.split('.')[0].split('/')[0]) > 500:\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if any(e['catalog_number'] == cat_num for e in entries):\n",
    "                continue\n",
    "            \n",
    "            if re.match(r'\\d+[a-zA-Z]+$', cat_num, re.IGNORECASE):\n",
    "                base = self.extract_base_stamp_number(cat_num)\n",
    "                entries.append({\n",
    "                    'catalog_number': cat_num,\n",
    "                    'node_type': 'variety',\n",
    "                    'sub_type': 'variety',\n",
    "                    'base_stamp': base\n",
    "                })\n",
    "            else:\n",
    "                entries.append({\n",
    "                    'catalog_number': cat_num,\n",
    "                    'node_type': 'stamp',\n",
    "                    'sub_type': 'regular_issue',\n",
    "                    'base_stamp': None\n",
    "                })\n",
    "        \n",
    "        return entries\n",
    "    def extract_denominations(self, line: str) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Extract denominations with their normalized values.\"\"\"\n",
    "        denoms = []\n",
    "        \n",
    "        for match in self.DENOMINATION.finditer(line):\n",
    "            value = match.group(1)\n",
    "            unit = match.group(2)\n",
    "            \n",
    "            # ONLY skip if it's EXACTLY a 2-character catalog pattern at word boundary\n",
    "            # AND appears at the START of text (catalog numbers come first)\n",
    "            matched_text = match.group(0)\n",
    "            \n",
    "            # Pattern: \"1c\" or \"2a\" appearing isolated (not \"5c\" in middle of sentence)\n",
    "            if re.match(r'^[1-9][a-z]$', matched_text):\n",
    "                # Check if this appears at the very start or after whitespace only\n",
    "                match_pos = match.start()\n",
    "                prefix = line[:match_pos].strip()\n",
    "                \n",
    "                # If there's meaningful text before this match, it's likely a real denomination\n",
    "                if prefix and not re.match(r'^\\d+$', prefix):\n",
    "                    # Text before suggests this is mid-sentence denomination, keep it\n",
    "                    pass\n",
    "                elif not prefix or re.match(r'^\\d+$', prefix):\n",
    "                    # This is at start or after just a number - might be catalog number\n",
    "                    # Skip ONLY if followed by space and descriptive text (not another number)\n",
    "                    suffix = line[match.end():match.end()+20].strip()\n",
    "                    if suffix and re.match(r'^[a-zA-Z]', suffix):\n",
    "                        # Followed by letters = likely catalog number like \"1c double\"\n",
    "                        continue\n",
    "            \n",
    "            # Skip quantities\n",
    "            try:\n",
    "                num_val = float(value.replace('½', '.5').replace('¼', '.25').split('/')[0])\n",
    "                if num_val > 500:\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            denoms.append((value, unit))\n",
    "        \n",
    "        return denoms\n",
    "    \n",
    "    def parse_element(self, element: Dict, context_before: List[str], \n",
    "                 context_after: List[str], page_number: int) -> List[PhilatelicNode]:\n",
    "        \"\"\"Parse element and extract nodes - EXPERT VERSION\"\"\"\n",
    "        text = element.get('text', '')\n",
    "        label = element.get('label', '')\n",
    "        reading_order = element.get('reading_order', 0)\n",
    "        \n",
    "        if label in ['header', 'foot', 'fig']:\n",
    "            return []\n",
    "        \n",
    "        # CRITICAL: <sec>, <sub_sec>, <sub_sub_sec> define hierarchy\n",
    "        # Priority: sub_sub_sec > sub_sec > sec\n",
    "        if label == 'sec':\n",
    "            self.current_sec = text\n",
    "            if not hasattr(self, 'current_sub_sec') or not self.current_sub_sec:\n",
    "                self.current_issue = text\n",
    "            year_match = self.YEAR.search(text)\n",
    "            if year_match:\n",
    "                self.current_year = year_match.group(1)\n",
    "            return []\n",
    "\n",
    "        if label == 'sub_sec':\n",
    "            self.current_sub_sec = text\n",
    "            if not hasattr(self, 'current_sub_sub_sec') or not self.current_sub_sub_sec:\n",
    "                self.current_issue = text\n",
    "            return []\n",
    "\n",
    "        if label == 'sub_sub_sec':\n",
    "            self.current_sub_sub_sec = text\n",
    "            self.current_issue = text\n",
    "            return []\n",
    "        \n",
    "        # Section markers\n",
    "        text_lower = text.lower().strip()\n",
    "        if any(section in text_lower for section in ['proof', 'proofs', 'regular issue', 'essays', 'essay', 'plate proof', 'die proof', 'specimen', 'photographic proof']):\n",
    "            for section in ['proof', 'proofs', 'regular issue', 'essays', 'essay', 'plate proof', 'die proof', 'specimen', 'regular issues', 'photographic proof', 'photographic proofs']:\n",
    "                if section in text_lower:\n",
    "                    self.current_section = section\n",
    "                    break\n",
    "        \n",
    "        nodes = []\n",
    "        \n",
    "        # Handle tables\n",
    "        if label == 'tab':\n",
    "            nodes.extend(self._parse_table(text, page_number, reading_order, context_before))\n",
    "            return nodes\n",
    "        \n",
    "        # Check if paragraph contains catalog entries\n",
    "        # Special handling for bare catalog numbers separated by newlines\n",
    "        if label == 'para':\n",
    "            lines_temp = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "            bare_num_pattern = r'^\\d+$'\n",
    "            \n",
    "            # Check if ALL lines are just bare numbers\n",
    "            if len(lines_temp) >= 2 and all(re.match(bare_num_pattern, l) for l in lines_temp):\n",
    "                for num in lines_temp:\n",
    "                    if 1 <= int(num) <= 500:\n",
    "                        node = PhilatelicNode(\n",
    "                            catalog_number=num,\n",
    "                            node_type='stamp',\n",
    "                            sub_type='regular_issue',\n",
    "                            denomination=None,\n",
    "                            color=None,\n",
    "                            year=self.current_year,\n",
    "                            issue_name=self.current_issue,\n",
    "                            quantity=None,\n",
    "                            page_number=page_number,\n",
    "                            reading_order=reading_order,\n",
    "                            raw_text=text,\n",
    "                            context_before=context_before[-3:],\n",
    "                            context_after=context_after[:1],\n",
    "                            attributes=[],\n",
    "                            reference_numbers=[],\n",
    "                            base_stamp=None\n",
    "                        )\n",
    "                        nodes.append(node)\n",
    "                return nodes  # Only return for THIS paragraph\n",
    "    \n",
    "            # If not bare numbers, check for paragraph entries\n",
    "            if re.search(r'(?:^|\\n)\\s*[A-Z]*\\d+[a-z]*\\s+', text):\n",
    "                nodes.extend(self._parse_paragraph_entries(\n",
    "                    text, page_number, reading_order, context_before\n",
    "                ))\n",
    "                if nodes:\n",
    "                    return nodes\n",
    "        \n",
    "        # Clean and process remaining content\n",
    "        clean_text = self.clean_latex(text)\n",
    "        \n",
    "        # DEBUG: Print cleaned text for specific problematic elements\n",
    "        if page_number in [10, 11] and label == 'para' and reading_order in [17, 10, 11]:\n",
    "            print(f\"\\n=== DEBUG PAGE {page_number}, ORDER {reading_order} ===\")\n",
    "            print(f\"ORIGINAL: {text[:200]}\")\n",
    "            print(f\"CLEANED:  {clean_text[:200]}\")\n",
    "            print(f\"===\\n\")\n",
    "        \n",
    "        lines = [line.strip() for line in clean_text.split('\\n') if line.strip()]\n",
    "        \n",
    "        for line in lines:\n",
    "            entries = self.parse_catalog_entry(line)\n",
    "            \n",
    "            if not entries:\n",
    "                continue\n",
    "            \n",
    "            # Extract denominations\n",
    "            denoms_raw = self.extract_denominations(line)\n",
    "            denominations = [self.normalize_denomination(v, u) for v, u in denoms_raw]\n",
    "            \n",
    "            # Extract colors\n",
    "            colors = []\n",
    "            for entry in entries:\n",
    "                cat_num = entry['catalog_number']\n",
    "                color = self.extract_stamp_color(line, cat_num)\n",
    "                colors.append(color)\n",
    "            \n",
    "            # Fallback color extraction\n",
    "            if not any(colors):\n",
    "                colors_matches = self.COLORS.findall(line)\n",
    "                for color_match in colors_matches:\n",
    "                    if isinstance(color_match, tuple):\n",
    "                        color_parts = [p.strip() for p in color_match if p.strip()]\n",
    "                        if color_parts:\n",
    "                            colors.append(' '.join(color_parts))\n",
    "                    else:\n",
    "                        colors.append(color_match.strip())\n",
    "            \n",
    "            # Extract quantity\n",
    "            quantity = None\n",
    "            qty_match = self.QUANTITY.search(line)\n",
    "            if qty_match:\n",
    "                raw_quantity = qty_match.group(1) or qty_match.group(2)\n",
    "                quantity = raw_quantity.replace(',', '')\n",
    "            \n",
    "            references = self.REFERENCE.findall(line)\n",
    "            attributes = self.extract_attributes(line)\n",
    "            \n",
    "            # Create nodes\n",
    "            for i, entry in enumerate(entries):\n",
    "                cat_num = entry['catalog_number']\n",
    "                node_type = entry['node_type']\n",
    "                sub_type = entry['sub_type']\n",
    "                base_stamp = entry['base_stamp']\n",
    "                \n",
    "                if node_type == 'stamp' and cat_num in self.stamps_seen:\n",
    "                    continue\n",
    "                \n",
    "                node = PhilatelicNode(\n",
    "                    catalog_number=cat_num,\n",
    "                    node_type=node_type,\n",
    "                    sub_type=sub_type,\n",
    "                    denomination=denominations[0] if denominations else None,\n",
    "                    color=colors[i] if i < len(colors) else (colors[0] if colors else None),\n",
    "                    year=self.current_year,\n",
    "                    issue_name=self.current_issue,\n",
    "                    quantity=quantity if node_type == 'stamp' else None,\n",
    "                    page_number=page_number,\n",
    "                    reading_order=reading_order,\n",
    "                    raw_text=line,\n",
    "                    context_before=context_before[-3:],\n",
    "                    context_after=context_after[:1],\n",
    "                    attributes=attributes,\n",
    "                    reference_numbers=references,\n",
    "                    base_stamp=base_stamp\n",
    "                )\n",
    "                \n",
    "                if node_type == 'stamp' and self.current_section and 'regular issue' in self.current_section.lower():\n",
    "                    self.stamps_seen.add(cat_num)\n",
    "                \n",
    "                nodes.append(node)\n",
    "        \n",
    "        return nodes\n",
    "    def _parse_paragraph_entries(self, text: str, page_number: int, \n",
    "                             reading_order: int, context: List[str]) -> List[PhilatelicNode]:\n",
    "        \"\"\"Parse catalog entries from paragraph format (not tables)\"\"\"\n",
    "        nodes = []\n",
    "        \n",
    "        # Pattern: catalog number at start of line/sentence\n",
    "        # Examples: \"5    1c on ½r blue\", \"7a   surcharge on 1A\"\n",
    "        pattern = r'(?:^|\\n)\\s*([A-Z]*\\d+[a-z]*)\\s+(.*?)(?=\\n\\s*[A-Z]*\\d+[a-z]*\\s+|\\Z)'\n",
    "        \n",
    "        for match in re.finditer(pattern, text, re.MULTILINE | re.DOTALL):\n",
    "            cat_num = match.group(1).strip()\n",
    "            description = match.group(2).strip()\n",
    "            \n",
    "            # Determine node type\n",
    "            if cat_num.startswith(('DP', 'PP', 'CP')):\n",
    "                node_type = 'proof'\n",
    "                sub_type = {'DP': 'die_proof', 'PP': 'plate_proof', 'CP': 'color_proof'}[cat_num[:2]]\n",
    "                base_stamp = self.extract_base_stamp_number(cat_num)\n",
    "            elif cat_num.startswith(('S', 'M')):\n",
    "                node_type = 'specimen'\n",
    "                sub_type = 'specimen'\n",
    "                base_stamp = self.extract_base_stamp_number(cat_num)\n",
    "            elif re.match(r'^\\d+[a-z]$', cat_num):\n",
    "                node_type = 'variety'\n",
    "                sub_type = 'variety'\n",
    "                base_stamp = cat_num[:-1]\n",
    "            else:\n",
    "                node_type = 'stamp'\n",
    "                sub_type = 'regular_issue'\n",
    "                base_stamp = None\n",
    "            \n",
    "            # Extract denomination\n",
    "            denoms_raw = self.extract_denominations(description)\n",
    "            denomination = self.normalize_denomination(*denoms_raw[0]) if denoms_raw else None\n",
    "            \n",
    "            # Check for surcharge pattern: \"Xc on Yr\"\n",
    "            surcharge_match = re.search(r'(\\d+)\\s*c\\s+on\\s+([½¼\\d/]+)\\s*([rp])', description)\n",
    "            if surcharge_match:\n",
    "                new_val = surcharge_match.group(1)\n",
    "                old_val = surcharge_match.group(2)\n",
    "                old_unit = surcharge_match.group(3)\n",
    "                denomination = f\"{new_val}c on {old_val}{old_unit}\"\n",
    "            \n",
    "            # Extract color\n",
    "            color = self.extract_stamp_color(description, cat_num)\n",
    "            \n",
    "            # Extract attributes\n",
    "            attributes = self.extract_attributes(description)\n",
    "            \n",
    "            node = PhilatelicNode(\n",
    "                catalog_number=cat_num,\n",
    "                node_type=node_type,\n",
    "                sub_type=sub_type,\n",
    "                denomination=denomination,\n",
    "                color=color,\n",
    "                year=self.current_year,\n",
    "                issue_name=self.current_issue,\n",
    "                quantity=None,\n",
    "                page_number=page_number,\n",
    "                reading_order=reading_order,\n",
    "                raw_text=description,\n",
    "                context_before=context[-3:],\n",
    "                attributes=attributes,\n",
    "                base_stamp=base_stamp\n",
    "            )\n",
    "            nodes.append(node)\n",
    "        \n",
    "        return nodes\n",
    "    \n",
    "    def _parse_table(self, html_text: str, page_number: int, \n",
    "                reading_order: int, context: List[str]) -> List[PhilatelicNode]:\n",
    "        \"\"\"Parse table elements with expert denomination handling\"\"\"\n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        rows = []\n",
    "        \n",
    "        for tr in soup.find_all('tr'):\n",
    "            cells = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "            if cells and not all(c == '' for c in cells):\n",
    "                rows.append(cells)\n",
    "        \n",
    "        nodes = []\n",
    "        last_denomination = None\n",
    "        \n",
    "        for row in rows:\n",
    "            created_catalog_numbers = set(node.catalog_number for node in nodes)\n",
    "            \n",
    "            if not row or len(row) < 2:\n",
    "                continue\n",
    "            \n",
    "            print(f\"DEBUG: Processing table row with {len(row)} cells: {row}\")\n",
    "            \n",
    "            # Skip headers\n",
    "            header_keywords = ['perf', 'imperf', 'date', 'order', 'plate', 'essays']\n",
    "            if len(row) <= 5 and all(any(kw in cell.lower() for kw in header_keywords) for cell in row if cell):\n",
    "                print(f\"DEBUG: Skipping header row\")\n",
    "                continue\n",
    "            \n",
    "            first_cell = row[0].strip()\n",
    "            entries = []\n",
    "            \n",
    "            # Case 1: 2-cell variety rows\n",
    "            if len(row) == 2 and re.match(r'^\\d+[a-zA-Z]+$', first_cell):\n",
    "                base = self.extract_base_stamp_number(first_cell)\n",
    "                entries = [{\n",
    "                    'catalog_number': first_cell,\n",
    "                    'node_type': 'variety',\n",
    "                    'sub_type': 'variety',\n",
    "                    'base_stamp': base\n",
    "                }]\n",
    "                row_text = ' '.join(row)\n",
    "                print(f\"DEBUG: 2-cell variety row: {first_cell} -> base {base}\")\n",
    "                last_denomination = None\n",
    "            \n",
    "            # Case 2: 2-cell bare number rows\n",
    "            elif len(row) == 2 and re.match(r'^\\d+$', first_cell):\n",
    "                desc = row[1].lower()\n",
    "                variety_keywords = ['perf', 'diagonal', 'horizontal', 'cracked', 'impression', 'pair', 'inverted']\n",
    "                \n",
    "                # Special case: catalog #1 is likely a real stamp even with variety keywords\n",
    "                if first_cell == '1' and any(kw in desc for kw in variety_keywords):\n",
    "                    entries = [{\n",
    "                        'catalog_number': first_cell,\n",
    "                        'node_type': 'stamp',\n",
    "                        'sub_type': 'regular_issue',\n",
    "                        'base_stamp': None\n",
    "                    }]\n",
    "                    row_text = ' '.join(row)\n",
    "                    print(f\"DEBUG: Special case - stamp #1\")\n",
    "                    last_denomination = None\n",
    "                \n",
    "                elif any(kw in desc for kw in variety_keywords):\n",
    "                    print(f\"DEBUG: Row {first_cell} appears to be variety with missing letter, skipping\")\n",
    "                    continue\n",
    "                else:\n",
    "                    entries = [{\n",
    "                        'catalog_number': first_cell,\n",
    "                        'node_type': 'stamp',\n",
    "                        'sub_type': 'regular_issue',\n",
    "                        'base_stamp': None\n",
    "                    }]\n",
    "                    row_text = ' '.join(row)\n",
    "                    print(f\"DEBUG: 2-cell stamp row: {first_cell}\")\n",
    "                    last_denomination = None\n",
    "            \n",
    "            # Case 3: Multi-cell rows (3+)\n",
    "            elif len(row) >= 3 and re.match(r'^\\d+[a-zA-Z]*$', first_cell):\n",
    "                rest_of_row = ' '.join(row[1:])\n",
    "                row_text_full = ' '.join(row)\n",
    "                \n",
    "                print(f\"DEBUG: Found catalog number in first cell: {first_cell}\")\n",
    "                \n",
    "                # Subcase 3a: It's a variety\n",
    "                if re.match(r'^\\d+[a-zA-Z]+$', first_cell):\n",
    "                    base = self.extract_base_stamp_number(first_cell)\n",
    "                    entries = [{\n",
    "                        'catalog_number': first_cell,\n",
    "                        'node_type': 'variety',\n",
    "                        'sub_type': 'variety',\n",
    "                        'base_stamp': base\n",
    "                    }]\n",
    "                    print(f\"DEBUG: Identified as variety: {first_cell} -> base {base}\")\n",
    "                    \n",
    "                    # Check column 2 for additional varieties\n",
    "                    if len(row) >= 2:\n",
    "                        second_cell = row[1].strip()\n",
    "                        # Fixed version - only single letters or specific patterns:\n",
    "                        additional_varieties = []\n",
    "                        # Pattern 1: Single lowercase letter (a, b, c)\n",
    "                        for match in re.finditer(r'\\b([a-z])\\b', second_cell):\n",
    "                            additional_varieties.append(match.group(1))\n",
    "                        # Pattern 2: Uppercase + lowercase (like \"Aa\" from \"1Aa\")\n",
    "                        for match in re.finditer(r'([A-Z][a-z])', second_cell):\n",
    "                            additional_varieties.append(match.group(1))\n",
    "                        \n",
    "                        # Filter out if it's part of a color word\n",
    "                        color_words = ['dark', 'light', 'deep', 'pale', 'bright', 'red', 'green', 'blue', \n",
    "                                    'violet', 'yellow', 'orange', 'brown', 'black', 'white', 'gray', 'rose']\n",
    "                        additional_varieties = [v for v in additional_varieties \n",
    "                                            if not any(word.startswith(v.lower()) for word in color_words)]\n",
    "                        \n",
    "                        for var_code in additional_varieties:\n",
    "                            full_cat = f\"{base}{var_code}\"\n",
    "                            # Skip duplicates\n",
    "                            if full_cat not in [e['catalog_number'] for e in entries] and full_cat != first_cell and full_cat not in created_catalog_numbers:\n",
    "                                entries.append({\n",
    "                                    'catalog_number': full_cat,\n",
    "                                    'node_type': 'variety',\n",
    "                                    'sub_type': 'variety',\n",
    "                                    'base_stamp': base\n",
    "                                })\n",
    "                                print(f\"DEBUG: Additional variety: {full_cat}\")\n",
    "                \n",
    "                # Subcase 3b: It's a stamp\n",
    "                else:\n",
    "                    denoms_raw = self.extract_denominations(rest_of_row)\n",
    "                    \n",
    "                    if denoms_raw:\n",
    "                        # Found denomination in rest of row\n",
    "                        entries = [{\n",
    "                            'catalog_number': first_cell,\n",
    "                            'node_type': 'stamp',\n",
    "                            'sub_type': 'regular_issue',\n",
    "                            'base_stamp': None\n",
    "                        }]\n",
    "                        print(f\"DEBUG: Stamp with denomination in row: {first_cell}\")\n",
    "                    else:\n",
    "                        # No denomination found - use heuristics\n",
    "                        second_cell = row[1].strip() if len(row) > 1 else \"\"\n",
    "                        third_col_text = ' '.join(row[2:]) if len(row) >= 3 else \"\"\n",
    "                        \n",
    "                        # Heuristic 1: Column 2 is a variety code\n",
    "                        if re.match(r'^\\d+[a-z]$', second_cell):\n",
    "                            denoms_in_desc = self.extract_denominations(third_col_text)\n",
    "                            last_col = row[-1].strip() if row else \"\"\n",
    "                            \n",
    "                            if denoms_in_desc:\n",
    "                                entries = [{\n",
    "                                    'catalog_number': first_cell,\n",
    "                                    'node_type': 'stamp',\n",
    "                                    'sub_type': 'regular_issue',\n",
    "                                    'base_stamp': None\n",
    "                                }]\n",
    "                                rest_of_row = third_col_text\n",
    "                                print(f\"DEBUG: Stamp {first_cell} - denom in column 3\")\n",
    "                            elif re.match(r'^\\d{2,3},\\d{3}$', last_col):\n",
    "                                entries = [{\n",
    "                                    'catalog_number': first_cell,\n",
    "                                    'node_type': 'stamp',\n",
    "                                    'sub_type': 'regular_issue',\n",
    "                                    'base_stamp': None\n",
    "                                }]\n",
    "                                rest_of_row = third_col_text\n",
    "                                print(f\"DEBUG: Stamp {first_cell} inferred from quantity\")\n",
    "                                last_denomination = None\n",
    "                            else:\n",
    "                                print(f\"DEBUG: No denomination for {first_cell}, skipping\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Add variety from column 2\n",
    "                            base_of_variety = second_cell[:-1]\n",
    "                            entries.append({\n",
    "                                'catalog_number': second_cell,\n",
    "                                'node_type': 'variety',\n",
    "                                'sub_type': 'variety',\n",
    "                                'base_stamp': base_of_variety\n",
    "                            })\n",
    "                            print(f\"DEBUG: Added variety {second_cell}\")\n",
    "                        else:\n",
    "                            print(f\"DEBUG: No denomination for {first_cell}, skipping\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Check for variety in same row (after stamp created)\n",
    "                    if entries and entries[0]['node_type'] == 'stamp' and len(row) >= 2:\n",
    "                        second_cell = row[1].strip()\n",
    "                        if re.match(r'^\\d+[a-z]$', second_cell) and second_cell not in [e['catalog_number'] for e in entries]:\n",
    "                            base_of_variety = second_cell[:-1]\n",
    "                            entries.append({\n",
    "                                'catalog_number': second_cell,\n",
    "                                'node_type': 'variety',\n",
    "                                'sub_type': 'variety',\n",
    "                                'base_stamp': base_of_variety\n",
    "                            })\n",
    "                            print(f\"DEBUG: Variety {second_cell} in same row\")\n",
    "                \n",
    "                row_text = row_text_full\n",
    "            \n",
    "            # Case 4: Normal parsing\n",
    "            else:\n",
    "                row_text = ' '.join(row)\n",
    "                print(f\"DEBUG: Normal parsing\")\n",
    "                entries = self.parse_catalog_entry(row_text)\n",
    "            \n",
    "            print(f\"DEBUG: Found {len(entries)} entries: {[e['catalog_number'] for e in entries]}\")\n",
    "            \n",
    "            if entries:\n",
    "                surcharge_match = self.SURCHARGE.search(row_text)\n",
    "                surcharge_info = None\n",
    "                if surcharge_match:\n",
    "                    new_value = surcharge_match.group(1)\n",
    "                    old_value = surcharge_match.group(2)\n",
    "                    old_unit = surcharge_match.group(3)\n",
    "                    surcharge_info = f\"{new_value}c on {old_value} {old_unit}\"\n",
    "                \n",
    "                denoms_raw = self.extract_denominations(row_text)\n",
    "                denominations = [self.normalize_denomination(v, u) for v, u in denoms_raw]\n",
    "                print(f\"DEBUG: Denominations: {denominations}\")\n",
    "                \n",
    "                if not denominations and last_denomination:\n",
    "                    denominations = [last_denomination]\n",
    "                    print(f\"DEBUG: Using last denomination: {last_denomination}\")\n",
    "                elif denominations:\n",
    "                    last_denomination = denominations[0]\n",
    "                \n",
    "                if not denominations:\n",
    "                    special_match = re.search(\n",
    "                        r'([E]\\d+[a-zA-Z]*(?:\\s+[E]\\d+[a-zA-Z]*)*)\\s+(\\d+)\\s+',\n",
    "                        row_text, re.IGNORECASE\n",
    "                    )\n",
    "                    if special_match:\n",
    "                        denom_value = special_match.group(2)\n",
    "                        denominations = [self.normalize_denomination(denom_value, 'c')]\n",
    "                        last_denomination = denominations[0]\n",
    "                \n",
    "                colors = []\n",
    "                for entry in entries:\n",
    "                    color = self.extract_stamp_color(row_text, entry['catalog_number'])\n",
    "                    colors.append(color)\n",
    "                \n",
    "                attributes = self.extract_attributes(row_text)\n",
    "                \n",
    "                quantity = None\n",
    "                qty_match = self.QUANTITY.search(row_text)\n",
    "                if qty_match:\n",
    "                    raw_quantity = qty_match.group(1) or qty_match.group(2)\n",
    "                    quantity = raw_quantity.replace(',', '')\n",
    "                    print(f\"DEBUG: Quantity: {quantity}\")\n",
    "                \n",
    "                for i, entry in enumerate(entries):\n",
    "                    cat_num = entry['catalog_number']\n",
    "                    node_type = entry['node_type']\n",
    "                    sub_type = entry['sub_type']\n",
    "                    base_stamp = entry['base_stamp']\n",
    "                    \n",
    "                    final_attributes = attributes.copy()\n",
    "                    if surcharge_info:\n",
    "                        final_attributes.append(f'surcharge_{surcharge_info}')\n",
    "                    \n",
    "                    if node_type == 'stamp' and cat_num in self.stamps_seen:\n",
    "                        print(f\"DEBUG: Skipping duplicate stamp {cat_num}\")\n",
    "                        continue\n",
    "                    \n",
    "                    node = PhilatelicNode(\n",
    "                        catalog_number=cat_num,\n",
    "                        node_type=node_type,\n",
    "                        sub_type=sub_type,\n",
    "                        denomination=denominations[0] if denominations else None,\n",
    "                        color=colors[i] if i < len(colors) else (colors[0] if colors else None),\n",
    "                        year=self.current_year,\n",
    "                        issue_name=self.current_issue,\n",
    "                        quantity=quantity if node_type == 'stamp' else None,\n",
    "                        page_number=page_number,\n",
    "                        reading_order=reading_order,\n",
    "                        raw_text=row_text,\n",
    "                        context_before=context[-3:],\n",
    "                        attributes=final_attributes,\n",
    "                        base_stamp=base_stamp\n",
    "                    )\n",
    "                    nodes.append(node)\n",
    "                    print(f\"DEBUG: Created {cat_num} - {node.denomination} {node.color}\")\n",
    "                    \n",
    "                    if node_type == 'stamp' and self.current_section and 'regular' in self.current_section.lower():\n",
    "                        self.stamps_seen.add(cat_num)\n",
    "                        print(f\"DEBUG: Added {cat_num} to stamps_seen\")\n",
    "            \n",
    "        return nodes\n",
    "class PhilatelicExtractor:\n",
    "    \"\"\"Main extractor with expert Costa Rica knowledge\"\"\"\n",
    "    \n",
    "    def __init__(self, context_window: Tuple[int, int] = (-3, 1)):\n",
    "        self.context_window = context_window\n",
    "        self.parser = CostaRicaCatalogParser()\n",
    "    \n",
    "    def get_context(self, elements: List[Dict], index: int) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Get context around element\"\"\"\n",
    "        start = max(0, index + self.context_window[0])\n",
    "        end_after = min(len(elements), index + self.context_window[1] + 1)\n",
    "        \n",
    "        context_before = []\n",
    "        for i in range(start, index):\n",
    "            text = elements[i].get('text', '')\n",
    "            if text and elements[i].get('label') not in ['header', 'foot', 'fig']:\n",
    "                context_before.append(text)\n",
    "        \n",
    "        context_after = []\n",
    "        for i in range(index + 1, end_after):\n",
    "            text = elements[i].get('text', '')\n",
    "            if text and elements[i].get('label') not in ['header', 'foot', 'fig']:\n",
    "                context_after.append(text)\n",
    "        \n",
    "        return context_before, context_after\n",
    "    \n",
    "    def process_page(self, page_data: Dict) -> List[PhilatelicNode]:\n",
    "        \"\"\"Process single page\"\"\"\n",
    "        elements = page_data.get('elements', [])\n",
    "        page_number = page_data.get('page_number', 0)\n",
    "        \n",
    "        elements = sorted(elements, key=lambda x: x.get('reading_order', 0))\n",
    "        \n",
    "        # Reset state for new page\n",
    "        # BUT keep issue_name if no new <sec> found (issues can span pages)\n",
    "        self.parser.current_section = None\n",
    "        self.parser.current_sub_sec = None\n",
    "        self.parser.current_sub_sub_sec = None\n",
    "        # Don't reset current_issue - it carries over pages\n",
    "        # Don't reset current_year - it carries over\n",
    "        # Don't reset stamps_seen - we need to track across pages\n",
    "        \n",
    "        all_nodes = []\n",
    "        \n",
    "        for i, element in enumerate(elements):\n",
    "            context_before, context_after = self.get_context(elements, i)\n",
    "            nodes = self.parser.parse_element(element, context_before, context_after, page_number)\n",
    "            all_nodes.extend(nodes)\n",
    "        \n",
    "        return all_nodes\n",
    "    \n",
    "    def build_relationships(self, nodes: List[PhilatelicNode]) -> List[Dict]:\n",
    "        \"\"\"Build relationships between nodes\"\"\"\n",
    "        relationships = []\n",
    "        \n",
    "        # Index nodes by catalog number\n",
    "        by_catalog = {n.catalog_number: n for n in nodes}\n",
    "        \n",
    "        for node in nodes:\n",
    "            if node.base_stamp and node.base_stamp in by_catalog:\n",
    "                base = by_catalog[node.base_stamp]\n",
    "                relationships.append({\n",
    "                    'from': node.catalog_number,\n",
    "                    'to': base.catalog_number,\n",
    "                    'type': f'{node.node_type.upper()}_OF',\n",
    "                    'sub_type': node.sub_type,\n",
    "                    'description': f\"{node.catalog_number} ({node.sub_type}) is a {node.node_type} of stamp {base.catalog_number}\"\n",
    "                })\n",
    "        \n",
    "        return relationships\n",
    "    \n",
    "    def process_sample_pages(self, input_path: str, start_page: int = 30, num_pages: int = 2) -> Dict:\n",
    "        \"\"\"Process sample pages\"\"\"\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, dict) and 'page_number' in data:\n",
    "            pages = [data]\n",
    "        elif isinstance(data, list):\n",
    "            pages = data\n",
    "        else:\n",
    "            pages = []\n",
    "        \n",
    "        pages = [p for p in pages if p.get('page_number', 0) >= start_page \n",
    "                 and p.get('page_number', 0) < start_page + num_pages]\n",
    "        \n",
    "        all_nodes = []\n",
    "        for page in pages:\n",
    "            nodes = self.process_page(page)\n",
    "            all_nodes.extend(nodes)\n",
    "        \n",
    "        # Build relationships\n",
    "        relationships = self.build_relationships(all_nodes)\n",
    "        \n",
    "        result = {\n",
    "            'total_nodes': len(all_nodes),\n",
    "            'nodes_by_type': {},\n",
    "            'all_nodes': [node.to_dict() for node in all_nodes],\n",
    "            'relationships': relationships,\n",
    "            'relationship_count': len(relationships)\n",
    "        }\n",
    "        \n",
    "        for node in all_nodes:\n",
    "            node_type = node.node_type\n",
    "            if node_type not in result['nodes_by_type']:\n",
    "                result['nodes_by_type'][node_type] = []\n",
    "            result['nodes_by_type'][node_type].append(node.to_dict())\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def inspect_json_structure(self, input_path: str, max_pages: int = 3):\n",
    "        \"\"\"Inspect JSON\"\"\"\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, dict) and 'page_number' in data:\n",
    "            pages = [data]\n",
    "        elif isinstance(data, list):\n",
    "            pages = data\n",
    "        else:\n",
    "            print(\"Unexpected JSON structure\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Total pages: {len(pages)}\")\n",
    "        print(f\"\\nInspecting first {min(max_pages, len(pages))} pages:\\n\")\n",
    "        \n",
    "        for page in pages[:max_pages]:\n",
    "            print(f\"Page {page.get('page_number')}:\")\n",
    "            elements = page.get('elements', [])\n",
    "            print(f\"  Elements: {len(elements)}\")\n",
    "            \n",
    "            types = {}\n",
    "            for el in elements:\n",
    "                label = el.get('label', 'unknown')\n",
    "                types[label] = types.get(label, 0) + 1\n",
    "            \n",
    "            print(f\"  Types: {types}\")\n",
    "            \n",
    "            # Show <sec> elements (issue names)\n",
    "            sec_elements = [el for el in elements if el.get('label') == 'sec']\n",
    "            if sec_elements:\n",
    "                print(f\"  Issues found:\")\n",
    "                for sec in sec_elements:\n",
    "                    print(f\"    - {sec.get('text', 'N/A')}\")\n",
    "            print()\n",
    "    \n",
    "    def process_file(self, input_path: str, output_path: str):\n",
    "        \"\"\"Process entire file\"\"\"\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, dict) and 'page_number' in data:\n",
    "            pages = [data]\n",
    "        elif isinstance(data, list):\n",
    "            pages = data\n",
    "        else:\n",
    "            pages = []\n",
    "        \n",
    "        all_nodes = []\n",
    "        # Reset parser state at start\n",
    "        self.parser.current_issue = None\n",
    "        self.parser.current_section = None\n",
    "        self.parser.current_year = None\n",
    "        self.parser.stamps_seen = set()\n",
    "        \n",
    "        for page in pages:\n",
    "            nodes = self.process_page(page)\n",
    "            all_nodes.extend(nodes)\n",
    "        \n",
    "        # Build relationships\n",
    "        relationships = self.build_relationships(all_nodes)\n",
    "        \n",
    "        output = {\n",
    "            'total_nodes': len(all_nodes),\n",
    "            'pages_processed': len(pages),\n",
    "            'nodes': [node.to_dict() for node in all_nodes],\n",
    "            'relationships': relationships,\n",
    "            'summary': {\n",
    "                'by_type': {},\n",
    "                'by_page': {},\n",
    "                'by_issue': {},\n",
    "                'by_denomination': {},\n",
    "                'relationship_count': len(relationships)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Generate statistics\n",
    "        for node in all_nodes:\n",
    "            node_type = node.node_type\n",
    "            page_num = node.page_number\n",
    "            \n",
    "            # By type\n",
    "            output['summary']['by_type'][node_type] = \\\n",
    "                output['summary']['by_type'].get(node_type, 0) + 1\n",
    "            \n",
    "            # By page\n",
    "            output['summary']['by_page'][str(page_num)] = \\\n",
    "                output['summary']['by_page'].get(str(page_num), 0) + 1\n",
    "            \n",
    "            # By issue\n",
    "            if node.issue_name:\n",
    "                output['summary']['by_issue'][node.issue_name] = \\\n",
    "                    output['summary']['by_issue'].get(node.issue_name, 0) + 1\n",
    "            \n",
    "            # By denomination\n",
    "            if node.denomination:\n",
    "                output['summary']['by_denomination'][node.denomination] = \\\n",
    "                    output['summary']['by_denomination'].get(node.denomination, 0) + 1\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba516ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_denomination_extraction():\n",
    "    \"\"\"Test comprehensive denomination extraction\"\"\"\n",
    "    \n",
    "    parser = CostaRicaCatalogParser()\n",
    "    \n",
    "    test_cases = [\n",
    "        # Centavos/céntimos\n",
    "        {'text': '99 15c black', 'expected': '15c', 'note': 'Standard centavos'},\n",
    "        {'text': 'DP100 5c violet', 'expected': '5c', 'note': 'Small value'},\n",
    "        {'text': 'PP101 100c orange', 'expected': '100c', 'note': '100 centavos (not Colones)'},\n",
    "        {'text': 'S102 15centimos black', 'expected': '15c', 'note': 'Full word \"centimos\"'},\n",
    "        \n",
    "        # Colones\n",
    "        {'text': '200 1col blue', 'expected': '1col', 'note': 'One colón'},\n",
    "        {'text': '201 5C green', 'expected': '5col', 'note': 'Capital C = Colones'},\n",
    "        {'text': '202 2colones red', 'expected': '2col', 'note': 'Full word \"colones\"'},\n",
    "        \n",
    "        # Pesos\n",
    "        {'text': '50 1p black', 'expected': '1p', 'note': '1 peso'},\n",
    "        {'text': '51 10pesos violet', 'expected': '10p', 'note': 'Full word \"pesos\"'},\n",
    "        \n",
    "        # Reales with fractions\n",
    "        {'text': '10 ½r black', 'expected': '0.5r', 'note': 'Half real'},\n",
    "        {'text': '11 1/2r violet', 'expected': '0.5r', 'note': 'Fraction 1/2 real'},\n",
    "        {'text': '12 2r green', 'expected': '2r', 'note': '2 reales'},\n",
    "        {'text': '13 ¼r orange', 'expected': '0.25r', 'note': 'Quarter real'},\n",
    "        \n",
    "        # Edge cases\n",
    "        {'text': '99 15c deep violet 1,000,000', 'expected': '15c', 'note': 'Implicit \"c\", quantity present'},\n",
    "        {'text': 'DP99 15c black #34009', 'expected': '15c', 'note': 'With reference number'},\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 1: DENOMINATION EXTRACTION\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        print(f\"{i}. {test['text']}\")\n",
    "        print(f\"   Note: {test['note']}\")\n",
    "        \n",
    "        denoms_raw = parser.extract_denominations(test['text'])\n",
    "        \n",
    "        if denoms_raw:\n",
    "            denom_normalized = parser.normalize_denomination(denoms_raw[0][0], denoms_raw[0][1])\n",
    "            \n",
    "            if denom_normalized == test['expected']:\n",
    "                print(f\"   ✅ PASS - Extracted: {denom_normalized}\")\n",
    "                passed += 1\n",
    "            else:\n",
    "                print(f\"   ❌ FAIL - Expected: {test['expected']}, Got: {denom_normalized}\")\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"   ❌ FAIL - No denomination extracted\")\n",
    "            failed += 1\n",
    "        print()\n",
    "    \n",
    "    print(f\"Results: {passed}/{len(test_cases)} passed\\n\")\n",
    "    return passed, failed\n",
    "\n",
    "def test_issue_name_tracking():\n",
    "    \"\"\"Test that issue names from <sec> are properly tracked\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 2: ISSUE NAME TRACKING (from <sec> elements)\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Simulate page with multiple issues\n",
    "    test_page = {\n",
    "        'page_number': 30,\n",
    "        'elements': [\n",
    "            {'label': 'sec', 'text': 'Simon Bolivar Birthday issue', 'reading_order': 1},\n",
    "            {'label': 'para', 'text': 'July 24, 1921. Decree #18', 'reading_order': 2},\n",
    "            {'label': 'para', 'text': 'Proof', 'reading_order': 3},\n",
    "            {'label': 'para', 'text': 'DP99 15c black', 'reading_order': 4},\n",
    "            {'label': 'para', 'text': 'Regular issue', 'reading_order': 5},\n",
    "            {'label': 'para', 'text': '99 15c deep violet', 'reading_order': 6},\n",
    "            \n",
    "            {'label': 'sec', 'text': 'Central America Independence issue', 'reading_order': 7},\n",
    "            {'label': 'para', 'text': 'September 15, 1921', 'reading_order': 8},\n",
    "            {'label': 'para', 'text': 'PP100 5c violet', 'reading_order': 9},\n",
    "            {'label': 'para', 'text': '100 5c violet', 'reading_order': 10},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    extractor = PhilatelicExtractor()\n",
    "    nodes = extractor.process_page(test_page)\n",
    "    \n",
    "    print(f\"Extracted {len(nodes)} nodes\\n\")\n",
    "    \n",
    "    expected_issues = {\n",
    "        'DP99': 'Simon Bolivar Birthday issue',\n",
    "        '99': 'Simon Bolivar Birthday issue',\n",
    "        'PP100': 'Central America Independence issue',\n",
    "        '100': 'Central America Independence issue'\n",
    "    }\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for cat_num, expected_issue in expected_issues.items():\n",
    "        matching = [n for n in nodes if n.catalog_number == cat_num]\n",
    "        \n",
    "        if matching:\n",
    "            node = matching[0]\n",
    "            if node.issue_name == expected_issue:\n",
    "                print(f\"✅ {cat_num}: '{node.issue_name}'\")\n",
    "                passed += 1\n",
    "            else:\n",
    "                print(f\"❌ {cat_num}: Expected '{expected_issue}', got '{node.issue_name}'\")\n",
    "                failed += 1\n",
    "        else:\n",
    "            print(f\"❌ {cat_num}: Node not found\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(f\"\\nResults: {passed}/{len(expected_issues)} passed\\n\")\n",
    "    return passed, failed\n",
    "\n",
    "def test_quantity_vs_denomination():\n",
    "    \"\"\"Test that quantities are not confused with denominations\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 3: QUANTITY vs DENOMINATION DISAMBIGUATION\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            'text': '99 15c deep violet 1,000,000',\n",
    "            'catalog': '99',\n",
    "            'expected_denom': '15c',\n",
    "            'expected_qty': '1,000,000',\n",
    "            'note': 'Quantity has comma'\n",
    "        },\n",
    "        {\n",
    "            'text': 'DP99 15c black #34009',\n",
    "            'catalog': 'DP99',\n",
    "            'expected_denom': '15c',\n",
    "            'expected_qty': None,\n",
    "            'note': 'No quantity'\n",
    "        },\n",
    "        {\n",
    "            'text': '100 5c violet printed 500,000',\n",
    "            'catalog': '100',\n",
    "            'expected_denom': '5c',\n",
    "            'expected_qty': '500,000',\n",
    "            'note': 'Quantity with \"printed\" keyword'\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    parser = CostaRicaCatalogParser()\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        print(f\"{i}. {test['text']}\")\n",
    "        print(f\"   Note: {test['note']}\")\n",
    "        \n",
    "        # Extract denomination\n",
    "        denoms_raw = parser.extract_denominations(test['text'])\n",
    "        denom = parser.normalize_denomination(denoms_raw[0][0], denoms_raw[0][1]) if denoms_raw else None\n",
    "        \n",
    "        # Extract quantity\n",
    "        qty_match = parser.QUANTITY.search(test['text'])\n",
    "        qty = qty_match.group(1) or qty_match.group(2) if qty_match else None\n",
    "        \n",
    "        denom_ok = (denom == test['expected_denom'])\n",
    "        qty_ok = (qty == test['expected_qty'])\n",
    "        \n",
    "        if denom_ok and qty_ok:\n",
    "            print(f\"   ✅ PASS - Denom: {denom}, Qty: {qty}\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"   ❌ FAIL\")\n",
    "            if not denom_ok:\n",
    "                print(f\"      Denom: Expected {test['expected_denom']}, Got {denom}\")\n",
    "            if not qty_ok:\n",
    "                print(f\"      Qty: Expected {test['expected_qty']}, Got {qty}\")\n",
    "            failed += 1\n",
    "        print()\n",
    "    \n",
    "    print(f\"Results: {passed}/{len(test_cases)} passed\\n\")\n",
    "    return passed, failed\n",
    "\n",
    "def test_color_extraction_expert():\n",
    "    \"\"\"Expert-level color extraction test\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 4: EXPERT COLOR EXTRACTION\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    parser = CostaRicaCatalogParser()\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            'text': 'S99 15c violet, op \"specimen\" in red with hole',\n",
    "            'catalog': 'S99',\n",
    "            'expected_color': 'violet',\n",
    "            'should_have_attr': 'overprint_red',\n",
    "            'note': 'Red is overprint color, not stamp color'\n",
    "        },\n",
    "        {\n",
    "            'text': '106 1c brown, blue op inverted op',\n",
    "            'catalog': '106',\n",
    "            'expected_color': 'brown',\n",
    "            'should_have_attr': 'overprint_blue',\n",
    "            'note': 'Blue is overprint, brown is stamp'\n",
    "        },\n",
    "        {\n",
    "            'text': 'PP99 15centimos light gray violet, imperf',\n",
    "            'catalog': 'PP99',\n",
    "            'expected_color': 'light gray violet',\n",
    "            'note': 'Compound color with full word denomination'\n",
    "        },\n",
    "        {\n",
    "            'text': '50 1p black on green',\n",
    "            'catalog': '50',\n",
    "            'expected_color': 'black',\n",
    "            'note': 'Bicolor: black on green paper'\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        print(f\"{i}. {test['text']}\")\n",
    "        print(f\"   Note: {test['note']}\")\n",
    "        \n",
    "        color = parser.extract_stamp_color(test['text'], test['catalog'])\n",
    "        attrs = parser.extract_attributes(test['text'])\n",
    "        \n",
    "        color_ok = (color == test['expected_color'])\n",
    "        attr_ok = True\n",
    "        \n",
    "        if 'should_have_attr' in test:\n",
    "            attr_ok = test['should_have_attr'] in attrs\n",
    "        \n",
    "        if color_ok and attr_ok:\n",
    "            print(f\"   ✅ PASS - Color: {color}\")\n",
    "            if 'should_have_attr' in test:\n",
    "                print(f\"      Attribute found: {test['should_have_attr']}\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"   ❌ FAIL\")\n",
    "            if not color_ok:\n",
    "                print(f\"      Expected color: {test['expected_color']}, Got: {color}\")\n",
    "            if not attr_ok:\n",
    "                print(f\"      Missing attribute: {test['should_have_attr']}\")\n",
    "            failed += 1\n",
    "        print()\n",
    "    \n",
    "    print(f\"Results: {passed}/{len(test_cases)} passed\\n\")\n",
    "    return passed, failed\n",
    "\n",
    "def test_full_integration():\n",
    "    \"\"\"Full integration test with real pages 30-31 from file\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST 5: FULL INTEGRATION (Real Pages 30-31 from file)\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    input_path = \"./results/recognition_json/Mena 2018 CRPC .json\"\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"⚠️  File not found: {input_path}\")\n",
    "        print(\"   Using minimal sample data instead\\n\")\n",
    "        \n",
    "        # Fallback to minimal sample\n",
    "        sample_data = [{\n",
    "            'page_number': 30,\n",
    "            'elements': [\n",
    "                {\"label\": \"sec\", \"text\": \"Simon Bolivar Birthday issue\", \"reading_order\": 8},\n",
    "                {\"label\": \"para\", \"text\": \"DP99 15c black\", \"reading_order\": 11},\n",
    "                {\"label\": \"para\", \"text\": \"99 15c deep violet\", \"reading_order\": 17}\n",
    "            ]\n",
    "        }]\n",
    "    else:\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # CORRECCIÓN: Extraer páginas del diccionario\n",
    "        if isinstance(data, dict) and 'pages' in data:\n",
    "            all_pages = data['pages']\n",
    "        elif isinstance(data, list):\n",
    "            all_pages = data\n",
    "        else:\n",
    "            print(\"⚠️  Unexpected JSON structure\")\n",
    "            all_pages = []\n",
    "        \n",
    "        # Filter pages 30-31\n",
    "        sample_data = [p for p in all_pages if p.get('page_number') in [10, 11]]\n",
    "        print(f\"Loaded {len(sample_data)} pages from file\\n\")\n",
    "        print(f\"Total pages in catalog: {len(all_pages)}\\n\")\n",
    "    \n",
    "    extractor = PhilatelicExtractor()\n",
    "    \n",
    "    all_nodes = []\n",
    "    for page in sample_data:\n",
    "        nodes = extractor.process_page(page)\n",
    "        all_nodes.extend(nodes)\n",
    "    \n",
    "    print(f\"Total nodes extracted: {len(all_nodes)}\")\n",
    "    print(f\"Expected for pages 30-31: 58-70 nodes\\n\")\n",
    "    \n",
    "    # Group by issue\n",
    "    by_issue = {}\n",
    "    for node in all_nodes:\n",
    "        issue = node.issue_name or 'No issue'\n",
    "        if issue not in by_issue:\n",
    "            by_issue[issue] = []\n",
    "        by_issue[issue].append(node)\n",
    "    \n",
    "    print(\"Nodes by Issue:\")\n",
    "    for issue, nodes in by_issue.items():\n",
    "        print(f\"  {issue}: {len(nodes)} nodes\")\n",
    "    print()\n",
    "    \n",
    "    # Group by type\n",
    "    by_type = {}\n",
    "    for node in all_nodes:\n",
    "        if node.node_type not in by_type:\n",
    "            by_type[node.node_type] = []\n",
    "        by_type[node.node_type].append(node)\n",
    "    \n",
    "    print(\"Nodes by Type:\")\n",
    "    for node_type, nodes in sorted(by_type.items()):\n",
    "        print(f\"  {node_type:15s}: {len(nodes)} nodes\")\n",
    "    print()\n",
    "    \n",
    "    # Validation checks - GENERALIZED\n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: All nodes have issue_name\n",
    "    nodes_with_issue = [n for n in all_nodes if n.issue_name]\n",
    "    checks.append({\n",
    "        'name': 'All nodes have issue_name',\n",
    "        'passed': len(nodes_with_issue) == len(all_nodes),\n",
    "        'detail': f\"{len(nodes_with_issue)}/{len(all_nodes)}\"\n",
    "    })\n",
    "    \n",
    "    # Check 2: All nodes have denomination\n",
    "    nodes_with_denom = [n for n in all_nodes if n.denomination]\n",
    "    checks.append({\n",
    "        'name': 'All nodes have denomination',\n",
    "        'passed': len(nodes_with_denom) == len(all_nodes),\n",
    "        'detail': f\"{len(nodes_with_denom)}/{len(all_nodes)}\"\n",
    "    })\n",
    "    \n",
    "    # Check 3: Multiple issues detected (GENERALIZED)\n",
    "    unique_issues = set(n.issue_name for n in all_nodes if n.issue_name)\n",
    "    checks.append({\n",
    "        'name': 'Multiple issues detected',\n",
    "        'passed': len(unique_issues) >= 1,\n",
    "        'detail': f\"{len(unique_issues)} unique issues found\"\n",
    "    })\n",
    "    \n",
    "    # Check 4: Overprint colors captured as attributes (GENERALIZED)\n",
    "    nodes_with_op_attrs = [n for n in all_nodes \n",
    "                          if any('overprint' in attr.lower() for attr in n.attributes)]\n",
    "    checks.append({\n",
    "        'name': 'Overprint colors in attributes',\n",
    "        'passed': True,  # Non-critical, just informational\n",
    "        'detail': f\"{len(nodes_with_op_attrs)} nodes with overprint attributes\"\n",
    "    })\n",
    "    \n",
    "    # Check 5: Base stamps exist\n",
    "    base_stamps = [n for n in all_nodes if n.node_type == 'stamp' and not n.base_stamp]\n",
    "    checks.append({\n",
    "        'name': 'Base stamps detected',\n",
    "        'passed': len(base_stamps) > 0,\n",
    "        'detail': f\"{len(base_stamps)} base stamps\"\n",
    "    })\n",
    "    \n",
    "    # Check 6: Varieties/Proofs have base_stamp reference\n",
    "    derived_nodes = [n for n in all_nodes if n.node_type in ['proof', 'variety', 'specimen']]\n",
    "    with_base = [n for n in derived_nodes if n.base_stamp]\n",
    "    checks.append({\n",
    "        'name': 'Derived nodes have base_stamp',\n",
    "        'passed': len(with_base) > 0 if derived_nodes else True,\n",
    "        'detail': f\"{len(with_base)}/{len(derived_nodes)} have base reference\" if derived_nodes else \"N/A\"\n",
    "    })\n",
    "    \n",
    "    # Check 7: Relationships exist\n",
    "    relationships = extractor.build_relationships(all_nodes)\n",
    "    checks.append({\n",
    "        'name': 'Relationships built',\n",
    "        'passed': len(relationships) > 0,\n",
    "        'detail': f\"{len(relationships)} relationships\"\n",
    "    })\n",
    "    \n",
    "    # Check 8: Year captured\n",
    "    nodes_with_year = [n for n in all_nodes if n.year]\n",
    "    checks.append({\n",
    "        'name': 'Year information captured',\n",
    "        'passed': len(nodes_with_year) > 0,\n",
    "        'detail': f\"{len(nodes_with_year)} nodes with year info\"\n",
    "    })\n",
    "    \n",
    "    # Check 9: Node count reasonable\n",
    "    reasonable_count = 50 <= len(all_nodes) <= 80\n",
    "    checks.append({\n",
    "        'name': 'Node count within expected range',\n",
    "        'passed': reasonable_count,\n",
    "        'detail': f\"{len(all_nodes)} nodes (expected 58-70)\"\n",
    "    })\n",
    "    \n",
    "    # Print validation results\n",
    "    print(\"=\"*80)\n",
    "    print(\"VALIDATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    passed = sum(1 for c in checks if c['passed'])\n",
    "    \n",
    "    for check in checks:\n",
    "        status = '✅' if check['passed'] else '❌'\n",
    "        print(f\"{status} {check['name']}: {check['detail']}\")\n",
    "    \n",
    "    print(f\"\\nValidation: {passed}/{len(checks)} checks passed\\n\")\n",
    "    \n",
    "    # Show detailed breakdown\n",
    "    print(\"=\"*80)\n",
    "    print(\"DETAILED BREAKDOWN BY ISSUE\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    for issue_name, nodes in sorted(by_issue.items()):\n",
    "        print(f\"\\n{issue_name}:\")\n",
    "        print(f\"  Total: {len(nodes)} nodes\")\n",
    "        \n",
    "        # Count by type within this issue\n",
    "        types_in_issue = {}\n",
    "        for n in nodes:\n",
    "            types_in_issue[n.node_type] = types_in_issue.get(n.node_type, 0) + 1\n",
    "        \n",
    "        print(f\"  Types: {dict(types_in_issue)}\\n\")\n",
    "        \n",
    "        # Show first 5 nodes\n",
    "        for i, node in enumerate(nodes, 1): #enumerate(nodes[:5], 1)\n",
    "            attrs_str = f\", attrs: {node.attributes if node.attributes else '[]'}\"\n",
    "            refs_str = f\", refs: {node.reference_numbers[:2]}\" if node.reference_numbers else \"\"\n",
    "            base_str = f\" → {node.base_stamp}\" if node.base_stamp else \"\"\n",
    "            \n",
    "            print(f\"  {i}. {node.catalog_number} ({node.node_type}/{node.sub_type}){base_str}\")\n",
    "            qty_str = f\", qty: {node.quantity}\" if node.quantity else \"\"\n",
    "            print(f\"     {node.denomination} {node.color or 'N/A'}{qty_str}{attrs_str}{refs_str}\")\n",
    "        \n",
    "        # if len(nodes) > 5:\n",
    "        #     print(f\"  ... and {len(nodes) - 5} more\")\n",
    "    \n",
    "    # Show relationships\n",
    "    if relationships:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RELATIONSHIPS\")\n",
    "        print(\"=\"*80)\n",
    "        print()\n",
    "        \n",
    "        # Group relationships by type\n",
    "        by_rel_type = {}\n",
    "        for rel in relationships:\n",
    "            rel_type = rel['type']\n",
    "            if rel_type not in by_rel_type:\n",
    "                by_rel_type[rel_type] = []\n",
    "            by_rel_type[rel_type].append(rel)\n",
    "        \n",
    "        for rel_type, rels in sorted(by_rel_type.items()):\n",
    "            print(f\"\\n{rel_type} ({len(rels)} relationships):\")\n",
    "            for rel in rels[:5]:\n",
    "                print(f\"  {rel['from']:10s} --> {rel['to']}\")\n",
    "            if len(rels) > 5:\n",
    "                print(f\"  ... and {len(rels) - 5} more\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Results: {passed}/{len(checks)} checks passed\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # DEBUG: Mostrar nodos sin denominación\n",
    "    nodes_without_denom = [n for n in all_nodes if not n.denomination]\n",
    "    if nodes_without_denom:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DEBUG: NODES WITHOUT DENOMINATION\")\n",
    "        print(\"=\"*80)\n",
    "        print()\n",
    "        print(f\"Found {len(nodes_without_denom)} nodes without denomination:\\n\")\n",
    "        \n",
    "        for i, node in enumerate(nodes_without_denom, 1):\n",
    "            print(f\"{i}. Catalog: {node.catalog_number}\")\n",
    "            print(f\"   Type: {node.node_type}/{node.sub_type}\")\n",
    "            print(f\"   Issue: {node.issue_name}\")\n",
    "            print(f\"   Page: {node.page_number}, Order: {node.reading_order}\")\n",
    "            print(f\"   Raw text: {node.raw_text[:100]}...\")\n",
    "            print(f\"   Color: {node.color}\")\n",
    "            print()\n",
    "        \n",
    "    return passed, len(checks) - passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def create_stamp_graph(base_stamp_node, all_nodes, relationships, output_dir=\"./graph_outputs\"):\n",
    "    \"\"\"\n",
    "    Create a detailed graph for a single stamp and all its relationships.\n",
    "    \n",
    "    Args:\n",
    "        base_stamp_node: The main stamp node\n",
    "        all_nodes: List of all nodes\n",
    "        relationships: List of all relationships\n",
    "        output_dir: Directory to save graph images\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Find all related nodes\n",
    "    related_nodes = set()\n",
    "    related_relationships = []\n",
    "    \n",
    "    # Get the catalog number of the base stamp\n",
    "    base_id = base_stamp_node.catalog_number\n",
    "    \n",
    "    # Add base stamp to graph\n",
    "    qty_display = f\"\\nQty: {base_stamp_node.quantity}\" if base_stamp_node.quantity else \"\"\n",
    "    G.add_node(base_id, \n",
    "            node_obj=base_stamp_node,\n",
    "            node_type=base_stamp_node.node_type,\n",
    "            label=f\"{base_id}\\n{base_stamp_node.denomination}\\n{base_stamp_node.color or ''}{qty_display}\".strip())\n",
    "    \n",
    "    # Find all relationships involving this stamp\n",
    "    for rel in relationships:\n",
    "        if rel['from'] == base_id or rel['to'] == base_id:\n",
    "            related_relationships.append(rel)\n",
    "            related_nodes.add(rel['from'])\n",
    "            related_nodes.add(rel['to'])\n",
    "    \n",
    "    # Add related nodes to graph\n",
    "    node_lookup = {n.catalog_number: n for n in all_nodes}\n",
    "    \n",
    "    for node_id in related_nodes:\n",
    "        if node_id != base_id and node_id in node_lookup:\n",
    "            node = node_lookup[node_id]\n",
    "            label_parts = [node_id]\n",
    "            if node.denomination:\n",
    "                label_parts.append(node.denomination)\n",
    "            if node.color:\n",
    "                label_parts.append(node.color)\n",
    "            if node.node_type != 'stamp':\n",
    "                label_parts.append(f\"({node.node_type})\")\n",
    "            \n",
    "            G.add_node(node_id, \n",
    "                      node_obj=node,\n",
    "                      node_type=node.node_type,\n",
    "                      label='\\n'.join(label_parts))\n",
    "    \n",
    "    # Add edges with relationship types\n",
    "    for rel in related_relationships:\n",
    "        G.add_edge(rel['from'], rel['to'], \n",
    "                  rel_type=rel['type'],\n",
    "                  label=rel['type'].replace('_', ' ').title())\n",
    "    \n",
    "    # Create figure with better size\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Define node colors by type\n",
    "    node_colors = {\n",
    "        'stamp': '#4CAF50',        # Green for base stamps\n",
    "        'variety': '#2196F3',       # Blue for varieties\n",
    "        'proof': '#FF9800',         # Orange for proofs\n",
    "        'specimen': '#9C27B0',      # Purple for specimens\n",
    "        'error': '#F44336',         # Red for errors\n",
    "        'overprint': '#00BCD4',     # Cyan for overprints\n",
    "        'surcharge': '#FFEB3B',     # Yellow for surcharges\n",
    "    }\n",
    "    \n",
    "    # Get colors for nodes\n",
    "    colors = []\n",
    "    for node_id in G.nodes():\n",
    "        node_type = G.nodes[node_id].get('node_type', 'stamp')\n",
    "        colors.append(node_colors.get(node_type, '#9E9E9E'))\n",
    "    \n",
    "    # Calculate layout - hierarchical for better visualization\n",
    "    if len(G.nodes()) > 1:\n",
    "        # Try hierarchical layout with base stamp at center\n",
    "        pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "        \n",
    "        # Adjust position to put base stamp at center-top\n",
    "        if base_id in pos:\n",
    "            # Center the base stamp\n",
    "            base_pos = pos[base_id]\n",
    "            pos[base_id] = (0.5, 0.9)\n",
    "            \n",
    "            # Arrange related nodes in a semi-circle below\n",
    "            related = [n for n in G.nodes() if n != base_id]\n",
    "            if related:\n",
    "                angle_step = 3.14 / (len(related) + 1)\n",
    "                for i, node_id in enumerate(related):\n",
    "                    angle = angle_step * (i + 1)\n",
    "                    radius = 0.4\n",
    "                    x = 0.5 + radius * np.cos(angle + 3.14)\n",
    "                    y = 0.4 + radius * np.sin(angle + 3.14) * 0.6\n",
    "                    pos[node_id] = (x, y)\n",
    "    else:\n",
    "        pos = {base_id: (0.5, 0.5)}\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          node_color=colors, \n",
    "                          node_size=3000,\n",
    "                          alpha=0.9,\n",
    "                          ax=ax)\n",
    "    \n",
    "    # Draw labels with better formatting\n",
    "    labels = nx.get_node_attributes(G, 'label')\n",
    "    nx.draw_networkx_labels(G, pos, labels, \n",
    "                           font_size=8, \n",
    "                           font_weight='bold',\n",
    "                           ax=ax)\n",
    "    \n",
    "    # Draw edges with labels\n",
    "    nx.draw_networkx_edges(G, pos, \n",
    "                          edge_color='gray',\n",
    "                          arrows=True,\n",
    "                          arrowsize=20,\n",
    "                          arrowstyle='-|>',\n",
    "                          width=2,\n",
    "                          alpha=0.6,\n",
    "                          ax=ax)\n",
    "    \n",
    "    # Draw edge labels\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels, \n",
    "                                font_size=7,\n",
    "                                font_color='red',\n",
    "                                ax=ax)\n",
    "    \n",
    "    # Add title with stamp details\n",
    "    title_parts = [f\"Stamp Network: {base_id}\"]\n",
    "    if base_stamp_node.issue_name:\n",
    "        title_parts.append(f\"Issue: {base_stamp_node.issue_name}\")\n",
    "    if base_stamp_node.year:\n",
    "        title_parts.append(f\"Year: {base_stamp_node.year}\")\n",
    "    \n",
    "    plt.title('\\n'.join(title_parts), fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = []\n",
    "    for node_type, color in node_colors.items():\n",
    "        if any(G.nodes[n].get('node_type') == node_type for n in G.nodes()):\n",
    "            legend_elements.append(plt.scatter([], [], c=color, s=100, \n",
    "                                              label=node_type.title()))\n",
    "    \n",
    "    if legend_elements:\n",
    "        plt.legend(handles=legend_elements, loc='upper left', frameon=True)\n",
    "    \n",
    "    # Add statistics box\n",
    "    stats_text = f\"Nodes: {len(G.nodes())}\\nRelationships: {len(G.edges())}\"\n",
    "    plt.text(0.02, 0.02, stats_text, transform=ax.transAxes,\n",
    "            fontsize=10, verticalalignment='bottom',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    safe_filename = base_id.replace('/', '_').replace(' ', '_')\n",
    "    output_path = os.path.join(output_dir, f\"stamp_{safe_filename}.png\")\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return output_path, G\n",
    "\n",
    "\n",
    "def create_comparative_table(base_stamp_node, all_nodes, relationships, output_dir=\"./graph_outputs\"):\n",
    "    \"\"\"\n",
    "    Create a comparative table showing the stamp and all its variants/related items.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    base_id = base_stamp_node.catalog_number\n",
    "    related_data = []\n",
    "    \n",
    "    # Add base stamp\n",
    "    related_data.append({\n",
    "        'Catalog #': base_id,\n",
    "        'Type': base_stamp_node.node_type,\n",
    "        'Denomination': base_stamp_node.denomination,\n",
    "        'Color': base_stamp_node.color or 'N/A',\n",
    "        'Quantity': base_stamp_node.quantity or 'N/A',\n",
    "        'Year': base_stamp_node.year or 'N/A',\n",
    "        'Attributes': ', '.join(base_stamp_node.attributes) if base_stamp_node.attributes else 'N/A',\n",
    "        'References': ', '.join(base_stamp_node.reference_numbers) if base_stamp_node.reference_numbers else 'N/A',\n",
    "        'Relationship': 'BASE STAMP'\n",
    "    })\n",
    "    \n",
    "    # Find all related nodes\n",
    "    node_lookup = {n.catalog_number: n for n in all_nodes}\n",
    "    \n",
    "    for rel in relationships:\n",
    "        if rel['from'] == base_id:\n",
    "            if rel['to'] in node_lookup:\n",
    "                node = node_lookup[rel['to']]\n",
    "                related_data.append({\n",
    "                    'Catalog #': node.catalog_number,\n",
    "                    'Type': node.node_type,\n",
    "                    'Denomination': node.denomination or 'N/A',\n",
    "                    'Color': node.color or 'N/A',\n",
    "                    'Year': node.year or 'N/A',\n",
    "                    'Attributes': ', '.join(node.attributes) if node.attributes else 'N/A',\n",
    "                    'References': ', '.join(node.reference_numbers) if node.reference_numbers else 'N/A',\n",
    "                    'Relationship': rel['type'].replace('_', ' ').upper()\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(related_data)\n",
    "    \n",
    "    # Create figure with table\n",
    "    fig, ax = plt.subplots(figsize=(14, max(4, len(related_data) * 0.5)))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create table\n",
    "    table = ax.table(cellText=df.values, \n",
    "                    colLabels=df.columns,\n",
    "                    cellLoc='left',\n",
    "                    loc='center',\n",
    "                    colWidths=[0.10, 0.09, 0.11, 0.10, 0.09, 0.08, 0.17, 0.13, 0.10])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.5)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(df.columns)):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Highlight base stamp row\n",
    "    table[(1, 0)].set_facecolor('#E8F5E9')\n",
    "    for i in range(len(df.columns)):\n",
    "        table[(1, i)].set_facecolor('#E8F5E9')\n",
    "    \n",
    "    # Add title\n",
    "    title = f\"Stamp Catalog Comparison: {base_id}\"\n",
    "    if base_stamp_node.issue_name:\n",
    "        title += f\"\\nIssue: {base_stamp_node.issue_name}\"\n",
    "    plt.title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Save\n",
    "    safe_filename = base_id.replace('/', '_').replace(' ', '_')\n",
    "    output_path = os.path.join(output_dir, f\"table_{safe_filename}.png\")\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def enhanced_test_full_integration():\n",
    "    \"\"\"Enhanced version with graph visualization per stamp\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENHANCED TEST WITH GRAPH VISUALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    input_path = \"./results/recognition_json/Mena 2018 CRPC .json\"\n",
    "    \n",
    "    # [Previous loading code remains the same...]\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"⚠️  File not found: {input_path}\")\n",
    "        return\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if isinstance(data, dict) and 'pages' in data:\n",
    "        all_pages = data['pages']\n",
    "    elif isinstance(data, list):\n",
    "        all_pages = data\n",
    "    else:\n",
    "        print(\"⚠️  Unexpected JSON structure\")\n",
    "        return\n",
    "    \n",
    "    # Filter pages as before\n",
    "    sample_data = [p for p in all_pages if p.get('page_number') in [8, 9]]\n",
    "    \n",
    "    # Process with your extractor\n",
    "    extractor = PhilatelicExtractor()\n",
    "    \n",
    "    all_nodes = []\n",
    "    for page in sample_data:\n",
    "        nodes = extractor.process_page(page)\n",
    "        all_nodes.extend(nodes)\n",
    "    \n",
    "    # Build relationships\n",
    "    relationships = extractor.build_relationships(all_nodes)\n",
    "    \n",
    "    # Find all base stamps (stamps without base_stamp reference)\n",
    "    base_stamps = [n for n in all_nodes if n.node_type == 'stamp' and not n.base_stamp]\n",
    "    \n",
    "    print(f\"Found {len(base_stamps)} base stamps to visualize\")\n",
    "    print(\"Creating individual graphs for each stamp...\\n\")\n",
    "    \n",
    "    # Create graphs for each base stamp\n",
    "    graph_paths = []\n",
    "    table_paths = []\n",
    "    \n",
    "    for i, stamp in enumerate(base_stamps, 1):\n",
    "        print(f\"Processing {i}/{len(base_stamps)}: {stamp.catalog_number} - {stamp.issue_name}\")\n",
    "        \n",
    "        # Create network graph\n",
    "        graph_path, G = create_stamp_graph(stamp, all_nodes, relationships)\n",
    "        graph_paths.append(graph_path)\n",
    "        print(f\"  ✅ Graph saved: {graph_path}\")\n",
    "        \n",
    "        # Create comparative table\n",
    "        table_path = create_comparative_table(stamp, all_nodes, relationships)\n",
    "        table_paths.append(table_path)\n",
    "        print(f\"  ✅ Table saved: {table_path}\")\n",
    "        \n",
    "        # Print graph statistics\n",
    "        print(f\"  📊 Graph stats: {len(G.nodes())} nodes, {len(G.edges())} relationships\")\n",
    "        print()\n",
    "    \n",
    "    # Create summary HTML file for easy viewing\n",
    "    create_html_summary(base_stamps, graph_paths, table_paths)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"VISUALIZATION COMPLETE\")\n",
    "    print(f\"Generated {len(graph_paths)} stamp graphs\")\n",
    "    print(f\"Generated {len(table_paths)} comparison tables\")\n",
    "    print(\"Check ./graph_outputs/ directory for results\")\n",
    "    print(\"Open summary.html for easy navigation\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "def create_html_summary(base_stamps, graph_paths, table_paths, output_dir=\"./graph_outputs\"):\n",
    "    \"\"\"Create an HTML file to easily view all generated graphs\"\"\"\n",
    "    \n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Philatelic Catalog Verification</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "            h1 { color: #333; }\n",
    "            .stamp-section { \n",
    "                border: 2px solid #ddd; \n",
    "                margin: 20px 0; \n",
    "                padding: 15px; \n",
    "                border-radius: 5px;\n",
    "            }\n",
    "            .stamp-header { \n",
    "                background: #f5f5f5; \n",
    "                padding: 10px; \n",
    "                margin: -15px -15px 15px -15px;\n",
    "                border-radius: 3px 3px 0 0;\n",
    "            }\n",
    "            .images { display: flex; gap: 20px; }\n",
    "            .image-container { flex: 1; text-align: center; }\n",
    "            img { max-width: 100%; border: 1px solid #ccc; }\n",
    "            .navigation { \n",
    "                position: fixed; \n",
    "                right: 20px; \n",
    "                top: 20px; \n",
    "                background: white; \n",
    "                border: 1px solid #ddd;\n",
    "                padding: 10px;\n",
    "                max-height: 80vh;\n",
    "                overflow-y: auto;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Philatelic Catalog Verification Graphs</h1>\n",
    "        <div class=\"navigation\">\n",
    "            <h3>Quick Navigation</h3>\n",
    "            <ul>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add navigation links\n",
    "    for i, stamp in enumerate(base_stamps):\n",
    "        safe_id = stamp.catalog_number.replace('/', '_').replace(' ', '_')\n",
    "        html_content += f'<li><a href=\"#{safe_id}\">{stamp.catalog_number}</a></li>\\n'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "        <div style=\"margin-right: 200px;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add stamp sections\n",
    "    for i, stamp in enumerate(base_stamps):\n",
    "        safe_id = stamp.catalog_number.replace('/', '_').replace(' ', '_')\n",
    "        graph_filename = os.path.basename(graph_paths[i])\n",
    "        table_filename = os.path.basename(table_paths[i])\n",
    "        \n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"stamp-section\" id=\"{safe_id}\">\n",
    "            <div class=\"stamp-header\">\n",
    "                <h2>{stamp.catalog_number}</h2>\n",
    "                <p><strong>Issue:</strong> {stamp.issue_name or 'N/A'}</p>\n",
    "                <p><strong>Denomination:</strong> {stamp.denomination or 'N/A'}</p>\n",
    "                <p><strong>Color:</strong> {stamp.color or 'N/A'}</p>\n",
    "                <p><strong>Year:</strong> {stamp.year or 'N/A'}</p>\n",
    "            </div>\n",
    "            <div class=\"images\">\n",
    "                <div class=\"image-container\">\n",
    "                    <h3>Relationship Graph</h3>\n",
    "                    <img src=\"{graph_filename}\" alt=\"Graph for {stamp.catalog_number}\">\n",
    "                </div>\n",
    "                <div class=\"image-container\">\n",
    "                    <h3>Comparison Table</h3>\n",
    "                    <img src=\"{table_filename}\" alt=\"Table for {stamp.catalog_number}\">\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save HTML file\n",
    "    html_path = os.path.join(output_dir, \"summary.html\")\n",
    "    with open(html_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"✅ HTML summary created: {html_path}\")\n",
    "\n",
    "\n",
    "# Additional utility function for verification\n",
    "def export_verification_csv(all_nodes, relationships, output_path=\"./graph_outputs/verification.csv\"):\n",
    "    \"\"\"Export all data to CSV for manual verification against catalog\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    for node in all_nodes:\n",
    "        # Find relationships for this node\n",
    "        related_to = []\n",
    "        for rel in relationships:\n",
    "            if rel['from'] == node.catalog_number:\n",
    "                related_to.append(f\"{rel['to']} ({rel['type']})\")\n",
    "        \n",
    "        data.append({\n",
    "            'Catalog_Number': node.catalog_number,\n",
    "            'Type': node.node_type,\n",
    "            'SubType': node.sub_type,\n",
    "            'Issue': node.issue_name,\n",
    "            'Year': node.year,\n",
    "            'Denomination': node.denomination,\n",
    "            'Color': node.color,\n",
    "            'Attributes': ', '.join(node.attributes) if node.attributes else '',\n",
    "            'References': ', '.join(node.reference_numbers) if node.reference_numbers else '',\n",
    "            'Base_Stamp': node.base_stamp or '',\n",
    "            'Related_To': '; '.join(related_to),\n",
    "            'Page': node.page_number,\n",
    "            'Reading_Order': node.reading_order\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Verification CSV exported: {output_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3728ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run all expert validation tests\"\"\"\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"╔\" + \"=\"*78 + \"╗\")\n",
    "print(\"║\" + \" \"*15 + \"EXPERT VALIDATION TEST SUITE - COSTA RICA\" + \" \"*22 + \"║\")\n",
    "print(\"║\" + \" \"*22 + \"Philately & Regex Expert Edition\" + \" \"*24 + \"║\")\n",
    "print(\"╚\" + \"=\"*78 + \"╝\")\n",
    "print()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test 1: Denominations\n",
    "p1, f1 = test_denomination_extraction()\n",
    "results.append(('Denomination Extraction', p1, f1))\n",
    "\n",
    "# Test 2: Issue names\n",
    "p2, f2 = test_issue_name_tracking()\n",
    "results.append(('Issue Name Tracking', p2, f2))\n",
    "\n",
    "# Test 3: Quantity vs Denomination\n",
    "p3, f3 = test_quantity_vs_denomination()\n",
    "results.append(('Quantity vs Denomination', p3, f3))\n",
    "\n",
    "# Test 4: Color extraction\n",
    "p4, f4 = test_color_extraction_expert()\n",
    "results.append(('Expert Color Extraction', p4, f4))\n",
    "\n",
    "# Test 5: Full integration\n",
    "p5, f5 = test_full_integration()\n",
    "results.append(('Full Integration', p5, f5))\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "total_passed = sum(r[1] for r in results)\n",
    "total_tests = sum(r[1] + r[2] for r in results)\n",
    "\n",
    "for name, passed, failed in results:\n",
    "    total = passed + failed\n",
    "    pct = (passed / total * 100) if total > 0 else 0\n",
    "    status = '✅' if failed == 0 else '⚠️ '\n",
    "    print(f\"{status} {name:30s}: {passed:2d}/{total:2d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL: {total_passed}/{total_tests} tests passed ({total_passed/total_tests*100:.1f}%)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "if total_passed == total_tests:\n",
    "    print(\"🎉 ALL TESTS PASSED!\")\n",
    "    print(\"\\n✅ El extractor está listo para procesar el catálogo completo de Costa Rica\")\n",
    "    print(\"✅ Maneja todas las denominaciones: centavos, colones, pesos, reales\")\n",
    "    print(\"✅ Extrae issue names correctamente de elementos <sec>\")\n",
    "    print(\"✅ Distingue cantidades de denominaciones\")\n",
    "    print(\"✅ Extrae colores sin confundirlos con overprints\")\n",
    "    print(\"\\n🚀 Próximo paso: Ejecutar en páginas 30-31 completas\")\n",
    "else:\n",
    "    print(f\"⚠️  {total_tests - total_passed} tests fallaron\")\n",
    "    print(\"Revisa los detalles arriba para corregir los problemas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_test_full_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43642d",
   "metadata": {},
   "source": [
    "## Watson Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from landingai_ade import LandingAIADE\n",
    "# Load environment variables \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio, asyncio, logging\n",
    "nest_asyncio.apply()                        # permite reusar el event loop de Jupyter\n",
    "logging.getLogger('asyncio').setLevel(logging.CRITICAL)\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from beeai_framework.backend import ChatModel, ChatModelParameters, UserMessage, SystemMessage\n",
    "\n",
    "# ---- Modelo Pydantic para salida estructurada ----\n",
    "class BusinessPlan(BaseModel):\n",
    "    business_name: str = Field(description=\"Catchy name for the business\")\n",
    "    elevator_pitch: str = Field(description=\"30-second description of the business\")\n",
    "    target_market: str = Field(description=\"Primary target audience\")\n",
    "    unique_value_proposition: str = Field(description=\"What makes this business special\")\n",
    "    revenue_streams: List[str] = Field(description=\"Ways the business will make money\")\n",
    "    startup_costs: str = Field(description=\"Estimated initial investment needed\")\n",
    "    key_success_factors: List[str] = Field(description=\"Critical elements for success\")\n",
    "\n",
    "# ---- Función async original (no la cambies) ----\n",
    "async def structured_output_example():\n",
    "    llm = ChatModel.from_name(\"openai:gpt-5-nano\", ChatModelParameters(temperature=0))\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an expert business consultant and entrepreneur.\"),\n",
    "        UserMessage(content=\"Create a business plan for a mobile app that helps people find and book unique local experiences in their city.\")\n",
    "    ]\n",
    "    \n",
    "    response = await llm.create_structure(\n",
    "        schema=BusinessPlan,\n",
    "        messages=messages\n",
    "    )\n",
    "    print(\"User: Create a business plan for a mobile app that helps people find and book unique local experiences in their city.\")\n",
    "    print('*' * 50)  \n",
    "    print(\"\\n🚀 AI-Generated Business Plan:\")\n",
    "    print(f\"💡 Business Name: {response.object['business_name']}\")\n",
    "    print(f\"🎯 Elevator Pitch: {response.object['elevator_pitch']}\")\n",
    "    print(f\"👥 Target Market: {response.object['target_market']}\")\n",
    "    print(f\"⭐ Unique Value Proposition: {response.object['unique_value_proposition']}\")\n",
    "    print(f\"💰 Revenue Streams: {', '.join(response.object['revenue_streams'])}\")\n",
    "    print(f\"💵 Startup Costs: {response.object['startup_costs']}\")\n",
    "    print(\"🔑 Key Success Factors:\")\n",
    "    for factor in response.object['key_success_factors']:\n",
    "        print(f\"  - {factor}\")\n",
    "\n",
    "# ---- En Jupyter: usa await (NO asyncio.run) ----\n",
    "await structured_output_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d65a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ibm-watsonx-ai python-dotenv\n",
    "from os import getenv\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=\"meta-llama/llama-4-maverick-17b-128e-instruct-fp8\",\n",
    "    credentials=Credentials(\n",
    "        url=getenv(\"WATSONX_URL\"),\n",
    "        api_key=getenv(\"WATSONX_API_KEY\"),\n",
    "    ),\n",
    "    project_id=getenv(\"WATSONX_PROJECT_ID\"),\n",
    "    params={\"temperature\": 0, \"max_new_tokens\": 8192},\n",
    ")\n",
    "\n",
    "resp = model.generate(prompt=\"[Tu catálogo Costa Rica aquí]\")\n",
    "print(resp[\"results\"][0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900bd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d4c86e5",
   "metadata": {},
   "source": [
    "## Get the Catalogues with Landing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f51e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from landingai_ade import LandingAIADE\n",
    "# Load environment variables \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF PATH\n",
    "pdf_path = \"./pdfs/Catalogues/\"\n",
    "pdf_file_name = \"Mena 2014 51-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bb7d5",
   "metadata": {},
   "source": [
    "## Parse Doc using Landing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the document\n",
    "response = LandingAIADE().parse(document_url=pdf_path+pdf_file_name+\".pdf\",model=\"dpt-2-latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6588154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Extracted Markdown:\")\n",
    "print(response.markdown)\n",
    "print(\"Extracted Chunks:\")\n",
    "print(response.chunks)\n",
    "\n",
    "# Save Markdown to a file\n",
    "if response.markdown:\n",
    "    with open(f'results/parsed_catalogues/{pdf_file_name}.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(response.markdown)\n",
    "    print(\"\\nMarkdown content saved to a Markdown file.\")\n",
    "else:\n",
    "    print(\"No 'markdown' field found in the response\")\n",
    "    \n",
    "# Save Chunks to a JSON file\n",
    "if response.chunks:\n",
    "    # Convertir chunks a diccionarios para serialización JSON\n",
    "    chunks_data = [chunk.model_dump() for chunk in response.chunks]\n",
    "    \n",
    "    with open(f'results/parsed_catalogues/{pdf_file_name}_chunks.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunks_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n{len(chunks_data)} chunks saved to JSON file.\")\n",
    "else:\n",
    "    print(\"No 'chunks' field found in the response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a6751",
   "metadata": {},
   "source": [
    "### Leyendo el archivo de Landing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chunks = []\n",
    "with open(f'results/parsed_catalogues/{pdf_file_name}_chunks.json', 'r', encoding='utf-8') as f:\n",
    "    chunks_data = json.load(f)\n",
    "    print(f\"Se cargaron {len(chunks_data)} chunks desde el archivo JSON.\\n\")\n",
    "    group_chunks = chunks_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39282f",
   "metadata": {},
   "source": [
    "### Logica para agrupar Mena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chunk_text(text: str) -> str:\n",
    "    \"\"\"Clean markdown and formatting artifacts\"\"\"\n",
    "    # Remove anchor tags\n",
    "    text = re.sub(r'<a id=[\\'\"][^\\'\"]+[\\'\"]></a>', '', text)\n",
    "    return text\n",
    "\n",
    "def get_header(texto):\n",
    "    patron_1 = r'\\n\\n(.*?)\\n'\n",
    "    match = re.search(patron_1, texto)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    \n",
    "    patron_2 = r'\\n\\n\\*\\*(.*?)\\*\\*' ##\\n\\n**Plasma Technology Export issue**\n",
    "    match = re.search(patron_2, texto)\n",
    "    if match:\n",
    "        return match.group(1).strip()    \n",
    "    \n",
    "    return None\n",
    "\n",
    "def has_year(texto):\n",
    "    \"\"\"\n",
    "    Detecta si el texto contiene años entre 1862 y 2025\n",
    "    Devuelve True si encuentra al menos un año, False si no\n",
    "    \"\"\"\n",
    "    # Buscar todos los números de 4 dígitos\n",
    "    patron = r'\\b(18[6-9]\\d|19\\d{2}|20[0-1]\\d|202[0-5])\\b'\n",
    "    match = re.search(patron, texto)\n",
    "    return match is not None\n",
    "\n",
    "def has_issue(texto):\n",
    "    \"\"\"\n",
    "    Retorna True si contiene \"issue\" pero NO si es \"regular issue\"\n",
    "    \"\"\"\n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    # Si contiene \"regular issue\", retornar False\n",
    "    if \"regular issue\" in texto_lower:\n",
    "        return False\n",
    "    \n",
    "    # Si contiene \"issue\" (pero ya sabemos que no es \"regular issue\")\n",
    "    return \"issue\" in texto_lower\n",
    "def has_guanacaste_type(texto):\n",
    "    texto_lower = texto.lower()\n",
    "    return \"guanacaste type\" in texto_lower\n",
    "\n",
    "def has_prestamp_postmark(texto):\n",
    "    texto_lower = texto.lower()\n",
    "    return \"pre stamp postmark\" in texto_lower\n",
    "\n",
    "def has_receptoria(texto):\n",
    "    texto_lower = texto.lower()\n",
    "    return \"receptoria\" in texto_lower\n",
    "def has_postal_related_revenue(texto):\n",
    "    texto_lower = texto.lower()\n",
    "    return \"postal related revenue\" in texto_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_texto_entre_marcadores(texto):\n",
    "    \"\"\"\n",
    "    Elimina todo el texto que esté entre <:: y ::>\n",
    "    \"\"\"\n",
    "    # Patrón para encontrar <:: cualquier texto ::>\n",
    "    # El ? hace que sea no-greedy (no codicioso)\n",
    "    patron = r'<::.*?::>'\n",
    "    \n",
    "    # Reemplaza todas las ocurrencias con cadena vacía\n",
    "    texto_limpio = re.sub(patron, '', texto, flags=re.DOTALL)\n",
    "    \n",
    "    return texto_limpio\n",
    "\n",
    "def extraer_texto_entre_marcadores(texto):\n",
    "    \"\"\"\n",
    "    Extrae todo el texto que esté entre <:: y ::>\n",
    "    Retorna una lista con todos los textos encontrados\n",
    "    \"\"\"\n",
    "    # Patrón para encontrar <:: cualquier texto ::>\n",
    "    patron = r'<::(.*?)::>'\n",
    "    \n",
    "    # Encuentra todas las coincidencias\n",
    "    textos_extraidos = re.findall(patron, texto, flags=re.DOTALL)\n",
    "    \n",
    "    return textos_extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_chunks = []\n",
    "# with open(f'results/parsed_catalogues/{pdf_file_name}_chunks.json', 'r', encoding='utf-8') as f:\n",
    "#     chunks_data = json.load(f)\n",
    "#     print(f\"Se cargaron {len(chunks_data)} chunks desde el archivo JSON.\\n\")\n",
    "#     group_chunks = chunks_data\n",
    "\n",
    "\n",
    "# grouped_chunks = []\n",
    "# current_group = None\n",
    "\n",
    "# special_cases_1_50 = ['Overprint \"Correos\" on revenue stamps',\"Issue of 1903\",'Surcharges on 1923 stamps','Surcharge on 1923 stamp','**Bar Cancels**','**\"Un Centimo\" Surcharge**','Surcharge \"Correos/5 Centimos\"','Overprint \"Compre Ud. Cafe de Costa Rica\" in circle']\n",
    "# special_cases_51_100 = ['Surcharge on Mauro Fernandez stamp',\"Surcharges on revenue stamps\",'Surcharges on Christmas tax stamps','**Heroes 1856 Campaign issue**','**Orchids issue**']\n",
    "# keywords = [\"ELECTORAL STAMPS\", \"TELEGRAPH SEALS\", \"RADIOGRAM SEALS\", \n",
    "#             \"MISCELLANEOUS\", \"UNAPPROVED ESSAYS\", \n",
    "#             \"INTERNATIONAL REPLY COUPONS\", \"NON OFFICIAL\",\n",
    "#             \"OFFICIAL POSTAL SEALS\", \"REGISTRATION LABELS\",\"ROSS FANTASIES\",\"First Issue Fantasies\",\"1901 Overprint Fantasy\"]\n",
    "# for i, chunk in enumerate(chunks_data):\n",
    "    \n",
    "#     is_text_or_table = chunk.get('type') in [\"text\",\"table\"]\n",
    "#     is_fig= chunk.get('type') in [\"figure\"]\n",
    "#     chunk_text = clean_chunk_text(chunk.get('markdown', 'N/A'))\n",
    "#     chunk_page = chunk.get('grounding', 'N/A')['page']\n",
    "    \n",
    "#     # Verificar si es un header válido\n",
    "#     header_found = None\n",
    "#     if is_text_or_table and chunk_text.startswith(\"\\n\\n\"):\n",
    "#         chunk_text = chunk_text.replace(\"\\n\\nHR Mena                                 SURFACE MAIL                                Costa Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "#         chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "#         chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL Costa Rica Post\\n\",\"\\n\\n\") ##BUG FIX     \n",
    "#         chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\n\\nSURFACE MAIL\\n\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX    \n",
    "#         header_candidate = get_header(chunk_text)\n",
    "#         if header_candidate:\n",
    "#             # Validar que no sea uno de los casos excluidos\n",
    "#             if header_candidate.lower() == \"costa rica postal catalogue\":\n",
    "#                 pass\n",
    "#             elif \"Essay\" in header_candidate: ##UN BUG\n",
    "#                     pass\n",
    "#             elif \"Essays,\" in header_candidate: ##UN BUG\n",
    "#                 pass\n",
    "#             elif \"Decree,\" in header_candidate: ##UN BUG\n",
    "#                 pass\n",
    "#             elif \"Decree\" in header_candidate: ##UN BUG\n",
    "#                 pass\n",
    "#             elif \"All stamps\" in header_candidate: ##UN BUG\n",
    "#                 pass\n",
    "#             elif has_guanacaste_type(header_candidate): ##CASO GUANACASTE TYPES\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif has_prestamp_postmark(header_candidate): ##CASO PRE STAMP POSTMARK\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif has_receptoria(header_candidate): ##CASO RECEPTORIA\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif has_postal_related_revenue(header_candidate): ##CASO POSTAL RELATED REVENUE\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif any(keyword in header_candidate for keyword in keywords):\n",
    "#                 header_found = header_candidate\n",
    "#                 print(f\"{header_candidate} --> in page: {chunk_page}\")                  \n",
    "#             elif header_candidate in special_cases_1_50: ##CASO ESPECIAL 1-50\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif header_candidate in special_cases_51_100: ##CASO ESPECIAL 51-100\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif has_year(header_candidate) or has_issue(header_candidate):\n",
    "#                 if len(header_candidate) > 10: ##CONSIDERARLO\n",
    "#                     pass\n",
    "#                 header_found = header_candidate\n",
    "#                 print(header_candidate,\"--> in page:\",chunk_page)\n",
    "#             elif len(header_candidate) > 5: ## ESTO NO ES UN HEADER\n",
    "#                 pass\n",
    "#     if is_fig and chunk_text.startswith(\"\\n\\n\"):\n",
    "#         plain_fig = chunk_text.startswith(\"\\n\\n<::\")\n",
    "#         if not plain_fig:            \n",
    "#             chunk_text = chunk_text.replace(\"\\n\\nHR Mena                                 SURFACE MAIL                                Costa Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "#             chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX     \n",
    "#             header_candidate = get_header(chunk_text) \n",
    "#             if header_candidate:\n",
    "#                 if has_year(header_candidate) or has_issue(header_candidate):\n",
    "#                     if len(header_candidate) > 10: ##CONSIDERARLO\n",
    "#                         pass\n",
    "#                     header_found = header_candidate\n",
    "#                     print(header_candidate,\"--> in page:\",chunk_page) \n",
    "\n",
    "#     # Si encontramos un header válido\n",
    "#     if header_found:\n",
    "#         # Guardar el grupo anterior si existe\n",
    "#         if current_group is not None:\n",
    "#             grouped_chunks.append(current_group)\n",
    "        \n",
    "#         # Crear un nuevo grupo con este header\n",
    "#         current_group = {\n",
    "#             \"header\": header_found,\n",
    "#             \"chunks\": [chunk]\n",
    "#         }\n",
    "#     else:\n",
    "#         # Si no es header, agregar al grupo actual (si existe)\n",
    "#         if current_group is not None:\n",
    "#             current_group[\"chunks\"].append(chunk)\n",
    "\n",
    "# # No olvidar agregar el último grupo\n",
    "# if current_group is not None:\n",
    "#     grouped_chunks.append(current_group)\n",
    "\n",
    "# # Ahora grouped_chunks contiene todos los grupos\n",
    "# print(f\"\\nTotal de grupos creados: {len(grouped_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_chunks(group_chunks):\n",
    "    grouped_chunks = []\n",
    "    current_group = None\n",
    "\n",
    "    special_cases_1_50 = ['Overprint \"Correos\" on revenue stamps',\"Issue of 1903\",'Surcharges on 1923 stamps','Surcharge on 1923 stamp','**Bar Cancels**','**\"Un Centimo\" Surcharge**','Surcharge \"Correos/5 Centimos\"','Overprint \"Compre Ud. Cafe de Costa Rica\" in circle']\n",
    "    special_cases_51_100 = ['Surcharge on Mauro Fernandez stamp',\"Surcharges on revenue stamps\",'Surcharges on Christmas tax stamps','**Heroes 1856 Campaign issue**','**Orchids issue**']\n",
    "    keywords = [\"ELECTORAL STAMPS\", \"TELEGRAPH SEALS\", \"RADIOGRAM SEALS\", \n",
    "                \"MISCELLANEOUS\", \"UNAPPROVED ESSAYS\", \n",
    "                \"INTERNATIONAL REPLY COUPONS\", \"NON OFFICIAL\",\n",
    "                \"OFFICIAL POSTAL SEALS\", \"REGISTRATION LABELS\",\"ROSS FANTASIES\",\"First Issue Fantasies\",\"1901 Overprint Fantasy\"]\n",
    "    for i, chunk in enumerate(group_chunks):\n",
    "        \n",
    "        is_text_or_table = chunk.get('type') in [\"text\",\"table\"]\n",
    "        is_fig= chunk.get('type') in [\"figure\"]\n",
    "        chunk_text = clean_chunk_text(chunk.get('markdown', 'N/A'))\n",
    "        chunk_page = chunk.get('grounding', 'N/A')['page']\n",
    "        \n",
    "        # Verificar si es un header válido\n",
    "        header_found = None\n",
    "        if is_text_or_table and chunk_text.startswith(\"\\n\\n\"):\n",
    "            chunk_text = chunk_text.replace(\"\\n\\nHR Mena                                 SURFACE MAIL                                Costa Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "            chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "            chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL Costa Rica Post\\n\",\"\\n\\n\") ##BUG FIX     \n",
    "            chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\n\\nSURFACE MAIL\\n\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX    \n",
    "            header_candidate = get_header(chunk_text)\n",
    "            if header_candidate:\n",
    "                # Validar que no sea uno de los casos excluidos\n",
    "                if header_candidate.lower() == \"costa rica postal catalogue\":\n",
    "                    pass\n",
    "                elif \"Essay\" in header_candidate: ##UN BUG\n",
    "                        pass\n",
    "                elif \"Essays,\" in header_candidate: ##UN BUG\n",
    "                    pass\n",
    "                elif \"Decree,\" in header_candidate: ##UN BUG\n",
    "                    pass\n",
    "                elif \"Decree\" in header_candidate: ##UN BUG\n",
    "                    pass\n",
    "                elif \"All stamps\" in header_candidate: ##UN BUG\n",
    "                    pass\n",
    "                elif has_guanacaste_type(header_candidate): ##CASO GUANACASTE TYPES\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif has_prestamp_postmark(header_candidate): ##CASO PRE STAMP POSTMARK\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif has_receptoria(header_candidate): ##CASO RECEPTORIA\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif has_postal_related_revenue(header_candidate): ##CASO POSTAL RELATED REVENUE\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif any(keyword in header_candidate for keyword in keywords):\n",
    "                    header_found = header_candidate\n",
    "                    #print(f\"{header_candidate} --> in page: {chunk_page}\")                  \n",
    "                elif header_candidate in special_cases_1_50: ##CASO ESPECIAL 1-50\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif header_candidate in special_cases_51_100: ##CASO ESPECIAL 51-100\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif has_year(header_candidate) or has_issue(header_candidate):\n",
    "                    if len(header_candidate) > 10: ##CONSIDERARLO\n",
    "                        pass\n",
    "                    header_found = header_candidate\n",
    "                    #print(header_candidate,\"--> in page:\",chunk_page)\n",
    "                elif len(header_candidate) > 5: ## ESTO NO ES UN HEADER\n",
    "                    pass\n",
    "        if is_fig and chunk_text.startswith(\"\\n\\n\"):\n",
    "            plain_fig = chunk_text.startswith(\"\\n\\n<::\")\n",
    "            if not plain_fig:            \n",
    "                chunk_text = chunk_text.replace(\"\\n\\nHR Mena                                 SURFACE MAIL                                Costa Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX\n",
    "                chunk_text = chunk_text.replace(\"\\n\\nHR Mena\\nSURFACE MAIL\\nCosta Rica Postal Catalogue\\n\\n\",\"\\n\\n\") ##BUG FIX     \n",
    "                header_candidate = get_header(chunk_text) \n",
    "                if header_candidate:\n",
    "                    if has_year(header_candidate) or has_issue(header_candidate):\n",
    "                        if len(header_candidate) > 10: ##CONSIDERARLO\n",
    "                            pass\n",
    "                        header_found = header_candidate\n",
    "                        #print(header_candidate,\"--> in page:\",chunk_page) \n",
    "\n",
    "        # Si encontramos un header válido\n",
    "        if header_found:\n",
    "            # Guardar el grupo anterior si existe\n",
    "            if current_group is not None:\n",
    "                grouped_chunks.append(current_group)\n",
    "            \n",
    "            # Crear un nuevo grupo con este header\n",
    "            current_group = {\n",
    "                \"header\": header_found,\n",
    "                \"chunks\": [chunk]\n",
    "            }\n",
    "        else:\n",
    "            # Si no es header, agregar al grupo actual (si existe)\n",
    "            if current_group is not None:\n",
    "                current_group[\"chunks\"].append(chunk)\n",
    "\n",
    "    # No olvidar agregar el último grupo\n",
    "    if current_group is not None:\n",
    "        grouped_chunks.append(current_group)\n",
    "\n",
    "    # Ahora grouped_chunks contiene todos los grupos\n",
    "    print(f\"\\nTotal de grupos creados: {len(grouped_chunks)}\")\n",
    "    \n",
    "    return grouped_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b91dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"results/parsed_catalogues/\"\n",
    "\n",
    "# Obtener lista de archivos que cumplen los criterios\n",
    "archivos_mena = [\n",
    "    archivo for archivo in os.listdir(pdf_path)\n",
    "    if archivo.startswith(\"Mena 2014\") and archivo.endswith(\".json\")\n",
    "]\n",
    "\n",
    "print(archivos_mena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_mena = ['Mena 2014 1-50_chunks.json', 'Mena 2014 51-100_chunks.json', 'Mena 2014 101-150_chunks.json', 'Mena 2014 151-200_chunks.json', 'Mena 2014 201-250_chunks.json', 'Mena 2014 251-300_chunks.json', 'Mena 2014 301-315_chunks.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_grouped_chunks = []\n",
    "for mena_chunks_file in archivos_mena:\n",
    "    group_chunks = []\n",
    "    with open(f'results/parsed_catalogues/{mena_chunks_file}', 'r', encoding='utf-8') as f:\n",
    "        chunks_data = json.load(f)\n",
    "        group_chunks = chunks_data\n",
    "    mena_file_groups = get_grouped_chunks(group_chunks)\n",
    "    total_grouped_chunks.extend(mena_file_groups)\n",
    "    print(mena_chunks_file,\"-->\",len(mena_file_groups))\n",
    "print(\"Total Grouped Chunks:\",len(total_grouped_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04266695",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_text = \"\"\n",
    "for grouped_chunk in total_grouped_chunks[0:1]:\n",
    "    #print(grouped_chunk['header'])\n",
    "    chunks = grouped_chunk['chunks']\n",
    "    final_text = \"\"\n",
    "    for chunk in chunks:\n",
    "        if chunk['type'] == 'attestation' or chunk['type'] == 'marginalia':\n",
    "            pass\n",
    "        else:\n",
    "            final_text += clean_chunk_text(chunk['markdown'])\n",
    "    print(\"------- TEXTO FIGURAS ----------\")\n",
    "    print(extraer_texto_entre_marcadores(final_text))\n",
    "    print(\"------- PLAIN TEXT -------------\")\n",
    "    final_test_text = eliminar_texto_entre_marcadores(final_text)\n",
    "    print(final_test_text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e45782",
   "metadata": {},
   "source": [
    "### Logica de Agrupamiento Scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def _clean_chunk_text(text: str) -> str:\n",
    "    \"\"\"Clean markdown and formatting artifacts\"\"\"\n",
    "    # Remove anchor tags\n",
    "    text = re.sub(r'<a id=[\\'\"][^\\'\"]+[\\'\"]></a>\\n*', '', text)\n",
    "    # Remove figure markup but keep content\n",
    "    #text = re.sub(r'<::(.*?)::>', r'\\1', text, flags=re.DOTALL)\n",
    "    # Clean excessive whitespace\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d16d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from icecream import ic\n",
    "# for i,group_chunk in enumerate(group_chunks):\n",
    "#     if len(group_chunk) == 1:\n",
    "#         print(\"Group Number \",i)\n",
    "#         for chunk in group_chunk:\n",
    "#             print(\"SOLUTION\")\n",
    "#             chunk_solution = group_chunks[i-1][-1]\n",
    "#             print(f\"Tipo: {chunk_solution.get('type', 'N/A')}\")\n",
    "#             print(f\"Texto: {_clean_chunk_text(chunk_solution.get('markdown', 'N/A'))}\")\n",
    "#             print(f\"Página: {chunk_solution.get('grounding', 'N/A')['page']}\")\n",
    "#             print(\"-------END SOLUTION----------\")\n",
    "#             print()                \n",
    "#             print(f\"Tipo: {chunk.get('type', 'N/A')}\")\n",
    "#             print(f\"Texto: {_clean_chunk_text(chunk.get('markdown', 'N/A'))}\")\n",
    "#             print(f\"Página: {chunk.get('grounding', 'N/A')['page']}\")\n",
    "#             print(\"---------------\")\n",
    "#         print(\"****************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62298fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "# Crear el nuevo arreglo fusionado\n",
    "group_chunks_merged = []\n",
    "\n",
    "for i, group_chunk in enumerate(group_chunks):\n",
    "    # Si es el primer grupo, simplemente lo agregamos\n",
    "    if i == 0:\n",
    "        group_chunks_merged.append(group_chunk[:])  # Copia del grupo\n",
    "    # Si el grupo actual tiene solo 1 elemento\n",
    "    elif len(group_chunk) == 1:\n",
    "        # Obtenemos el grupo anterior del nuevo arreglo (ya procesado)\n",
    "        previous_group = group_chunks_merged[-1]\n",
    "        \n",
    "        # Si el grupo anterior tiene elementos\n",
    "        if len(previous_group) > 0:\n",
    "            # Extraemos el último elemento del grupo anterior\n",
    "            chunk_solution = previous_group[-1]\n",
    "            \n",
    "            # Removemos ese elemento del grupo anterior en el nuevo arreglo\n",
    "            group_chunks_merged[-1] = previous_group[:-1]\n",
    "            \n",
    "            # Creamos el nuevo grupo fusionado: [chunk_solution, chunk_actual]\n",
    "            merged_group = [chunk_solution, group_chunk[0]]\n",
    "            group_chunks_merged.append(merged_group)\n",
    "            \n",
    "            print(f\"✓ Grupo {i} fusionado con último elemento del grupo {i-1}\")\n",
    "        else:\n",
    "            # Si el grupo anterior ya está vacío, solo agregamos el actual\n",
    "            group_chunks_merged.append(group_chunk[:])\n",
    "    else:\n",
    "        # Si tiene más de 1 elemento, lo agregamos tal cual\n",
    "        group_chunks_merged.append(group_chunk[:])\n",
    "\n",
    "# Limpiamos grupos vacíos si existen\n",
    "group_chunks_merged = [group for group in group_chunks_merged if len(group) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0af7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "for i,group_chunk in enumerate(group_chunks_merged[0:30]):    \n",
    "    print(\"Group Number \",i)\n",
    "    for chunk in group_chunk:\n",
    "        print(f\"Tipo: {chunk.get('type', 'N/A')}\")\n",
    "        print(f\"Texto: {_clean_chunk_text(chunk.get('markdown', 'N/A'))}\")\n",
    "        print(f\"Página: {chunk.get('grounding', 'N/A')['page']}\")\n",
    "        print(\"---------------\")\n",
    "    print(\"****************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9dce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_chunks_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b9be8",
   "metadata": {},
   "source": [
    "## Parseando el Catalogo Scott con LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86714d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your stamp models (assuming they're in a file called 'kg_pydantic.py')\n",
    "# from stamp_models import ScottEntry, ScottNumber, Denomination, ColorDescription, Perforation, MonetaryValue, PrintingMethod, StampType, PaperType\n",
    "from kg_pydantic import *\n",
    "# Load environment variables \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simplified Scott Catalog Parser with Direct Examples\n",
    "This version uses a more straightforward approach with explicit examples\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "\n",
    "class SimpleScottParser:\n",
    "    \"\"\"Simplified parser that works with direct examples\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, model_name: str = \"gpt-4o-mini\"):\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=0.0,\n",
    "            model_name=model_name,\n",
    "            openai_api_key=openai_api_key,\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        \n",
    "        # Use JSON output parser instead of Pydantic\n",
    "        self.output_parser = JsonOutputParser()\n",
    "        \n",
    "        # Create the chain\n",
    "        self.chain = self._create_chain()\n",
    "    \n",
    "    def parse_chunk(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse a chunk of catalog text\"\"\"\n",
    "        \n",
    "        # Clean the text\n",
    "        # text = re.sub(r'<a id=[\\'\"][^\\'\"]+[\\'\"]></a>\\n*', '', text)\n",
    "        # text = re.sub(r'<::(.*?)::>', r'\\1', text, flags=re.DOTALL)\n",
    "        # text = text.strip()\n",
    "        \n",
    "        try:\n",
    "            with get_openai_callback() as cb:\n",
    "                result = self.chain.invoke({\"input\": text})\n",
    "                print(\"Prompt tokens:\", cb.prompt_tokens)\n",
    "                print(\"Completion tokens:\", cb.completion_tokens)\n",
    "                print(\"Total tokens:\", cb.total_tokens)\n",
    "                print(\"Costo (USD):\", cb.total_cost)\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            print(f\"Parsing error: {e}\")\n",
    "            return {\"stamps\": [], \"error\": str(e)}\n",
    "    \n",
    "    def _create_chain(self):\n",
    "        \"\"\"Create the parsing chain with explicit examples\"\"\"\n",
    "        \n",
    "        # Define examples with exact input/output\n",
    "        examples = [\n",
    "            {\n",
    "                \"input\": \"\"\"1889 Black Overprint\n",
    "23 A8 1c rose     5.00 3.00\n",
    "24 A9 5c brown    7.00 3.00\n",
    "Vertical and inverted overprints are fakes.\"\"\",\n",
    "                \"output\": json.dumps({\n",
    "                    \"stamps\": [\n",
    "                        {\n",
    "                            \"scott_number\": \"23\",\n",
    "                            \"illustration\": \"A8\",\n",
    "                            \"denomination\": \"1c\",\n",
    "                            \"color\": \"rose\",\n",
    "                            \"mint_value\": 5.00,\n",
    "                            \"used_value\": 3.00\n",
    "                        },\n",
    "                        {\n",
    "                            \"scott_number\": \"24\",\n",
    "                            \"illustration\": \"A9\",\n",
    "                            \"denomination\": \"5c\",\n",
    "                            \"color\": \"brown\",\n",
    "                            \"mint_value\": 7.00,\n",
    "                            \"used_value\": 3.00\n",
    "                        }\n",
    "                    ],\n",
    "                    \"header\": \"1889 Black Overprint\",\n",
    "                    \"notes\": [\"Vertical and inverted overprints are fakes.\"]\n",
    "                }, indent=2)\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"\"\"1901, Jan.                                Perf. 12-15½\n",
    "45 A30    1c green & blk                  3.25    .30\n",
    "a.        Horiz. pair, imperf. btwn.      150.00\n",
    "46 A31    2c ver & blk                    1.25    .30\"\"\",\n",
    "                \"output\": json.dumps({\n",
    "                    \"stamps\": [\n",
    "                        {\n",
    "                            \"scott_number\": \"45\",\n",
    "                            \"illustration\": \"A30\",\n",
    "                            \"denomination\": \"1c\",\n",
    "                            \"color\": \"green & blk\",\n",
    "                            \"mint_value\": 3.25,\n",
    "                            \"used_value\": 0.30,\n",
    "                            \"perforation\": \"12-15½\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"scott_number\": \"45a\",\n",
    "                            \"variety_of\": \"45\",\n",
    "                            \"description\": \"Horiz. pair, imperf. btwn.\",\n",
    "                            \"mint_value\": 150.00\n",
    "                        },\n",
    "                        {\n",
    "                            \"scott_number\": \"46\",\n",
    "                            \"illustration\": \"A31\",\n",
    "                            \"denomination\": \"2c\",\n",
    "                            \"color\": \"ver & blk\",\n",
    "                            \"mint_value\": 1.25,\n",
    "                            \"used_value\": 0.30,\n",
    "                            \"perforation\": \"12-15½\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"header\": \"1901, Jan.\",\n",
    "                    \"perforation\": \"Perf. 12-15½\"\n",
    "                }, indent=2)\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"\"\"<::A dark-colored postage stamp with a portrait of a man with a mustache in the center. The stamp has \"CORREOS\" and \"COSTA RICA\" written in a circular pattern around the portrait. The number \"5\" is visible in the top left and bottom right corners, and \"CENTAVOS\" is at the bottom. The stamp has perforated edges. : postage stamp::>\n",
    "President Bernardo Soto Alfaro — A7\"\"\",\n",
    "                \"output\": json.dumps({\n",
    "                    \"stamps\": [],\n",
    "                    \"illustrations\": [\n",
    "                        {\n",
    "                            \"illustration_number\": \"A7\",\n",
    "                            \"design_name\": \"President Bernardo Soto Alfaro\",\n",
    "                            \"design_description\": \"A dark-colored postage stamp with a portrait of a man with a mustache in the center. The stamp has \\\"CORREOS\\\" and \\\"COSTA RICA\\\" written in a circular pattern around the portrait. The number \\\"5\\\" is visible in the top left and bottom right corners, and \\\"CENTAVOS\\\" is at the bottom. The stamp has perforated edges.\",\n",
    "                            \"denomination\": \"5 CENTAVOS\"\n",
    "                        }\n",
    "                    ]\n",
    "                }, indent=2)\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"\"\"<::A collection of six postage stamps, each featuring a portrait of President Soto Alfaro. The stamps are arranged in two columns. Top row: - Left stamp (A10): A brown stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"1 CENTAVO\" at the bottom, with the number \"1\" in the upper corners. - Right stamp (A11): A greenish-blue stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"2 CENTAVOS\" at the bottom, with the number \"2\" in the upper corners. Middle row: - Left stamp (A12): A reddish-orange stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"5 CENTAVOS\" at the bottom, with the number \"5\" in the upper corners. - Right stamp (A13): A reddish-orange stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"10 CENTAVOS\" at the bottom, with the number \"10\" in the upper corners. Bottom row: - Left stamp (A14): A green stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"20 CENTAVOS\" at the bottom, with the number \"20\" in the upper corners. - Right stamp (A15): A reddish-orange stamp with a portrait of a man, labeled \"COSTA RICA\" at the top and \"50 CENTAVOS\" at the bottom, with the number \"50\" in the upper corners. : figure::>\"\"\",\n",
    "                \"output\": json.dumps({\n",
    "                    \"stamps\": [],\n",
    "                    \"illustrations\": [\n",
    "                        {\n",
    "                            \"illustration_number\": \"A10\",\n",
    "                            \"design_description\": \"A brown stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"1 CENTAVO\",\n",
    "                            \"color\": \"brown\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"illustration_number\": \"A11\",\n",
    "                            \"design_description\": \"A greenish-blue stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"2 CENTAVOS\",\n",
    "                            \"color\": \"greenish-blue\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"illustration_number\": \"A12\",\n",
    "                            \"design_description\": \"A reddish-orange stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"5 CENTAVOS\",\n",
    "                            \"color\": \"reddish-orange\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"illustration_number\": \"A13\",\n",
    "                            \"design_description\": \"A reddish-orange stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"10 CENTAVOS\",\n",
    "                            \"color\": \"reddish-orange\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"illustration_number\": \"A14\",\n",
    "                            \"design_description\": \"A green stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"20 CENTAVOS\",\n",
    "                            \"color\": \"green\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"illustration_number\": \"A15\",\n",
    "                            \"design_description\": \"A reddish-orange stamp with a portrait of President Soto Alfaro\",\n",
    "                            \"denomination\": \"50 CENTAVOS\",\n",
    "                            \"color\": \"reddish-orange\"\n",
    "                        }\n",
    "                    ]\n",
    "                }, indent=2)\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Create the few-shot prompt\n",
    "        example_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\")\n",
    "        ])\n",
    "        \n",
    "        few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=example_prompt,\n",
    "            examples=examples,\n",
    "        )\n",
    "        \n",
    "        # Final prompt\n",
    "        final_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "    You are a Scott catalog parser. Extract stamp information and illustration descriptions from catalog text.\n",
    "\n",
    "    CONTENT TYPES:\n",
    "    1. STAMP ENTRIES: Lines starting with numbers (45, 46, 47) containing catalog data\n",
    "    2. VARIETIES: Lines starting with letters (a., b., c.) that modify the stamp above\n",
    "    3. ILLUSTRATIONS: Text within <::...::> describes stamp images, often followed by illustration numbers (A7, A10, etc.)\n",
    "\n",
    "    RULES FOR STAMPS:\n",
    "    - Main stamps start with numbers\n",
    "    - Format: [number] [illustration] [denomination] [color] [mint_price] [used_price]\n",
    "    - Multi-line entries continue from above\n",
    "    - Prices: \"3.25 .30\" = mint $3.25, used $0.30\n",
    "    - Dash (—) = no price\n",
    "\n",
    "    RULES FOR ILLUSTRATIONS:\n",
    "    - Text between <:: and ::> is a design description\n",
    "    - Look for illustration numbers (A10, A11) within or after the description\n",
    "    - Extract denomination and color when mentioned\n",
    "    - May describe single or multiple stamps\n",
    "\n",
    "    EXAMPLE COLOR ABBREVIATIONS:\n",
    "    blk=black, grn=green, ver=vermillion, lil=lilac, ol=olive, bis=bistre, car=carmine, yel=yellow, brn=brown, dk=dark\n",
    "\n",
    "    ALWAYS return valid JSON with the keys: \"stamps\", \"illustrations\", \"header\" and \"notes\" .\n",
    "    Example of JSON for return:\n",
    "\n",
    "    \"stamps\": [],        // If there are stamps if not empty\n",
    "    \"illustrations\": [], // If there are illustrations if not empty\n",
    "    \"header\": \"1901, Jan.\",  //Always if is possible \n",
    "    \"notes\": [\"....\"] //Always if there are notes if not empty\n",
    "\n",
    "\n",
    "\"\"\"),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        return final_prompt | self.llm | self.output_parser\n",
    "    \n",
    "    def parse_and_display(self, text: str):\n",
    "        \"\"\"Parse and display results in a readable format\"\"\"\n",
    "        \n",
    "        # print(\"INPUT TEXT:\")\n",
    "        # print(\"-\" * 60)\n",
    "        # print(text[:500] + \"...\" if len(text) > 500 else text)\n",
    "        # print(\"-\" * 60)\n",
    "        \n",
    "        result = self.parse_chunk(text)\n",
    "        print(result)\n",
    "                \n",
    "        print(\"\\nPARSING RESULTS:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            print(f\"ERROR: {result['error']}\")\n",
    "            return result\n",
    "        \n",
    "        # Display stamps\n",
    "        stamps = result.get(\"stamps\", [])\n",
    "        if stamps:\n",
    "            print(f\"Found {len(stamps)} stamps:\\n\")\n",
    "            \n",
    "            for stamp in stamps:\n",
    "                if stamp.get(\"variety_of\"):\n",
    "                    print(f\"  └─ #{stamp['scott_number']}: {stamp.get('description', 'Variety')}\")\n",
    "                    if stamp.get('mint_value'):\n",
    "                        print(f\"      Value: ${stamp['mint_value']}\")\n",
    "                else:\n",
    "                    print(f\"#{stamp['scott_number']} ({stamp.get('illustration', 'N/A')}): \"\n",
    "                         f\"{stamp.get('denomination', '')} {stamp.get('color', '')}\")\n",
    "                    if stamp.get('mint_value'):\n",
    "                        print(f\"  Values: ${stamp['mint_value']} mint / \"\n",
    "                             f\"${stamp.get('used_value', 'N/A')} used\")\n",
    "        \n",
    "        # Display illustrations\n",
    "        illustrations = result.get(\"illustrations\", [])\n",
    "        if illustrations:\n",
    "            print(f\"\\nFound {len(illustrations)} illustration descriptions:\\n\")\n",
    "            \n",
    "            for illus in illustrations:\n",
    "                print(f\"Illustration {illus['illustration_number']}:\")\n",
    "                if illus.get('design_name'):\n",
    "                    print(f\"  Name: {illus['design_name']}\")\n",
    "                if illus.get('denomination'):\n",
    "                    print(f\"  Denomination: {illus['denomination']}\")\n",
    "                if illus.get('color'):\n",
    "                    print(f\"  Color: {illus['color']}\")\n",
    "                desc = illus.get('design_description', '')\n",
    "                if desc:\n",
    "                    # Truncate long descriptions for display\n",
    "                    if len(desc) > 100:\n",
    "                        print(f\"  Description: {desc[:100]}...\")\n",
    "                    else:\n",
    "                        print(f\"  Description: {desc}\")\n",
    "        \n",
    "        # Display notes\n",
    "        if result.get(\"notes\"):\n",
    "            print(\"\\nNOTES:\")\n",
    "            for note in result[\"notes\"]:\n",
    "                print(f\"  • {note}\")\n",
    "        \n",
    "        # Display header info\n",
    "        if result.get(\"header\"):\n",
    "            print(f\"\\nHEADER: {result['header']}\")\n",
    "        if result.get(\"perforation\"):\n",
    "            print(f\"PERFORATION: {result['perforation']}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        return result\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_parser():\n",
    "    \"\"\"Test the parser with your actual chunk\"\"\"\n",
    "    \n",
    "    # Your actual chunk text\n",
    "    chunk_text = \"\"\"1881-82\n",
    "Red or Black Surcharge\n",
    "7 A1(a) 1c on ½r ('82) 3.00 6.00\n",
    "a. On No. 1a 15.00 -\n",
    "8 A1(b) 1c on ½r ('82) 18.00 30.00\n",
    "9 A1(c) 2c on ½r, #1a 3.00 2.75\n",
    "a. On No. 1 8.00\n",
    "12 A1(c) 5c on ½r 15.00\n",
    "13 A1(d) 5c on ½r ('82) 35.00\n",
    "14 A1(d) 10c on 2r (Bk)\n",
    "('82) 72.50 -\n",
    "15 A1(e) 20c on 4r ('82) 300.00 -\n",
    "\n",
    "Overprints with different fonts and \"OFICIAL\" were never placed in use, and are said to have been surcharged to a dealer's order. The ½r surcharged \"DOS CTS\" is not a postage stamp. It probably is an essay.\n",
    "Postally used examples of Nos. 7-15 are rare. Nos. 13-15 exist with a favor cancel having a hyphen between \"San\" and \"Jose.\" Values same as unused. Fake cancellations exist.\n",
    "Counterfeits exist of surcharges on Nos. 7-15.\n",
    "---------------\n",
    " stamp of Gen. Prospero Fernández : figure\n",
    "\n",
    "Gen. Prospero\n",
    "Fernández - A6\n",
    "\n",
    "1883, Jan. 1\n",
    "\n",
    "| | | | | |\n",
    "|---|---|---|---|---|\n",
    "| 16 | A6 | 1c green | 3.00 | 1.50 |\n",
    "| 17 | A6 | 2c carmine | 3.25 | 1.50 |\n",
    "| 18 | A6 | 5c blue violet | 32.50 | 2.00 |\n",
    "| 19 | A6 | 10c orange | 150.00 | 12.00 |\n",
    "| 20 | A6 | 40c blue | 3.00 | 3.00 |\n",
    "| Nos. 16-20 (5) | | | 191.75 | 20.00 |\n",
    "\n",
    "Unused examples of 40c usually lack gum.\n",
    "For overprints see Nos. O1-O20, O24,\n",
    "Guanacaste 1-38, 44.\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "    # Initialize parser\n",
    "    parser = SimpleScottParser(\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key\"),\n",
    "        model_name=\"gpt-4o-mini\"\n",
    "    )\n",
    "    \n",
    "    # Parse and display\n",
    "    result = parser.parse_and_display(chunk_text)\n",
    "    \n",
    "    # Save results\n",
    "    with open(\"scott_parse_results.json\", \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nResults saved to scott_parse_results.json\")\n",
    "    \n",
    "    # Summary\n",
    "    stamps = result.get(\"stamps\", [])\n",
    "    main_stamps = [s for s in stamps if not s.get(\"variety_of\")]\n",
    "    varieties = [s for s in stamps if s.get(\"variety_of\")]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nSUMMARY:\")\n",
    "    print(f\"  Total entries: {len(stamps)}\")\n",
    "    print(f\"  Main stamps: {len(main_stamps)}\")\n",
    "    print(f\"  Varieties: {len(varieties)}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Run the test\n",
    "#     test_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9df3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_chunks_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72507695",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chunk = group_chunks_merged[592]\n",
    "group_text = \"\"\n",
    "for chunk in group_chunk:\n",
    "        # print(f\"Tipo: {chunk.get('type', 'N/A')}\")\n",
    "        # print(f\"Texto: {_clean_chunk_text(chunk.get('markdown', 'N/A'))}\")\n",
    "        # print(f\"Página: {chunk.get('grounding', 'N/A')['page']}\")\n",
    "        # print(\"---------------\")\n",
    "        group_text += _clean_chunk_text(chunk.get('markdown', 'N/A'))\n",
    "print(group_text)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642347c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SimpleScottParser(\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key\"),\n",
    "model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# Parse and display\n",
    "result = parser.parse_and_display(group_text)\n",
    "\n",
    "# Save results\n",
    "with open(\"scott_parse_results_1-17.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to scott_parse_results.json\")\n",
    "\n",
    "# Summary\n",
    "stamps = result.get(\"stamps\", [])\n",
    "main_stamps = [s for s in stamps if not s.get(\"variety_of\")]\n",
    "varieties = [s for s in stamps if s.get(\"variety_of\")]\n",
    "illustrations = result.get(\"illustrations\", [])\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"  Total entries: {len(stamps)}\")\n",
    "print(f\"  Main stamps: {len(main_stamps)}\")\n",
    "print(f\"  Varieties: {len(varieties)}\")\n",
    "print(f\"  Illustrations: {len(illustrations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b500dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "error_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, datetime, traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "parser = SimpleScottParser(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "total = len(group_chunks_merged)\n",
    "start = time.perf_counter()\n",
    "\n",
    "start_num = 1\n",
    "start_idx = start_num - 1  # = 13\n",
    "\n",
    "remaining = len(group_chunks_merged[start_idx:])\n",
    "\n",
    "\n",
    "with tqdm(total=total, desc=\"Parseando grupos\", unit=\"grp\") as pbar:\n",
    "    for i, group_chunk in enumerate(group_chunks_merged[start_idx:], start_num):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            group_text = \"\".join(_clean_chunk_text(ch.get('markdown', 'N/A')) for ch in group_chunk)\n",
    "            result = parser.parse_and_display(group_text)\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Guarda índice, error y (opcional) un recorte del texto para depurar\n",
    "            error_groups.append({\n",
    "                \"group_number\": i,\n",
    "                \"error\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "                # Si quieres: \"sample\": group_text[:500] if 'group_text' in locals() else \"\"\n",
    "            })\n",
    "        finally:\n",
    "            # Actualiza métricas/ETA y la barra aunque haya fallo\n",
    "            iter_sec = time.perf_counter() - t0\n",
    "            elapsed = time.perf_counter() - start\n",
    "            done = (i - start_num + 1)  # iteraciones totales (éxito+fallo) desde que empezaste\n",
    "            avg = elapsed / done\n",
    "            remaining_sec = avg * (remaining - done)\n",
    "            eta = datetime.timedelta(seconds=max(0, int(remaining_sec)))\n",
    "\n",
    "            pbar.set_postfix(iter_s=f\"{iter_sec:.2f}\", avg_s=f\"{avg:.2f}\", eta=str(eta))\n",
    "            pbar.update(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd26972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar\n",
    "with open(\"results/parsed_catalogues/scott_parse_results_1-17.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nResults saved to scott_parse_results_1-17.json\")\n",
    "print(f\"Tiempo total: {datetime.timedelta(seconds=int(time.perf_counter()-start))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e19506",
   "metadata": {},
   "source": [
    "### Codigo en Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c118681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, datetime\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "\n",
    "def chunked(it, size):\n",
    "    it = iter(it)\n",
    "    while True:\n",
    "        batch = list(islice(it, size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "# --- Preparación de entradas ---\n",
    "inputs = []\n",
    "start_num = 1\n",
    "start_idx = start_num - 1\n",
    "for i, group_chunk in enumerate(group_chunks_merged[start_idx:], start_num):\n",
    "    try:\n",
    "        group_text = \"\".join(_clean_chunk_text(ch.get('markdown', 'N/A')) for ch in group_chunk)\n",
    "        inputs.append({\"i\": i, \"input\": group_text})\n",
    "    except Exception as e:\n",
    "        # Si incluso preparar el texto falla, lo registramos y NO lo mandamos al LLM\n",
    "        # (opcional: podrías agregarlo igual y que falle abajo)\n",
    "        pass\n",
    "\n",
    "max_concurrency = 3      # ajusta según límites\n",
    "subbatch_size   = 5     # tamaño de oleadas\n",
    "max_retries     = 2      # reintentos por oleada\n",
    "\n",
    "results = [None] * len(inputs)\n",
    "error_groups = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "with tqdm(total=len(inputs), desc=\"Parseando (batch)\", unit=\"grp\") as pbar:\n",
    "    with get_openai_callback() as cb:\n",
    "        base = 0\n",
    "        for sub in chunked(inputs, subbatch_size):\n",
    "            sub_payload = [{\"input\": s[\"input\"]} for s in sub]\n",
    "\n",
    "            # --- Llamada batch con reintentos (try/except) ---\n",
    "            outs = None\n",
    "            last_err = None\n",
    "            for attempt in range(1, max_retries + 1):\n",
    "                try:\n",
    "                    outs = parser.chain.batch(\n",
    "                        sub_payload,\n",
    "                        config={\"max_concurrency\": max_concurrency},\n",
    "                        return_exceptions=True  # <- errores por ítem como objetos Exception\n",
    "                    )\n",
    "                    break  # éxito: salimos del bucle de reintentos\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "                    # Backoff exponencial simple\n",
    "                    if attempt < max_retries:\n",
    "                        sleep(2 ** (attempt - 1))\n",
    "                    else:\n",
    "                        # Si falló toda la oleada tras reintentos, marcamos todos los ítems de esta oleada como error\n",
    "                        for j in range(len(sub)):\n",
    "                            idx_global = base + j\n",
    "                            item = inputs[idx_global]\n",
    "                            error_groups.append({\n",
    "                                \"group_number\": item[\"i\"],\n",
    "                                \"error\": f\"BATCH_FAILURE: {type(e).__name__}: {str(e)}\"\n",
    "                            })\n",
    "                        # avanzamos la barra igualmente\n",
    "                        pbar.update(len(sub))\n",
    "\n",
    "            if outs is None:\n",
    "                # Ya registramos los errores y actualizamos pbar arriba\n",
    "                base += len(sub)\n",
    "                continue\n",
    "\n",
    "            # --- Procesar salidas por ítem (try implícito con return_exceptions=True) ---\n",
    "            for j, out in enumerate(outs):\n",
    "                idx_global = base + j\n",
    "                item = inputs[idx_global]\n",
    "                if isinstance(out, Exception):\n",
    "                    error_groups.append({\n",
    "                        \"group_number\": item[\"i\"],\n",
    "                        \"error\": f\"ITEM_FAILURE: {type(out).__name__}: {str(out)}\"\n",
    "                    })\n",
    "                else:\n",
    "                    results[idx_global] = out\n",
    "                pbar.update(1)\n",
    "\n",
    "            base += len(sub)\n",
    "\n",
    "        print(f\"\\nTokens prompt: {cb.prompt_tokens} | completion: {cb.completion_tokens} | total: {cb.total_tokens}\")\n",
    "        print(f\"Costo total (USD): {cb.total_cost:.6f}\")\n",
    "\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"Tiempo total: {datetime.timedelta(seconds=int(elapsed))}\")\n",
    "\n",
    "# --- Guardar ---\n",
    "os.makedirs(\"results/parsed_catalogues\", exist_ok=True)\n",
    "ok = [r for r in results if r is not None]\n",
    "with open(\"results/parsed_catalogues/scott_parse_results_18-34.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ok, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(\"results/parsed_catalogues/scott_parse_errors_18-34.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(error_groups, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"OK: {len(ok)} | Errores: {len(error_groups)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718286c",
   "metadata": {},
   "source": [
    "## Catalogo Mena Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mena Catalog Parser (Costa Rica) — Simplified, Robust, English-only\n",
    "Author: (Your Name)\n",
    "\n",
    "- Parses Mena-style catalog fragments into a normalized JSON:\n",
    "  {\n",
    "    \"issue_data\": {...},\n",
    "    \"production_orders\": {...},\n",
    "    \"stamps\": [...],\n",
    "    \"varieties\": [...],\n",
    "    \"proofs\": {...},\n",
    "    \"essays\": [...],\n",
    "    \"specimens\": []\n",
    "  }\n",
    "\n",
    "- If a section is not present in the text, it is still returned\n",
    "  with empty containers (e.g., \"specimens\": []).\n",
    "\n",
    "- Few-shot examples: surcharges/varieties, production orders/plates, proofs DP/PP.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_ibm import ChatWatsonx\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers for normalization\n",
    "# ----------------------------\n",
    "\n",
    "def remove_null_quantities(data: Dict[str, Any]) -> None:\n",
    "    \"\"\"Remove production order quantities with null values.\"\"\"\n",
    "    prod = data.get(\"production_orders\", {})\n",
    "    printings = prod.get(\"printings\", [])\n",
    "    \n",
    "    for printing in printings:\n",
    "        quantities = printing.get(\"quantities\", [])\n",
    "        # Keep only non-null quantities\n",
    "        valid_quantities = [\n",
    "            q for q in quantities \n",
    "            if q.get(\"quantity\") is not None\n",
    "        ]\n",
    "        printing[\"quantities\"] = valid_quantities\n",
    "        \n",
    "        if not valid_quantities:\n",
    "            print(f\"⚠️ Printing on {printing.get('date')} has no valid quantities\")\n",
    "    \n",
    "    # Remove printings with no quantities\n",
    "    prod[\"printings\"] = [p for p in printings if p.get(\"quantities\")]\n",
    "\n",
    "def validate_varieties(data: Dict[str, Any]) -> None:\n",
    "    \"\"\"Remove varieties whose base doesn't exist in stamps OR postal_stationery.\"\"\"\n",
    "    stamps = data.get(\"stamps\", [])\n",
    "    postal_stationery = data.get(\"postal_stationery\", [])\n",
    "    \n",
    "    valid_catalog_nos = {s.get(\"catalog_no\", \"\") for s in stamps}\n",
    "    valid_catalog_nos.update({ps.get(\"catalog_no\", \"\") for ps in postal_stationery})\n",
    "    \n",
    "    # ← DEBUG\n",
    "    print(f\"\\nDEBUG validate_varieties:\")\n",
    "    print(f\"  Valid catalog nos: {valid_catalog_nos}\")\n",
    "    \n",
    "    varieties = data.get(\"varieties\", [])\n",
    "    print(f\"  Varieties to validate: {len(varieties)}\")\n",
    "    \n",
    "    valid_varieties = []\n",
    "    \n",
    "    for v in varieties:\n",
    "        base = v.get(\"base_catalog_no\", \"\")\n",
    "        suffix = v.get(\"suffix\", \"\")\n",
    "        print(f\"  Checking: base='{base}', suffix='{suffix}' -> '{base}' in valid? {base in valid_catalog_nos}\")\n",
    "        \n",
    "        if base in valid_catalog_nos:\n",
    "            valid_varieties.append(v)\n",
    "        else:\n",
    "            print(f\"  ⚠️ Removed: {base}{suffix} (base not found)\")\n",
    "    \n",
    "    data[\"varieties\"] = valid_varieties\n",
    "    print(f\"  Final varieties: {len(valid_varieties)}\\n\")\n",
    "\n",
    "def mena_schema_stub() -> Dict[str, Any]:\n",
    "    \"\"\"Return the full output schema with empty defaults.\"\"\"\n",
    "    return {\n",
    "        \"issue_data\": {\n",
    "            \"issue_id\": \"\",\n",
    "            \"section\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"country\": \"\",\n",
    "            \"issue_dates\": {\n",
    "                \"announced\": None,\n",
    "                \"placed_on_sale\": None,\n",
    "                \"probable_first_circulation\": None,\n",
    "                \"second_plate_sale\": None,\n",
    "                \"demonetized\": None\n",
    "            },\n",
    "            \"legal_basis\": [],\n",
    "            \"currency_context\": {\n",
    "                \"original\": \"\",\n",
    "                \"decimal_adoption\": None,\n",
    "                \"revaluation_date\": None,\n",
    "                \"revaluation_map\": {}\n",
    "            },\n",
    "            \"printing\": {\n",
    "                \"printer\": \"\",\n",
    "                \"process\": [],\n",
    "                \"format\": {\n",
    "                    \"panes\": None\n",
    "                },\n",
    "                \"plates\": {}\n",
    "            },\n",
    "            \"perforation\": \"\"\n",
    "        },\n",
    "        \"production_orders\": {\n",
    "            \"printings\": [],\n",
    "            \"remainders\": {\n",
    "                \"date\": None,\n",
    "                \"note\": \"\",\n",
    "                \"quantities\": []\n",
    "            }\n",
    "        },\n",
    "        \"stamps\": [],\n",
    "        \"varieties\": [],\n",
    "        \"proofs\": {\n",
    "            \"die_proofs\": [],\n",
    "            \"plate_proofs\": [],\n",
    "            \"color_proofs\": [],\n",
    "            \"imperforate_proofs\": []\n",
    "        },\n",
    "        \"essays\": [],\n",
    "        \"specimens\": [],\n",
    "        \"postal_stationery\": []\n",
    "    }\n",
    "\n",
    "def migrate_lettered_to_varieties(data: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Move only lowercase-suffixed catalog numbers (e.g., '17a', '7b') into 'varieties'.\n",
    "    Preserve uppercase catalog numbers (e.g., '1A') as MAIN STAMPS.\n",
    "    \"\"\"\n",
    "    stamps = data.get(\"stamps\", [])\n",
    "    keep_stamps = []\n",
    "    varieties = data.setdefault(\"varieties\", [])\n",
    "\n",
    "    # ONLY lowercase letters count as variety suffix\n",
    "    VARIETY_RE = re.compile(r\"^(\\d+)([a-z]+)$\")  # <-- lowercase only\n",
    "\n",
    "    for s in stamps:\n",
    "        cat = (s.get(\"catalog_no\") or \"\").strip()\n",
    "        m = VARIETY_RE.fullmatch(cat)\n",
    "        if m:\n",
    "            base_no, suffix = m.group(1), m.group(2)\n",
    "            color = (s.get(\"color\") or \"\").strip()\n",
    "            notes = s.get(\"notes\") or []\n",
    "            desc = \", \".join([p for p in [color] + notes[:1] if p])\n",
    "\n",
    "            varieties.append({\n",
    "                \"base_catalog_no\": base_no,\n",
    "                \"suffix\": suffix,\n",
    "                \"type\": \"color\" if color else \"other\",\n",
    "                \"description\": desc or \"variety\",\n",
    "                \"position\": None,\n",
    "                \"plate\": s.get(\"plate\")\n",
    "            })\n",
    "        else:\n",
    "            keep_stamps.append(s)\n",
    "\n",
    "    data[\"stamps\"] = keep_stamps\n",
    "\n",
    "def normalize_variety_types(data):\n",
    "    mapping = {\n",
    "        \"op\": \"overprint\",\n",
    "        \"overprnt\": \"overprint\",\n",
    "        \"o/p\": \"overprint\",\n",
    "        \"surch\": \"surcharge\",\n",
    "        \"dbl surcharge\": \"surcharge\",\n",
    "        \"double op\": \"overprint\",\n",
    "        \"double overprint\": \"overprint\",\n",
    "        \"inv op\": \"overprint\",\n",
    "        \"inverted op\": \"overprint\"\n",
    "    }\n",
    "    for v in data.get(\"varieties\", []):\n",
    "        t = (v.get(\"type\") or \"\").strip().lower()\n",
    "        desc = (v.get(\"description\") or \"\").strip()\n",
    "        # re-type by description hints if type is empty/other\n",
    "        if not t or t == \"other\":\n",
    "            lower = desc.lower()\n",
    "            if \"surcharge\" in lower or \"surc\" in lower:\n",
    "                v[\"type\"] = \"surcharge\"\n",
    "            elif \"overprint\" in lower or \" op\" in lower or \"op \" in lower:\n",
    "                v[\"type\"] = \"overprint\"\n",
    "        # canonicalize common aliases\n",
    "        v[\"type\"] = mapping.get(v[\"type\"], v[\"type\"])\n",
    "        v[\"description\"] = desc\n",
    "\n",
    "def dedupe_varieties(data):\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for v in data.get(\"varieties\", []):\n",
    "        key = (\n",
    "            v.get(\"base_catalog_no\",\"\"),\n",
    "            v.get(\"suffix\",\"\"),\n",
    "            (v.get(\"type\") or \"\").lower(),\n",
    "            (v.get(\"description\") or \"\").lower()\n",
    "        )\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            uniq.append(v)\n",
    "    data[\"varieties\"] = uniq\n",
    "\n",
    "def _normalize_mena_unit(raw: Optional[str], value: Optional[float]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Normalize Mena monetary units PRESERVING CASE DISTINCTION:\n",
    "      - centavo/céntimo/centime/etc.  -> \"c\" (lowercase)\n",
    "      - colón/colon/colones/₡         -> \"C\" (uppercase)\n",
    "      - peso/pesos                    -> \"P\" (uppercase)\n",
    "      - real/reales/r/rs              -> \"real\" or \"reales\" (plural based on value)\n",
    "    Leaves unknowns untouched.\n",
    "    \"\"\"\n",
    "    if raw is None:\n",
    "        return raw\n",
    "    \n",
    "    # Preserve original for case-sensitive checks\n",
    "    original = raw.strip()\n",
    "    \n",
    "    # Lowercase version for synonym matching\n",
    "    u_lower = original.lower()\n",
    "    \n",
    "    # Remove common punctuation/symbol noise from lowercase version\n",
    "    u_normalized = u_lower.replace(\".\", \"\").replace(\"-\", \"\").replace(\"_\", \"\").strip()\n",
    "\n",
    "    # CRITICAL: Check single-letter codes FIRST using original case\n",
    "    if original == \"c\":\n",
    "        return \"c\"  # centavo (lowercase)\n",
    "    if original == \"C\":\n",
    "        return \"C\"  # Colón (uppercase)\n",
    "    if original == \"P\" or original == \"p\":\n",
    "        return \"P\"  # Peso\n",
    "\n",
    "    # Now check multi-character synonyms using lowercase version\n",
    "    \n",
    "    # Cent equivalents → \"c\"\n",
    "    cent_syn = {\n",
    "        \"ct\", \"cts\",\n",
    "        \"cent\", \"cents\",\n",
    "        \"centavo\", \"centavos\",\n",
    "        \"centimo\", \"centimos\",\n",
    "        \"céntimo\", \"céntimos\",\n",
    "        \"centime\", \"centimes\",\n",
    "        \"¢\"\n",
    "    }\n",
    "\n",
    "    # Peso equivalents → \"P\"\n",
    "    peso_syn = {\"peso\", \"pesos\", \"$p\", \"₱\"}\n",
    "\n",
    "    # Colón equivalents → \"C\"\n",
    "    colon_syn = {\"colon\", \"colón\", \"colones\", \"crc\", \"₡\", \"costa rican colon\"}\n",
    "\n",
    "    # Real equivalents → \"real\"/\"reales\"\n",
    "    real_syn = {\"r\", \"rs\", \"real\", \"reales\"}\n",
    "\n",
    "    # Check synonyms (order doesn't matter now since single letters handled above)\n",
    "    if u_normalized in cent_syn:\n",
    "        return \"c\"\n",
    "    if u_normalized in peso_syn:\n",
    "        return \"P\"\n",
    "    if u_normalized in colon_syn:\n",
    "        return \"C\"\n",
    "    if u_normalized in real_syn:\n",
    "        # Pick singular/plural based on value (best effort)\n",
    "        try:\n",
    "            if isinstance(value, str):\n",
    "                # parse simple fractions like \"1/2\"\n",
    "                if re.fullmatch(r\"\\d+/\\d+\", value):\n",
    "                    num, den = value.split(\"/\")\n",
    "                    value_num = float(num) / float(den)\n",
    "                else:\n",
    "                    value_num = float(value)\n",
    "            else:\n",
    "                value_num = float(value) if value is not None else None\n",
    "        except Exception:\n",
    "            value_num = None\n",
    "\n",
    "        if value_num is not None and value_num <= 1.0:\n",
    "            return \"real\"  # singular para 0.5, 1.0\n",
    "        else:\n",
    "            return \"reales\"   # plural\n",
    "    \n",
    "    # Unknown → return original (preserve for safety)\n",
    "    return original\n",
    "\n",
    "\n",
    "def normalize_units_and_perf(data: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    - Normalize denomination units according to Mena system:\n",
    "        centavo/céntimo → \"c\"\n",
    "        peso            → \"P\"\n",
    "        colón           → \"C\"\n",
    "        real/reales     → \"real\"/\"reales\" (plurality by value)\n",
    "    - Normalize perforations: keep only the gauge if input has 'perf ...'\n",
    "    \"\"\"\n",
    "    # Stamp-level normalization\n",
    "    for s in data.get(\"stamps\", []):\n",
    "        den = s.get(\"denomination\") or {}\n",
    "        value = den.get(\"value\")\n",
    "        unit_raw = den.get(\"unit\")\n",
    "        den[\"unit\"] = _normalize_mena_unit(unit_raw, value)\n",
    "        s[\"denomination\"] = den\n",
    "\n",
    "        # perforation: drop the word 'perf' and punctuation; keep the gauge text intact\n",
    "        perf = (s.get(\"perforation\") or \"\").strip()\n",
    "        perf_l = perf.lower()\n",
    "        if perf_l.startswith(\"perf\"):\n",
    "            perf = perf_l.replace(\"perf\", \"\", 1).strip()\n",
    "            perf = perf.lstrip(\".:;,- \")\n",
    "        s[\"perforation\"] = perf\n",
    "\n",
    "    # Issue-level perforation (if ever present there)\n",
    "    issue = data.get(\"issue_data\", {}) or {}\n",
    "    perf_issue = (issue.get(\"perforation\") or \"\").strip()\n",
    "    perf_issue_l = perf_issue.lower()\n",
    "    if perf_issue_l.startswith(\"perf\"):\n",
    "        perf_clean = perf_issue_l.replace(\"perf\", \"\", 1).strip()\n",
    "        perf_clean = perf_clean.lstrip(\".:;,- \")\n",
    "        issue[\"perforation\"] = perf_clean\n",
    "        data[\"issue_data\"] = issue\n",
    "\n",
    "def coerce_notes_fields(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in list(obj.items()):\n",
    "            if k == \"notes\":\n",
    "                if isinstance(v, list):\n",
    "                    # filtra no-strings y une con espacio\n",
    "                    obj[k] = \" \".join([str(x) for x in v if isinstance(x, (str, int, float))]).strip()\n",
    "                elif v is None:\n",
    "                    obj[k] = \"\"\n",
    "                elif not isinstance(v, str):\n",
    "                    obj[k] = str(v)\n",
    "            else:\n",
    "                coerce_notes_fields(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            coerce_notes_fields(item)\n",
    "\n",
    "\n",
    "def coerce_to_mena_schema(obj: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ensure all top-level keys exist and have the right container types,\n",
    "    filling missing keys with empty defaults. Also ensure nested\n",
    "    structures exist even if empty data.\n",
    "    \"\"\"\n",
    "    base = mena_schema_stub()\n",
    "\n",
    "    def ensure(target: Dict[str, Any], default: Dict[str, Any]):\n",
    "        for k, v in default.items():\n",
    "            if k not in target:\n",
    "                target[k] = v\n",
    "            else:\n",
    "                if isinstance(v, dict):\n",
    "                    if not isinstance(target[k], dict):\n",
    "                        target[k] = v\n",
    "                    else:\n",
    "                        ensure(target[k], v)\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        return base\n",
    "\n",
    "    for k in base.keys():\n",
    "        if k not in obj:\n",
    "            obj[k] = base[k]\n",
    "\n",
    "    ensure(obj, base)\n",
    "\n",
    "    if not isinstance(obj[\"stamps\"], list):\n",
    "        obj[\"stamps\"] = []\n",
    "    if not isinstance(obj[\"varieties\"], list):\n",
    "        obj[\"varieties\"] = []\n",
    "    if not isinstance(obj[\"essays\"], list):\n",
    "        obj[\"essays\"] = []\n",
    "    if not isinstance(obj[\"specimens\"], list):\n",
    "        obj[\"specimens\"] = []\n",
    "    if not isinstance(obj[\"postal_stationery\"], list):\n",
    "        obj[\"postal_stationery\"] = []    \n",
    "        \n",
    "\n",
    "    proofs = obj.get(\"proofs\", {})\n",
    "    if not isinstance(proofs, dict):\n",
    "        obj[\"proofs\"] = mena_schema_stub()[\"proofs\"]\n",
    "    else:\n",
    "        for k in [\"die_proofs\", \"plate_proofs\", \"color_proofs\", \"imperforate_proofs\"]:\n",
    "            if k not in proofs or not isinstance(proofs[k], list):\n",
    "                proofs[k] = []\n",
    "\n",
    "    prod = obj.get(\"production_orders\", {})\n",
    "    if not isinstance(prod, dict):\n",
    "        obj[\"production_orders\"] = mena_schema_stub()[\"production_orders\"]\n",
    "    else:\n",
    "        if \"printings\" not in prod or not isinstance(prod[\"printings\"], list):\n",
    "            prod[\"printings\"] = []\n",
    "        rem = prod.get(\"remainders\", {})\n",
    "        if not isinstance(rem, dict):\n",
    "            prod[\"remainders\"] = mena_schema_stub()[\"production_orders\"][\"remainders\"]\n",
    "        else:\n",
    "            if \"quantities\" not in rem or not isinstance(rem[\"quantities\"], list):\n",
    "                rem[\"quantities\"] = []\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# The Parser\n",
    "# ----------------------------\n",
    "\n",
    "class MenaParser:\n",
    "    \"\"\"LLM-driven parser specialized for Mena Catalog (Costa Rica).\"\"\"\n",
    "\n",
    "    def __init__(self, openai_api_key: str, model_name: str = \"gpt-4o-mini\", temperature: float = 0.0):\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=temperature,\n",
    "            model=model_name,\n",
    "            api_key=openai_api_key,\n",
    "            timeout=300.0,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"low\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            }\n",
    "            #max_tokens=28000,\n",
    "        )\n",
    "        # self.llm = ChatWatsonx(\n",
    "        #   model_id= \"meta-llama/llama-3-3-70b-instruct\", #\"openai/gpt-5-mini\"\n",
    "        #   url=os.getenv(\"WATSONX_URL\"),\n",
    "        #   apikey=os.getenv(\"WATSONX_API_KEY\"),\n",
    "        #   project_id=os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "        #   params={\n",
    "        #       \"temperature\": 0,\n",
    "        #       \"verbosity\": \"low\",\n",
    "        #       \"reasoning_effort\" : \"low\"\n",
    "        #   })\n",
    "        self.output_parser = JsonOutputParser()\n",
    "        self.chain = self._create_chain()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def parse_chunk(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse a chunk of Mena catalog text into the normalized Mena JSON.\n",
    "        Always returns the full schema; missing sections are empty.\n",
    "        \"\"\"\n",
    "        cleaned = self._preclean_text(text)\n",
    "        try:\n",
    "            with get_openai_callback() as cb:\n",
    "                result = self.chain.invoke({\"input\": cleaned})\n",
    "                print(\"Prompt tokens:\", cb.prompt_tokens)\n",
    "                print(\"Completion tokens:\", cb.completion_tokens)\n",
    "                print(\"Total tokens:\", cb.total_tokens)\n",
    "                \n",
    "                \n",
    "                cost_per_1m_input = 0.250\n",
    "                cost_per_1m_output = 2.0\n",
    "                \n",
    "                # Convert to cost per token\n",
    "                cost_per_input_token = cost_per_1m_input / 1_000_000\n",
    "                cost_per_output_token = cost_per_1m_output / 1_000_000\n",
    "                \n",
    "                input_cost = cb.prompt_tokens * cost_per_input_token\n",
    "                output_cost = cb.completion_tokens * cost_per_output_token\n",
    "                total_cost = input_cost + output_cost\n",
    "                print(\"Cost (USD):\", total_cost)\n",
    "                \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Parsing error: {e}\")\n",
    "            result = {}\n",
    "\n",
    "        coerced = coerce_to_mena_schema(result)\n",
    "        remove_null_quantities(coerced)\n",
    "        migrate_lettered_to_varieties(coerced)        \n",
    "        normalize_units_and_perf(coerced)        \n",
    "        normalize_variety_types(coerced)\n",
    "        coerce_notes_fields(coerced)\n",
    "        dedupe_varieties(coerced)\n",
    "        validate_varieties(coerced)\n",
    "        self._light_sanitize(coerced)\n",
    "        return coerced\n",
    "\n",
    "    def parse_and_save(self, text: str, out_path: str = \"mena_parse_result.json\") -> Dict[str, Any]:\n",
    "        result = self.parse_chunk(text)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Saved: {out_path}\")\n",
    "        return result\n",
    "\n",
    "    # ---------- Internals ----------\n",
    "\n",
    "    def expand_rowspan_cells(self, html: str) -> str:\n",
    "      \"\"\"\n",
    "      Pre-process HTML to expand rowspan cells by duplicating content.\n",
    "      \n",
    "      Example:\n",
    "      <tr><td>A</td><td rowspan=\"2\">shared</td><td>C</td></tr>\n",
    "      <tr><td>D</td><td>E</td></tr>\n",
    "      \n",
    "      Becomes:\n",
    "      <tr><td>A</td><td>shared</td><td>C</td></tr>\n",
    "      <tr><td>D</td><td>shared</td><td>E</td></tr>\n",
    "      \"\"\"\n",
    "      from bs4 import BeautifulSoup, NavigableString\n",
    "      \n",
    "      try:\n",
    "          soup = BeautifulSoup(html, 'html.parser')\n",
    "          \n",
    "          for table in soup.find_all('table'):\n",
    "              rows = table.find_all('tr')\n",
    "              \n",
    "              # Track which columns have active rowspans\n",
    "              rowspan_tracker = {}  # {row_idx: {col_idx: (content, remaining_rows)}}\n",
    "              \n",
    "              for i, row in enumerate(rows):\n",
    "                  cells = row.find_all(['td', 'th'])\n",
    "                  current_col = 0\n",
    "                  cells_to_insert = []  # (position, cell_copy)\n",
    "                  \n",
    "                  # First, insert any pending rowspan cells from previous rows\n",
    "                  if i in rowspan_tracker:\n",
    "                      for col_idx, (content, remaining) in sorted(rowspan_tracker[i].items()):\n",
    "                          # Create a copy of the cell without rowspan\n",
    "                          cell_copy = BeautifulSoup(str(content), 'html.parser').find(['td', 'th'])\n",
    "                          if cell_copy and 'rowspan' in cell_copy.attrs:\n",
    "                              del cell_copy['rowspan']\n",
    "                          cells_to_insert.append((col_idx, cell_copy))\n",
    "                  \n",
    "                  # Now process current row's cells\n",
    "                  for cell in cells:\n",
    "                      # Skip columns that should have rowspan cells inserted\n",
    "                      while current_col in [pos for pos, _ in cells_to_insert]:\n",
    "                          current_col += 1\n",
    "                      \n",
    "                      rowspan = cell.get('rowspan')\n",
    "                      if rowspan and int(rowspan) > 1:\n",
    "                          rowspan_count = int(rowspan)\n",
    "                          \n",
    "                          # Schedule this cell to be inserted in following rows\n",
    "                          for j in range(1, rowspan_count):\n",
    "                              target_row = i + j\n",
    "                              if target_row < len(rows):\n",
    "                                  if target_row not in rowspan_tracker:\n",
    "                                      rowspan_tracker[target_row] = {}\n",
    "                                  rowspan_tracker[target_row][current_col] = (cell, rowspan_count - j)\n",
    "                          \n",
    "                          # Remove rowspan from current cell\n",
    "                          del cell['rowspan']\n",
    "                      \n",
    "                      current_col += 1\n",
    "                  \n",
    "                  # Insert rowspan cells at correct positions\n",
    "                  for pos, cell_copy in reversed(cells_to_insert):\n",
    "                      # Find insertion point\n",
    "                      existing_cells = row.find_all(['td', 'th'])\n",
    "                      if pos < len(existing_cells):\n",
    "                          existing_cells[pos].insert_before(cell_copy)\n",
    "                      else:\n",
    "                          row.append(cell_copy)\n",
    "          \n",
    "          return str(soup)\n",
    "      except Exception as e:\n",
    "          print(f\"⚠️ Rowspan expansion failed: {e}\")\n",
    "          import traceback\n",
    "          traceback.print_exc()\n",
    "          return html   \n",
    "    def _preclean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Minimal pre-clean:\n",
    "        - Keep the <:: ... ::> figure blocks (they can help LLM anchoring).\n",
    "        - Remove empty anchor tags if present.\n",
    "        \"\"\"\n",
    "        t = text\n",
    "        t = re.sub(r'<a id=[\\'\"][^\\'\"]+[\\'\"]></a>\\s*', '', t)\n",
    "        \n",
    "        # Expand rowspan cells if HTML detected\n",
    "        if '<table' in t.lower():\n",
    "            t = self.expand_rowspan_cells(t)\n",
    "        \n",
    "        return t.strip()\n",
    "\n",
    "    def _light_sanitize(self, data: Dict[str, Any]) -> None:\n",
    "        def strip_if_str(x):\n",
    "            return x.strip() if isinstance(x, str) else x\n",
    "\n",
    "        issue = data.get(\"issue_data\", {})\n",
    "        for k in [\"issue_id\", \"section\", \"title\", \"country\", \"perforation\"]:\n",
    "            if k in issue:\n",
    "                issue[k] = strip_if_str(issue[k])\n",
    "\n",
    "        for s in data.get(\"stamps\", []):\n",
    "            s[\"color\"] = strip_if_str(s.get(\"color\", \"\"))\n",
    "            if isinstance(s.get(\"notes\"), list):\n",
    "                s[\"notes\"] = [strip_if_str(n) for n in s[\"notes\"]]\n",
    "\n",
    "        for v in data.get(\"varieties\", []):\n",
    "            v[\"description\"] = strip_if_str(v.get(\"description\", \"\"))\n",
    "\n",
    "    def _create_chain(self):\n",
    "        \"\"\"\n",
    "        Build the few-shot chain specialized for Mena.\n",
    "        The assistant must always return a single JSON object matching the Mena schema.\n",
    "        \"\"\"\n",
    "\n",
    "        # --------------------------\n",
    "        # Few-shot: REGULAR + VARIETIES tables (two tables + constant plate varieties)\n",
    "        # --------------------------\n",
    "        ex_input_regular_var = \"\"\"<table id=\"8-I\">\n",
    "        <tr><td id=\"8-J\">Regular issue</td><td id=\"8-K\"></td><td id=\"8-L\"></td></tr>\n",
    "        <tr><td id=\"8-M\">1</td><td id=\"8-N\">½ real blue (plate 1)</td><td id=\"8-O\">3,000,000</td></tr>\n",
    "        <tr><td id=\"8-P\">1a</td><td id=\"8-Q\">double perf horizontal</td><td id=\"8-R\"></td></tr>\n",
    "        <tr><td id=\"8-S\">1b</td><td id=\"8-T\">double perf diagonal</td><td id=\"8-U\"></td></tr>\n",
    "        <tr><td id=\"8-V\">1c</td><td id=\"8-W\">double impression at right</td><td id=\"8-X\"></td></tr>\n",
    "        <tr><td id=\"8-Y\">1d</td><td id=\"8-Z\">cracked plate (pos 1)</td><td id=\"8-10\"></td></tr>\n",
    "        <tr><td id=\"8-11\">1e</td><td id=\"8-12\">cracked plate (pos 11)</td><td id=\"8-13\"></td></tr>\n",
    "        <tr><td id=\"8-14\">1f</td><td id=\"8-15\">cracked plate (pos 21)</td><td id=\"8-16\"></td></tr>\n",
    "        </table>\n",
    "\n",
    "        Constant plate varieties:\n",
    "        g: period in center second star (pos 87)\n",
    "        h: period in center third star (pos 89)\n",
    "        I: line on top volcano (pos 96)\n",
    "\n",
    "        <table><thead><tr><th>Col&nbsp;1</th><th>Col&nbsp;2</th></tr></thead><tbody>\n",
    "        <tr><td>1A 1½ real light blue (plate 2)</td><td>2,750,000</td></tr>\n",
    "        <tr><td>&nbsp;&nbsp;&nbsp;&nbsp;1Aa imperf horizontal (pair or blocks-38)</td><td></td></tr>\n",
    "        <tr><td>2 2 reales scarlet</td><td>750,000</td></tr>\n",
    "        <tr><td>&nbsp;&nbsp;&nbsp;&nbsp;2a engraver line through DOS (pos 1)</td><td></td></tr>\n",
    "        <tr><td>3 4 reales green</td><td>70,000</td></tr>\n",
    "        <tr><td>&nbsp;&nbsp;&nbsp;&nbsp;3a double entry of \"Correos de Costa Rica\" (pos 8)</td><td></td></tr>\n",
    "        <tr><td>4 1 peso yellow</td><td>35,000</td></tr>\n",
    "        </tbody></table>\n",
    "        \"\"\"\n",
    "\n",
    "        ex_output_regular_var = json.dumps({\n",
    "        \"issue_data\": {\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"section\": \"Surface Mail\",\n",
    "            \"title\": \"Regular issue\",\n",
    "            \"country\": \"Costa Rica\",\n",
    "            \"issue_dates\": {\n",
    "            \"announced\": None,\n",
    "            \"placed_on_sale\": None,\n",
    "            \"probable_first_circulation\": None,\n",
    "            \"second_plate_sale\": None,\n",
    "            \"demonetized\": None\n",
    "            },\n",
    "            \"legal_basis\": [],\n",
    "            \"currency_context\": {\n",
    "            \"original\": \"\",\n",
    "            \"decimal_adoption\": None,\n",
    "            \"revaluation_date\": None,\n",
    "            \"revaluation_map\": {}\n",
    "            },\n",
    "            \"printing\": {\n",
    "            \"printer\": \"\",\n",
    "            \"process\": [],\n",
    "            \"format\": { \"panes\": None },\n",
    "            \"plates\": {}\n",
    "            },\n",
    "            \"perforation\": \"\"\n",
    "        },\n",
    "        \"production_orders\": {\n",
    "            \"printings\": [],\n",
    "            \"remainders\": { \"date\": None, \"note\": \"\", \"quantities\": [] }\n",
    "        },\n",
    "        \"stamps\": [\n",
    "            {\n",
    "            \"catalog_no\": \"1\",\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"denomination\": { \"value\": 0.5, \"unit\": \"real\" },\n",
    "            \"color\": \"blue\",\n",
    "            \"plate\": 1,\n",
    "            \"perforation\": \"\",\n",
    "            \"watermark\": None,\n",
    "            \"quantity_reported\": 3000000,\n",
    "            \"status\": \"regular\",\n",
    "            \"notes\": []\n",
    "            },\n",
    "            {\n",
    "            \"catalog_no\": \"1A\",\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"denomination\": { \"value\": 1.5, \"unit\": \"real\" },\n",
    "            \"color\": \"light blue\",\n",
    "            \"plate\": 2,\n",
    "            \"perforation\": \"\",\n",
    "            \"watermark\": None,\n",
    "            \"quantity_reported\": 2750000,\n",
    "            \"status\": \"regular\",\n",
    "            \"notes\": []\n",
    "            },\n",
    "            {\n",
    "            \"catalog_no\": \"2\",\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"denomination\": { \"value\": 2, \"unit\": \"real\" },\n",
    "            \"color\": \"scarlet\",\n",
    "            \"plate\": None,\n",
    "            \"perforation\": \"\",\n",
    "            \"watermark\": None,\n",
    "            \"quantity_reported\": 750000,\n",
    "            \"status\": \"regular\",\n",
    "            \"notes\": []\n",
    "            },\n",
    "            {\n",
    "            \"catalog_no\": \"3\",\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"denomination\": { \"value\": 4, \"unit\": \"real\" },\n",
    "            \"color\": \"green\",\n",
    "            \"plate\": None,\n",
    "            \"perforation\": \"\",\n",
    "            \"watermark\": None,\n",
    "            \"quantity_reported\": 70000,\n",
    "            \"status\": \"regular\",\n",
    "            \"notes\": []\n",
    "            },\n",
    "            {\n",
    "            \"catalog_no\": \"4\",\n",
    "            \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "            \"denomination\": { \"value\": 1, \"unit\": \"P\" },\n",
    "            \"color\": \"yellow\",\n",
    "            \"plate\": None,\n",
    "            \"perforation\": \"\",\n",
    "            \"watermark\": None,\n",
    "            \"quantity_reported\": 35000,\n",
    "            \"status\": \"regular\",\n",
    "            \"notes\": []\n",
    "            }\n",
    "        ],\n",
    "        \"varieties\": [\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"a\", \"type\": \"perforation\", \"description\": \"double perf horizontal\", \"position\": None, \"plate\": None },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"b\", \"type\": \"perforation\", \"description\": \"double perf diagonal\", \"position\": None, \"plate\": None },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"c\", \"type\": \"impression\", \"description\": \"double impression at right\", \"position\": None, \"plate\": None },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"d\", \"type\": \"plate_flaw\", \"description\": \"cracked plate\", \"position\": \"pos 1\", \"plate\": 1 },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"e\", \"type\": \"plate_flaw\", \"description\": \"cracked plate\", \"position\": \"pos 11\", \"plate\": 1 },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"f\", \"type\": \"plate_flaw\", \"description\": \"cracked plate\", \"position\": \"pos 21\", \"plate\": 1 },\n",
    "\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"g\", \"type\": \"plate_flaw\", \"description\": \"period in center second star\", \"position\": \"pos 87\", \"plate\": None },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"h\", \"type\": \"plate_flaw\", \"description\": \"period in center third star\", \"position\": \"pos 89\", \"plate\": None },\n",
    "            { \"base_catalog_no\": \"1\", \"suffix\": \"i\", \"type\": \"plate_flaw\", \"description\": \"line on top volcano\", \"position\": \"pos 96\", \"plate\": None },\n",
    "\n",
    "            { \"base_catalog_no\": \"1A\", \"suffix\": \"a\", \"type\": \"perforation\", \"description\": \"imperf horizontal (pair or blocks-38)\", \"position\": None, \"plate\": 2 },\n",
    "\n",
    "            { \"base_catalog_no\": \"2\", \"suffix\": \"a\", \"type\": \"plate_flaw\", \"description\": \"engraver line through DOS\", \"position\": \"pos 1\", \"plate\": None },\n",
    "            { \"base_catalog_no\": \"3\", \"suffix\": \"a\", \"type\": \"plate_flaw\", \"description\": \"double entry of \\\"Correos de Costa Rica\\\"\", \"position\": \"pos 8\", \"plate\": None }\n",
    "        ],\n",
    "        \"proofs\": { \"die_proofs\": [], \"plate_proofs\": [], \"color_proofs\": [], \"imperforate_proofs\": [] },\n",
    "        \"essays\": [],\n",
    "        \"specimens\": [],\n",
    "        \"postal_stationery\" : []\n",
    "        }, indent=2)\n",
    "\n",
    "        \n",
    "        \n",
    "        # --------------------------\n",
    "        # Few-shot: SURCHARGES block (fixed)\n",
    "        # --------------------------\n",
    "        ex_input_surcharges = \"\"\"Surcharges 1881-82\n",
    "\n",
    "        December 16, 1880. Accord 53 (2c), September or October 1882 (1c), December 1882 (5c).\n",
    "        Surcharged by Imprenta Nacional in vermilion.\n",
    "        Decimal currency was adopted in 1864: 100 centavos = 1 peso.\n",
    "        Quantities unknown. Demonetized February 1, 1883. (Ref Ox 100, 1985, Ox 211, 2013).\n",
    "\n",
    "        5\n",
    "        1c on ½ real (plate 1) in straight letters\n",
    "\n",
    "        5a\n",
    "        surcharge on 1A (plate 2)\n",
    "\n",
    "        6\n",
    "        1c on ½ real (plate 1) in cursive letters\n",
    "\n",
    "        7\n",
    "        2c on ½ real (plate 1)\n",
    "\n",
    "        7a\n",
    "        surcharge on 1A (plate 2)\n",
    "\n",
    "        7b\n",
    "        double surcharge\n",
    "\n",
    "        7c\n",
    "        inverted op (one known in a block)\n",
    "\n",
    "        7d\n",
    "        Cts instead of cts (doubtful-Ox 114)\n",
    "\n",
    "        8\n",
    "        5c on ½ real 1A (plate 2) - never used\n",
    "\n",
    "        8a\n",
    "        double surcharge\n",
    "\n",
    "        All varieties of base stamp #1 exist on stamp #5, 6 and 7.\n",
    "        #5 and 6 exist se-tenant.\n",
    "        Proofs in black of 5, 7 & 8 may exist.\n",
    "        \"\"\"\n",
    "\n",
    "        ex_output_surcharges = json.dumps({\n",
    "            \"issue_data\": {\n",
    "                \"issue_id\": \"CR-1881-82-SURCHARGES\",\n",
    "                \"section\": \"Surface Mail\",\n",
    "                \"title\": \"Surcharges 1881–82\",\n",
    "                \"country\": \"Costa Rica\",\n",
    "                \"issue_dates\": {\n",
    "                    \"announced\": None,\n",
    "                    \"placed_on_sale\": None,\n",
    "                    \"probable_first_circulation\": None,\n",
    "                    \"second_plate_sale\": None,\n",
    "                    \"demonetized\": \"1883-02-01\"\n",
    "                },\n",
    "                \"legal_basis\": [\n",
    "                    {\"type\": \"resolution\", \"id\": \"Accord 53\", \"date\": \"1880-12-16\", \"ids\": [], \"officials\": []}\n",
    "                ],\n",
    "                \"currency_context\": {\n",
    "                    \"original\": \"c\",\n",
    "                    \"decimal_adoption\": \"1864-01-01\",\n",
    "                    \"revaluation_date\": None,\n",
    "                    \"revaluation_map\": {}\n",
    "                },\n",
    "                \"printing\": {\n",
    "                    \"printer\": \"Imprenta Nacional\",\n",
    "                    \"process\": [\"surcharge\"],\n",
    "                    \"format\": {\"panes\": None},\n",
    "                    \"plates\": {\n",
    "                        \"0.5_real\": {\n",
    "                            \"plates\": [1, 2],\n",
    "                            \"notes\": [\"plate 1 straight vs cursive fonts noted\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"perforation\": \"\"\n",
    "            },\n",
    "            \"production_orders\": {\n",
    "                \"printings\": [],\n",
    "                \"remainders\": {\"date\": None, \"note\": \"\", \"quantities\": []}\n",
    "            },\n",
    "            \"stamps\": [\n",
    "                {\n",
    "                    \"catalog_no\": \"5\",\n",
    "                    \"issue_id\": \"CR-1881-82-SURCHARGES\",\n",
    "                    \"denomination\": {\"value\": 1, \"unit\": \"c\"},\n",
    "                    \"color\": \"\",\n",
    "                    \"plate\": 1,\n",
    "                    \"perforation\": \"\",\n",
    "                    \"watermark\": None,\n",
    "                    \"quantity_reported\": None,\n",
    "                    \"status\": \"regular\",\n",
    "                    \"notes\": [\n",
    "                        \"1c on 1/2 real (plate 1), straight letters\",\n",
    "                        \"surcharge in vermilion\"\n",
    "                    ],\n",
    "                    \"overprint\": {\n",
    "                        \"present\": True,\n",
    "                        \"type\": \"surcharge\",\n",
    "                        \"surcharge_denomination\": {\"value\": 1, \"unit\": \"c\"},\n",
    "                        \"on_denomination\": {\"value\": 0.5, \"unit\": \"reales\"}\n",
    "                    },\n",
    "                    \"base_stamp_ref\": \"1\"\n",
    "                },\n",
    "                {\n",
    "                    \"catalog_no\": \"6\",\n",
    "                    \"issue_id\": \"CR-1881-82-SURCHARGES\",\n",
    "                    \"denomination\": {\"value\": 1, \"unit\": \"c\"},\n",
    "                    \"color\": \"\",\n",
    "                    \"plate\": 1,\n",
    "                    \"perforation\": \"\",\n",
    "                    \"watermark\": None,\n",
    "                    \"quantity_reported\": None,\n",
    "                    \"status\": \"regular\",\n",
    "                    \"notes\": [\n",
    "                        \"1c on 1/2 real (plate 1), cursive letters\",\n",
    "                        \"surcharge in vermilion\"\n",
    "                    ],\n",
    "                    \"overprint\": {\n",
    "                        \"present\": True,\n",
    "                        \"type\": \"surcharge\",\n",
    "                        \"surcharge_denomination\": {\"value\": 1, \"unit\": \"c\"},\n",
    "                        \"on_denomination\": {\"value\": 0.5, \"unit\": \"reales\"}\n",
    "                    },\n",
    "                    \"base_stamp_ref\": \"1\"\n",
    "                },\n",
    "                {\n",
    "                    \"catalog_no\": \"7\",\n",
    "                    \"issue_id\": \"CR-1881-82-SURCHARGES\",\n",
    "                    \"denomination\": {\"value\": 2, \"unit\": \"c\"},\n",
    "                    \"color\": \"\",\n",
    "                    \"plate\": 1,\n",
    "                    \"perforation\": \"\",\n",
    "                    \"watermark\": None,\n",
    "                    \"quantity_reported\": None,\n",
    "                    \"status\": \"regular\",\n",
    "                    \"notes\": [\n",
    "                        \"2c on 1/2 real (plate 1)\",\n",
    "                        \"surcharge in vermilion\"\n",
    "                    ],\n",
    "                    \"overprint\": {\n",
    "                        \"present\": True,\n",
    "                        \"type\": \"surcharge\",\n",
    "                        \"surcharge_denomination\": {\"value\": 2, \"unit\": \"c\"},\n",
    "                        \"on_denomination\": {\"value\": 0.5, \"unit\": \"reales\"}\n",
    "                    },\n",
    "                    \"base_stamp_ref\": \"1\"\n",
    "                },\n",
    "                {\n",
    "                    \"catalog_no\": \"8\",\n",
    "                    \"issue_id\": \"CR-1881-82-SURCHARGES\",\n",
    "                    \"denomination\": {\"value\": 5, \"unit\": \"c\"},\n",
    "                    \"color\": \"\",\n",
    "                    \"plate\": 2,\n",
    "                    \"perforation\": \"\",\n",
    "                    \"watermark\": None,\n",
    "                    \"quantity_reported\": None,\n",
    "                    \"status\": \"regular\",\n",
    "                    \"notes\": [\n",
    "                        \"5c on 1/2 real 1A (plate 2) - never used\",\n",
    "                        \"surcharge in vermilion\"\n",
    "                    ],\n",
    "                    \"overprint\": {\n",
    "                        \"present\": True,\n",
    "                        \"type\": \"surcharge\",\n",
    "                        \"surcharge_denomination\": {\"value\": 5, \"unit\": \"c\"},\n",
    "                        \"on_denomination\": {\"value\": 0.5, \"unit\": \"reales\"}\n",
    "                    },\n",
    "                    \"base_stamp_ref\": \"1A\"\n",
    "                }\n",
    "            ],\n",
    "            \"varieties\": [\n",
    "                {\n",
    "                    \"base_catalog_no\": \"5\",\n",
    "                    \"suffix\": \"a\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"description\": \"surcharge on 1A (plate 2)\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": 2\n",
    "                },\n",
    "                {\n",
    "                    \"base_catalog_no\": \"7\",\n",
    "                    \"suffix\": \"a\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"description\": \"surcharge on 1A (plate 2)\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": 2\n",
    "                },\n",
    "                {\n",
    "                    \"base_catalog_no\": \"7\",\n",
    "                    \"suffix\": \"b\",\n",
    "                    \"type\": \"surcharge\",\n",
    "                    \"description\": \"double surcharge\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": None\n",
    "                },\n",
    "                {\n",
    "                    \"base_catalog_no\": \"7\",\n",
    "                    \"suffix\": \"c\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"description\": \"inverted overprint (one known in a block)\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": None\n",
    "                },\n",
    "                {\n",
    "                    \"base_catalog_no\": \"7\",\n",
    "                    \"suffix\": \"d\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"description\": \"Cts instead of cts (doubtful - Ox 114)\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": None\n",
    "                },\n",
    "                {\n",
    "                    \"base_catalog_no\": \"8\",\n",
    "                    \"suffix\": \"a\",\n",
    "                    \"type\": \"surcharge\",\n",
    "                    \"description\": \"double surcharge\",\n",
    "                    \"position\": None,\n",
    "                    \"plate\": None\n",
    "                }\n",
    "            ],\n",
    "            \"proofs\": {\n",
    "                \"die_proofs\": [],\n",
    "                \"plate_proofs\": [],\n",
    "                \"color_proofs\": [\n",
    "                    {\n",
    "                        \"code\": \"\",\n",
    "                        \"denomination\": \"No. 5\",\n",
    "                        \"color\": \"black\",\n",
    "                        \"notes\": \"Proof in black reportedly may exist (unconfirmed)\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"code\": \"\",\n",
    "                        \"denomination\": \"No. 7\",\n",
    "                        \"color\": \"black\",\n",
    "                        \"notes\": \"Proof in black reportedly may exist (unconfirmed)\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"code\": \"\",\n",
    "                        \"denomination\": \"No. 8\",\n",
    "                        \"color\": \"black\",\n",
    "                        \"notes\": \"Proof in black reportedly may exist (unconfirmed)\"\n",
    "                    }\n",
    "                ],\n",
    "                \"imperforate_proofs\": []\n",
    "            },\n",
    "            \"essays\": [],\n",
    "            \"specimens\": [],\n",
    "            \"postal_stationery\" : []\n",
    "        }, indent=2)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Few-shot: PRODUCTION ORDERS / PLATE DATA\n",
    "        # ----------------------------------------\n",
    "        ex_input_prod = \"\"\"First Issue\n",
    "April 11, 1863. Decree #2 of August 18, 1862. Engraved and recess printed by ABNCo. in panes of 100. Perf 12.\n",
    "The half real stamp printed from two plates since the original one developed a crack.\n",
    "Orders:\n",
    "October 11, 1862 — 250,000 (1/2 real plate 1), 250,000 (2 reales)\n",
    "September 30, 1863 — 20,000 (4 reales), 10,000 (1 peso)\n",
    "September 1865 — 500,000 (1/2 real plate 1), 500,000 (2 reales), 50,000 (4 reales), 25,000 (1 peso)\n",
    "December 24, 1872 — 2,000,000 (1/2 real plate 1)\n",
    "June 18, 1875 — 250,000 (1/2 real plate 1), 2,750,000 (1/2 real plate 2)\n",
    "Remainders sold May 23, 1883: 1,000,000 (1/2 real plate 1), 1,615,000 (1/2 real plate 2), 385,000 (2 reales), 23,000 (4 reales), 10,500 (1 peso)\n",
    "\"\"\"\n",
    "        ex_output_prod = json.dumps({\n",
    "            \"issue_data\": {\n",
    "                \"issue_id\": \"CR-1863-FIRST-ISSUE\",\n",
    "                \"section\": \"Surface Mail\",\n",
    "                \"title\": \"First Issue\",\n",
    "                \"country\": \"Costa Rica\",\n",
    "                \"issue_dates\": {\n",
    "                    \"announced\": None,\n",
    "                    \"placed_on_sale\": \"1863-12-01\",\n",
    "                    \"probable_first_circulation\": \"1863-04-11\",\n",
    "                    \"second_plate_sale\": \"1875-09-01\",\n",
    "                    \"demonetized\": \"1883-01-31\"\n",
    "                },\n",
    "                \"legal_basis\": [\n",
    "                    {\"type\": \"decree\", \"id\": \"Decree #2\", \"date\": \"1862-08-18\", \"ids\": [], \"officials\": []}\n",
    "                ],\n",
    "                \"currency_context\": {\n",
    "                    \"original\": \"real/peso\",\n",
    "                    \"decimal_adoption\": \"1864-01-01\",\n",
    "                    \"revaluation_date\": \"1866-06-09\",\n",
    "                    \"revaluation_map\": {\"2 real\": \"5c\", \"2 reales\": \"25c\", \"4 reales\": \"50c\"}\n",
    "                },\n",
    "                \"printing\": {\n",
    "                    \"printer\": \"ABNCo.\",\n",
    "                    \"process\": [\"engraved\", \"recess printed\"],\n",
    "                    \"format\": {\"panes\": 100},\n",
    "                    \"plates\": {\"0.5_real\": {\"plates\": [1, 2], \"notes\": [\"plate 1 cracked\"]}}\n",
    "                },\n",
    "                \"perforation\": \"12\"\n",
    "            },\n",
    "            \"production_orders\": {\n",
    "                \"printings\": [\n",
    "                    {\"date\": \"1862-10-11\", \"quantities\": [\n",
    "                        {\"plate_desc\": \"0.5_real_plate1\", \"quantity\": 250000},\n",
    "                        {\"plate_desc\": \"2_reales\", \"quantity\": 250000}\n",
    "                    ]},\n",
    "                    {\"date\": \"1863-09-30\", \"quantities\": [\n",
    "                        {\"plate_desc\": \"4_reales\", \"quantity\": 20000},\n",
    "                        {\"plate_desc\": \"1_peso\", \"quantity\": 10000}\n",
    "                    ]},\n",
    "                    {\"date\": \"1865-09-01\", \"quantities\": [\n",
    "                        {\"plate_desc\": \"0.5_real_plate1\", \"quantity\": 500000},\n",
    "                        {\"plate_desc\": \"2_reales\", \"quantity\": 500000},\n",
    "                        {\"plate_desc\": \"4_reales\", \"quantity\": 50000},\n",
    "                        {\"plate_desc\": \"1_peso\", \"quantity\": 25000}\n",
    "                    ]},\n",
    "                    {\"date\": \"1872-12-24\", \"quantities\": [\n",
    "                        {\"plate_desc\": \"0.5_real_plate1\", \"quantity\": 2000000}\n",
    "                    ]},\n",
    "                    {\"date\": \"1875-06-18\", \"quantities\": [\n",
    "                        {\"plate_desc\": \"0.5_real_plate1\", \"quantity\": 250000},\n",
    "                        {\"plate_desc\": \"0.5_real_plate2\", \"quantity\": 2750000}\n",
    "                    ]}\n",
    "                ],\n",
    "                \"remainders\": {\n",
    "                    \"date\": \"1883-05-23\",\n",
    "                    \"note\": \"remainder sale\",\n",
    "                    \"quantities\": [\n",
    "                        {\"plate_desc\": \"0.5_real_plate1\", \"quantity\": 1000000},\n",
    "                        {\"plate_desc\": \"0.5_real_plate2\", \"quantity\": 1615000},\n",
    "                        {\"plate_desc\": \"2_reales\", \"quantity\": 385000},\n",
    "                        {\"plate_desc\": \"4_reales\", \"quantity\": 23000},\n",
    "                        {\"plate_desc\": \"1_peso\", \"quantity\": 10500}\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"stamps\": [],\n",
    "            \"varieties\": [],\n",
    "            \"proofs\": {\"die_proofs\": [], \"plate_proofs\": [], \"color_proofs\": [], \"imperforate_proofs\": []},\n",
    "            \"essays\": [],\n",
    "            \"specimens\": [],\n",
    "            \"postal_stationery\" : []\n",
    "        }, indent=2)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Few-shot: PROOFS (DP/PP) block\n",
    "        # ----------------------------------------\n",
    "        ex_input_proofs = \"\"\"Die Proofs on India paper, imperf or sunk on card\n",
    "\n",
    "DP1: 1/2 real black die #332\n",
    "DP2: 2 reales black die #330\n",
    "  DP2a: scarlet\n",
    "DP3: 4 reales black die #387\n",
    "DP4: 1 peso black die #388\n",
    "  DP4a: green\n",
    "  DP4b: brown\n",
    "  DP4c: reddish brown\n",
    "\n",
    "Plate PP1 — Proofs in India paper, imperf or on card\n",
    "1/2 real blue (plate 1)\n",
    "PP1a PP1b PP1c PP1d — black on backer; yellow; green; orange\n",
    "\n",
    "PP1A — 1/2 real light blue (plate 2)\n",
    "\n",
    "PP2 — 2 reales scarlet\n",
    "PP2a — reddish purple\n",
    "PP2c — yellow\n",
    "PP2d — green\n",
    "\"\"\"\n",
    "        ex_output_proofs = json.dumps({\n",
    "            \"issue_data\": {\n",
    "                \"issue_id\": \"CR-1863-PROOFS-SEGMENT\",\n",
    "                \"section\": \"Surface Mail\",\n",
    "                \"title\": \"First Issue Proofs\",\n",
    "                \"country\": \"Costa Rica\",\n",
    "                \"issue_dates\": {\n",
    "                    \"announced\": None,\n",
    "                    \"placed_on_sale\": None,\n",
    "                    \"probable_first_circulation\": None,\n",
    "                    \"second_plate_sale\": None,\n",
    "                    \"demonetized\": None\n",
    "                },\n",
    "                \"legal_basis\": [],\n",
    "                \"currency_context\": {\n",
    "                    \"original\": \"\",\n",
    "                    \"decimal_adoption\": None,\n",
    "                    \"revaluation_date\": None,\n",
    "                    \"revaluation_map\": {}\n",
    "                },\n",
    "                \"printing\": {\"printer\": \"\", \"process\": [], \"format\": {\"panes\": None}, \"plates\": {}},\n",
    "                \"perforation\": \"\"\n",
    "            },\n",
    "            \"production_orders\": {\"printings\": [], \"remainders\": {\"date\": None, \"note\": \"\", \"quantities\": []}},\n",
    "            \"stamps\": [],\n",
    "            \"varieties\": [],\n",
    "            \"proofs\": {\n",
    "                \"die_proofs\": [\n",
    "                    {\"code\": \"DP1\", \"denomination\": \"1/2 real\", \"color\": \"black\", \"die_no\": \"332\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP2\", \"denomination\": \"2 reales\", \"color\": \"black\", \"die_no\": \"330\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP2a\", \"denomination\": \"2 reales\", \"color\": \"scarlet\", \"die_no\": \"330\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP3\", \"denomination\": \"4 reales\", \"color\": \"black\", \"die_no\": \"387\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP4\", \"denomination\": \"1 peso\", \"color\": \"black\", \"die_no\": \"388\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP4a\", \"denomination\": \"1 peso\", \"color\": \"green\", \"die_no\": \"388\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP4b\", \"denomination\": \"1 peso\", \"color\": \"brown\", \"die_no\": \"388\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"},\n",
    "                    {\"code\": \"DP4c\", \"denomination\": \"1 peso\", \"color\": \"reddish brown\", \"die_no\": \"388\",\n",
    "                     \"substrate\": \"India paper\", \"finish\": \"imperf or sunk on card\"}\n",
    "                ],\n",
    "                \"plate_proofs\": [\n",
    "                    {\"code\": \"PP1\", \"note\": \"India paper; imperf or on card\",\n",
    "                     \"items\": [\n",
    "                         {\"variant\": \"PP1\", \"denomination\": \"1/2 real\", \"color\": \"blue\", \"plate\": 1, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP1a\", \"denomination\": \"\", \"color\": \"\", \"plate\": None, \"note\": \"black on backer\"},\n",
    "                         {\"variant\": \"PP1b\", \"denomination\": \"\", \"color\": \"yellow\", \"plate\": None, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP1c\", \"denomination\": \"\", \"color\": \"green\", \"plate\": None, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP1d\", \"denomination\": \"\", \"color\": \"orange\", \"plate\": None, \"note\": \"\"}\n",
    "                     ]},\n",
    "                    {\"code\": \"PP1A\", \"note\": \"\",\n",
    "                     \"items\": [{\"variant\": \"PP1A\", \"denomination\": \"1/2 real\", \"color\": \"light blue\", \"plate\": 2, \"note\": \"\"}]},\n",
    "                    {\"code\": \"PP2\", \"note\": \"\",\n",
    "                     \"items\": [\n",
    "                         {\"variant\": \"PP2\", \"denomination\": \"2 reales\", \"color\": \"scarlet\", \"plate\": None, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP2a\", \"denomination\": \"\", \"color\": \"reddish purple\", \"plate\": None, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP2c\", \"denomination\": \"\", \"color\": \"yellow\", \"plate\": None, \"note\": \"\"},\n",
    "                         {\"variant\": \"PP2d\", \"denomination\": \"\", \"color\": \"green\", \"plate\": None, \"note\": \"\"}\n",
    "                     ]}\n",
    "                ],\n",
    "                \"color_proofs\": [],\n",
    "                \"imperforate_proofs\": []\n",
    "            },\n",
    "            \"essays\": [],\n",
    "            \"specimens\": [],\n",
    "            \"postal_stationery\" : []\n",
    "        }, indent=2)\n",
    "        \n",
    "        # --------------------------\n",
    "        # Few-shot: SPECIMENS block (Costa Rica MUESTRA overprints)\n",
    "        # --------------------------\n",
    "        ex_input_specimens = \"\"\"Specimens\n",
    "\n",
    "        Overprint \"MUESTRA\" in black or red:\n",
    "\n",
    "        MA46a bk 10c scarlet\n",
    "        MA47a red 15c purple\n",
    "        MA48a red 25c light blue\n",
    "        MA49a red 35c bistre brown\n",
    "        MA50a red 60c bluish green\n",
    "        MA51a red 75c olive\n",
    "        MA52a bk 1.35C red orange\n",
    "        MA53a red 5C sepia\n",
    "        MA54a bk 10C red lilac\n",
    "\n",
    "        Overprint \"muestra\" oblique in red:\n",
    "\n",
    "        MA180 15c blue\n",
    "        MA181 20c red\n",
    "        MA182 35c dark green\n",
    "        MA183 45c purple\n",
    "        MA184 50c carmine\n",
    "        MA185 75c red violet\n",
    "        MA186 1C olive\n",
    "        MA187 2C red brown\n",
    "        MA188 5C orange yellow\n",
    "        MA189 10C bright blue\n",
    "        \"\"\"\n",
    "\n",
    "        ex_output_specimens = json.dumps({\n",
    "            \"issue_data\": {\n",
    "                \"issue_id\": \"CR-SPECIMENS-SEGMENT\",\n",
    "                \"section\": \"Surface Mail\",\n",
    "                \"title\": \"Specimens\",\n",
    "                \"country\": \"Costa Rica\",\n",
    "                \"issue_dates\": {\n",
    "                    \"announced\": None,\n",
    "                    \"placed_on_sale\": None,\n",
    "                    \"probable_first_circulation\": None,\n",
    "                    \"second_plate_sale\": None,\n",
    "                    \"demonetized\": None\n",
    "                },\n",
    "                \"legal_basis\": [],\n",
    "                \"currency_context\": {\n",
    "                    \"original\": \"\",\n",
    "                    \"decimal_adoption\": None,\n",
    "                    \"revaluation_date\": None,\n",
    "                    \"revaluation_map\": {}\n",
    "                },\n",
    "                \"printing\": {\n",
    "                    \"printer\": \"\",\n",
    "                    \"process\": [],\n",
    "                    \"format\": {\"panes\": None},\n",
    "                    \"plates\": {}\n",
    "                },\n",
    "                \"perforation\": \"\"\n",
    "            },\n",
    "            \"production_orders\": {\n",
    "                \"printings\": [],\n",
    "                \"remainders\": {\"date\": None, \"note\": \"\", \"quantities\": []}\n",
    "            },\n",
    "            \"stamps\": [],\n",
    "            \"varieties\": [],\n",
    "            \"proofs\": {\n",
    "                \"die_proofs\": [],\n",
    "                \"plate_proofs\": [],\n",
    "                \"color_proofs\": [],\n",
    "                \"imperforate_proofs\": []\n",
    "            },\n",
    "            \"essays\": [],\n",
    "            \"specimens\": [\n",
    "                {\n",
    "                    \"code\": \"MA46a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"10c\",\n",
    "                    \"base_color\": \"scarlet\",\n",
    "                    \"overprint_color\": \"black\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA47a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"15c\",\n",
    "                    \"base_color\": \"purple\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA48a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"25c\",\n",
    "                    \"base_color\": \"light blue\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA49a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"35c\",\n",
    "                    \"base_color\": \"bistre brown\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA50a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"60c\",\n",
    "                    \"base_color\": \"bluish green\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA51a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"75c\",\n",
    "                    \"base_color\": \"olive\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA52a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"1.35C\",\n",
    "                    \"base_color\": \"red orange\",\n",
    "                    \"overprint_color\": \"black\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA53a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"5C\",\n",
    "                    \"base_color\": \"sepia\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA54a\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"10C\",\n",
    "                    \"base_color\": \"red lilac\",\n",
    "                    \"overprint_color\": \"black\",\n",
    "                    \"notes\": \"MUESTRA overprint\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA180\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"15c\",\n",
    "                    \"base_color\": \"blue\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA181\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"20c\",\n",
    "                    \"base_color\": \"red\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA182\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"35c\",\n",
    "                    \"base_color\": \"dark green\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA183\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"45c\",\n",
    "                    \"base_color\": \"purple\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA184\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"50c\",\n",
    "                    \"base_color\": \"carmine\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA185\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"75c\",\n",
    "                    \"base_color\": \"red violet\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA186\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"1C\",\n",
    "                    \"base_color\": \"olive\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA187\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"2C\",\n",
    "                    \"base_color\": \"red brown\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA188\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"5C\",\n",
    "                    \"base_color\": \"orange yellow\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                },\n",
    "                {\n",
    "                    \"code\": \"MA189\",\n",
    "                    \"applies_to\": \"stamps\",\n",
    "                    \"type\": \"overprint\",\n",
    "                    \"denomination\": \"10C\",\n",
    "                    \"base_color\": \"bright blue\",\n",
    "                    \"overprint_color\": \"red\",\n",
    "                    \"notes\": \"MUESTRA overprint oblique\"\n",
    "                }\n",
    "            ],\n",
    "            \"postal_stationery\" : []\n",
    "        }, indent=2)\n",
    "        # --------------------------\n",
    "        # Few-shot: POSTAL STATIONERY (all types)\n",
    "        # --------------------------\n",
    "        ex_input_postal_stationery = \"\"\"Postal Stationery\n",
    "\n",
    "        Die Proofs\n",
    "        DPPC1  2c black\n",
    "        DPEN1  5c black\n",
    "\n",
    "        Overprint \"muestra\"\n",
    "        MPC1   2c black\n",
    "\n",
    "        Regular issue - Postal Cards\n",
    "        PC1    2c black                        50,000\n",
    "        PC2    4c black, with reply card       50,000\n",
    "\n",
    "        Envelopes\n",
    "        EN1    5c blue (thin paper)           180,000\n",
    "        EN1a   pale blue\n",
    "        EN2    10c orange yellow              75,000\n",
    "\n",
    "        Aerogrammes\n",
    "        LS1    2C multicolor                  100,000\n",
    "\n",
    "        Official Envelopes\n",
    "        OEN1   2c green, op \"Servicio Oficial\"\n",
    "        OEN1a  inverted op\n",
    "\n",
    "        Wrappers\n",
    "        W1     2c green\n",
    "        \"\"\"\n",
    "\n",
    "        ex_output_postal_stationery = json.dumps({\n",
    "            \"issue_data\": {\n",
    "                \"issue_id\": \"CR-POSTAL-STATIONERY-SEGMENT\",\n",
    "                \"section\": \"Postal Stationery\",\n",
    "                \"title\": \"Postal Stationery\",\n",
    "                \"country\": \"Costa Rica\",\n",
    "                \"issue_dates\": {\"announced\": None, \"placed_on_sale\": None, \"probable_first_circulation\": None, \"second_plate_sale\": None, \"demonetized\": None},\n",
    "                \"legal_basis\": [],\n",
    "                \"currency_context\": {\"original\": \"\", \"decimal_adoption\": None, \"revaluation_date\": None, \"revaluation_map\": {}},\n",
    "                \"printing\": {\"printer\": \"\", \"process\": [], \"format\": {\"panes\": None}, \"plates\": {}},\n",
    "                \"perforation\": \"\"\n",
    "            },\n",
    "            \"production_orders\": {\"printings\": [], \"remainders\": {\"date\": None, \"note\": \"\", \"quantities\": []}},\n",
    "            \"stamps\": [],\n",
    "            \"varieties\": [\n",
    "                {\"base_catalog_no\": \"EN1\", \"suffix\": \"a\", \"type\": \"color\", \"description\": \"pale blue\", \"position\": None, \"plate\": None},\n",
    "                {\"base_catalog_no\": \"OEN1\", \"suffix\": \"a\", \"type\": \"overprint\", \"description\": \"inverted overprint\", \"position\": None, \"plate\": None}\n",
    "            ],\n",
    "            \"proofs\": {\n",
    "                \"die_proofs\": [\n",
    "                    {\"code\": \"DPPC1\", \"denomination\": \"2c\", \"color\": \"black\", \"die_no\": \"\", \"substrate\": \"\", \"finish\": \"\"},\n",
    "                    {\"code\": \"DPEN1\", \"denomination\": \"5c\", \"color\": \"black\", \"die_no\": \"\", \"substrate\": \"\", \"finish\": \"\"}\n",
    "                ],\n",
    "                \"plate_proofs\": [],\n",
    "                \"color_proofs\": [],\n",
    "                \"imperforate_proofs\": []\n",
    "            },\n",
    "            \"essays\": [],\n",
    "            \"specimens\": [\n",
    "                {\"code\": \"MPC1\", \"applies_to\": \"postal_stationery\", \"type\": \"overprint\", \"denomination\": \"2c\", \"base_color\": \"black\", \"overprint_color\": \"black\", \"notes\": \"MUESTRA overprint\"}\n",
    "            ],\n",
    "            \"postal_stationery\": [\n",
    "                {\"catalog_no\": \"PC1\", \"stationery_type\": \"postal_card\", \"denomination\": {\"value\": 2, \"unit\": \"c\"}, \"color\": \"black\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": 50000, \"card_type\": \"single\", \"notes\": \"\"},\n",
    "                {\"catalog_no\": \"PC2\", \"stationery_type\": \"postal_card\", \"denomination\": {\"value\": 4, \"unit\": \"c\"}, \"color\": \"black\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": 50000, \"card_type\": \"reply\", \"notes\": \"with reply card\"},\n",
    "                {\"catalog_no\": \"EN1\", \"stationery_type\": \"envelope\", \"denomination\": {\"value\": 5, \"unit\": \"c\"}, \"color\": \"blue\", \"paper\": \"thin paper\", \"size\": \"\", \"quantity_reported\": 180000, \"notes\": \"\"},\n",
    "                {\"catalog_no\": \"EN2\", \"stationery_type\": \"envelope\", \"denomination\": {\"value\": 10, \"unit\": \"c\"}, \"color\": \"orange yellow\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": 75000, \"notes\": \"\"},\n",
    "                {\"catalog_no\": \"LS1\", \"stationery_type\": \"aerogramme\", \"denomination\": {\"value\": 2, \"unit\": \"C\"}, \"color\": \"multicolor\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": 100000, \"notes\": \"\"},\n",
    "                {\"catalog_no\": \"OEN1\", \"stationery_type\": \"official_envelope\", \"denomination\": {\"value\": 2, \"unit\": \"c\"}, \"color\": \"green\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": None, \"notes\": \"\", \"overprint\": {\"present\": True, \"type\": \"overprint\", \"text\": \"Servicio Oficial\", \"color\": \"black\"}},\n",
    "                {\"catalog_no\": \"W1\", \"stationery_type\": \"wrapper\", \"denomination\": {\"value\": 2, \"unit\": \"c\"}, \"color\": \"green\", \"paper\": \"\", \"size\": \"\", \"quantity_reported\": None, \"notes\": \"\"}\n",
    "            ]\n",
    "        }, indent=2)\n",
    "        # Few-shot wrapper\n",
    "        example_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\")\n",
    "        ])\n",
    "\n",
    "        few_shot = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=example_prompt,\n",
    "            examples=[\n",
    "                {\"input\": ex_input_surcharges, \"output\": ex_output_surcharges},\n",
    "                {\"input\": ex_input_prod,       \"output\": ex_output_prod},\n",
    "                {\"input\": ex_input_proofs,     \"output\": ex_output_proofs},                \n",
    "                {\"input\": ex_input_regular_var, \"output\": ex_output_regular_var},\n",
    "                {\"input\": ex_input_specimens,   \"output\": ex_output_specimens},\n",
    "                {\"input\": ex_input_postal_stationery,   \"output\": ex_output_postal_stationery}\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # System prompt — ALL BRACES ARE ESCAPED {{like this}} to avoid LangChain templating errors.\n",
    "        system_prompt = \"\"\"\n",
    "You are a structured parser for the Mena Catalog (Costa Rica). Extract data into ONE JSON object\n",
    "with EXACTLY these top-level keys:\n",
    "- \"issue_data\"\n",
    "- \"production_orders\"\n",
    "- \"stamps\"\n",
    "- \"varieties\"\n",
    "- \"proofs\"\n",
    "- \"essays\"\n",
    "- \"specimens\"\n",
    "- \"postal_stationery\"\n",
    "\n",
    "Return the FULL schema even if empty. If a section doesn't appear, return it as empty containers:\n",
    "- lists as []\n",
    "- maps as {{}}\n",
    "- dates as null\n",
    "- strings as \"\"\n",
    "\n",
    "Output schema (types and intent):\n",
    "\n",
    "issue_data:\n",
    "  - issue_id (string): Stable unique ID (recommend COUNTRY-YYYY[-YYYY]-TITLE).\n",
    "  - section (string): Catalog section (e.g., \"Surface Mail\").\n",
    "  - title (string): Issue title as printed.\n",
    "  - country (string): Country name.\n",
    "  - issue_dates (object):\n",
    "      announced | placed_on_sale | probable_first_circulation | second_plate_sale | demonetized (ISO or null)\n",
    "  - legal_basis (array of objects):\n",
    "      {{ type: \"decree\"|\"law\"|\"letter\"|\"resolution\"|..., id: string, date: ISO|null, ids: [], officials: [] }}\n",
    "  - currency_context (object):\n",
    "      original (string), decimal_adoption (ISO|null), revaluation_date (ISO|null), revaluation_map (object string->string)\n",
    "  - printing (object):\n",
    "      printer (string), process (string[]), format {{ panes: number|null }}, plates {{ \"<denom_token>\": {{ plates: number[], notes: string[] }} }}\n",
    "  - perforation (string): numeric gauge like \"12\" if specified, else \"\".\n",
    "\n",
    "production_orders:\n",
    "  - printings (array):\n",
    "      {{ date: ISO|null, quantities: [ {{ plate_desc: string, quantity: number }} ] }}\n",
    "  - remainders (object):\n",
    "      {{ date: ISO|null, note: string, quantities: [ {{ plate_desc: string, quantity: number }} ] }}\n",
    "\n",
    "stamps (regular issues + souvenir sheets):\n",
    "  - array of objects with these fields:\n",
    "    \n",
    "    FOR REGULAR STAMPS:\n",
    "    {{\n",
    "      catalog_no: string,                       // e.g., \"54\", \"83\", \"1A\"\n",
    "      issue_id: string,                         // link to issue_data.issue_id\n",
    "      denomination: {{                          // resulting face value of the issued stamp\n",
    "        value: number,\n",
    "        unit: \"c\" | \"C\" | \"P\" | \"reales\"        // normalize: centavo/cts/centime -> \"c\"; Colón -> \"C\"; Peso -> \"P\"; real/reales -> \"reales\"\n",
    "      }},\n",
    "      color: string,                            // \"\" if not stated\n",
    "      plate: number | null,                     // null if not given\n",
    "      perforation: string | \"\",                 // gauge only (e.g., \"12\"); \"\" if unknown (do NOT include \"perf\")\n",
    "      watermark: string | null,                 // null if not mentioned\n",
    "      quantity_reported: number | null,         // ONLY if the specific catalog number line states a quantity; else null\n",
    "      status: \"regular\",                        // ALWAYS \"regular\" for regular stamps\n",
    "      notes: string[],                          // [] if none\n",
    "\n",
    "      // ONLY when the REGULAR stamp line itself is a surcharge/overprint listing (e.g., \"2c/10C\"):\n",
    "      overprint?: {{\n",
    "        present: boolean,\n",
    "        type: \"surcharge\" | \"overprint\" | \"bar_cancel\" | \"other\",\n",
    "        surcharge_denomination?: {{ value: number, unit: \"c\" | \"C\" | \"P\" | \"reales\" }},\n",
    "        on_denomination?: {{ value: number, unit: \"c\" | \"C\" | \"P\" | \"reales\" }},\n",
    "        color?: string\n",
    "      }},\n",
    "      base_stamp_ref?: string                   // optional cross-ref (e.g., \"1\", \"1A\", \"091\")\n",
    "    }}\n",
    "    \n",
    "    FOR SOUVENIR SHEETS (SS codes):\n",
    "    {{\n",
    "      catalog_no: string,                       // e.g., \"SSA752\", \"SS123\"\n",
    "      issue_id: string,                         // link to issue_data.issue_id\n",
    "      denomination: {{\n",
    "        value: null,                            // ALWAYS null for souvenir sheets\n",
    "        unit: \"sheet\"                           // ALWAYS \"sheet\" for souvenir sheets\n",
    "      }},\n",
    "      color: string,                            // often \"multicolor\"\n",
    "      plate: number | null,                     // usually null\n",
    "      perforation: string | \"\",                 // gauge if perforated (e.g., \"10.5\"), \"\" if imperf\n",
    "      watermark: string | null,                 // usually null\n",
    "      quantity_reported: number | null,         // from table if available\n",
    "      status: \"souvenir_sheet\",                 // ALWAYS \"souvenir_sheet\" for SS codes\n",
    "      notes: string[],                          // describe contents: [\"Souvenir sheet with 5 values perf and island map\"]\n",
    "      \n",
    "      // OPTIONAL: list of stamps contained in the sheet\n",
    "      sheet_contents?: string[]                 // e.g., [\"A747\", \"A748\", \"A749\", \"A750\", \"A751\"]\n",
    "                                                // Only populate if text explicitly lists which stamps\n",
    "                                                // Otherwise omit field or use []\n",
    "    }}\n",
    "\n",
    "varieties:\n",
    "  - array of:\n",
    "    {{\n",
    "      base_catalog_no: string,                 // base main number (e.g., \"31\", \"1A\")\n",
    "      suffix: string,                          // LOWERCASE suffix only (e.g., \"a\", \"b\")\n",
    "      type: \"perforation\"|\"impression\"|\"plate_flaw\"|\"overprint\"|\"surcharge\"|\"color\"|\"color_shift\"|\"watermark\"|\"paper\"|\"gumming\"|\"other\",\n",
    "      description: string,\n",
    "      position: string|null,\n",
    "      plate: number|null\n",
    "    }}\n",
    "\n",
    "proofs:\n",
    "  - die_proofs: [\n",
    "      {{ code: string, denomination: string, color: string, die_no: string, substrate: string, finish: string }}\n",
    "    ]\n",
    "  - plate_proofs: [\n",
    "      {{ code: string, note: string, items: [ {{ variant: string, denomination: string, color: string, plate: number|null, note: string }} ] }}\n",
    "    ]\n",
    "  - color_proofs: [ {{ code: string, denomination: string, color: string, notes: string }} ]\n",
    "  - imperforate_proofs: [ {{ code: string, denomination: string, notes: string }} ]\n",
    "\n",
    "essays:\n",
    "  - [ {{ code: string, medium: string, paper: string, denomination: string, provenance: string[], notes: string[] }} ]\n",
    "\n",
    "specimens:\n",
    "  - [ {{ code: string, applies_to: \"proofs\"|\"stamps\", type: \"overprint\"|\"punch\"|\"perfin\"|\"handstamp\"|string, denomination: string, base_color: string, overprint_color: string, notes: string }} ]\n",
    "postal_stationery: [\n",
    "  {{\n",
    "    catalog_no: string,                    // e.g., \"PC1\", \"EN5\", \"LS1\", \"OEN2\", \"W1\"\n",
    "    issue_id: string,\n",
    "    stationery_type: \"postal_card\" | \"envelope\" | \"aerogramme\" | \"official_envelope\" | \"wrapper\",\n",
    "    denomination: {{\n",
    "      value: number,\n",
    "      unit: \"c\" | \"C\" | \"P\"\n",
    "    }},\n",
    "    color: string,                         // printed color\n",
    "    paper: string,                         // e.g., \"buff manila\", \"white laid\", \"thick paper\"\n",
    "    size: string,                          // dimensions (e.g., \"132 x 80 mm\", \"138 x 80 mm\")\n",
    "    quantity_reported: number|null,\n",
    "    notes: string[],\n",
    "    \n",
    "    // OPTIONAL fields (only when applicable):\n",
    "    card_type?: \"single\" | \"reply\" | \"double\",  // only for postal_card type\n",
    "    overprint?: {{                         // for official envelopes with overprints\n",
    "      present: boolean,\n",
    "      type: \"overprint\" | \"surcharge\",\n",
    "      text: string,                        // e.g., \"Servicio Oficial\", \"Libre de Porte\"\n",
    "      color: string\n",
    "    }},\n",
    "    base_ref?: string                      // if overprinted on another stationery item\n",
    "  }}\n",
    "]\n",
    "\n",
    "CRITICAL: Only populate postal_stationery if the input text explicitly \n",
    "mentions postal cards (PC), envelopes (EN), aerogrammes (LS), wrappers (W), \n",
    "or letter sheets.\n",
    "\n",
    "If there is NO mention of postal stationery in the input, return:\n",
    "\"postal_stationery\": []\n",
    "\n",
    "NEVER invent postal stationery data.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "HARD SEPARATION: SPECIMENS vs VARIETIES (NEVER MIX)\n",
    "--------------------------------------------------------------------------------\n",
    "A) SPECIMENS (S-codes)\n",
    "- Detector: any line that BEGINS with uppercase \"S\" + digits + optional lowercase (regex: ^S\\\\d+[a-z]?$).\n",
    "- Each S-code MUST yield ONE item in top-level \"specimens\".\n",
    "- NEVER place S-codes under \"varieties\", \"proofs\", or inside \"stamps\".\n",
    "- \"applies_to\": default \"stamps\". Use \"proofs\" ONLY if the text explicitly binds that S-code to proofs.\n",
    "- \"type\": default \"overprint\" unless the line explicitly indicates \"punch\", \"perfin\", \"handstamp\", etc.\n",
    "- 'Muestra' is an special specimen that is an overprint and always starts with MA, example: \"MA46a bk 10c scarlet\" → code: MA46a, overprint_color: black, denomination: 10c, base_color: scarlet\n",
    "- \"denomination\": take the face value and unit on the same row if present; if not, inherit from the row header ONLY if unambiguous; otherwise \"\".\n",
    "- \"base_color\": color BEFORE the overprint phrase, lowercased.\n",
    "- \"overprint_color\": keep orientation adjectives (e.g., \"black\", \"red\", \"in a black circle\").\n",
    "- \"notes\": carry remaining qualifiers (e.g., \"imperforate; ungummed thin paper with hole\"; \"Perf 12.5\"; \"salesman samples\").\n",
    "- IMPORTANT: Even if an S-code mentions “inverted overprint” or “Perf 12.5”, it REMAINS a specimen and stays in \"specimens\" (not in \"varieties\").\n",
    "\n",
    "B) VARIETIES (lowercase suffixes of MAIN numbers)\n",
    "- Detector: main catalog number + lowercase suffix (e.g., \"31a\", \"33b\", \"1Aa\").\n",
    "- Keep ONLY these in \"varieties\".\n",
    "- Uppercase letter immediately after digits forms a MAIN number (e.g., \"1A\"): keep in \"stamps\", not \"varieties\".\n",
    "- Typical entries: imperf between, margin imperf, inverted OP of a REGULAR non-S specimen, paper, watermark, color shade, plate flaw.\n",
    "- **VARIETY BASE NUMBER**:\n",
    "  Always use catalog number from Column 1 as base_catalog_no, even if variety code in Column 2 \n",
    "  contains a different number. Example: <tr><td>34</td><td>33d</td></tr> → base_catalog_no: \"34\", suffix: \"d\"\n",
    "Collision resolution:\n",
    "- If a feature appears both in a REGULAR listing and in an S-code list:\n",
    "  • Regular listing feature → \"varieties\".\n",
    "  • S-code feature → keep inside that S-code item in \"specimens\" (as type/notes). Do NOT mirror it into \"varieties\".\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "PROGRESSIVE DIES & SPECIAL CASES\n",
    "--------------------------------------------------------------------------------\n",
    "- Progressive die (e.g., “DPA31a vignette only”): put under \"proofs.die_proofs\" as:\n",
    "  {{ code: \"DPA31a\", denomination: \"\", color: \"\", die_no: \"\", substrate: \"\", finish: \"progressive: vignette only\" }}\n",
    "- Bar cancels: only use stamps[].overprint.type = \"bar_cancel\" when the main regular line defines it as such.\n",
    "- Do NOT convert progressive dies or salesman sheets into \"varieties\".\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "NON-ISSUED STAMPS (NEA CODES)\n",
    "--------------------------------------------------------------------------------\n",
    "When a table shows specimen categories including \"without overprint\" or \n",
    "\"non-emis\", these are non-issued stamps that should be captured in specimens.\n",
    "\n",
    "DETECTION:\n",
    "- Code pattern: NEA\\d+[a-z]?\n",
    "- Table columns showing: I. Without overprint, II. specimen, III. muestra\n",
    "\n",
    "FIELD ASSIGNMENT:\n",
    "- code: as written (NEA46, NEA47, etc.)\n",
    "- applies_to: \"stamps\"\n",
    "- type: \"non-issued\" or \"unissued\"\n",
    "- overprint_color: \"\" (no overprint)\n",
    "- notes: \"non-issued stamp without overprint\" or similar\n",
    "\n",
    "These are distinct from regular specimens (SNEA, MNEA, MA codes).\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "CONSTANT VARIETIES - EXPANSION RULE\n",
    "--------------------------------------------------------------------------------\n",
    "When text contains \"Constant [X] varieties in [Y]:\" followed by variety list,\n",
    "these varieties apply to ALL items in the specified range, not just one.\n",
    "\n",
    "DETECTION PATTERNS:\n",
    "1. \"Constant overprint plate varieties in regular issue\"\n",
    "   → Apply to all regular stamps in the issue\n",
    "   \n",
    "2. \"Constant varieties in regular issue and 'muestra' overprints\"\n",
    "   → Apply to all regular stamps AND note in muestra specimens\n",
    "   \n",
    "3. \"Constant plate varieties\"\n",
    "   → Apply to all stamps using that plate\n",
    "\n",
    "IMPLEMENTATION:\n",
    "When parsing varieties section, if header says \"Constant ... varieties in [scope]\":\n",
    "\n",
    "Step 1: Parse the variety definitions:\n",
    "  a: description (pos X)\n",
    "  b: description (pos Y)\n",
    "  \n",
    "Step 2: Identify the applicable range:\n",
    "  - If \"in regular issue\": apply to ALL stamps with status=\"regular\"\n",
    "  - If \"in stamps A46-A52\": apply to that specific range\n",
    "  - If no range specified: apply to all stamps in current issue\n",
    "  \n",
    "Step 3: For EACH stamp in range, create variety entry:\n",
    "  {{\n",
    "    \"base_catalog_no\": \"<stamp_catalog_no>\",\n",
    "    \"suffix\": \"<variety_letter>\",\n",
    "    \"type\": \"<variety_type>\",\n",
    "    \"description\": \"<variety_description>\",\n",
    "    \"position\": \"<pos if specified>\",\n",
    "    \"plate\": <plate_number if known>\n",
    "  }}\n",
    "\n",
    "EXAMPLE FROM CURRENT TEST:\n",
    "Input:\n",
    "  Regular stamps: A46, A47, A48, A49, A50, A51, A52, A53, A54\n",
    "  \"Constant overprint plate varieties in regular issue:\n",
    "   a: hyphen missing between 2 and Diciembre (pos 13)\n",
    "   b: DJA for DIA (pos 49)\"\n",
    "\n",
    "Output varieties[] should contain 18 entries:\n",
    "  - A46a, A46b\n",
    "  - A47a, A47b\n",
    "  - A48a, A48b\n",
    "  - A49a, A49b\n",
    "  - A50a, A50b\n",
    "  - A51a, A51b\n",
    "  - A52a, A52b\n",
    "  - A53a, A53b\n",
    "  - A54a, A54b\n",
    "\n",
    "All with the same descriptions but different base_catalog_no.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "OVERPRINT PROOFS (OP codes)\n",
    "--------------------------------------------------------------------------------\n",
    "Codes starting with \"OP\" (e.g., OPA46, OPB23) are OVERPRINT PROOFS.\n",
    "These should be placed in \"proofs.plate_proofs\", NOT in \"imperforate_proofs\".\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "UNIT NORMALIZATION\n",
    "--------------------------------------------------------------------------------\n",
    "- UNITS normalization:\n",
    "  • \"c\", \"cent\", \"centavo\", \"centavos\", \"cts\", \"centime\" -> \"c\"\n",
    "  • Capital \"C\" = \"Colón\", MUST remain \"C\"\n",
    "  • \"P\" = \"Peso\"; \"real\"/\"reales\" -> \"reales\"\n",
    "\n",
    "\n",
    "Pattern recognition:\n",
    "- \"1.35C\" → unit: \"C\" (Colón, not centavo)\n",
    "- \"5C\" → unit: \"C\" (Colón)\n",
    "- \"10C\" → unit: \"C\" (Colón)\n",
    "- \"10c\" → unit: \"c\" (centavo | centimo | cts)\n",
    "- \"75c\" → unit: \"c\" (centavo | centimo | cts)\n",
    "\n",
    "MUST preserve the case of the unit letter from the source.\n",
    "Never convert \"C\" → \"c\" or vice versa.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "DENOMINATIONS & SURCHARGES (\"/\" RULE)\n",
    "--------------------------------------------------------------------------------\n",
    "- \"2c/10C\" means a surcharge: the result denomination is 2c; base was 10C.\n",
    "- Populate:\n",
    "  \"denomination\": {{ \"value\": 2, \"unit\": \"c\" }}\n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"surcharge\",\n",
    "    \"surcharge_denomination\": {{ \"value\": 2, \"unit\": \"c\" }},\n",
    "    \"on_denomination\": {{ \"value\": 10, \"unit\": \"C\" }}\n",
    "  }}\n",
    "  \n",
    "--------------------------------------------------------------------------------\n",
    "DENOMINATION EXTRACTION - NO AUTO-CONVERSION\n",
    "--------------------------------------------------------------------------------\n",
    "CRITICAL: Extract denomination EXACTLY as written in the source.\n",
    "\n",
    "NEVER convert between units automatically:\n",
    "- If source says \"90c\" → value: 90, unit: \"c\" (NOT 0.9C)\n",
    "- If source says \"0.9C\" → value: 0.9, unit: \"C\" (NOT 90c)\n",
    "- If source says \"2.10C\" → value: 2.1, unit: \"C\"\n",
    "\n",
    "Even though 100 centavos = 1 Colón in Costa Rica, do NOT perform conversions.\n",
    "The denomination must reflect what is PRINTED on the stamp, not mathematical equivalents.\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SURCHARGE STAMPS - COLOR FIELD EXTRACTION\n",
    "--------------------------------------------------------------------------------\n",
    "For stamps with surcharge format: \"Xc on Yc COLOR, in COLOR2\"\n",
    "\n",
    "Example: \"10c on 15c green, in black\"\n",
    "         \"35c on 50c violet, in orange\"\n",
    "\n",
    "PARSING RULES:\n",
    "1. denomination = Xc (the NEW value after surcharge)\n",
    "2. color = COLOR (ONLY the color of the BASE stamp)\n",
    "3. overprint.surcharge_denomination = Xc\n",
    "4. overprint.on_denomination = Yc\n",
    "5. overprint.color = COLOR2 (from \"in COLOR2\")\n",
    "\n",
    "CRITICAL: The \"color\" field must contain ONLY the base stamp color.\n",
    "Do NOT include the entire phrase \"on Yc COLOR, in COLOR2\".\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SOUVENIR SHEETS\n",
    "--------------------------------------------------------------------------------\n",
    "Souvenir sheets (SS codes like SSA752, SS123) are special collectible formats.\n",
    "\n",
    "DETECTION: Codes starting with \"SS\" followed by optional letter and numbers\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"SSA752\",\n",
    "  \"denomination\": {{\"value\": null, \"unit\": \"sheet\"}},\n",
    "  \"status\": \"souvenir_sheet\",\n",
    "  \"color\": \"multicolor\",\n",
    "  \"perforation\": \"10.5\",\n",
    "  \"quantity_reported\": 40000,\n",
    "  \"notes\": \"Souvenir sheet with 5 values perf and island map\",\n",
    "  \"sheet_contents\": []  // optional: [\"A747\", \"A748\"] if explicitly stated\n",
    "}}\n",
    "\n",
    "VARIETIES: If SSA752a is imperforated version → place in varieties[], not stamps[]:\n",
    "{{\n",
    "  \"base_catalog_no\": \"SSA752\",\n",
    "  \"suffix\": \"a\",\n",
    "  \"type\": \"perforation\",\n",
    "  \"description\": \"imperforated\"\n",
    "}}\n",
    "\n",
    "EXAMPLE:\n",
    "Input:\n",
    "  SSA752    sheet with 5 values perf    40,000\n",
    "  SSA752a   sheet imperforated\n",
    "\n",
    "Output:\n",
    "- stamps[]: SSA752 with status: \"souvenir_sheet\", unit: \"sheet\", value: null\n",
    "- varieties[]: SSA752a as perforation variety\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SPECIAL PREFIX CODES - IA, IB, IC (Imperforate Variants)\n",
    "--------------------------------------------------------------------------------\n",
    "Some catalog systems use prefix codes for special variants:\n",
    "\n",
    "DETECTION:\n",
    "Codes starting with \"I\" followed by regular code: IA722, IB123, IC45\n",
    "\n",
    "MEANING:\n",
    "- IA722 = Imperforate version of A722\n",
    "- Similar to SSA (Souvenir Sheet A), IA (Imperforate A)\n",
    "\n",
    "CLASSIFICATION:\n",
    "These are COMPLETE catalog codes, NOT suffixes.\n",
    "\n",
    "IA722 is NOT the same as A722i or A722a\n",
    "\n",
    "PLACE AS SEPARATE STAMP:\n",
    "{{\n",
    "  \"catalog_no\": \"IA722\",\n",
    "  \"denomination\": {{...}},\n",
    "  \"perforation\": \"\",  // always imperf for IA codes\n",
    "  \"status\": \"error\" | \"printer_waste\" | \"regular\",  // based on context\n",
    "  \"notes\": \"Imperforate (printer's waste)\" or similar\n",
    "}}\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "ATM STAMPS (VARIABLE VALUE STAMPS)\n",
    "--------------------------------------------------------------------------------\n",
    "ATM stamps (Automaten Marken - Automated Teller Machine stamps) are variable \n",
    "value stamps printed by machines. They have no fixed denomination.\n",
    "\n",
    "DETECTION: Codes starting with \"ATM\" followed by numbers: ATM9, ATM12, ATM5\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"ATM9\",\n",
    "  \"denomination\": {{\n",
    "    \"value\": null,           // no fixed value\n",
    "    \"unit\": \"variable\"       // special unit for ATM stamps\n",
    "  }},\n",
    "  \"status\": \"atm\",           // special status\n",
    "  \"color\": string,           // if mentioned\n",
    "  \"perforation\": \"\",         // typically imperf or machine cut\n",
    "  \"quantity_reported\": null, // variable, not typically reported\n",
    "  \"notes\": string            // include description, e.g., \"Papagayo Gulf. Variable value stamp. Size 57 x 27 mm\"\n",
    "}}\n",
    "\n",
    "NOTES FIELD:\n",
    "Include relevant details:\n",
    "- Subject/design description\n",
    "- Size dimensions (e.g., \"Size 57 x 27 mm\")\n",
    "- \"Variable value stamp\" or \"ATM stamp\"\n",
    "- Any special characteristics\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "CHRISTMAS POSTAL TAX STAMPS\n",
    "--------------------------------------------------------------------------------\n",
    "Christmas Tax stamps (CT codes) are special postal tax stamps.\n",
    "\n",
    "DETECTION: Codes starting with \"CT\" followed by numbers/letters: CT1, CT1A, CT25\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"CT1\",\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,              // the surcharge/final value (e.g., 5)\n",
    "    \"unit\": \"c\" | \"C\"             // standard units\n",
    "  }},\n",
    "  \"status\": \"postal_tax\",         // special status for tax stamps\n",
    "  \"color\": string,\n",
    "  \"perforation\": string,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"notes\": string,                // include \"Christmas postal tax stamp\" + details\n",
    "  \n",
    "  // Most CT stamps are surcharges on other stamps:\n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"surcharge\",\n",
    "    \"surcharge_denomination\": {{value: number, unit: string}},\n",
    "    \"on_denomination\": {{value: number, unit: string}},\n",
    "    \"color\": string\n",
    "  }},\n",
    "  \"base_stamp_ref\": string        // e.g., \"A210\"\n",
    "}}\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "POSTAL STATIONERY (Unified Category)\n",
    "--------------------------------------------------------------------------------\n",
    "Postal stationery are pre-stamped items (cards, envelopes, etc.), separate from \n",
    "adhesive stamps. All types go in the \"postal_stationery\" array.\n",
    "\n",
    "CODE DETECTION & TYPE MAPPING:\n",
    "Pattern              stationery_type        Example\n",
    "^PC\\d+[a-z]?$       → \"postal_card\"        PC1, PC25\n",
    "^EN\\d+[a-z]?$       → \"envelope\"           EN1, EN12\n",
    "^LS\\d+[a-z]?$       → \"aerogramme\"         LS1, LS5\n",
    "^OEN\\d+[a-z]?$      → \"official_envelope\"  OEN1, OEN23\n",
    "^W\\d+[a-z]?$        → \"wrapper\"            W1, W3\n",
    "\n",
    "STRUCTURE:\n",
    "{{\n",
    "  \"catalog_no\": \"PC1\",\n",
    "  \"stationery_type\": \"postal_card\",\n",
    "  \"denomination\": {{\"value\": 2, \"unit\": \"c\"}},\n",
    "  \"color\": \"black\",\n",
    "  \"paper\": \"buff manila\",\n",
    "  \"size\": \"132 x 80 mm\",\n",
    "  \"quantity_reported\": 50000,\n",
    "  \"notes\": [],\n",
    "  \n",
    "  // ONLY for postal_card type:\n",
    "  \"card_type\": \"single\" | \"reply\" | \"double\"\n",
    "}}\n",
    "\n",
    "CARD TYPES (postal_card only):\n",
    "- \"single\": Regular postal card\n",
    "- \"reply\": Card mentions \"with reply card\" or \"reply card\"\n",
    "- \"double\": Double-sized reply card format\n",
    "\n",
    "OFFICIAL ENVELOPES with overprints:\n",
    "{{\n",
    "  \"catalog_no\": \"OEN1\",\n",
    "  \"stationery_type\": \"official_envelope\",\n",
    "  \"denomination\": {{\"value\": 2, \"unit\": \"c\"}},\n",
    "  \"color\": \"green\",\n",
    "  \"notes\": [\"For use by Secretary of Finance\"],\n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"overprint\",\n",
    "    \"text\": \"Servicio Oficial\",\n",
    "    \"color\": \"black\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "PROOFS & SPECIMENS OF POSTAL STATIONERY:\n",
    "Identified by prefix + stationery type:\n",
    "- DPPC# = Die Proof Postal Card → proofs.die_proofs[]\n",
    "- DPEN# = Die Proof Envelope → proofs.die_proofs[]\n",
    "- DPLS# = Die Proof Aerogramme → proofs.die_proofs[]\n",
    "- DPOEN# = Die Proof Official Envelope → proofs.die_proofs[]\n",
    "- DPW# = Die Proof Wrapper → proofs.die_proofs[]\n",
    "\n",
    "- MPC# = Muestra Postal Card → specimens[]\n",
    "- MEN# = Muestra Envelope → specimens[]\n",
    "- MLS# = Muestra Aerogramme → specimens[]\n",
    "- etc.\n",
    "\n",
    "For specimens, use applies_to: \"postal_stationery\"\n",
    "\n",
    "VARIETIES:\n",
    "Lowercase suffixes go in varieties[]:\n",
    "{{\n",
    "  \"base_catalog_no\": \"EN1\",\n",
    "  \"suffix\": \"a\",\n",
    "  \"type\": \"color\" | \"impression\" | \"overprint\" | \"plate_flaw\",\n",
    "  \"description\": \"pale blue\" | \"double impression\" | \"inverted op\"\n",
    "}}\n",
    "\n",
    "CRITICAL POSTAL STATIONARY NOTES:\n",
    "- ALL postal stationery types go in ONE \"postal_stationery\" array\n",
    "- stationery_type field distinguishes the specific type\n",
    "- Postal stationery are NOT stamps - don't put in stamps[] array\n",
    "- Uppercase letter suffixes (EN1A) = main items, not varieties\n",
    "- Lowercase suffixes (EN1a) = varieties → varieties[] array\n",
    "- Proofs use DP + type prefix (DPPC, DPEN, DPLS, DPOEN, DPW)\n",
    "- Specimens use M + type prefix (MPC, MEN, MLS, MOEN, MW)\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "OFFICIAL STAMPS (Surface Mail & Airmail)\n",
    "--------------------------------------------------------------------------------\n",
    "Official stamps are regular postage stamps overprinted for official government \n",
    "use. They go in the stamps[] array with special status and overprint structure.\n",
    "\n",
    "CODE DETECTION:\n",
    "Surface Mail:     ^O\\d+[a-z]?$        → O1, O25, O3a\n",
    "Airmail:          ^OA\\d+[a-z]?$       → OA107, OA115, OA119a\n",
    "\n",
    "Both types use same structure, only differ in section (Surface Mail vs Airmail).\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"O1\" | \"OA107\",\n",
    "  \"issue_id\": string,\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,\n",
    "    \"unit\": \"c\" | \"C\" | \"P\" | \"reales\"\n",
    "  }},\n",
    "  \"color\": string,                      // color of base stamp\n",
    "  \"perforation\": string,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"official\",                 // same status for O and OA\n",
    "  \"notes\": string[],\n",
    "  \n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"overprint\",\n",
    "    \"text\": string,                       // e.g., \"Oficial\", \"OFFICIAL\"\n",
    "    \"color\": string                     // color of overprint\n",
    "  }},\n",
    "  \"base_stamp_ref\": string              // reference to base stamp\n",
    "}}\n",
    "\n",
    "OVERPRINT EXTRACTION:\n",
    "- From text: \"Overprint 'Oficial' in red\" → text: \"Oficial\", color: \"red\"\n",
    "- Color format: \"5c green, in red\" → base: green, overprint: red\n",
    "- If no explicit text, use: \"Official use overprint\"\n",
    "\n",
    "SPECIMENS: SO# (surface) and SOA# (airmail) → specimens[] with applies_to: \"stamps\"\n",
    "VARIETIES: Lowercase suffixes (O2a, OA115a) → varieties[]\n",
    "SECTION: O# → \"Surface Mail\", OA# → \"Airmail\"\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input:\n",
    "  Overprint Issue of 1934\n",
    "  Overprint \"Oficial\" in red. Perf 12.\n",
    "  \n",
    "  Overprint \"specimen\" in red\n",
    "  SOA107   5c green\n",
    "  \n",
    "  Regular issue\n",
    "  OA107    5c green       75,000\n",
    "  OA108    10c carmine rose   35,000\n",
    "  OA108a   inverted overprint\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"issue_data\": {{\"section\": \"Airmail\", ...}},\n",
    "  \"stamps\": [\n",
    "    {{\n",
    "      \"catalog_no\": \"OA107\",\n",
    "      \"denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "      \"color\": \"green\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 75000,\n",
    "      \"status\": \"official\",\n",
    "      \"notes\": [\"Official airmail stamp\"],\n",
    "      \"overprint\": {{\"present\": true, \"type\": \"overprint\", \"text\": \"Oficial\", \"color\": \"red\"}},\n",
    "      \"base_stamp_ref\": \"A107\"\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"OA108\",\n",
    "      \"denomination\": {{\"value\": 10, \"unit\": \"c\"}},\n",
    "      \"color\": \"carmine rose\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 35000,\n",
    "      \"status\": \"official\",\n",
    "      \"overprint\": {{\"present\": true, \"type\": \"overprint\", \"text\": \"Oficial\", \"color\": \"red\"}},\n",
    "      \"base_stamp_ref\": \"A108\"\n",
    "    }}\n",
    "  ],\n",
    "  \"varieties\": [\n",
    "    {{\"base_catalog_no\": \"OA108\", \"suffix\": \"a\", \"type\": \"overprint\", \"description\": \"inverted overprint\"}}\n",
    "  ],\n",
    "  \"specimens\": [\n",
    "    {{\"code\": \"SOA107\", \"applies_to\": \"stamps\", \"type\": \"overprint\", \"denomination\": \"5c\", \"base_color\": \"green\", \"overprint_color\": \"red\", \"notes\": \"SPECIMEN overprint\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "CRITICAL FOR OFFICIAL STAMPS: O# and OA# both use status: \"official\" and go in stamps[] array.\n",
    "Base ref: remove O/OA prefix (OA107 → A107, O5 → 5).\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "GUANACASTE OVERPRINTS\n",
    "--------------------------------------------------------------------------------\n",
    "Guanacaste stamps are regular postage or revenue stamps overprinted with \n",
    "\"Guanacaste\" for use in Guanacaste Province (1885-1892). They go in stamps[] \n",
    "array with special status and overprint structure.\n",
    "\n",
    "CODE DETECTION:\n",
    "Postage:    ^G\\d+[a-z]?$        → G1, G5, G12a\n",
    "Revenue:    ^GR\\d+[a-z]?$       → GR1, GR5, GR8a\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"G1\" | \"GR1\",\n",
    "  \"issue_id\": string,\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,\n",
    "    \"unit\": \"c\" | \"C\" | \"P\" | \"reales\"\n",
    "  }},\n",
    "  \"color\": string,                      // color of base stamp\n",
    "  \"perforation\": string,\n",
    "  \"watermark\": string|null,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"guanacaste\" | \"guanacaste_revenue\",\n",
    "  \"notes\": string[],\n",
    "  \n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"overprint\",\n",
    "    \"text\": \"Guanacaste\",\n",
    "    \"color\": \"black\" | \"red\"            // extracted from section header\n",
    "  }},\n",
    "  \"base_stamp_ref\": string              // reference to base stamp\n",
    "}}\n",
    "\n",
    "STATUS VALUES:\n",
    "- G# codes → status: \"guanacaste\"\n",
    "- GR# codes → status: \"guanacaste_revenue\"\n",
    "\n",
    "OVERPRINT COLOR:\n",
    "Extract from section headers:\n",
    "- \"Black Overprint\" → all following stamps have color: \"black\"\n",
    "- \"Red Overprint\" → all following stamps have color: \"red\"\n",
    "\n",
    "PLATE ERRORS (varieties):\n",
    "When text describes plate errors with positions:\n",
    "\"a: first A broken (pos 19)\" → create variety with position: 19\n",
    "\n",
    "{{\n",
    "  \"base_catalog_no\": \"G1\",\n",
    "  \"suffix\": \"a\",\n",
    "  \"type\": \"plate_flaw\",\n",
    "  \"description\": \"first A broken\",\n",
    "  \"position\": 19,\n",
    "  \"plate\": 1\n",
    "}}\n",
    "\n",
    "VARIETIES:\n",
    "- Lowercase suffixes (G1a, GR4a) go in varieties[]\n",
    "- Include position when mentioned (pos 19, pos 37, etc.)\n",
    "- type: usually \"plate_flaw\" or \"impression\"\n",
    "\n",
    "GUANACASTE CRITICAL NOTES:\n",
    "- G# and GR# codes go in stamps[] array\n",
    "- G# → status: \"guanacaste\"\n",
    "- GR# → status: \"guanacaste_revenue\"\n",
    "- overprint.text always \"Guanacaste\"\n",
    "- Overprint color from section headers (Black/Red Overprint)\n",
    "- Plate errors with positions go in varieties[] with position field populated\n",
    "- Base ref: G1 → \"1\", GR1 → \"R1\"\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SEMIPOSTAL STAMPS\n",
    "--------------------------------------------------------------------------------\n",
    "Semipostal stamps are postage stamps sold at a premium above face value, with \n",
    "proceeds benefiting charitable causes. They go in stamps[] array with special \n",
    "status and optional surcharge structure.\n",
    "\n",
    "CODE DETECTION:\n",
    "Regular:    ^SP\\d+[a-z]?$        → SP1, SP2, SP4a\n",
    "Imperf:     ^ISP\\d+[a-z]?$       → ISP2, ISP4a\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"SP1\" | \"ISP2\",\n",
    "  \"issue_id\": string,\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,\n",
    "    \"unit\": \"c\" | \"C\" | \"P\"\n",
    "  }},\n",
    "  \"color\": string,\n",
    "  \"perforation\": string,              // \"\" for ISP codes\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"semipostal\",             // for both SP and ISP\n",
    "  \"notes\": string[],                  // include benefit purpose and premium\n",
    "  \n",
    "  // ONLY when surcharged:\n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"surcharge\",\n",
    "    \"surcharge_denomination\": {{value: number, unit: string}},\n",
    "    \"on_denomination\": {{value: number, unit: string}},\n",
    "    \"color\": string\n",
    "  }},\n",
    "  \"base_stamp_ref\": string\n",
    "}}\n",
    "\n",
    "NOTES FIELD:\n",
    "Include charitable purpose and premium amount:\n",
    "- \"Sold with 10c premium for Olympic Games Committee benefit\"\n",
    "- \"Red Cross Society benefit. Premium: 5c\"\n",
    "\n",
    "ISP CODES (Imperforates):\n",
    "- ISP# are separate catalog items, NOT varieties\n",
    "- status: \"semipostal\" (same as SP)\n",
    "- perforation: \"\" (empty for imperf)\n",
    "\n",
    "PROOFS:\n",
    "- DPSP# → proofs.die_proofs[]\n",
    "- OPSP# → proofs.overprint_proofs[]\n",
    "- Color proofs in combined format: \"SP2-4a brown red\" means one proof sheet \n",
    "  with SP2, SP3, SP4 in same color → one entry in color_proofs[]\n",
    "\n",
    "VARIETIES:\n",
    "Lowercase suffixes (SP1a, ISP4a) go in varieties[]:\n",
    "- \"tete-beche\" → type: \"arrangement\"\n",
    "- \"lower surcharge\" → type: \"overprint\"\n",
    "- \"shifted perf\" → type: \"perforation\"\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input:\n",
    "  Red Cross Society benefit surcharge\n",
    "  October 17, 1922. Surcharge on 1910 stamp. Perf 12.\n",
    "  \n",
    "  Overprint Proof\n",
    "  OPSP1  5c red on onionskin paper\n",
    "  \n",
    "  Regular issue\n",
    "  SP1    5c on 5c orange (68)    200,000\n",
    "  SP1a   lower surcharge\n",
    "  SP1b   surcharge displaced upwards\n",
    "  \n",
    "  Sold with 5c premium for Red Cross benefit.\n",
    "  \n",
    "  Olympic Games benefit\n",
    "  Die Proofs\n",
    "  DPSP2  5c black\n",
    "  DPSP3  10c black\n",
    "  \n",
    "  Three values in a sheet\n",
    "  SP2-4a brown red\n",
    "  SP2-4b black\n",
    "  \n",
    "  Imperforate\n",
    "  ISP2   5c dark green    15,000\n",
    "  ISP3   10c carmine      15,000\n",
    "  \n",
    "  Regular issue\n",
    "  SP2    5c dark green    15,000\n",
    "  SP3    10c carmine      15,000\n",
    "  SP4    20c dark blue    15,000\n",
    "  SP4a   vertical pair tete beche\n",
    "  \n",
    "  Sold with 10c surcharge for Olympic Games Committee benefit.\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"stamps\": [\n",
    "    {{\n",
    "      \"catalog_no\": \"SP1\",\n",
    "      \"denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "      \"color\": \"orange\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 200000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Red Cross Society benefit. Sold with 5c premium\"],\n",
    "      \"overprint\": {{\n",
    "        \"present\": true,\n",
    "        \"type\": \"surcharge\",\n",
    "        \"surcharge_denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "        \"on_denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "        \"color\": \"red\"\n",
    "      }},\n",
    "      \"base_stamp_ref\": \"68\"\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"ISP2\",\n",
    "      \"denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "      \"color\": \"dark green\",\n",
    "      \"perforation\": \"\",\n",
    "      \"quantity_reported\": 15000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Olympic Games benefit. Sold with 10c premium. Imperforate\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"ISP3\",\n",
    "      \"denomination\": {{\"value\": 10, \"unit\": \"c\"}},\n",
    "      \"color\": \"carmine\",\n",
    "      \"perforation\": \"\",\n",
    "      \"quantity_reported\": 15000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Olympic Games benefit. Sold with 10c premium. Imperforate\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"SP2\",\n",
    "      \"denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "      \"color\": \"dark green\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 15000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Olympic Games benefit. Sold with 10c premium\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"SP3\",\n",
    "      \"denomination\": {{\"value\": 10, \"unit\": \"c\"}},\n",
    "      \"color\": \"carmine\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 15000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Olympic Games benefit. Sold with 10c premium\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"SP4\",\n",
    "      \"denomination\": {{\"value\": 20, \"unit\": \"c\"}},\n",
    "      \"color\": \"dark blue\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"quantity_reported\": 15000,\n",
    "      \"status\": \"semipostal\",\n",
    "      \"notes\": [\"Olympic Games benefit. Sold with 10c premium\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"varieties\": [\n",
    "    {{\n",
    "      \"base_catalog_no\": \"SP1\",\n",
    "      \"suffix\": \"a\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"description\": \"lower surcharge\",\n",
    "      \"position\": null,\n",
    "      \"plate\": null\n",
    "    }},\n",
    "    {{\n",
    "      \"base_catalog_no\": \"SP1\",\n",
    "      \"suffix\": \"b\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"description\": \"surcharge displaced upwards\",\n",
    "      \"position\": null,\n",
    "      \"plate\": null\n",
    "    }},\n",
    "    {{\n",
    "      \"base_catalog_no\": \"SP4\",\n",
    "      \"suffix\": \"a\",\n",
    "      \"type\": \"arrangement\",\n",
    "      \"description\": \"vertical pair tete-beche\",\n",
    "      \"position\": null,\n",
    "      \"plate\": null\n",
    "    }}\n",
    "  ],\n",
    "  \"proofs\": {{\n",
    "    \"die_proofs\": [\n",
    "      {{\"code\": \"DPSP2\", \"denomination\": \"5c\", \"color\": \"black\", \"substrate\": \"bond paper\", ...}},\n",
    "      {{\"code\": \"DPSP3\", \"denomination\": \"10c\", \"color\": \"black\", \"substrate\": \"bond paper\", ...}}\n",
    "    ],\n",
    "    \"overprint_proofs\": [\n",
    "      {{\"code\": \"OPSP1\", \"denomination\": \"5c\", \"color\": \"red\", \"substrate\": \"onionskin paper\", ...}}\n",
    "    ],\n",
    "    \"color_proofs\": [\n",
    "      {{\"code\": \"SP2-4a\", \"denomination\": \"5c/10c/20c\", \"color\": \"brown red\", \"notes\": \"Three values in a sheet\"}},\n",
    "      {{\"code\": \"SP2-4b\", \"denomination\": \"5c/10c/20c\", \"color\": \"black\", \"notes\": \"Three values in a sheet\"}}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "SEMI POSTAL CRITICAL NOTES:\n",
    "- SP# and ISP# codes go in stamps[] array\n",
    "- Both use status: \"semipostal\"\n",
    "- ISP# are imperf stamps, NOT varieties\n",
    "- Notes must include benefit purpose and premium amount\n",
    "- Combined color proofs (SP2-4a) → one entry in color_proofs[]\n",
    "- Varieties (SP1a, ISP4a) go in varieties[]\n",
    "- Proofs: DPSP#, OPSP# go in respective proof sections\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "POSTAGE DUE STAMPS\n",
    "--------------------------------------------------------------------------------\n",
    "Postage due stamps are used to collect unpaid or underpaid postage. They go in \n",
    "stamps[] array with special status.\n",
    "\n",
    "CODE DETECTION:\n",
    "Regular:    ^D\\d+[a-z]?$         → D1, D8, D15a\n",
    "Specimens:  ^SD\\d+[a-z]?$        → SD1, SD4a\n",
    "Proofs:     ^DPD\\d+$             → DPD1\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"D1\",\n",
    "  \"issue_id\": string,\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,\n",
    "    \"unit\": \"c\" | \"C\" | \"P\"\n",
    "  }},\n",
    "  \"color\": string,\n",
    "  \"perforation\": string,\n",
    "  \"watermark\": string|null,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"postage_due\",\n",
    "  \"notes\": string[]\n",
    "}}\n",
    "\n",
    "SPECIMENS:\n",
    "SD# codes go in specimens[] array:\n",
    "{{\n",
    "  \"code\": \"SD1\",\n",
    "  \"applies_to\": \"stamps\",\n",
    "  \"type\": \"overprint\",\n",
    "  \"denomination\": \"5c\",\n",
    "  \"base_color\": string,\n",
    "  \"overprint_color\": \"black\" | \"purple\",\n",
    "  \"notes\": \"SPECIMEN overprint\" or \"Waterlow & Sons Ltd/Specimen\"\n",
    "}}\n",
    "\n",
    "PROOFS:\n",
    "DPD# codes go in proofs.die_proofs[]:\n",
    "{{\n",
    "  \"code\": \"DPD1\",\n",
    "  \"denomination\": string or \"no numeral\",\n",
    "  \"color\": \"black\",\n",
    "  \"die_no\": string,\n",
    "  \"substrate\": \"bond paper\",\n",
    "  \"finish\": \"\"\n",
    "}}\n",
    "\n",
    "VARIETIES:\n",
    "Lowercase suffixes (D1a, SD4a) go in varieties[] for D codes.\n",
    "For SD codes with lowercase, they may be separate specimens if significantly \n",
    "different (color/perforation changes).\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input:\n",
    "  Issue of 1903\n",
    "  September 10, 1903. Decree #53. Engraved by Waterlow & Sons. Perf 14, 15.\n",
    "  \n",
    "  Die Proof\n",
    "  DPD1  black, no numeral, bond paper #3428\n",
    "  \n",
    "  Overprint \"specimen\" in black, numerals in black\n",
    "  SD1   5c slate blue\n",
    "  SD2   10c brown orange\n",
    "  SD4   20c carmine\n",
    "  \n",
    "  Overprint \"Waterlow & Sons Ltd/Specimen\"\n",
    "  SD4a  20c red orange, imperf\n",
    "  SD4b  20c red orange, perf 12.5\n",
    "  \n",
    "  Regular issue\n",
    "  D1    5c slate blue\n",
    "  D2    10c brown orange\n",
    "  D3    15c yellow green\n",
    "  D4    20c carmine\n",
    "  D5    25c slate gray\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"issue_data\": {{\n",
    "    \"issue_id\": \"CR-1903-POSTAGE-DUE\",\n",
    "    \"section\": \"Postage Due\",\n",
    "    ...\n",
    "  }},\n",
    "  \"stamps\": [\n",
    "    {{\n",
    "      \"catalog_no\": \"D1\",\n",
    "      \"denomination\": {{\"value\": 5, \"unit\": \"c\"}},\n",
    "      \"color\": \"slate blue\",\n",
    "      \"perforation\": \"14\",\n",
    "      \"quantity_reported\": null,\n",
    "      \"status\": \"postage_due\",\n",
    "      \"notes\": [\"Postage due stamp\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"D2\",\n",
    "      \"denomination\": {{\"value\": 10, \"unit\": \"c\"}},\n",
    "      \"color\": \"brown orange\",\n",
    "      \"perforation\": \"14\",\n",
    "      \"status\": \"postage_due\",\n",
    "      \"notes\": [\"Postage due stamp\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"D3\",\n",
    "      \"denomination\": {{\"value\": 15, \"unit\": \"c\"}},\n",
    "      \"color\": \"yellow green\",\n",
    "      \"perforation\": \"14\",\n",
    "      \"status\": \"postage_due\",\n",
    "      \"notes\": [\"Postage due stamp\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"D4\",\n",
    "      \"denomination\": {{\"value\": 20, \"unit\": \"c\"}},\n",
    "      \"color\": \"carmine\",\n",
    "      \"perforation\": \"14\",\n",
    "      \"status\": \"postage_due\",\n",
    "      \"notes\": [\"Postage due stamp\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"D5\",\n",
    "      \"denomination\": {{\"value\": 25, \"unit\": \"c\"}},\n",
    "      \"color\": \"slate gray\",\n",
    "      \"perforation\": \"14\",\n",
    "      \"status\": \"postage_due\",\n",
    "      \"notes\": [\"Postage due stamp\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"proofs\": {{\n",
    "    \"die_proofs\": [\n",
    "      {{\n",
    "        \"code\": \"DPD1\",\n",
    "        \"denomination\": \"no numeral\",\n",
    "        \"color\": \"black\",\n",
    "        \"die_no\": \"3428\",\n",
    "        \"substrate\": \"bond paper\",\n",
    "        \"finish\": \"\"\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"specimens\": [\n",
    "    {{\n",
    "      \"code\": \"SD1\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"5c\",\n",
    "      \"base_color\": \"slate blue\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"SPECIMEN overprint\"\n",
    "    }},\n",
    "    {{\n",
    "      \"code\": \"SD2\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"10c\",\n",
    "      \"base_color\": \"brown orange\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"SPECIMEN overprint\"\n",
    "    }},\n",
    "    {{\n",
    "      \"code\": \"SD4\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"20c\",\n",
    "      \"base_color\": \"carmine\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"SPECIMEN overprint\"\n",
    "    }},\n",
    "    {{\n",
    "      \"code\": \"SD4a\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"20c\",\n",
    "      \"base_color\": \"red orange\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"Waterlow & Sons Ltd/Specimen. Imperf\"\n",
    "    }},\n",
    "    {{\n",
    "      \"code\": \"SD4b\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"20c\",\n",
    "      \"base_color\": \"red orange\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"Waterlow & Sons Ltd/Specimen. Perf 12.5\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "POSTAGE DUES CRITICAL NOTES:\n",
    "- D# codes go in stamps[] with status: \"postage_due\"\n",
    "- SD# codes go in specimens[] (NOT stamps[])\n",
    "- DPD# codes go in proofs.die_proofs[]\n",
    "- SD codes with suffixes (SD4a, SD4b) are separate specimen items if they have \n",
    "  different perforation/color, NOT varieties\n",
    "- Section: \"Postage Due\" for issue_data\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "SPECIAL DELIVERY STAMPS\n",
    "--------------------------------------------------------------------------------\n",
    "Special delivery stamps (Entrega Inmediata) are used for express mail service. \n",
    "They go in stamps[] array with special status.\n",
    "\n",
    "CODE DETECTION:\n",
    "Regular:       ^SD\\d+[a-z]?$         → SD3, SD5, SD6a\n",
    "Color Proofs:  ^CPSD\\d+$             → CPSD3\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "{{\n",
    "  \"catalog_no\": \"SD3\",\n",
    "  \"issue_id\": string,\n",
    "  \"denomination\": {{\n",
    "    \"value\": number,\n",
    "    \"unit\": \"c\" | \"C\" | \"P\"\n",
    "  }},\n",
    "  \"color\": string,\n",
    "  \"perforation\": string,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"special_delivery\",\n",
    "  \"notes\": string[]                   // include service type (local/international)\n",
    "}}\n",
    "\n",
    "NOTES FIELD:\n",
    "Include service type when mentioned:\n",
    "- \"Special delivery. Local rate\"\n",
    "- \"Special delivery. International rate\"\n",
    "- \"Special delivery. Local and U.P.A.E. countries rate\"\n",
    "\n",
    "PROOFS:\n",
    "CPSD# codes go in proofs.color_proofs[]:\n",
    "{{\n",
    "  \"code\": \"CPSD3\",\n",
    "  \"denomination\": \"75c\",\n",
    "  \"color\": \"black\",\n",
    "  \"notes\": \"Color proof\"\n",
    "}}\n",
    "\n",
    "VARIETIES:\n",
    "Lowercase suffixes (SD5a, SD6a) go in varieties[]:\n",
    "- \"triple impression\" → type: \"impression\"\n",
    "- \"imperf left margin\" → type: \"perforation\"\n",
    "- \"double impression\" → type: \"impression\"\n",
    "\n",
    "SPECIAL DELIVERY STAMPS CRITICAL NOTES:\n",
    "- SD# codes go in stamps[] with status: \"special_delivery\"\n",
    "- CPSD# codes go in proofs.color_proofs[]\n",
    "- Include service type in notes (local/international/U.P.A.E.)\n",
    "- Varieties (SD5a, SD6b) go in varieties[]\n",
    "- Section: \"Special Delivery\" or can be included in \"Surface Mail\"/\"Airmail\"\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "POSTAL RELATED REVENUE STAMPS\n",
    "--------------------------------------------------------------------------------\n",
    "These are stamps with postal-revenue connections:\n",
    "1. PR# = Postal stamps surcharged/overprinted for Revenue/Fiscal use (various types: \n",
    "   regular fiscal, electoral, archive, etc.)\n",
    "2. R# = Revenue stamps used for Postal purposes\n",
    "\n",
    "CODE DETECTION:\n",
    "Postal to Revenue:         ^PR\\d+[a-z]?$       → PR4, PR12\n",
    "Revenue to Postal:         ^R\\d+[a-z]?$        → R23, R25\n",
    "Specimens:                 ^MPR\\d+[a-z]?$      → MPR12a\n",
    "Surcharge Proofs:          ^SPPR\\d+[a-z]?$     → SPPR13a\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "\n",
    "FOR PR# (Postal stamps converted to revenue use):\n",
    "{{\n",
    "  \"catalog_no\": \"PR4\",\n",
    "  \"denomination\": {{\"value\": number, \"unit\": \"c\"|\"C\"|\"P\"}},\n",
    "  \"color\": string,\n",
    "  \"quantity_reported\": number|null,\n",
    "  \"status\": \"postal_revenue\",\n",
    "  \"notes\": string[],                    // Include type: \"Electoral stamp\", \"Archive stamp\", etc.\n",
    "  \n",
    "  \"overprint\": {{\n",
    "    \"present\": true,\n",
    "    \"type\": \"surcharge\" | \"overprint\",\n",
    "    \"text\": string,                     // e.g., \"Elecciones/1946\", \"Timbre de/Archivo\"\n",
    "    \"surcharge_denomination\": {{...}},  // only for surcharges\n",
    "    \"on_denomination\": {{...}},         // only for surcharges\n",
    "    \"color\": string\n",
    "  }},\n",
    "  \"base_stamp_ref\": string\n",
    "}}\n",
    "\n",
    "FOR R# (Revenue stamps used for postage):\n",
    "{{\n",
    "  \"catalog_no\": \"R23\",\n",
    "  \"denomination\": {{\"value\": number, \"unit\": \"c\"|\"C\"|\"P\"}},\n",
    "  \"color\": string,\n",
    "  \"status\": \"revenue_postal\",\n",
    "  \"notes\": [\"Revenue stamp used for postage without authorization\"]\n",
    "}}\n",
    "\n",
    "SPECIMENS & PROOFS:\n",
    "- MPR# → specimens[] with applies_to: \"stamps\"\n",
    "- SPPR# → proofs.surcharge_proofs[] or proofs.overprint_proofs[]\n",
    "\n",
    "NOTES FIELD for PR#:\n",
    "Include specific use type:\n",
    "- \"Regular postal stamp surcharged for fiscal use\"\n",
    "- \"Electoral stamp. National Exposition overprinted Elecciones/1946\"\n",
    "- \"Archive stamp. Postage due surcharged Timbre de/Archivo\"\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input:\n",
    "  REGULAR FISCAL USE\n",
    "  1947. Airmail stamps surcharged \"Timbre Fiscal/1947/ Dos Colones\".\n",
    "  PR4  2C on 5C black, in red      25,500\n",
    "  \n",
    "  ELECTORAL STAMPS\n",
    "  1946. National Exposition stamps overprinted \"Elecciones/1946\", in black.\n",
    "  Overprint \"muestra\"\n",
    "  MPR12a  2c gray black\n",
    "  MPR12b  3c red orange, no date\n",
    "  Regular issue\n",
    "  PR12    2c gray black\n",
    "  \n",
    "  ARCHIVE STAMPS\n",
    "  1946. Postage due stamps surcharged \"Timbre de/ Archivo\" and value, in blue.\n",
    "  Surcharge Proofs\n",
    "  SPPR13a  10c on 10c violet, in black\n",
    "  SPPR13b  10c on 10c violet, in red\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"stamps\": [\n",
    "    {{\n",
    "      \"catalog_no\": \"PR4\",\n",
    "      \"denomination\": {{\"value\": 2, \"unit\": \"C\"}},\n",
    "      \"color\": \"black\",\n",
    "      \"quantity_reported\": 25500,\n",
    "      \"status\": \"postal_revenue\",\n",
    "      \"notes\": [\"Regular airmail stamp surcharged for fiscal use. Timbre Fiscal 1947\"],\n",
    "      \"overprint\": {{\n",
    "        \"present\": true,\n",
    "        \"type\": \"surcharge\",\n",
    "        \"text\": \"Timbre Fiscal/1947/ Dos Colones\",\n",
    "        \"surcharge_denomination\": {{\"value\": 2, \"unit\": \"C\"}},\n",
    "        \"on_denomination\": {{\"value\": 5, \"unit\": \"C\"}},\n",
    "        \"color\": \"red\"\n",
    "      }},\n",
    "      \"base_stamp_ref\": \"A26\"\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"PR12\",\n",
    "      \"denomination\": {{\"value\": 2, \"unit\": \"c\"}},\n",
    "      \"color\": \"gray black\",\n",
    "      \"status\": \"postal_revenue\",\n",
    "      \"notes\": [\"Electoral stamp. National Exposition overprinted Elecciones/1946\"],\n",
    "      \"overprint\": {{\n",
    "        \"present\": true,\n",
    "        \"type\": \"overprint\",\n",
    "        \"text\": \"Elecciones/1946\",\n",
    "        \"color\": \"black\"\n",
    "      }},\n",
    "      \"base_stamp_ref\": \"A31\"\n",
    "    }}\n",
    "  ],\n",
    "  \"specimens\": [\n",
    "    {{\n",
    "      \"code\": \"MPR12a\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"2c\",\n",
    "      \"base_color\": \"gray black\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"MUESTRA overprint. Electoral stamp\"\n",
    "    }},\n",
    "    {{\n",
    "      \"code\": \"MPR12b\",\n",
    "      \"applies_to\": \"stamps\",\n",
    "      \"type\": \"overprint\",\n",
    "      \"denomination\": \"3c\",\n",
    "      \"base_color\": \"red orange\",\n",
    "      \"overprint_color\": \"black\",\n",
    "      \"notes\": \"MUESTRA overprint. Electoral stamp, no date\"\n",
    "    }}\n",
    "  ],\n",
    "  \"proofs\": {{\n",
    "    \"surcharge_proofs\": [\n",
    "      {{\n",
    "        \"code\": \"SPPR13a\",\n",
    "        \"denomination\": \"10c on 10c\",\n",
    "        \"color\": \"violet\",\n",
    "        \"surcharge_color\": \"black\",\n",
    "        \"notes\": \"Surcharge proof. Archive stamp\"\n",
    "      }},\n",
    "      {{\n",
    "        \"code\": \"SPPR13b\",\n",
    "        \"denomination\": \"10c on 10c\",\n",
    "        \"color\": \"violet\",\n",
    "        \"surcharge_color\": \"red\",\n",
    "        \"notes\": \"Surcharge proof. Archive stamp\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "POSTAL RELATED REVENUES CRITICAL NOTES:\n",
    "- PR# = Postal → Revenue (various fiscal uses: regular, electoral, archive)\n",
    "- R# = Revenue → Postal\n",
    "- PR# codes have status: \"postal_revenue\" WITH overprint/surcharge\n",
    "- R# codes have status: \"revenue_postal\" WITHOUT overprint\n",
    "- MPR# specimens → specimens[] with applies_to: \"stamps\"\n",
    "- SPPR# proofs → proofs.surcharge_proofs[] or proofs.overprint_proofs[]\n",
    "- Notes should specify type: electoral, archive, regular fiscal, etc.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "TELEGRAPH STAMPS AND SEALS\n",
    "--------------------------------------------------------------------------------\n",
    "Telegraph items include regular telegraph stamps (T#), telegraph seals (TS#), \n",
    "and radiogram seals (RS#). All go in stamps[] array with appropriate status.\n",
    "\n",
    "CODE DETECTION:\n",
    "Telegraph Stamps:      ^T\\d+[A-Z]?[a-z]?$     → T1, T2A, T3a\n",
    "Telegraph Seals:       ^TS\\d+[a-z]?$          → TS1, TS5, TS8a\n",
    "Radiogram Seals:       ^RS\\d+[a-z]?$          → RS1, RS6\n",
    "Imperf Radiogram:      ^IRS\\d+[a-z]?$         → IRS1\n",
    "\n",
    "Proofs:\n",
    "Die Proofs Telegraph:       ^DPT\\d+[a-z]?$     → DPT1\n",
    "Plate Proofs Telegraph:     ^PPT\\d+[a-z]?$     → PPT1\n",
    "Plate Proofs Telegraph Seal: ^PTS\\d+[a-z]?$    → PTS2, PTS5a\n",
    "Specimens Telegraph:        ^ST\\d+[a-z]?$      → ST1\n",
    "\n",
    "IMPORTANT: Uppercase letter suffixes (T2A) are separate stamps, not varieties.\n",
    "Lowercase suffixes (TS2a, RS5a) are varieties.\n",
    "\n",
    "STRUCTURE (in stamps[] array):\n",
    "\n",
    "FOR T# (Telegraph Stamps):\n",
    "{{\n",
    "  \"catalog_no\": \"T2\" | \"T2A\",\n",
    "  \"denomination\": {{\"value\": number, \"unit\": \"c\"|\"C\"|\"P\"}},\n",
    "  \"color\": string,\n",
    "  \"perforation\": string,\n",
    "  \"watermark\": string|null,\n",
    "  \"status\": \"telegraph\",\n",
    "  \"notes\": [\"Telegraph stamp\"]\n",
    "}}\n",
    "\n",
    "FOR TS# (Telegraph Seals):\n",
    "{{\n",
    "  \"catalog_no\": \"TS2\",\n",
    "  \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},  // seals have no denomination\n",
    "  \"color\": string,\n",
    "  \"paper\": string,                    // \"white paper\", \"pink paper\", etc.\n",
    "  \"perforation\": string,\n",
    "  \"status\": \"telegraph_seal\",\n",
    "  \"notes\": [\"Telegraph seal\"]\n",
    "}}\n",
    "\n",
    "FOR RS# and IRS# (Radiogram Seals):\n",
    "{{\n",
    "  \"catalog_no\": \"RS1\" | \"IRS1\",\n",
    "  \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "  \"color\": string,\n",
    "  \"paper\": string,                    // paper color\n",
    "  \"perforation\": string,              // often \"\"\n",
    "  \"status\": \"radiogram_seal\",\n",
    "  \"notes\": [\"Radiogram seal. Design with CR/RN in center\"]\n",
    "}}\n",
    "\n",
    "PROOFS:\n",
    "- DPT#/PPT# → telegraph stamp proofs\n",
    "- PTS# → telegraph seal proofs (proofs.plate_proofs[])\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input:\n",
    "  TELEGRAPH SEALS\n",
    "  Lithography by Litografia Nacional. Perf 12.\n",
    "  \n",
    "  Proofs, imperf\n",
    "  PTS2   blue, white paper\n",
    "  PTS2a  blue, pink paper\n",
    "  PTS5   dark blue, white paper\n",
    "  \n",
    "  Regular issue\n",
    "  TS1    blue\n",
    "  TS2    light blue, perf 12\n",
    "  TS2a   horizontal pair imperf between\n",
    "  TS3    black, imperf\n",
    "  TS5    dark blue, white paper\n",
    "  TS8    blue, pink paper\n",
    "  \n",
    "  RADIOGRAM SEALS\n",
    "  \"Radios de Costa Rica\". \"CR\" in center. Imperforate.\n",
    "  \n",
    "  IRS1   brown, yellow paper\n",
    "  RS1    brown, yellow paper\n",
    "  RS2    reddish brown, pink paper\n",
    "  RS6    brown, pink paper\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"stamps\": [\n",
    "    {{\n",
    "      \"catalog_no\": \"TS1\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"blue\",\n",
    "      \"paper\": \"\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"status\": \"telegraph_seal\",\n",
    "      \"notes\": [\"Telegraph seal\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"TS2\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"light blue\",\n",
    "      \"paper\": \"\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"status\": \"telegraph_seal\",\n",
    "      \"notes\": [\"Telegraph seal\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"TS3\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"black\",\n",
    "      \"paper\": \"\",\n",
    "      \"perforation\": \"\",\n",
    "      \"status\": \"telegraph_seal\",\n",
    "      \"notes\": [\"Telegraph seal. Imperf\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"TS5\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"dark blue\",\n",
    "      \"paper\": \"white paper\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"status\": \"telegraph_seal\",\n",
    "      \"notes\": [\"Telegraph seal\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"TS8\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"blue\",\n",
    "      \"paper\": \"pink paper\",\n",
    "      \"perforation\": \"12\",\n",
    "      \"status\": \"telegraph_seal\",\n",
    "      \"notes\": [\"Telegraph seal\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"IRS1\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"brown\",\n",
    "      \"paper\": \"yellow paper\",\n",
    "      \"perforation\": \"\",\n",
    "      \"status\": \"radiogram_seal\",\n",
    "      \"notes\": [\"Radiogram seal. Radios de Costa Rica. Imperf\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"RS1\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"brown\",\n",
    "      \"paper\": \"yellow paper\",\n",
    "      \"perforation\": \"\",\n",
    "      \"status\": \"radiogram_seal\",\n",
    "      \"notes\": [\"Radiogram seal. Radios de Costa Rica. Imperf\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"RS2\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"reddish brown\",\n",
    "      \"paper\": \"pink paper\",\n",
    "      \"perforation\": \"\",\n",
    "      \"status\": \"radiogram_seal\",\n",
    "      \"notes\": [\"Radiogram seal. Design with CR in center. Imperf\"]\n",
    "    }},\n",
    "    {{\n",
    "      \"catalog_no\": \"RS6\",\n",
    "      \"denomination\": {{\"value\": null, \"unit\": \"seal\"}},\n",
    "      \"color\": \"brown\",\n",
    "      \"paper\": \"pink paper\",\n",
    "      \"perforation\": \"\",\n",
    "      \"status\": \"radiogram_seal\",\n",
    "      \"notes\": [\"Radiogram seal. Design with RN in center. Imperf\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"varieties\": [\n",
    "    {{\n",
    "      \"base_catalog_no\": \"TS2\",\n",
    "      \"suffix\": \"a\",\n",
    "      \"type\": \"perforation\",\n",
    "      \"description\": \"horizontal pair imperf between\",\n",
    "      \"position\": null,\n",
    "      \"plate\": null\n",
    "    }}\n",
    "  ],\n",
    "  \"proofs\": {{\n",
    "    \"plate_proofs\": [\n",
    "      {{\"code\": \"PTS2\", \"denomination\": \"seal\", \"color\": \"blue\", \"notes\": \"Telegraph seal proof. White paper. Imperf\"}},\n",
    "      {{\"code\": \"PTS2a\", \"denomination\": \"seal\", \"color\": \"blue\", \"notes\": \"Telegraph seal proof. Pink paper. Imperf\"}},\n",
    "      {{\"code\": \"PTS5\", \"denomination\": \"seal\", \"color\": \"dark blue\", \"notes\": \"Telegraph seal proof. White paper. Imperf\"}}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "TELEGRAPH STAMPS AND SEALS CRITICAL NOTES:\n",
    "- T# → status: \"telegraph\" (stamps with denominations)\n",
    "- TS# → status: \"telegraph_seal\" (seals without denominations)\n",
    "- RS#/IRS# → status: \"radiogram_seal\" (radio service seals)\n",
    "- Seals have denomination.unit: \"seal\" with value: null\n",
    "- Paper color is important field for seals\n",
    "- T#A (uppercase) = separate stamps in stamps[]\n",
    "- TS#a/RS#a (lowercase) = varieties in varieties[]\n",
    "- PTS# proofs → proofs.plate_proofs[]\n",
    "- IRS# are complete catalog codes, NOT varieties\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "QUANTITIES & DATES\n",
    "--------------------------------------------------------------------------------\n",
    "- Tables of print runs by denomination → \"production_orders.printings\".\n",
    "- DO NOT assign table totals to \"stamps[*].quantity_reported\" unless that SPECIFIC catalog number line states a quantity.\n",
    "- Ignore placeholder zeros: if a table shows 0 for a denomination/period, omit that row.\n",
    "- Remainders (Mint/Used) → \"production_orders.remainders.quantities\" with the Mint/Used tag in \"plate_desc\".\n",
    "- Dates: ISO (YYYY-MM-DD). If only month/year, use first day of month. Do NOT invent \"probable_first_circulation\" unless explicitly stated.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "PERFORATIONS\n",
    "--------------------------------------------------------------------------------\n",
    "- \"issue_data.perforation\" can contain a range summary (e.g., \"13.5-15.5\") IF stated.\n",
    "- \"stamps[*].perforation\" should contain a specific gauge if uniquely stated for that stamp; otherwise \"\" (do not copy the range blindly).\n",
    "- Do NOT include the word \"perf\" in this field (gauge only).\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "POST-PARSE VALIDATION CHECKLIST (MANDATORY)\n",
    "--------------------------------------------------------------------------------\n",
    "Before emitting JSON, ensure ALL are true:\n",
    "1) All S-codes are present EXCLUSIVELY in top-level \"specimens\". There are NO S-codes in \"varieties\", \"proofs\", or \"stamps\".\n",
    "2) \"varieties\" ONLY contains lowercase-suffix items of real main catalog numbers (e.g., \"31a\"). No S-codes here.\n",
    "3) \"stamps[*].quantity_reported\" is null unless a catalog line gives a specific quantity for that exact number.\n",
    "4) Progressive dies (e.g., \"DPA…\") are in \"proofs.die_proofs\" with finish starting \"progressive:\".\n",
    "5) No placeholder zeros were recorded in \"production_orders.printings\".\n",
    "6) All required top-level keys exist and are arrays/objects per schema.\n",
    "7) Notes fields are strings or arrays of strings (no nested objects).\n",
    "8) No extra keys beyond the schema.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "JSON FORMAT GUARDRAILS\n",
    "--------------------------------------------------------------------------------\n",
    "- Return ONLY the JSON object (no commentary or markdown).\n",
    "- Never emit code inside values.\n",
    "- Unknowns → \"\", null, [], or {{}} per schema.\n",
    "- If multiple notes are present, return an array of strings. If a single note is present, a single string is acceptable.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        final_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            few_shot,\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "\n",
    "        return final_prompt | self.llm | self.output_parser\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914dd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_text = \"\"\n",
    "for grouped_chunk in total_grouped_chunks[1:2]:\n",
    "    #print(grouped_chunk['header'])\n",
    "    chunks = grouped_chunk['chunks']\n",
    "    final_text = \"\"\n",
    "    for chunk in chunks:\n",
    "        if chunk['type'] == 'attestation' or chunk['type'] == 'marginalia':\n",
    "            pass\n",
    "        else:\n",
    "            final_text += clean_chunk_text(chunk['markdown'])\n",
    "    print(\"------- TEXTO FIGURAS ----------\")\n",
    "    print(extraer_texto_entre_marcadores(final_text))\n",
    "    print(\"------- PLAIN TEXT -------------\")\n",
    "    final_test_text = eliminar_texto_entre_marcadores(final_text)\n",
    "    print(final_test_text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Quick test / demo\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "TEST = final_test_text\n",
    "\n",
    "\n",
    "def test_mena_parser():\n",
    "    parser = MenaParser(\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key\"),\n",
    "        model_name=\"gpt-5-mini\", #gpt-4o-mini #\"gpt-4.1-mini\"\n",
    "        temperature=1, #0.0 para los demas       \n",
    "        \n",
    "    )\n",
    "    result = parser.parse_chunk(TEST)\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "    with open(\"mena_parse_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "    print(\"Saved to mena_parse_result.json\")\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_mena_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_grouped_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea69322",
   "metadata": {},
   "source": [
    "## Codigo Batch Parser Mena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, json, time, datetime, traceback\n",
    "from time import sleep\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import islice\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# Configuración de tu parser\n",
    "# =========================================================\n",
    "parser = MenaParser(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\", \"your-api-key\"),\n",
    "    model_name=\"gpt-5-mini\",   # ajusta si usas otro\n",
    "    temperature=1.0,           # 0.0 para más determinismo\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# Parámetros de ejecución\n",
    "# =========================================================\n",
    "start_num        = 800 + 1\n",
    "final_num        = 838\n",
    "start_idx        = start_num - 1\n",
    "subbatch_size    = 8        # cuántos items por oleada\n",
    "max_workers      = 4        # concurrencia por oleada\n",
    "max_retries      = 2        # reintentos por item\n",
    "backoff_base_sec = 2        # 2, 4, 8... (si aumentas intentos)\n",
    "\n",
    "# Archivos de salida\n",
    "OUT_DIR          = \"results/parsed_catalogues\"\n",
    "OUT_OK           = os.path.join(OUT_DIR, f\"mena_parse_results_{start_num}-{final_num}.json\")\n",
    "OUT_ERR          = os.path.join(OUT_DIR, f\"mena_parse_errors_{start_num}-{final_num}.json\")\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "def chunked(it, size):\n",
    "    \"\"\"Particiona un iterable en bloques (listas) de 'size' elementos.\"\"\"\n",
    "    it = iter(it)\n",
    "    while True:\n",
    "        batch = list(islice(it, size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "def preparar_texto(group_chunk: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Concatena los 'markdown' de cada chunk (excepto tipos ignorados),\n",
    "    limpia y elimina los segmentos marcados para obtener texto final.\n",
    "    \"\"\"\n",
    "    chunks = group_chunk.get('chunks', [])\n",
    "    final_text = []\n",
    "    for ch in chunks:\n",
    "        t = ch.get('type')\n",
    "        if t in ('attestation', 'marginalia'):\n",
    "            continue\n",
    "        md = ch.get('markdown', '') or ''\n",
    "        final_text.append(clean_chunk_text(md))\n",
    "    raw_text = \"\".join(final_text)\n",
    "\n",
    "    # (Opcional) si quieres extraer texto entre marcadores para logging/diagnóstico:\n",
    "    # figuras = extraer_texto_entre_marcadores(raw_text)\n",
    "    # print(\"------- TEXTO FIGURAS ----------\")\n",
    "    # print(figuras)\n",
    "\n",
    "    # Texto \"limpio\" para enviar al parser (sin marcadores):\n",
    "    return eliminar_texto_entre_marcadores(raw_text)\n",
    "\n",
    "def safe_parse(text: str, retries: int = 0, max_retries: int = 2):\n",
    "    \"\"\"\n",
    "    Envuelve parser.parse_chunk con reintentos y backoff exponencial.\n",
    "    Devuelve (ok, data|error_dict)\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            out = parser.parse_chunk(text)\n",
    "            return True, out\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            if attempt > max_retries:\n",
    "                return False, {\n",
    "                    \"error\": f\"{type(e).__name__}: {str(e)}\",\n",
    "                    \"traceback\": traceback.format_exc()\n",
    "                }\n",
    "            # Backoff exponencial simple\n",
    "            sleep(backoff_base_sec ** (attempt - 1))\n",
    "\n",
    "# =========================================================\n",
    "# Preparación de entradas\n",
    "# =========================================================\n",
    "inputs: List[Dict[str, Any]] = []\n",
    "for i, group_chunk in enumerate(total_grouped_chunks[start_idx:final_num], start_num):\n",
    "    try:\n",
    "        final_text = preparar_texto(group_chunk)\n",
    "        inputs.append({\"i\": i, \"payload\": final_text})\n",
    "    except Exception as e:\n",
    "        # Si falla la preparación, registramos para errores (no se envía al LLM)\n",
    "        # Igual podemos seguir con las demás entradas\n",
    "        pass\n",
    "\n",
    "# =========================================================\n",
    "# Ejecución por oleadas (sub-batches) con concurrencia\n",
    "# =========================================================\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "results: List[Any] = [None] * len(inputs)\n",
    "error_groups: List[Dict[str, Any]] = []\n",
    "\n",
    "t0_global = time.perf_counter()\n",
    "total_items = len(inputs)\n",
    "remaining = total_items\n",
    "\n",
    "with tqdm(total=total_items, desc=\"Parseando (oleadas)\", unit=\"grp\") as pbar:\n",
    "    base = 0\n",
    "    for sub in chunked(inputs, subbatch_size):\n",
    "        # Ejecutamos esta oleada concurrente\n",
    "        futures = {}\n",
    "        t_oleada = time.perf_counter()\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "            for j, item in enumerate(sub):\n",
    "                idx_global = base + j\n",
    "                futures[ex.submit(safe_parse, item[\"payload\"], 0, max_retries)] = (idx_global, item[\"i\"])\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                idx_global, group_number = futures[future]\n",
    "                try:\n",
    "                    ok, data = future.result()\n",
    "                    if ok:\n",
    "                        results[idx_global] = data\n",
    "                    else:\n",
    "                        error_groups.append({\n",
    "                            \"group_number\": group_number,\n",
    "                            \"error\": data[\"error\"],\n",
    "                            \"traceback\": data.get(\"traceback\", \"\")\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    # Error inesperado al obtener el futuro\n",
    "                    error_groups.append({\n",
    "                        \"group_number\": group_number,\n",
    "                        \"error\": f\"FUTURE_FAILURE: {type(e).__name__}: {str(e)}\",\n",
    "                        \"traceback\": traceback.format_exc()\n",
    "                    })\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "        # ETA/metrics por oleada (opcional)\n",
    "        iter_sec = time.perf_counter() - t_oleada\n",
    "        done = min(base + len(sub), total_items)\n",
    "        elapsed = time.perf_counter() - t0_global\n",
    "        avg = elapsed / max(1, done)\n",
    "        remaining_sec = avg * (total_items - done)\n",
    "        eta = datetime.timedelta(seconds=max(0, int(remaining_sec)))\n",
    "        pbar.set_postfix(oleada_s=f\"{iter_sec:.2f}\", avg_s=f\"{avg:.2f}\", eta=str(eta))\n",
    "\n",
    "        base += len(sub)\n",
    "\n",
    "elapsed = time.perf_counter() - t0_global\n",
    "print(f\"Tiempo total: {datetime.timedelta(seconds=int(elapsed))}\")\n",
    "\n",
    "# =========================================================\n",
    "# Guardado de resultados\n",
    "# =========================================================\n",
    "ok_results = [r for r in results if r is not None]\n",
    "with open(OUT_OK, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ok_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(OUT_ERR, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(error_groups, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"OK: {len(ok_results)} | Errores: {len(error_groups)}\")\n",
    "print(f\"Guardados:\\n- {OUT_OK}\\n- {OUT_ERR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2aa39",
   "metadata": {},
   "source": [
    "## Merge the Catalogues Results in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob\n",
    "\n",
    "IN_DIR = \"results/parsed_catalogues\"\n",
    "OUT_ALL_OK  = os.path.join(IN_DIR, \"scott_parse_results_ALL.json\")\n",
    "OUT_ALL_ERR = os.path.join(IN_DIR, \"scott_parse_errors_ALL.json\")\n",
    "\n",
    "def load_json_list(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        return data if isinstance(data, list) else []\n",
    "\n",
    "def save_json(path, data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# --- Merge RESULTS ---\n",
    "all_results = []\n",
    "result_files = sorted(glob.glob(os.path.join(IN_DIR, \"scott_parse_results_*.json\")))\n",
    "result_files = [p for p in result_files if not p.endswith(\"_ALL.json\")]\n",
    "\n",
    "for p in result_files:\n",
    "    all_results.extend(load_json_list(p))\n",
    "\n",
    "save_json(OUT_ALL_OK, all_results)\n",
    "print(f\"Resultados unidos: {len(all_results)} -> {OUT_ALL_OK}\")\n",
    "\n",
    "# --- Merge ERRORS ---\n",
    "all_errors = []\n",
    "error_files = sorted(glob.glob(os.path.join(IN_DIR, \"scott_parse_errors_*.json\")))\n",
    "error_files = [p for p in error_files if not p.endswith(\"_ALL.json\")]\n",
    "\n",
    "for p in error_files:\n",
    "    all_errors.extend(load_json_list(p))\n",
    "\n",
    "save_json(OUT_ALL_ERR, all_errors)\n",
    "print(f\"Errores unidos: {len(all_errors)} -> {OUT_ALL_ERR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf27544",
   "metadata": {},
   "source": [
    "### Print Results of Parsed Catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ebac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Ruta al archivo unido\n",
    "PATH = Path(\"results/parsed_catalogues/mena_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    items = json.load(f)\n",
    "\n",
    "# Conteo\n",
    "print(f\"Total de items: {len(items)}\")\n",
    "\n",
    "# Iterar (imprime un resumen por cada elemento)\n",
    "for i, item in enumerate(items, start=1):\n",
    "    issue_id = (item.get(\"issue_data\") or {}).get(\"issue_id\")\n",
    "    title    = (item.get(\"issue_data\") or {}).get(\"title\")\n",
    "    print(f\"[{i}] issue_id={issue_id or '—'} | title={title or '—'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Ruta al archivo unido\n",
    "PATH = Path(\"results/parsed_catalogues/scott_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    items = json.load(f)\n",
    "\n",
    "# Conteo\n",
    "print(f\"Total de items: {len(items)}\")\n",
    "\n",
    "# Iterar (imprime un resumen por cada elemento)\n",
    "for i, item in enumerate(items, start=1):\n",
    "    stamps = (item.get(\"stamps\") or [])\n",
    "    for stamp in stamps:\n",
    "        print(stamp.get(\"scott_number\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
