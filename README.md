# Oxcart Graph RAG â€” Philatelic Research & Document Intelligence

<div align="center">
  <img src="./assets/oxcart_logo.svg" width="300" alt="Oxcart Graph RAG Logo">
  <br><br>

  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-lightgray" alt="License: MIT"></a>
  <a href="https://www.python.org/"><img src="https://img.shields.io/badge/Python-3.10%2B-blue" alt="Python"></a>
  <a href="https://weaviate.io/"><img src="https://img.shields.io/badge/Vector%20DB-Weaviate-00cc66" alt="Weaviate"></a>
  <a href="https://openai.com/"><img src="https://img.shields.io/badge/Embeddings-OpenAI-000000" alt="OpenAI Embeddings"></a>
  <a href="https://www.landing.ai/"><img src="https://img.shields.io/badge/PDF%20Parser-Landing.ai%20ADE-3333aa" alt="Landing.ai ADE"></a>
  <a href="https://gradio.app/"><img src="https://img.shields.io/badge/UI-Gradio-ff6c3f" alt="Gradio"></a>
  <a href="https://neo4j.com/"><img src="https://img.shields.io/badge/Graph%20DB-Neo4j-008CC1" alt="Neo4j"></a>
</div>

## ğŸš€ Demo

**[Try the live demo â†’](https://8a01a9f76568cc066b.gradio.live)**

---

## ğŸ“‹ Overview

**Oxcart Graph RAG** is a domain-specialized Retrieval-Augmented Generation system for philatelic research (Costa Rica focus). It ingests complex PDF literature (catalogs, journals, monographs, exhibits), normalizes structure, indexes **193,180 text chunks** from **1,424 documents**, and serves trustworthy answers with first-class citations.

> ğŸ“š **[View Complete Literature Catalog â†’](PHILATELIC_LITERATURE.md)** â€” Comprehensive documentation of all 1,424 source documents, organized by category with detailed statistics.

The system combines:

- **Robust PDF parsing** (primary: Dolphin; selectively: Landing.ai ADE for difficult layouts)
- **High-recall, high-precision retrieval** over Weaviate
- **Domain filters** (e.g., Scott numbers, year ranges, issue types)
- **Multi-stage re-ranking and context compression**
- **Guardrails** for minimum similarity thresholds and grounded answers

---

## ğŸ“Š Corpus & Indexing Snapshot

- **Total chunks**: 193,180
- **Unique PDFs**: 1,424
- **Total pages**: 22,940
- **Temporal coverage**: 1863-2025 (162 years of philatelic history)

> ğŸ“– **Detailed breakdown available**: [PHILATELIC_LITERATURE.md](PHILATELIC_LITERATURE.md) â€” Complete catalog with all source documents, authors, and statistics.

### Chunk Types
- **text** (148,980)
- **header** (22,790)
- **marginalia** (15,073)
- **decree** (2,797)
- **footer** (1,746)
- **caption** (666)
- **issue_notice** (620)
- **auction_result** (508)

### Collection Highlights
- Catalogs (e.g., **Scott 2024**, **Mena 2018**)
- **AFCR BoletÃ­n** (192 complete issues, 2009-2025)
- **Oxcart Collection** (257 specialized research papers)
- **Government Bulletins** (521 official postal bulletins, 1970-2023)
- **Costa Rica Philatelist** (34 historical issues, 1952-1955)
- **Costa Rican Philatelic Federation** materials (142 CRF journals)
- **Repertorio FilatÃ©lico** by Fred O'Neill (428 documents)
- Postal history monographs (247+ pages by Frajola, Castro, Mitchell)
- Forgery studies (Raul Hernandez: 177 pages)
- Specialized books and exhibits (85+ documents)

---

## ğŸ” Retrieval Approaches

### Tier 1 â€” Basic (Fast & Strong Baseline)

- **Hybrid search** (Weaviate `hybrid()`): BM25 + vector; **alpha = 0.35**
- **MMR re-ranking** to diversify
- **Philatelic filters** (optional):
  - `year_start`â€“`year_end` (auto-sorted)
  - `scott_numbers` (catalog = "Scott")
- **Quality gates**:
  - Min hybrid score (e.g., >= 0.20)
  - Min cosine similarity (for pure vector mode; e.g., >= 0.78)
- **Adaptive top-k**: expand from k to kâ€² if threshold unmet, else fail safely with a helpful clarification prompt

### Tier 2 â€” Advanced (Maximum Answer Quality)

#### Multi-query expansion
Generate **3 high-quality query variants** with an LLM (+ original user query).

#### Parallel retrieval
Run hybrid for each query; union results; source-balanced sampling.

#### Multi-stage re-rank

- **Stage A**: Hybrid score desc + MMR (diversity)
- **Stage B**: Domain priors bonus (e.g., exact Scott/years hit, `issue_notice`, presence of figures/captions)
- **Stage C**: Cross-encoder optional (if enabled)

#### Summary compression
Trim long chunks into faithful summaries that preserve citations.

#### Final selection
Choose top N_ctx with coverage constraints (avoid same-page clustering; prefer multi-source corroboration).

#### Answering with guardrails
If coverage < threshold or evidence conflicts â†’ return "insufficient evidence" with suggested refinements.

---

## ğŸ”’ Confidence Thresholding (Recommended Defaults)

```python
# Retrieval acceptance gates (tune per collection)
MIN_HYBRID_SCORE      = 0.20     # for Weaviate hybrid metadata.score
MIN_COSINE_SIM        = 0.78     # for near_text distanceâ†’similarity
TOPK_BASE             = 12       # start k
TOPK_MAX              = 32       # expand k if under threshold
CONSENSUS_MIN_SOURCES = 2        # min distinct documents
```

### Fail-safe behavior (no low-confidence answers):

If `< CONSENSUS_MIN_SOURCES` or all scores `< thresholds` â†’ return a clarifying prompt ("Provide Scott number / years / issue keywords") instead of speculating.

---

## ğŸ—„ï¸ Data Model & Domain Filters

### Key metadata (per chunk) indexed in Weaviate:

- `doc_id`, `chunk_id`, `chunk_type`, `page_number`
- `text`, `text_original` (with figure dedupe)
- `catalog_systems`, `catalog_numbers`, `scott_numbers`
- `years`, `colors`, `topics_primary`, `variety_classes`
- Flags: `has_catalog`, `has_prices`, `has_varieties`, `is_guanacaste`
- `quality_score` (ingestion-time heuristic)

### Filter examples

**Year span**: `year_start=1881, year_end=1883`

**Scott**: `scott_numbers=["CR 55","CR 56"]` (catalog pinned to "Scott")

---

## ğŸ—ï¸ Architecture

```
PDFs â†’ (Dolphin | Landing.ai ADE) â†’ JSON/Markdown â†’ Chunker/Normalizer
    â†’ Quality checks â†’ Weaviate (OpenAI embeddings) â†’ RAG Orchestrator
                    â†˜                                      â†—
Mena Catalog â†’ Neo4j (Graph + Vector + Fulltext indexes)

    â†’ (Basic or Advanced Retrieval + Graph Expansion) â†’ Context Compression â†’ Answer & Citations
```

### PDF Parsers

- **Primary**: Dolphin (structure, figures, captions)
- **Selective fallback**: Landing.ai ADE (improved table/figure fidelity)

### Embeddings

- **OpenAI** (e.g., `text-embedding-3-large`), cosine distance

### Vector DB

- **Weaviate** (hybrid, BM25, near_text, metadata filters)

---

## ğŸ•¸ï¸ Graph Knowledge Layer (Neo4j)

Oxcart Graph RAG augments vector search with a **structured knowledge graph** built from the **Mena 2018 Costa Rica Catalog**. This graph provides precise relationships between philatelic entities that complement the literature corpus indexed in Weaviate.

### Graph Schema (V1 Model)

The Neo4j graph represents the complete taxonomy of Costa Rican postal history:

**Core Entities**:
- **`:Issue`** â€” Postal issues (e.g., "1863 First Issue")
- **`:Stamp`** â€” Base catalog numbers with denomination, color, perforation
- **`:Variety`** â€” Suffixed variants (plate flaws, perforation anomalies)
- **`:Proof`** â€” Die/Plate/Color proofs
- **`:Plate`** â€” Printing plates with position tracking
- **`:PlatePosition`** â€” Specific positions for constant plate flaws

**Administrative Context**:
- **`:LegalAct`** â€” Decrees, resolutions authorizing issues
- **`:Person`** â€” Officials, printers, provenance
- **`:Printer`** â€” Printing companies
- **`:Organization`** â€” Philatelic organizations
- **`:ProductionOrder`** â€” Print runs with quantities
- **`:RemaindersEvent`** â€” Unsold stock disposition

**Key Relationships**:
- `(:Issue)-[:HAS_STAMP]->(:Stamp)-[:HAS_VARIETY]->(:Variety)`
- `(:Issue)-[:AUTHORIZED_BY]->(:LegalAct)-[:SIGNED_BY]->(:Person)`
- `(:Stamp)-[:USES_PLATE]->(:Plate)`
- `(:Variety)-[:AT_POSITION]->(:PlatePosition)`
- `(:Stamp)-[:OVERPRINTED_ON]->(:Stamp)` (derivations)

### Hybrid Search Architecture

Queries combine three retrieval strategies:

1. **Full-text search** (Neo4j Lucene index on issue titles/descriptions)
2. **Vector similarity** (OpenAI embeddings, cosine distance)
3. **Graph expansion** (relationship traversal to enrich context)

**Example workflow**:
```
User query: "1863 first issue varieties"
  â†“
[1] Neo4j full-text â†’ retrieves Issue node
[2] Graph traversal â†’ HAS_STAMP â†’ HAS_VARIETY â†’ AT_POSITION
[3] Vector search â†’ finds related literature chunks in Weaviate
[4] Unified answer with catalog structure + textual evidence
```

### Interactive Graph Viewer (Gradio + vis.js)

The Gradio interface includes a **live graph viewer** that:
- Executes custom Cypher queries
- Renders relationships with color-coded node types
- Provides tooltips with entity properties
- Supports physics simulation (toggle, zoom, fullscreen)

**Sample Views**:

<div align="center">
  <img src="./neo4j_utils/img/Stamp View Sample.png" width="45%" alt="Stamp View">
  <img src="./neo4j_utils/img/Issue View Sample.png" width="45%" alt="Issue View">
  <br>
  <i>Left: Stamp-level view with varieties and plates. Right: Issue-level view with all related entities.</i>
</div>

### Sample Cypher Queries

**Find all stamps in an issue with varieties**:
```cypher
MATCH (iss:Issue {issue_id: 'CR-1863-FIRST-ISSUE'})-[:HAS_STAMP]->(s:Stamp)
OPTIONAL MATCH (s)-[:HAS_VARIETY]->(v:Variety)
RETURN s.catalog_no AS no, s.color, s.perforation,
       collect(v.suffix) AS varieties
ORDER BY no;
```

**Trace overprint derivations**:
```cypher
MATCH (d:Stamp)-[r:OVERPRINTED_ON]->(b:Stamp)
RETURN d.issue_id AS derived, d.catalog_no,
       r.type AS overprint_type,
       b.issue_id AS base, b.catalog_no
ORDER BY derived;
```

**Production orders timeline**:
```cypher
MATCH (iss:Issue)-[:HAS_PRODUCTION_ORDER]->(po:ProductionOrder)
      -[:INCLUDES]->(q:Quantity)
RETURN iss.issue_id, po.date, q.plate_desc, q.quantity
ORDER BY po.date;
```

> **ğŸ“š Full technical guide**: [neo4j_technical_guide_cypher_cookbook.md](neo4j_utils/neo4j_technical_guide_cypher_cookbook.md)

### Setup

**1. Start Neo4j** (Docker or Desktop):
```bash
docker run -d \
  --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/your_password \
  neo4j:latest
```

**2. Ingest Mena catalog**:
```bash
export DATA_JSON="path/to/mena_all_with_raw.json"
python neo4j_utils/neo4j_ingest_mena_v1.py
```

**3. Create indexes & embeddings**:
```bash
python neo4j_utils/neo4j_index_and_embed.py
```

**4. Launch graph viewer**:
```bash
python neo4j_utils/neo4j_gradio_VIS.py
```

Or use the integrated viewer in `gradio_app.ipynb` (Graph Viewer tab).

### Integration with RAG Pipeline

Graph knowledge enhances answers by:
- **Catalog precision**: Resolve Scott/Mena numbers to exact entities
- **Relationship context**: "Show all varieties of this stamp"
- **Temporal ordering**: Production dates, issue sequences
- **Provenance tracking**: Legal acts, printers, officials
- **Cross-reference validation**: Verify claims against structured catalog

When a query mentions catalog numbers or issue names, the system:
1. Queries Neo4j for exact matches + neighborhood
2. Expands via relationships (stamps â†’ varieties â†’ positions)
3. Retrieves related literature from Weaviate
4. Synthesizes structured data + textual evidence

---

## âš™ï¸ Installation

### Prerequisites

- Python 3.10+
- Docker and Docker Compose
- Git LFS (if you store large parser checkpoints)

### 1. Clone

```bash
git clone https://github.com/omontes/oxcart.git
cd oxcart
```

### 2. Install

```bash
pip install -r requirements.txt
```

### 3. Environment

Create `.env`:

```env
# Weaviate
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=your_weaviate_key

# OpenAI
OPENAI_API_KEY=your_openai_key
OPENAI_EMBED_MODEL=text-embedding-3-large

# Parsing
PARSER_BACKEND=dolphin          # dolphin | landing_ai_ade | auto
ADE_API_KEY=your_landing_ai_key # if using ADE for selected PDFs

# Neo4j Graph Database
NEO4J_URI=neo4j://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j            # optional

# RAG
HYBRID_ALPHA=0.35
MIN_HYBRID_SCORE=0.20
MIN_COSINE_SIM=0.78
TOPK_BASE=12
TOPK_MAX=32
CONSENSUS_MIN_SOURCES=2
```

### 4. Start Weaviate

```bash
docker-compose -f weaviate_docker_compose.yml up -d
```

---

## ğŸš€ Usage

### A) Parse PDFs

```bash
# Primary parser
python dolphin_transformer.py \
  --input_path ./pdfs/ \
  --save_dir ./results \
  --batch_size 4

# (Optional) Re-parse selected PDFs with Landing.ai ADE
python ade_transformer.py \
  --input_path ./pdfs/hard_layouts/ \
  --save_dir ./results_ade \
  --only_overwrite_if_better
```

### B) Enrich & Validate

```bash
python philatelic_patterns.py \
  --input_dir ./results/recognition_json \
  --output_dir ./results/parsed_jsons

python run_quality_check.py \
  --input_dir ./results/parsed_jsons \
  --output_dir ./results/quality_reports
```

### C) Index in Weaviate

```bash
python philatelic_weaviate.py \
  --data_dir ./results/parsed_jsons \
  --action index
```

### D) Query â€” Basic Tier

```python
from rag.search import search_and_answer_basic

resp = search_and_answer_basic(
    query="When were the 1881â€“82 surcharges demonetized?",
    rag_system={"client": weaviate_client, "collection_name": "Oxcart"},
    year_start=1881, year_end=1883,
    scott_numbers=["CR 55","CR 56"],
    max_results=10
)
print(resp["answer"])
print(resp["metadata"])
```

### E) Query â€” Advanced Tier

```python
from rag.search import search_and_answer_advanced

resp = search_and_answer_advanced(
    query="Identify forged overprints for UPU 1883 surcharge and cite sources.",
    rag_system={"client": weaviate_client, "collection_name": "Oxcart"},
    multiquery_n=3,      # original + 3 LLM variants
    ctx_size=1800,       # target compressed context tokens
    topk_base=12, topk_max=32
)
```

The advanced pipeline performs multi-query retrieval, merges & re-ranks, compresses to faithful summaries with citations, applies score/consensus thresholds, and only then drafts the final answer.

---

## ğŸ“ Project Structure

```
oxcart/
â”œâ”€â”€ ğŸ“„ README.md                           # Project documentation
â”œâ”€â”€ ğŸ“„ CLAUDE.md                           # Development guidelines
â”œâ”€â”€ ğŸ“š PHILATELIC_LITERATURE.md            # Complete corpus documentation (1,424 sources)
â”œâ”€â”€ ğŸ³ weaviate_docker_compose.yml         # Vector database setup
â”‚
â”œâ”€â”€ ğŸ“Š dolphin_transformer.py              # Main PDF parsing engine (Dolphin)
â”œâ”€â”€ ğŸ” philatelic_patterns.py              # Philatelic metadata extraction
â”œâ”€â”€ ğŸ—„ï¸ philatelic_weaviate.py              # Weaviate vector DB integration
â”œâ”€â”€ ğŸ¥ dolphin_quality_control.py          # Quality assessment system
â”œâ”€â”€ âš™ï¸ run_quality_check.py                # Quality control runner
â”œâ”€â”€ ğŸ“Š chat.py                             # DOLPHIN model interface
â”‚
â”œâ”€â”€ ğŸ§© philatelic_chunk_logic.py           # Chunk processing logic
â”œâ”€â”€ ğŸ“‹ philatelic_chunk_schema.py          # Schema definitions
â”œâ”€â”€ ğŸ›ï¸ mena_stamp_agent.py                 # MENA catalog processing
â”œâ”€â”€ ğŸ›ï¸ mena_catalog_schema.py              # MENA schema definitions
â”‚
â”œâ”€â”€ ğŸ““ gradio_app.ipynb                    # Interactive web UI (Gradio)
â”œâ”€â”€ ğŸ““ philatelic_rag.ipynb                # RAG pipeline notebook
â”œâ”€â”€ ğŸ““ dolphin_parser.ipynb                # Document parsing experiments
â”œâ”€â”€ ğŸ““ philatelic_kg_builder.ipynb         # Knowledge graph construction
â”œâ”€â”€ ğŸ““ mena_to_scott_matcher_PRODUCTION.ipynb  # Catalog matching
â”‚
â”œâ”€â”€ ğŸ§ª test_enrich_chunk.py                # Chunk enrichment tests
â”œâ”€â”€ ğŸ§ª test_scott_pattern.py               # Scott number extraction tests
â”œâ”€â”€ ğŸ§ª test_bilingual_philatelic.py        # Bilingual processing tests
â”œâ”€â”€ ğŸ§ª philatelic_metadata_tests.py        # Metadata validation tests
â”‚
â”œâ”€â”€ ğŸ“ neo4j_utils/                        # Neo4j graph knowledge layer
â”‚   â”œâ”€â”€ neo4j_ingest_mena_v1.py            # Mena catalog â†’ Neo4j ingestion
â”‚   â”œâ”€â”€ neo4j_index_and_embed.py           # Full-text + vector indexes
â”‚   â”œâ”€â”€ neo4j_search.py                    # Hybrid search (fulltext/vector/graph)
â”‚   â”œâ”€â”€ neo4j_gradio_VIS.py                # vis.js graph viewer (Gradio)
â”‚   â”œâ”€â”€ neo4j_ingest_mena_v1_en.md         # Schema documentation (V1 model)
â”‚   â”œâ”€â”€ neo4j_technical_guide_cypher_cookbook.md  # Cypher queries & cookbook
â”‚   â””â”€â”€ img/                               # Graph visualization samples
â”‚
â”œâ”€â”€ ğŸ“ utils/                              # Helper modules
â”œâ”€â”€ ğŸ“ config/                             # Model configurations
â”œâ”€â”€ ğŸ“ assets/                             # Images and diagrams
â”œâ”€â”€ ğŸ“ checkpoints/                        # Model checkpoints
â”œâ”€â”€ ğŸ“ deployment/                         # Deployment configs
â”œâ”€â”€ ğŸ“ pdfs/                               # Source documents
â”œâ”€â”€ ğŸ“ results/                            # Processing outputs
â””â”€â”€ ğŸ“ graph_outputs/                      # Knowledge graph outputs
```

---

## ğŸ›ï¸ Configuration Knobs

- **HYBRID_ALPHA** (default 0.35): blend between BM25 and vector
- **MIN_HYBRID_SCORE** / **MIN_COSINE_SIM**: acceptance thresholds
- **TOPK_BASE**, **TOPK_MAX**: adaptive recall window
- **CONSENSUS_MIN_SOURCES**: robustness to single-source bias
- **multiquery_n**: number of LLM expansions (3 recommended)
- **ctx_size**: target compressed context size (tokens)
- **use_cross_encoder**: toggle final neural re-rank pass

---

## âœ… Quality, Safety & Monitoring

- **Grounding**: Every answer references `doc_id`/`page` with links when available
- **Thresholds**: Refuse to answer if all candidates fall below MIN_HYBRID_SCORE/MIN_COSINE_SIM
- **Consensus**: Prefer evidence drawn from â‰¥2 sources
- **De-duplication**: Hash (`doc_id`, `page`, canonicalized text) to avoid repeated evidence
- **MMR Diversity**: Reduce redundancy; improve coverage across issues/years
- **Eval Harness**: Offline notebooks to:
  - Sweep alpha (hybrid), k, thresholds
  - LLM-judge rubric for accuracy, grounding, coverage
  - Per-query telemetry (latency, token cost)

---

## ğŸ“Š Benchmarks (indicative)

- Retrieval **alpha=0.35** performed best in philatelic queries combining exact nomenclature (Scott numbers, year spans) with narrative text
- **Multi-query + multi-rerank** increased Top-k@5 grounded answer rate vs baseline hybrid by **~8â€“15%** (internal rubric)

*(Your mileage may vary; use the eval harness to calibrate on your queries.)*

---

## ğŸ’» Dev Notes

- **Embedding model**: `text-embedding-3-large` (cosine) recommended for long-tail philatelic terminology
- **Tokenizer drift**: keep embedder consistent across (re)indexing
- **PDF fallbacks**: enable ADE only for documents where table/figure fidelity matters; prefer single source of truth per PDF to avoid duplication

---

## ğŸ¨ Gradio Interface

Start the UI:

```bash
# Launch from notebook
jupyter notebook gradio_app.ipynb
```

### Features:

- Query mode toggle (Basic / Advanced)
- Filters panel (Scott / year range / issue types)
- Live evidence cards with per-chunk scores and jump-to-page links
- Confidence banner (green â‰¥ threshold; amber near; red below)

---

## ğŸ³ Deployment

```bash
docker-compose up -d
# scale workers
docker-compose up -d --scale worker=4
```

### Production checklist

- Persistent Weaviate volume & nightly backups
- HTTPS + API auth
- Centralized logging (OpenTelemetry)
- Periodic re-embedding/eval after schema or parser updates

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [**Weaviate**](https://weaviate.io/) - Vector database for hybrid search
- [**Neo4j**](https://neo4j.com/) - Graph database for structured philatelic knowledge
- [**OpenAI**](https://openai.com/) - High-quality embeddings
- [**Dolphin**](https://github.com/bytedance/Dolphin) - PDF structure extraction
- [**Landing.ai ADE**](https://www.landing.ai/) - High-fidelity parsing on selected PDFs
- **Philatelic community & contributors** - For sharing knowledge and resources

---

<div align="center">
  <i>Built with â¤ï¸ for stamp history, scholarship, and collectors.</i>
</div>
