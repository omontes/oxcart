{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7400d800",
   "metadata": {},
   "source": [
    "## Mena to Scott Catalog Matcher\n",
    "\n",
    "Mena to Scott Catalog Matching Algorithm\n",
    "\n",
    "Matches stamps from Mena catalog to Scott catalog using multi-signal scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63808f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Any, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import re\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo unido\n",
    "PATH = Path(\"results/parsed_catalogues/scott_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    items = json.load(f)\n",
    "\n",
    "# Conteo\n",
    "print(f\"Total de items: {len(items)}\")\n",
    "\n",
    "# Iterar (imprime un resumen por cada elemento)\n",
    "for i, item in enumerate(items, start=1):\n",
    "    stamps = (item.get(\"stamps\") or [])\n",
    "    for stamp in stamps:\n",
    "        print(stamp.get(\"scott_number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e4441",
   "metadata": {},
   "source": [
    "### Data Stuctures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b19037",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MatchResult:\n",
    "    \"\"\"Represents a match between Mena and Scott catalogs\"\"\"\n",
    "    mena_catalog_no: str\n",
    "    scott_number: str\n",
    "    confidence: str\n",
    "    score: float\n",
    "    signals: Dict[str, float]\n",
    "    breakdown: str\n",
    "    boost_reasons: List[str]\n",
    "    requires_review: bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UnmatchedEntry:\n",
    "    \"\"\"Represents an unmatched catalog entry\"\"\"\n",
    "    catalog_no: str\n",
    "    denomination: str\n",
    "    color: str\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26deda",
   "metadata": {},
   "source": [
    "### Normalization Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_ABBREVIATIONS = {\n",
    "    # Scott abbreviations → Standard\n",
    "    \"pl brn\": \"pale brown\",\n",
    "    \"dk brn\": \"dark brown\",\n",
    "    \"lt bl\": \"light blue\",\n",
    "    \"dk bl\": \"dark blue\",\n",
    "    \"org\": \"orange\",\n",
    "    \"grn\": \"green\",\n",
    "    \"dk grn\": \"dark green\",\n",
    "    \"lt grn\": \"light green\",\n",
    "    \"yel\": \"yellow\",\n",
    "    \"blk\": \"black\",\n",
    "    \"scar\": \"scarlet\",\n",
    "    \"car\": \"carmine\",\n",
    "    \"vio\": \"violet\",\n",
    "    \"pur\": \"purple\",\n",
    "    \"brn\": \"brown\",\n",
    "    \"ol\": \"olive\",\n",
    "    \"org red\": \"orange red\",\n",
    "    \"red brn\": \"red brown\",\n",
    "    \"gray\": \"grey\",\n",
    "    \"grn bl\": \"green blue\",\n",
    "    \"bl grn\": \"blue green\",\n",
    "    \"red org\": \"red orange\",\n",
    "    \"yel grn\": \"yellow green\",\n",
    "    \"brn red\": \"brown red\",\n",
    "    \n",
    "    # Common Mena terms → Standard\n",
    "    \"pale brown\": \"pale brown\",\n",
    "    \"light blue\": \"light blue\",\n",
    "    \"dark brown\": \"dark brown\",\n",
    "    \"dark blue\": \"dark blue\",\n",
    "    \"light green\": \"light green\",\n",
    "    \"dark green\": \"dark green\",\n",
    "    \"orange red\": \"orange red\",\n",
    "    \"red brown\": \"red brown\",\n",
    "    \"reddish brown\": \"red brown\",\n",
    "    \"reddish purple\": \"red purple\",\n",
    "    \"blue green\": \"blue green\",\n",
    "    \"green blue\": \"green blue\",\n",
    "}\n",
    "\n",
    "COLOR_FAMILIES = {\n",
    "    \"blue_family\": [\n",
    "        \"blue\", \"light blue\", \"dark blue\", \"pale blue\", \"ultramarine\", \n",
    "        \"azure\", \"sky blue\", \"cobalt\", \"navy\"\n",
    "    ],\n",
    "    \"red_family\": [\n",
    "        \"red\", \"scarlet\", \"carmine\", \"rose\", \"vermillion\", \"crimson\", \n",
    "        \"red orange\", \"red brown\", \"red purple\"\n",
    "    ],\n",
    "    \"yellow_family\": [\n",
    "        \"yellow\", \"orange\", \"lemon\", \"gold\", \"amber\", \"yellow green\"\n",
    "    ],\n",
    "    \"green_family\": [\n",
    "        \"green\", \"light green\", \"dark green\", \"olive\", \"emerald\", \n",
    "        \"blue green\", \"green blue\", \"yellow green\"\n",
    "    ],\n",
    "    \"brown_family\": [\n",
    "        \"brown\", \"pale brown\", \"dark brown\", \"sepia\", \"chocolate\", \n",
    "        \"red brown\", \"brown red\"\n",
    "    ],\n",
    "    \"purple_family\": [\n",
    "        \"purple\", \"violet\", \"mauve\", \"red purple\", \"reddish purple\"\n",
    "    ],\n",
    "    \"black_family\": [\"black\", \"grey\", \"gray\"],\n",
    "    \"white_family\": [\"white\"]\n",
    "}\n",
    "\n",
    "DENOMINATION_ABBREVIATIONS = {\n",
    "    \"r\": \"real\",\n",
    "    \"½r\": \"half real\",\n",
    "    \"c\": \"centavo\",\n",
    "    \"ct\": \"centavo\",\n",
    "    \"cts\": \"centavos\",\n",
    "    \"p\": \"peso\",\n",
    "    \"ps\": \"pesos\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6b9e5",
   "metadata": {},
   "source": [
    "### Normalization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451af09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_color(color_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize color strings to standard format\n",
    "    \n",
    "    Args:\n",
    "        color_string: Raw color string (e.g., \"pl brn\", \"pale brown\")\n",
    "    \n",
    "    Returns:\n",
    "        Normalized color string\n",
    "    \"\"\"\n",
    "    if not color_string:\n",
    "        return \"\"\n",
    "    \n",
    "    color_lower = color_string.lower().strip()\n",
    "    \n",
    "    # Check abbreviation dictionary\n",
    "    if color_lower in COLOR_ABBREVIATIONS:\n",
    "        return COLOR_ABBREVIATIONS[color_lower]\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    color_lower = \" \".join(color_lower.split())\n",
    "    \n",
    "    return color_lower\n",
    "\n",
    "\n",
    "def find_color_family(color: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Find which color family a color belongs to\n",
    "    \n",
    "    Args:\n",
    "        color: Normalized color string\n",
    "    \n",
    "    Returns:\n",
    "        Family name or None\n",
    "    \"\"\"\n",
    "    color_normalized = normalize_color(color)\n",
    "    \n",
    "    for family, colors in COLOR_FAMILIES.items():\n",
    "        if color_normalized in colors:\n",
    "            return family\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_color_family_similarity(color1: str, color2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate similarity between two colors based on color families\n",
    "    \n",
    "    Args:\n",
    "        color1: First color (normalized)\n",
    "        color2: Second color (normalized)\n",
    "    \n",
    "    Returns:\n",
    "        Similarity score (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    norm1 = normalize_color(color1)\n",
    "    norm2 = normalize_color(color2)\n",
    "    \n",
    "    # Exact match\n",
    "    if norm1 == norm2:\n",
    "        return 1.0\n",
    "    \n",
    "    # Check color families\n",
    "    family1 = find_color_family(norm1)\n",
    "    family2 = find_color_family(norm2)\n",
    "    \n",
    "    if family1 and family2 and family1 == family2:\n",
    "        # Same family - high similarity\n",
    "        return 0.85\n",
    "    \n",
    "    # Use string similarity as fallback\n",
    "    return SequenceMatcher(None, norm1, norm2).ratio()\n",
    "\n",
    "\n",
    "def parse_denomination_string(denom_string: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse denomination string to extract value and unit\n",
    "    \n",
    "    Args:\n",
    "        denom_string: String like \"5c\", \"½r\", \"2 reales\", \"1p\"\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'value' and 'unit'\n",
    "    \"\"\"\n",
    "    if not denom_string:\n",
    "        return {\"value\": None, \"unit\": None}\n",
    "    \n",
    "    denom_string = denom_string.lower().strip()\n",
    "    \n",
    "    # Handle special case: ½\n",
    "    if \"½\" in denom_string:\n",
    "        value = 0.5\n",
    "        # Extract unit\n",
    "        unit = re.sub(r'[½\\d\\s.]', '', denom_string)\n",
    "    else:\n",
    "        # Extract numeric value\n",
    "        match = re.search(r'(\\d+\\.?\\d*)', denom_string)\n",
    "        if match:\n",
    "            value = float(match.group(1))\n",
    "        else:\n",
    "            return {\"value\": None, \"unit\": None}\n",
    "        \n",
    "        # Extract unit\n",
    "        unit = re.sub(r'[\\d\\s.]', '', denom_string)\n",
    "    \n",
    "    # Normalize unit\n",
    "    if unit in DENOMINATION_ABBREVIATIONS:\n",
    "        unit = DENOMINATION_ABBREVIATIONS[unit]\n",
    "    \n",
    "    return {\"value\": value, \"unit\": unit}\n",
    "\n",
    "\n",
    "def normalize_denomination(value: float, unit: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Normalize denomination to standard format\n",
    "    \n",
    "    Args:\n",
    "        value: Numeric value\n",
    "        unit: Unit string (real, peso, centavo, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized value and unit\n",
    "    \"\"\"\n",
    "    # Normalize unit names\n",
    "    unit_normalized = unit.lower().strip()\n",
    "    \n",
    "    # Handle plurals\n",
    "    if unit_normalized.endswith('s'):\n",
    "        unit_normalized = unit_normalized[:-1]\n",
    "    \n",
    "    # Map abbreviations\n",
    "    if unit_normalized in DENOMINATION_ABBREVIATIONS:\n",
    "        unit_normalized = DENOMINATION_ABBREVIATIONS[unit_normalized]\n",
    "    \n",
    "    # Special handling for \"P\" -> \"peso\"\n",
    "    if unit_normalized == \"p\":\n",
    "        unit_normalized = \"peso\"\n",
    "    \n",
    "    return {\n",
    "        \"value\": value,\n",
    "        \"unit\": unit_normalized\n",
    "    }\n",
    "\n",
    "\n",
    "def normalize_perforation(perf_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize perforation string\n",
    "    \n",
    "    Args:\n",
    "        perf_string: Perforation string like \"12\", \"Perf. 12\", \"Perf 12½\"\n",
    "    \n",
    "    Returns:\n",
    "        Normalized perforation string\n",
    "    \"\"\"\n",
    "    if not perf_string:\n",
    "        return \"\"\n",
    "    \n",
    "    # Extract numbers\n",
    "    numbers = re.findall(r'[\\d½]+', perf_string)\n",
    "    return \" \".join(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa790888",
   "metadata": {},
   "source": [
    "### Year Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_primary_year(issue_dates: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Extract the primary year from Mena issue dates\n",
    "    \n",
    "    Args:\n",
    "        issue_dates: Dictionary of issue dates\n",
    "    \n",
    "    Returns:\n",
    "        Primary year as integer\n",
    "    \"\"\"\n",
    "    # Priority order for date selection\n",
    "    date_priorities = [\n",
    "        'placed_on_sale',\n",
    "        'probable_first_circulation',\n",
    "        'announced',\n",
    "        'second_plate_sale'\n",
    "    ]\n",
    "    \n",
    "    for date_key in date_priorities:\n",
    "        if date_key in issue_dates and issue_dates[date_key]:\n",
    "            date_str = issue_dates[date_key]\n",
    "            if isinstance(date_str, str):\n",
    "                # Extract year from ISO date format\n",
    "                match = re.search(r'(\\d{4})', date_str)\n",
    "                if match:\n",
    "                    return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_scott_year(scott_stamp: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Extract year from Scott stamp entry\n",
    "    \n",
    "    Args:\n",
    "        scott_stamp: Scott stamp dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Year as integer\n",
    "    \"\"\"\n",
    "    # Try 'year' field first\n",
    "    if 'year' in scott_stamp and scott_stamp['year']:\n",
    "        return int(scott_stamp['year'])\n",
    "    \n",
    "    # Try 'header' field\n",
    "    if 'header' in scott_stamp and scott_stamp['header']:\n",
    "        header = scott_stamp['header']\n",
    "        # Extract year from header like \"1863\" or \"1863, Apr. 11\"\n",
    "        match = re.search(r'(\\d{4})', header)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184a867",
   "metadata": {},
   "source": [
    "### Candidate Pool Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41342a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidate_pool(\n",
    "    mena_issue: Dict[str, Any],\n",
    "    all_scott_stamps: List[Dict[str, Any]],\n",
    "    year_tolerance: int = 2\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Build a pool of Scott stamp candidates based on year\n",
    "    \n",
    "    Args:\n",
    "        mena_issue: Complete Mena issue data\n",
    "        all_scott_stamps: List of all Scott stamps\n",
    "        year_tolerance: Years +/- to include (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "        List of candidate Scott stamps\n",
    "    \"\"\"\n",
    "    primary_year = extract_primary_year(mena_issue['issue_data']['issue_dates'])\n",
    "    \n",
    "    if not primary_year:\n",
    "        print(\"Warning: Could not extract year from Mena issue\")\n",
    "        return all_scott_stamps  # Return all if no year found\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    for scott_stamp in all_scott_stamps:\n",
    "        scott_year = extract_scott_year(scott_stamp)\n",
    "        \n",
    "        if scott_year is None:\n",
    "            # Include stamps without year info\n",
    "            candidates.append(scott_stamp)\n",
    "        elif abs(scott_year - primary_year) <= year_tolerance:\n",
    "            candidates.append(scott_stamp)\n",
    "    \n",
    "    print(f\"Found {len(candidates)} Scott candidates for year {primary_year} (±{year_tolerance} years)\")\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071473c",
   "metadata": {},
   "source": [
    "### Multi Signal Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf48f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_score(\n",
    "    mena_stamp: Dict[str, Any],\n",
    "    scott_stamp: Dict[str, Any],\n",
    "    mena_issue_context: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate match score using multiple signals\n",
    "    \n",
    "    Args:\n",
    "        mena_stamp: Single Mena stamp entry\n",
    "        scott_stamp: Single Scott stamp entry\n",
    "        mena_issue_context: Issue-level context from Mena\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with total_score, signals, and breakdown\n",
    "    \"\"\"\n",
    "    signals = {}\n",
    "    total_score = 0.0\n",
    "    breakdown_parts = []\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SIGNAL 1: DENOMINATION MATCH (35 points)\n",
    "    # =========================================================================\n",
    "    mena_denom = normalize_denomination(\n",
    "        mena_stamp['denomination']['value'],\n",
    "        mena_stamp['denomination']['unit']\n",
    "    )\n",
    "    \n",
    "    scott_denom_str = scott_stamp.get('denomination', '')\n",
    "    scott_denom = parse_denomination_string(scott_denom_str)\n",
    "    \n",
    "    if (mena_denom['value'] == scott_denom['value'] and \n",
    "        mena_denom['unit'] == scott_denom['unit']):\n",
    "        signals['denomination'] = 35\n",
    "        total_score += 35\n",
    "        breakdown_parts.append(f\"Denom: {mena_denom['value']}{mena_denom['unit'][:1]} = {scott_denom_str} ✓\")\n",
    "    elif mena_denom['unit'] == scott_denom['unit'] and mena_denom['value']:\n",
    "        # Same unit, different value\n",
    "        diff_percentage = abs(mena_denom['value'] - scott_denom['value']) / mena_denom['value']\n",
    "        if diff_percentage < 0.2:\n",
    "            signals['denomination'] = 20\n",
    "            total_score += 20\n",
    "            breakdown_parts.append(f\"Denom: similar (~{int((1-diff_percentage)*100)}%)\")\n",
    "        else:\n",
    "            signals['denomination'] = 0\n",
    "            breakdown_parts.append(f\"Denom: mismatch\")\n",
    "    else:\n",
    "        signals['denomination'] = 0\n",
    "        breakdown_parts.append(f\"Denom: no match\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SIGNAL 2: COLOR MATCH (30 points)\n",
    "    # =========================================================================\n",
    "    mena_color = mena_stamp.get('color', '')\n",
    "    scott_color = scott_stamp.get('color', '')\n",
    "    \n",
    "    if mena_color and scott_color:\n",
    "        color_similarity = calculate_color_family_similarity(mena_color, scott_color)\n",
    "        color_score = color_similarity * 30\n",
    "        signals['color'] = color_score\n",
    "        total_score += color_score\n",
    "        \n",
    "        if color_similarity >= 0.95:\n",
    "            breakdown_parts.append(f\"Color: {mena_color} = {scott_color} ✓\")\n",
    "        elif color_similarity >= 0.80:\n",
    "            breakdown_parts.append(f\"Color: {mena_color} ≈ {scott_color} ({int(color_similarity*100)}%)\")\n",
    "        else:\n",
    "            breakdown_parts.append(f\"Color: {mena_color} vs {scott_color} ({int(color_similarity*100)}%)\")\n",
    "    else:\n",
    "        signals['color'] = 0\n",
    "        breakdown_parts.append(\"Color: missing data\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SIGNAL 3: YEAR PROXIMITY (20 points)\n",
    "    # =========================================================================\n",
    "    mena_year = extract_primary_year(mena_issue_context['issue_dates'])\n",
    "    scott_year = extract_scott_year(scott_stamp)\n",
    "    \n",
    "    if mena_year and scott_year:\n",
    "        year_diff = abs(mena_year - scott_year)\n",
    "        \n",
    "        if year_diff == 0:\n",
    "            signals['year'] = 20\n",
    "            total_score += 20\n",
    "            breakdown_parts.append(f\"Year: {mena_year} ✓\")\n",
    "        elif year_diff == 1:\n",
    "            signals['year'] = 15\n",
    "            total_score += 15\n",
    "            breakdown_parts.append(f\"Year: {mena_year} vs {scott_year} (±1)\")\n",
    "        elif year_diff == 2:\n",
    "            signals['year'] = 10\n",
    "            total_score += 10\n",
    "            breakdown_parts.append(f\"Year: {mena_year} vs {scott_year} (±2)\")\n",
    "        else:\n",
    "            signals['year'] = 0\n",
    "            breakdown_parts.append(f\"Year: {mena_year} vs {scott_year} (>{year_diff})\")\n",
    "    else:\n",
    "        signals['year'] = 0\n",
    "        breakdown_parts.append(\"Year: missing data\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SIGNAL 4: PERFORATION MATCH (10 points)\n",
    "    # =========================================================================\n",
    "    mena_perf = mena_stamp.get('perforation', '')\n",
    "    scott_perf = scott_stamp.get('perforation', '')\n",
    "    \n",
    "    if mena_perf and scott_perf:\n",
    "        mena_perf_norm = normalize_perforation(str(mena_perf))\n",
    "        scott_perf_norm = normalize_perforation(str(scott_perf))\n",
    "        \n",
    "        if mena_perf_norm == scott_perf_norm:\n",
    "            signals['perforation'] = 10\n",
    "            total_score += 10\n",
    "            breakdown_parts.append(f\"Perf: {mena_perf} ✓\")\n",
    "        else:\n",
    "            signals['perforation'] = 0\n",
    "            breakdown_parts.append(f\"Perf: {mena_perf} vs {scott_perf}\")\n",
    "    else:\n",
    "        signals['perforation'] = 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SIGNAL 5: ILLUSTRATION/DESIGN (5 points)\n",
    "    # =========================================================================\n",
    "    scott_illustration = scott_stamp.get('illustration', '')\n",
    "    if scott_illustration:\n",
    "        signals['illustration'] = 5\n",
    "        total_score += 5\n",
    "        breakdown_parts.append(f\"Illus: {scott_illustration}\")\n",
    "    else:\n",
    "        signals['illustration'] = 0\n",
    "    \n",
    "    return {\n",
    "        'total_score': total_score,\n",
    "        'signals': signals,\n",
    "        'breakdown': \" | \".join(breakdown_parts)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70d8e0",
   "metadata": {},
   "source": [
    "### Scoring Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ec56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_candidates(\n",
    "    mena_issue: Dict[str, Any],\n",
    "    scott_candidate_pool: List[Dict[str, Any]],\n",
    "    min_threshold: float = 30.0\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Score all Mena stamps against all Scott candidates\n",
    "    \n",
    "    Args:\n",
    "        mena_issue: Complete Mena issue\n",
    "        scott_candidate_pool: List of Scott candidate stamps\n",
    "        min_threshold: Minimum score to keep (default: 30)\n",
    "    \n",
    "    Returns:\n",
    "        List of scoring rows (one per Mena stamp)\n",
    "    \"\"\"\n",
    "    scoring_matrix = []\n",
    "    \n",
    "    for mena_stamp in mena_issue['stamps']:\n",
    "        mena_row = {\n",
    "            'mena_catalog_no': mena_stamp['catalog_no'],\n",
    "            'mena_stamp': mena_stamp,\n",
    "            'candidates': []\n",
    "        }\n",
    "        \n",
    "        for scott_candidate in scott_candidate_pool:\n",
    "            score_result = calculate_match_score(\n",
    "                mena_stamp,\n",
    "                scott_candidate,\n",
    "                mena_issue['issue_data']\n",
    "            )\n",
    "            \n",
    "            # Only keep candidates above threshold\n",
    "            if score_result['total_score'] >= min_threshold:\n",
    "                mena_row['candidates'].append({\n",
    "                    'scott_number': scott_candidate.get('scott_number', 'UNKNOWN'),\n",
    "                    'scott_stamp': scott_candidate,\n",
    "                    'score': score_result['total_score'],\n",
    "                    'signals': score_result['signals'],\n",
    "                    'breakdown': score_result['breakdown']\n",
    "                })\n",
    "        \n",
    "        # Sort candidates by score (descending)\n",
    "        mena_row['candidates'].sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        scoring_matrix.append(mena_row)\n",
    "    \n",
    "    return scoring_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2160273",
   "metadata": {},
   "source": [
    "## Optimal Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_assignment(scoring_matrix: List[Dict[str, Any]]) -> List[MatchResult]:\n",
    "    \"\"\"\n",
    "    Find optimal one-to-one assignment between Mena and Scott stamps\n",
    "    \n",
    "    Args:\n",
    "        scoring_matrix: Matrix of all possible matches with scores\n",
    "    \n",
    "    Returns:\n",
    "        List of MatchResult objects\n",
    "    \"\"\"\n",
    "    assignments = []\n",
    "    used_scott_numbers = set()\n",
    "    assigned_mena = set()\n",
    "    \n",
    "    # Flatten all matches\n",
    "    all_matches = []\n",
    "    for mena_row in scoring_matrix:\n",
    "        for candidate in mena_row['candidates']:\n",
    "            all_matches.append({\n",
    "                'mena_catalog_no': mena_row['mena_catalog_no'],\n",
    "                'scott_number': candidate['scott_number'],\n",
    "                'score': candidate['score'],\n",
    "                'signals': candidate['signals'],\n",
    "                'breakdown': candidate['breakdown']\n",
    "            })\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    all_matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Greedy assignment\n",
    "    for match in all_matches:\n",
    "        mena_no = match['mena_catalog_no']\n",
    "        scott_no = match['scott_number']\n",
    "        \n",
    "        # Check if already assigned\n",
    "        if mena_no in assigned_mena or scott_no in used_scott_numbers:\n",
    "            continue\n",
    "        \n",
    "        # Determine confidence level\n",
    "        score = match['score']\n",
    "        if score >= 70:\n",
    "            confidence = \"HIGH\"\n",
    "            requires_review = False\n",
    "        elif score >= 50:\n",
    "            confidence = \"MEDIUM\"\n",
    "            requires_review = True\n",
    "        else:\n",
    "            confidence = \"LOW\"\n",
    "            requires_review = True\n",
    "        \n",
    "        # Create match result\n",
    "        result = MatchResult(\n",
    "            mena_catalog_no=mena_no,\n",
    "            scott_number=scott_no,\n",
    "            confidence=confidence,\n",
    "            score=score,\n",
    "            signals=match['signals'],\n",
    "            breakdown=match['breakdown'],\n",
    "            boost_reasons=[],\n",
    "            requires_review=requires_review\n",
    "        )\n",
    "        \n",
    "        assignments.append(result)\n",
    "        used_scott_numbers.add(scott_no)\n",
    "        assigned_mena.add(mena_no)\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8efb53",
   "metadata": {},
   "source": [
    "### Validation and Confidence Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0135b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequential_pattern(assignments: List[MatchResult]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if assignments follow a sequential numbering pattern\n",
    "    \n",
    "    Args:\n",
    "        assignments: List of match results\n",
    "    \n",
    "    Returns:\n",
    "        True if sequential pattern detected\n",
    "    \"\"\"\n",
    "    if len(assignments) < 3:\n",
    "        return False\n",
    "    \n",
    "    # Sort by Mena catalog number\n",
    "    sorted_assignments = sorted(assignments, key=lambda x: x.mena_catalog_no)\n",
    "    \n",
    "    # Check if Scott numbers also increase\n",
    "    scott_numbers = []\n",
    "    for assignment in sorted_assignments:\n",
    "        try:\n",
    "            # Extract numeric part of Scott number\n",
    "            match = re.search(r'(\\d+)', assignment.scott_number)\n",
    "            if match:\n",
    "                scott_numbers.append(int(match.group(1)))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if len(scott_numbers) < 3:\n",
    "        return False\n",
    "    \n",
    "    # Check if mostly increasing\n",
    "    increasing_count = sum(1 for i in range(len(scott_numbers)-1) \n",
    "                          if scott_numbers[i] < scott_numbers[i+1])\n",
    "    \n",
    "    return increasing_count >= (len(scott_numbers) - 1) * 0.7\n",
    "\n",
    "\n",
    "def check_denomination_progression(assignments: List[MatchResult]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if denominations follow logical progression\n",
    "    \n",
    "    Args:\n",
    "        assignments: List of match results\n",
    "    \n",
    "    Returns:\n",
    "        True if logical progression detected\n",
    "    \"\"\"\n",
    "    if len(assignments) < 2:\n",
    "        return False\n",
    "    \n",
    "    # This is a simplified check\n",
    "    # Could be enhanced to check actual denomination values\n",
    "    return len(assignments) >= 3\n",
    "\n",
    "\n",
    "def validate_and_boost_confidence(\n",
    "    assignments: List[MatchResult],\n",
    "    mena_issue: Dict[str, Any]\n",
    ") -> List[MatchResult]:\n",
    "    \"\"\"\n",
    "    Validate assignments and boost confidence based on patterns\n",
    "    \n",
    "    Args:\n",
    "        assignments: List of match results\n",
    "        mena_issue: Original Mena issue data\n",
    "    \n",
    "    Returns:\n",
    "        Updated list of match results\n",
    "    \"\"\"\n",
    "    # Check patterns\n",
    "    has_sequential = check_sequential_pattern(assignments)\n",
    "    has_denom_progression = check_denomination_progression(assignments)\n",
    "    \n",
    "    for assignment in assignments:\n",
    "        confidence_boost = 0\n",
    "        boost_reasons = []\n",
    "        \n",
    "        if has_sequential:\n",
    "            confidence_boost += 10\n",
    "            boost_reasons.append(\"Sequential number pattern\")\n",
    "        \n",
    "        if has_denom_progression:\n",
    "            confidence_boost += 5\n",
    "            boost_reasons.append(\"Denomination progression\")\n",
    "        \n",
    "        # Apply boost\n",
    "        assignment.score += confidence_boost\n",
    "        assignment.boost_reasons = boost_reasons\n",
    "        \n",
    "        # Recalculate confidence level\n",
    "        if assignment.score >= 80:\n",
    "            assignment.confidence = \"HIGH\"\n",
    "            assignment.requires_review = False\n",
    "        elif assignment.score >= 60:\n",
    "            assignment.confidence = \"MEDIUM\"\n",
    "            assignment.requires_review = True\n",
    "        else:\n",
    "            assignment.confidence = \"LOW\"\n",
    "            assignment.requires_review = True\n",
    "    \n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac99db",
   "metadata": {},
   "source": [
    "### Unmatched Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_unmatched(\n",
    "    assignments: List[MatchResult],\n",
    "    mena_issue: Dict[str, Any],\n",
    "    scott_candidate_pool: List[Dict[str, Any]]\n",
    ") -> Dict[str, List[UnmatchedEntry]]:\n",
    "    \"\"\"\n",
    "    Identify unmatched entries in both catalogs\n",
    "    \n",
    "    Args:\n",
    "        assignments: List of successful matches\n",
    "        mena_issue: Mena issue data\n",
    "        scott_candidate_pool: Scott candidates\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with unmatched_mena and unmatched_scott lists\n",
    "    \"\"\"\n",
    "    # Find unmatched Mena stamps\n",
    "    matched_mena_numbers = {a.mena_catalog_no for a in assignments}\n",
    "    unmatched_mena = []\n",
    "    \n",
    "    for stamp in mena_issue['stamps']:\n",
    "        if stamp['catalog_no'] not in matched_mena_numbers:\n",
    "            unmatched_mena.append(UnmatchedEntry(\n",
    "                catalog_no=stamp['catalog_no'],\n",
    "                denomination=f\"{stamp['denomination']['value']}{stamp['denomination']['unit']}\",\n",
    "                color=stamp.get('color', 'N/A'),\n",
    "                reason=\"No suitable Scott match found\"\n",
    "            ))\n",
    "    \n",
    "    # Find unmatched Scott stamps\n",
    "    matched_scott_numbers = {a.scott_number for a in assignments}\n",
    "    unmatched_scott = []\n",
    "    \n",
    "    for stamp in scott_candidate_pool:\n",
    "        scott_no = stamp.get('scott_number', 'UNKNOWN')\n",
    "        if scott_no not in matched_scott_numbers:\n",
    "            unmatched_scott.append(UnmatchedEntry(\n",
    "                catalog_no=scott_no,\n",
    "                denomination=stamp.get('denomination', 'N/A'),\n",
    "                color=stamp.get('color', 'N/A'),\n",
    "                reason=\"No Mena equivalent found\"\n",
    "            ))\n",
    "    \n",
    "    return {\n",
    "        'unmatched_mena': unmatched_mena,\n",
    "        'unmatched_scott': unmatched_scott\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c54dfc",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6668b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_mena_to_scott(\n",
    "    mena_issue: Dict[str, Any],\n",
    "    all_scott_stamps: List[Dict[str, Any]],\n",
    "    year_tolerance: int = 2,\n",
    "    min_score_threshold: float = 30.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main function to match Mena issue to Scott catalog\n",
    "    \n",
    "    Args:\n",
    "        mena_issue: Complete Mena issue data structure\n",
    "        all_scott_stamps: List of all Scott stamp entries\n",
    "        year_tolerance: Years +/- to include in candidate pool\n",
    "        min_score_threshold: Minimum score to consider a match\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with complete matching results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MENA TO SCOTT CATALOG MATCHING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Phase 1: Build candidate pool\n",
    "    print(\"\\n[Phase 1] Building candidate pool...\")\n",
    "    scott_candidates = build_candidate_pool(mena_issue, all_scott_stamps, year_tolerance)\n",
    "    \n",
    "    # Phase 2: Score all candidates\n",
    "    print(f\"\\n[Phase 2] Scoring {len(mena_issue['stamps'])} Mena stamps against {len(scott_candidates)} Scott candidates...\")\n",
    "    scoring_matrix = score_all_candidates(mena_issue, scott_candidates, min_score_threshold)\n",
    "    \n",
    "    # Print scoring summary\n",
    "    for row in scoring_matrix:\n",
    "        print(f\"  Mena #{row['mena_catalog_no']}: {len(row['candidates'])} candidates found\")\n",
    "    \n",
    "    # Phase 3: Find optimal assignment\n",
    "    print(\"\\n[Phase 3] Finding optimal assignment...\")\n",
    "    assignments = find_optimal_assignment(scoring_matrix)\n",
    "    print(f\"  Created {len(assignments)} initial assignments\")\n",
    "    \n",
    "    # Phase 4: Validate and boost\n",
    "    print(\"\\n[Phase 4] Validating and boosting confidence...\")\n",
    "    assignments = validate_and_boost_confidence(assignments, mena_issue)\n",
    "    \n",
    "    # Phase 5: Identify unmatched\n",
    "    print(\"\\n[Phase 5] Identifying unmatched entries...\")\n",
    "    unmatched = identify_unmatched(assignments, mena_issue, scott_candidates)\n",
    "    print(f\"  Unmatched Mena: {len(unmatched['unmatched_mena'])}\")\n",
    "    print(f\"  Unmatched Scott: {len(unmatched['unmatched_scott'])}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_mena = len(mena_issue['stamps'])\n",
    "    high_conf = sum(1 for a in assignments if a.confidence == \"HIGH\")\n",
    "    medium_conf = sum(1 for a in assignments if a.confidence == \"MEDIUM\")\n",
    "    low_conf = sum(1 for a in assignments if a.confidence == \"LOW\")\n",
    "    success_rate = (len(assignments) / total_mena * 100) if total_mena > 0 else 0\n",
    "    \n",
    "    statistics = {\n",
    "        'total_mena_stamps': total_mena,\n",
    "        'total_assignments': len(assignments),\n",
    "        'high_confidence': high_conf,\n",
    "        'medium_confidence': medium_conf,\n",
    "        'low_confidence': low_conf,\n",
    "        'unmatched_mena': len(unmatched['unmatched_mena']),\n",
    "        'unmatched_scott': len(unmatched['unmatched_scott']),\n",
    "        'success_rate': round(success_rate, 1)\n",
    "    }\n",
    "    \n",
    "    # Build result\n",
    "    result = {\n",
    "        'issue_match': {\n",
    "            'mena_issue_id': mena_issue['issue_data']['issue_id'],\n",
    "            'mena_title': mena_issue['issue_data']['title'],\n",
    "            'mena_year': extract_primary_year(mena_issue['issue_data']['issue_dates']),\n",
    "            'candidate_pool_size': len(scott_candidates)\n",
    "        },\n",
    "        'assignments': [\n",
    "            {\n",
    "                'mena_catalog_no': a.mena_catalog_no,\n",
    "                'scott_number': a.scott_number,\n",
    "                'confidence': a.confidence,\n",
    "                'score': round(a.score, 1),\n",
    "                'signals': {k: round(v, 1) for k, v in a.signals.items()},\n",
    "                'breakdown': a.breakdown,\n",
    "                'boost_reasons': a.boost_reasons,\n",
    "                'requires_review': a.requires_review\n",
    "            }\n",
    "            for a in assignments\n",
    "        ],\n",
    "        'unmatched': {\n",
    "            'mena': [\n",
    "                {\n",
    "                    'catalog_no': u.catalog_no,\n",
    "                    'denomination': u.denomination,\n",
    "                    'color': u.color,\n",
    "                    'reason': u.reason\n",
    "                }\n",
    "                for u in unmatched['unmatched_mena']\n",
    "            ],\n",
    "            'scott': [\n",
    "                {\n",
    "                    'catalog_no': u.catalog_no,\n",
    "                    'denomination': u.denomination,\n",
    "                    'color': u.color,\n",
    "                    'reason': u.reason\n",
    "                }\n",
    "                for u in unmatched['unmatched_scott']\n",
    "            ]\n",
    "        },\n",
    "        'statistics': statistics,\n",
    "        'scoring_matrix': scoring_matrix  # Include for detailed analysis\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MATCHING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Mena stamps: {statistics['total_mena_stamps']}\")\n",
    "    print(f\"Successful matches: {statistics['total_assignments']}\")\n",
    "    print(f\"  - High confidence: {statistics['high_confidence']}\")\n",
    "    print(f\"  - Medium confidence: {statistics['medium_confidence']}\")\n",
    "    print(f\"  - Low confidence: {statistics['low_confidence']}\")\n",
    "    print(f\"Success rate: {statistics['success_rate']}%\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PRETTY PRINTING\n",
    "# ============================================================================\n",
    "\n",
    "def print_matching_results(result: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Pretty print the matching results\n",
    "    \n",
    "    Args:\n",
    "        result: Result dictionary from match_mena_to_scott\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED MATCHING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nIssue: {result['issue_match']['mena_title']} ({result['issue_match']['mena_year']})\")\n",
    "    print(f\"Mena ID: {result['issue_match']['mena_issue_id']}\")\n",
    "    print(f\"Scott candidate pool: {result['issue_match']['candidate_pool_size']} stamps\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"ASSIGNMENTS\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for assignment in result['assignments']:\n",
    "        print(f\"\\n✓ Mena #{assignment['mena_catalog_no']} → Scott #{assignment['scott_number']}\")\n",
    "        print(f\"  Confidence: {assignment['confidence']} (Score: {assignment['score']}/100)\")\n",
    "        print(f\"  Signals: {assignment['signals']}\")\n",
    "        print(f\"  Breakdown: {assignment['breakdown']}\")\n",
    "        if assignment['boost_reasons']:\n",
    "            print(f\"  Boosts: {', '.join(assignment['boost_reasons'])}\")\n",
    "        if assignment['requires_review']:\n",
    "            print(f\"  ⚠️  REQUIRES MANUAL REVIEW\")\n",
    "    \n",
    "    if result['unmatched']['mena']:\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"UNMATCHED MENA STAMPS\")\n",
    "        print(\"-\"*80)\n",
    "        for u in result['unmatched']['mena']:\n",
    "            print(f\"  ✗ Mena #{u['catalog_no']}: {u['denomination']} {u['color']}\")\n",
    "            print(f\"    Reason: {u['reason']}\")\n",
    "    \n",
    "    if result['unmatched']['scott']:\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"UNMATCHED SCOTT STAMPS\")\n",
    "        print(\"-\"*80)\n",
    "        for u in result['unmatched']['scott']:\n",
    "            print(f\"  ✗ Scott #{u['catalog_no']}: {u['denomination']} {u['color']}\")\n",
    "            print(f\"    Reason: {u['reason']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    stats = result['statistics']\n",
    "    print(f\"Total Mena stamps: {stats['total_mena_stamps']}\")\n",
    "    print(f\"Matched: {stats['total_assignments']} ({stats['success_rate']}%)\")\n",
    "    print(f\"  High confidence: {stats['high_confidence']}\")\n",
    "    print(f\"  Medium confidence: {stats['medium_confidence']}\")\n",
    "    print(f\"  Low confidence: {stats['low_confidence']}\")\n",
    "    print(f\"Unmatched Mena: {stats['unmatched_mena']}\")\n",
    "    print(f\"Unmatched Scott: {stats['unmatched_scott']}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158653d5",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e936fd",
   "metadata": {},
   "source": [
    "#### Get Mena Test Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo unido\n",
    "PATH = Path(\"results/parsed_catalogues/mena_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    items = json.load(f)\n",
    "\n",
    "# Conteo\n",
    "print(f\"Total de items: {len(items)}\")\n",
    "\n",
    "# Iterar (imprime un resumen por cada elemento)\n",
    "mena_issue = items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mena_issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857eb6f",
   "metadata": {},
   "source": [
    "#### Get Scott Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta al archivo unido\n",
    "PATH = Path(\"results/parsed_catalogues/scott_parse_results_ALL.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    items = json.load(f)\n",
    "\n",
    "all_scott_stamps = items\n",
    "# Conteo\n",
    "print(f\"Total de items: {len(all_scott_stamps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1212fc7",
   "metadata": {},
   "source": [
    "#### Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6030a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run matching\n",
    "result = match_mena_to_scott(\n",
    "    mena_issue=mena_issue,\n",
    "    all_scott_stamps=all_scott_stamps,\n",
    "    year_tolerance=2,\n",
    "    min_score_threshold=30.0\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print_matching_results(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
