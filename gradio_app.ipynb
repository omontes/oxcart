{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philatelic Gradio App with Weaviate\n",
    "Interactive web interface for CR Philately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "Load all the modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import weaviate\n",
    "import gradio as gr\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.retrievers import MultiQueryRetriever, EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "from philatelic_weaviate import *\n",
    "\n",
    "from philatelic_chunk_schema import *\n",
    "\n",
    "print(\"✅ Basic imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8083')\n",
    "PHILATELIC_JSONS_DIR = os.getenv('PHILATELIC_JSONS_DIR', './results/final_jsons')\n",
    "COLLECTION_NAME = os.getenv('WEAVIATE_COLLECTION_NAME', 'Oxcart')\n",
    "\n",
    "print(f\"🔧 Configuration:\")\n",
    "print(f\"   • Weaviate URL: {WEAVIATE_URL}\")\n",
    "print(f\"   • JSONs Directory: {PHILATELIC_JSONS_DIR}\")\n",
    "print(f\"   • Collection Name: {COLLECTION_NAME}\")\n",
    "print(f\"   • OpenAI API Key: {'✅ Configured' if OPENAI_API_KEY else '❌ Missing configuration'}\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"\\\\n⚠️  IMPORTANT: Configure your OPENAI_API_KEY in the .env file\")\n",
    "    print(\"   Copy .env.example to .env and add your API key\")\n",
    "\n",
    "# Verify that the JSONs directory exists\n",
    "if not os.path.exists(PHILATELIC_JSONS_DIR):\n",
    "    print(f\"\\\\n⚠️  Directory {PHILATELIC_JSONS_DIR} not found\")\n",
    "    print(\"   Make sure you have processed documents with the Dolphin parser\")\n",
    "else:\n",
    "    json_files = glob.glob(os.path.join(PHILATELIC_JSONS_DIR, '*_final.json'))\n",
    "    print(f\"\\\\n📁 Found {len(json_files)} philatelic JSON files\")\n",
    "    if json_files:\n",
    "        print(\"   Examples:\")\n",
    "        for file in json_files[:3]:\n",
    "            print(f\"   • {os.path.basename(file)}\")\n",
    "        if len(json_files) > 3:\n",
    "            print(f\"   • ... and {len(json_files) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-5-nano\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=1,  # obligatorio para gpt-5-nano\n",
    "            timeout=120.0,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"medium\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            })\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# 📝 RAG PROMPT TEMPLATE - Professional Philatelic Consultation\n",
    "# ========================================================================================\n",
    "\n",
    "philatelic_rag_template = \"\"\"You are a senior philatelic researcher and catalog specialist with expertise in Costa Rican stamps and postal history. Provide comprehensive, well-structured analysis based strictly on the source materials provided.\n",
    "\n",
    "SOURCE MATERIALS:\n",
    "{context}\n",
    "\n",
    "RESEARCH QUERY: {question}\n",
    "\n",
    "RESPONSE REQUIREMENTS:\n",
    "\n",
    "FORMATTING & STRUCTURE:\n",
    "• Use clear hierarchical organization with descriptive headers using markdown\n",
    "• Group related information under logical categories using ## and **bold subheadings**\n",
    "• Use bullet points (•) for individual facts and varieties\n",
    "• Include relevant emojis for major sections (🔍 📮 📚 🎯) to enhance readability\n",
    "• Bold key terms, catalog numbers, and important details\n",
    "• KEEP SECTIONS CONCISE - avoid excessive repetition or overly detailed explanations\n",
    "• Your output is in markdown format\n",
    "\n",
    "CITATION FORMAT:\n",
    "• Every factual statement must include the name of the document (doc_id) and its page numeber like this example: (CRF 100, page 15)\n",
    "• Multiple sources: (doc_id, page #; doc_id, page #) Example: (OXCART 123, page 24 ; OXCART 25, page 15)\n",
    "• Always cite catalog numbers (scott, yvert, michell, etc), varieties, dates, quantities, and technical specifications\n",
    "• When quoting directly, use quotation marks around quoted text\n",
    "\n",
    "CONTENT ORGANIZATION:\n",
    "• Lead with the most direct answer to the query\n",
    "• Organize by catalog numbers, chronological order, or logical categories as appropriate\n",
    "• Include technical specifications: dates, quantities, colors, perforations, varieties\n",
    "• Provide brief historical context and collecting significance\n",
    "• Note relationships between issues, varieties, or catalog entries\n",
    "• Address valuation or rarity when relevant to the query\n",
    "\n",
    "RESPONSE LENGTH:\n",
    "• Aim for clear, informative responses that are thorough but not excessive\n",
    "• Eliminate redundant information and repetitive explanations\n",
    "• Focus on the most relevant information that directly answers the query\n",
    "• If information is extensive, prioritize the most important catalog entries and varieties\n",
    "\n",
    "TECHNICAL STANDARDS:\n",
    "• Use precise philatelic terminology (definitive, commemorative, variety, error, overprint, etc.)\n",
    "• Specify exact catalog numbers with proper formatting (Scott C216, not just C216)\n",
    "• Include denomination and color details when available\n",
    "• Note printing quantities, dates, and technical varieties\n",
    "• Distinguish between verified catalog facts and expert opinions\n",
    "• Flag incomplete or uncertain information clearly\n",
    "\n",
    "RESEARCH COMPLETENESS:\n",
    "• If source materials are insufficient, state: \"The provided documents do not contain sufficient information about...\"\n",
    "• Suggest what additional sources or information would be needed\n",
    "• Note any gaps in catalog coverage or missing details\n",
    "\n",
    "PROFESSIONAL TONE:\n",
    "• Maintain authoritative but accessible language\n",
    "• Present information objectively without unnecessary qualifiers\n",
    "• Use active voice and clear, direct statements\n",
    "• Avoid speculation beyond what sources support\n",
    "\n",
    "RESPONSE:\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=philatelic_rag_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# 📄 OPTIMIZED DOCUMENT FORMATTING - For Academic Citation Style\n",
    "# ========================================================================================\n",
    "\n",
    "def format_docs_for_rag(docs_results: List[Dict]) -> str:\n",
    "    \"\"\"Efficient document formatting optimized for academic citation style (Document Name, p. Page)\"\"\"\n",
    "    \n",
    "    if not docs_results:\n",
    "        return \"\\nNo source documents available.\"\n",
    "    \n",
    "    # Group and sort documents by authority\n",
    "    #doc_groups = {'catalog': [], 'literature': [], 'collection': [], 'reference': []}\n",
    "    docs = []\n",
    "    \n",
    "    for i, doc in enumerate(docs_results, 1):\n",
    "        #category, reliability = classify_document_authority(doc.metadata.get('doc_id', 'Unknown'))\n",
    "        \n",
    "        doc_info = {\n",
    "            'doc_num': i,\n",
    "            'doc_id': doc.metadata.get('doc_id', 'Unknown'),\n",
    "            'page': doc.metadata.get('page_number', 'N/A'),\n",
    "            'content': doc.page_content,\n",
    "        }\n",
    "        #doc_groups[category].append(doc_info)\n",
    "        docs.append(doc_info)\n",
    "    return docs\n",
    "\n",
    "def create_rag_response(retriever_results: List[Dict], query: str) -> Dict:\n",
    "    \"\"\"Streamlined RAG chain execution with academic citation style\"\"\"\n",
    "    \n",
    "    if not retriever_results:\n",
    "        return {\"response\": \"No documents found for this query.\", \"generation_time\": 0}\n",
    "    \n",
    "    # Format context efficiently for academic citations\n",
    "    context = format_docs_for_rag(retriever_results)\n",
    "    \n",
    "    #limited_llm = llm.bind(max_tokens=4000)  # Limita la respuesta a 4000 tokens\n",
    "\n",
    "    \n",
    "    # Execute RAG chain\n",
    "    rag_chain = (\n",
    "        {\"context\": lambda x: context, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = rag_chain.invoke(query)\n",
    "    generation_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"generation_time\": generation_time,\n",
    "        \"context_docs_count\": len(retriever_results),\n",
    "        \"context_length\": len(context),\n",
    "       # \"max_tokens\": 4000  # Agregar para tracking\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weaviate Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Weaviate\n",
    "print(\"🔌 Connecting to Weaviate...\")\n",
    "\n",
    "try:\n",
    "    client = create_weaviate_client(WEAVIATE_URL, OPENAI_API_KEY)\n",
    "    print(\"✅ Connection successful\")\n",
    "    \n",
    "    # Verify that Weaviate is working\n",
    "    meta = client.get_meta()\n",
    "    print(f\"📊 Weaviate version: {meta.get('version', 'unknown')}\")\n",
    "    \n",
    "    # Verify if collection exists\n",
    "    try:\n",
    "        collections = client.collections.list_all()\n",
    "        collection_names = [col.name for col in collections]\n",
    "        \n",
    "        if COLLECTION_NAME in collection_names:\n",
    "            collection = client.collections.get(COLLECTION_NAME)\n",
    "            total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "            print(f\"📊 Collection '{COLLECTION_NAME}' exists with {total_objects} documents\")\n",
    "        else:\n",
    "            print(f\"📝 Collection '{COLLECTION_NAME}' does not exist (will be created during indexing)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not verify collections: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to Weaviate: {e}\")\n",
    "    print(\"💡 Make sure Weaviate is running:\")\n",
    "    print(\"   docker-compose up -d\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weaviate Search Tests\n",
    "\n",
    "Test the function search_chunks_semantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_chunks_semantic(\n",
    "                client, \n",
    "                \"Costa Rica 1907 2 colones stamp with original gum. Scott 68 issue of 1907\", \n",
    "                \"Oxcart\", \n",
    "                limit=50,\n",
    "                filters=[],\n",
    "                mode = \"hybrid\",\n",
    "                alpha= 0.35\n",
    "                \n",
    "            )\n",
    "            \n",
    "print(f\"   📊 Resultados: {len(results)}\")\n",
    "\n",
    "for j, result in enumerate(results, 1):\n",
    "    print(f\"\\n      🏷️ #{j} (Score: {result['score']:.3f})\")\n",
    "    print(f\"         📄 Documento: {result['doc_id']}\")\n",
    "    print(f\"         📋 Tipo: {result['chunk_type']}\")\n",
    "    print(f\"         📄 Página: {result['page_number']}\")\n",
    "    \n",
    "    # Mostrar metadatos relevantes\n",
    "    if result.get('catalog_systems'):\n",
    "        print(f\"         📖 Catálogos: {result['catalog_systems']}\")\n",
    "    if result.get('scott_numbers'):\n",
    "        print(f\"         🔢 Scott: {result['scott_numbers']}\")\n",
    "    if result.get('years'):\n",
    "        print(f\"         📅 Años: {result['years']}\")\n",
    "    if result.get('colors'):\n",
    "        print(f\"         🎨 Colores: {result['colors']}\")\n",
    "    if result.get('variety_classes'):\n",
    "        print(f\"         🔀 Variedades: {result['variety_classes']}\")\n",
    "    \n",
    "    # Texto truncado\n",
    "    text = result.get('text', '')\n",
    "    # if len(text) > 200:\n",
    "    #     text = text[:200] + \"...\"\n",
    "    print(f\"         📝 Texto: {text}\")\n",
    "    print(\"**********************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advance Retriever Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "def compress_documents_simple(documents: List[Document], query: str, llm) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Simple document compression using LangChain's native batch processing.\n",
    "    Each document is processed individually with the same prompt.\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return []\n",
    "    \n",
    "    # Simple compression prompt for individual documents\n",
    "    compress_prompt_template = \"\"\"You are a philatelic expert. Extract and compress ONLY the information relevant to this query from the document below.\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Extract only information directly relevant to the query\n",
    "- Preserve exact catalog numbers, dates, denominations, and technical specifications\n",
    "- Keep Scott numbers, Michel numbers, and other catalog references intact\n",
    "- Maintain variety descriptions and error information\n",
    "- Remove irrelevant content but preserve context for understanding\n",
    "\n",
    "If the document contains no relevant information, respond with exactly: NO_RELEVANT_CONTENT\n",
    "\n",
    "COMPRESSED CONTENT:\"\"\"\n",
    "\n",
    "    # Create individual prompts for each document\n",
    "    prompts = []\n",
    "    for doc in documents:\n",
    "        prompt_text = compress_prompt_template.format(\n",
    "            query=query, \n",
    "            document=doc.page_content\n",
    "        )\n",
    "        prompts.append([(\"user\", prompt_text)])\n",
    "    \n",
    "    # Use LangChain's native batch processing with concurrency control\n",
    "    config = RunnableConfig(max_concurrency=10)  # Process 10 documents concurrently\n",
    "    \n",
    "    try:\n",
    "        responses = llm.batch(prompts, config=config)\n",
    "        \n",
    "        # Filter and create compressed documents\n",
    "        compressed_docs = []\n",
    "        for i, response in enumerate(responses):\n",
    "            content = response.content.strip() if hasattr(response, 'content') else str(response).strip()\n",
    "            \n",
    "            # Only include documents that have relevant content\n",
    "            if content and content != \"NO_RELEVANT_CONTENT\":\n",
    "                compressed_doc = Document(\n",
    "                    page_content=content,\n",
    "                    metadata=documents[i].metadata\n",
    "                )\n",
    "                compressed_docs.append(compressed_doc)\n",
    "        \n",
    "        return compressed_docs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch compression: {e}\")\n",
    "        # Fallback: return original documents\n",
    "        return documents\n",
    "\n",
    "def search_stamps_with_compression(query, client, embeddings, llm, limit=100, \n",
    "                                 alpha=0.30, diversity_lambda=0.75):\n",
    "    \"\"\"\n",
    "    Optimized philatelic search with simple batch document compression using LangChain's native batch processing.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The stamp query\n",
    "        client: Weaviate client\n",
    "        embeddings: Embedding model\n",
    "        llm: Language model\n",
    "        limit (int): Maximum documents to retrieve\n",
    "        alpha (float): Hybrid search factor (0.30 = 30% vector, 70% keywords)\n",
    "        diversity_lambda (float): MMR diversity factor (0.75 = good diversity)\n",
    "    \n",
    "    Returns:\n",
    "        list: Compressed and optimized documents for philatelic queries\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=COLLECTION_NAME,\n",
    "        text_key=\"text\",\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Try to create hybrid retriever\n",
    "    hybrid_kwargs = {\"k\": limit // 2}\n",
    "    if alpha is not None:\n",
    "        hybrid_kwargs[\"alpha\"] = alpha\n",
    "    \n",
    "    # 1. Precision hybrid retriever (captures exact numbers + context)\n",
    "    precision_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs=hybrid_kwargs\n",
    "    )\n",
    "    \n",
    "    # 2. Diversity MMR retriever (avoids duplicate stamps)\n",
    "    diversity_retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": limit // 2, \"lambda_mult\": diversity_lambda}\n",
    "    )\n",
    "    \n",
    "    # 3. Ensemble with dual strategy\n",
    "    base_retriever = EnsembleRetriever(\n",
    "        retrievers=[precision_retriever, diversity_retriever],\n",
    "        weights=[0.7, 0.3]  # 70% precision + 30% diversity\n",
    "    )\n",
    "    \n",
    "    # Specialized prompt for philatelic multi-query generation\n",
    "    query_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"You are a specialized philatelic researcher expert in stamp catalogues and varieties.\n",
    "Generate 3 strategically different versions of the question to capture comprehensive stamp information:\n",
    "\n",
    "ORIGINAL: {question}\n",
    "\n",
    "Create variations that target:\n",
    "1. CATALOG PRECISION: Focus on exact catalog numbers, dates, and technical specifications\n",
    "2. CONTEXTUAL SEARCH: Include related series, printings, varieties, and historical context  \n",
    "3. TERMINOLOGY ALTERNATIVES: Use alternative philatelic terms and synonyms\n",
    "\n",
    "Consider these philatelic elements:\n",
    "- Catalog systems: Scott, Michel, Yvert, SG, local catalogs\n",
    "- Technical terms: definitive/commemorative, variety/error, overprint/surcharge\n",
    "- Time references: issue dates, printing dates, first day covers\n",
    "- Denominations: face values, colors, perforations\n",
    "\n",
    "Alternative searches:\n",
    "1.\n",
    "2. \n",
    "3.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # MultiQueryRetriever with specialized prompt\n",
    "    multi_retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=base_retriever,\n",
    "        llm=llm,\n",
    "        prompt=query_prompt,\n",
    "        parser_key=\"lines\"\n",
    "    )\n",
    "    \n",
    "    # Execute initial retrieval\n",
    "    initial_results = multi_retriever.invoke(query)\n",
    "       \n",
    "    compression_llm = ChatOpenAI(\n",
    "            model=\"gpt-5-nano\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=1,  # obligatorio para gpt-5-nano\n",
    "            timeout=120.0,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"medium\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            })\n",
    "    \n",
    "    # Simple batch compression using LangChain's native batch processing\n",
    "    compressed_results = compress_documents_simple(initial_results, query, compression_llm)\n",
    "    \n",
    "    # Reorder by quality_score if it exists\n",
    "    def get_quality_score(doc):\n",
    "        return getattr(doc, 'metadata', {}).get('quality_score', 0.0)\n",
    "    \n",
    "    sorted_results = sorted(compressed_results, key=get_quality_score, reverse=True)\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the method search_stamps_with_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the optimized search_stamps_with_compression with batch processing\n",
    "# print(\"🧪 Testing optimized batch compression...\")\n",
    "\n",
    "# # Test query focused on specific stamps\n",
    "# test_query = \"Costa Rica 1907 2 colones stamp with original gum Scott 68\"\n",
    "\n",
    "# print(f\"🔍 Query: {test_query}\")\n",
    "# print(\"⏱️ Starting optimized search with batch compression...\")\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# try:\n",
    "#     compressed_docs = search_stamps_with_compression(\n",
    "#         query=test_query,\n",
    "#         client=client, \n",
    "#         embeddings=embeddings, \n",
    "#         limit=30,\n",
    "#         llm=llm,\n",
    "#         alpha=0.30,  # 30% vectorial, 70% keywords for exact numbers\n",
    "#         diversity_lambda=0.75  # 75% relevance, 25% diversity\n",
    "#     )\n",
    "    \n",
    "#     end_time = time.time()\n",
    "#     execution_time = end_time - start_time\n",
    "    \n",
    "#     print(f\"✅ Batch compression completed in {execution_time:.2f} seconds\")\n",
    "#     print(f\"📊 Retrieved and compressed {len(compressed_docs)} documents\")\n",
    "    \n",
    "#     # Show sample results\n",
    "#     for i, doc in enumerate(compressed_docs[:3], 1):\n",
    "#         print(f\"\\\\n📄 Document {i}:\")\n",
    "#         print(f\"   Metadata: {getattr(doc, 'metadata', {})}\")\n",
    "#         content = getattr(doc, 'page_content', str(doc))\n",
    "#         preview = content[:200] + \"...\" if len(content) > 200 else content\n",
    "#         print(f\"   Content: {preview}\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Error during batch compression test: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_info() -> str:\n",
    "    \"\"\"\n",
    "    Get collection information to display in the interface.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return \"❌ No Weaviate connection\"\n",
    "    \n",
    "    try:\n",
    "        stats = get_collection_stats(client, \"Oxcart\")\n",
    "        if stats:\n",
    "            info = f\"📊 **Oxcart Collection Statistics:**\\\\n\\\\n\"\n",
    "            info += f\"📦 **Total chunks:** {stats['total_chunks']:,}\\\\n\"\n",
    "            info += f\"📄 **Documents:** {stats['total_documents']}\\\\n\\\\n\"\n",
    "            \n",
    "            if stats.get('documents'):\n",
    "                info += \"**Indexed documents:**\\\\n\"\n",
    "                for doc_id, count in stats['documents'].items():\n",
    "                    info += f\"• {doc_id}: {count:,} chunks\\\\n\"\n",
    "            \n",
    "            return info\n",
    "        else:\n",
    "            return \"❌ Could not retrieve statistics\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error: {e}\"\n",
    "\n",
    "print(\"✅ RAG functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_collection_stats(client, \"Oxcart\")\n",
    "stats['total_documents']\n",
    "stats['total_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura que usan tus funciones de búsqueda/respuesta\n",
    "rag_system = {\n",
    "    \"success\": True,\n",
    "    \"client\": client,                    # para que search_and_answer pueda consultar\n",
    "    \"collection_name\": COLLECTION_NAME,  # nombre de la colección\n",
    "    \"weaviate_url\": WEAVIATE_URL,        # info para la UI\n",
    "    \"total_documents\": stats['total_documents'],       # para mostrar estado\n",
    "    \"total_chunks\": stats['total_chunks'],        # opcional en la UI\n",
    "    \"embeddings\":embeddings,\n",
    "    \"llm\":llm,\n",
    "    # puedes añadir más campos que tu search_and_answer necesite\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def search_and_answer_basic(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    use_filters: bool = False,\n",
    "    catalog_system: str = \"\",\n",
    "    chunk_type: str = \"\",\n",
    "    has_varieties: bool = False,\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Basic hybrid search approach - ejecuta solo la búsqueda básica.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"❌ Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "\n",
    "    client_wv = rag_system[\"client\"]\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    \n",
    "    # Build filters\n",
    "    filters = None\n",
    "    if use_filters:\n",
    "        filters = {}\n",
    "        if catalog_system:\n",
    "            filters[\"catalog_system\"] = catalog_system\n",
    "        if chunk_type:\n",
    "            filters[\"chunk_type\"] = chunk_type\n",
    "        if has_varieties:\n",
    "            filters[\"has_varieties\"] = True\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Basic semantic search\n",
    "        results = search_chunks_semantic(\n",
    "            client=client_wv,\n",
    "            query=query,\n",
    "            collection_name=collection_name,\n",
    "            limit=int(max_results),\n",
    "            filters=filters,\n",
    "            mode=\"hybrid\",\n",
    "            alpha=0.35\n",
    "        )\n",
    "        \n",
    "        # Convert to LangChain document format for RAG\n",
    "        docs_for_rag = []\n",
    "        for r in results:\n",
    "            doc = type('Document', (), {\n",
    "                'page_content': r.get('text', ''),\n",
    "                'metadata': {\n",
    "                    'doc_id': r.get('doc_id', 'N/A'),\n",
    "                    'page_number': r.get('page_number', 'N/A'),\n",
    "                    'chunk_type': r.get('chunk_type', 'N/A'),\n",
    "                    'score': r.get('score', 0.0)\n",
    "                }\n",
    "            })()\n",
    "            docs_for_rag.append(doc)\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(docs_for_rag, query)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        metadata = {\n",
    "            \"approach\": \"Basic Hybrid Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"max_results\": int(max_results),\n",
    "            \"filters_used\": filters or {},\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response[\"context_docs_count\"]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response[\"response\"],\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"answer\": f\"❌ Basic search error: {e}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": str(e), \"generation_time\": 0}\n",
    "        }\n",
    "\n",
    "\n",
    "def search_and_answer_advanced(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    use_filters: bool = False,\n",
    "    catalog_system: str = \"\",\n",
    "    chunk_type: str = \"\",\n",
    "    has_varieties: bool = False,\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Advanced compression search approach - ejecuta solo la búsqueda avanzada.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"❌ Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "\n",
    "    client_wv = rag_system[\"client\"]\n",
    "    embeddings = rag_system.get(\"embeddings\")  # Asegúrate de que esto esté en rag_system\n",
    "    llm = rag_system.get(\"llm\")  # Asegúrate de que esto esté en rag_system\n",
    "    \n",
    "    # Build filters\n",
    "    filters = None\n",
    "    if use_filters:\n",
    "        filters = {}\n",
    "        if catalog_system:\n",
    "            filters[\"catalog_system\"] = catalog_system\n",
    "        if chunk_type:\n",
    "            filters[\"chunk_type\"] = chunk_type\n",
    "        if has_varieties:\n",
    "            filters[\"has_varieties\"] = True\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Advanced search with compression\n",
    "        compressed_docs = search_stamps_with_compression(\n",
    "            query=query,\n",
    "            client=client_wv,\n",
    "            embeddings=embeddings,\n",
    "            llm=llm,\n",
    "            limit=50,\n",
    "            alpha=0.30,\n",
    "            diversity_lambda=0.75\n",
    "        )\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(compressed_docs, query)\n",
    "        \n",
    "        # Convert compressed docs to results format for display\n",
    "        results = []\n",
    "        for i, doc in enumerate(compressed_docs):\n",
    "            result = {\n",
    "                'doc_id': doc.metadata.get('doc_id', 'N/A'),\n",
    "                'page_number': doc.metadata.get('page_number', 'N/A'),\n",
    "                'chunk_type': doc.metadata.get('chunk_type', 'N/A'),\n",
    "                'text': doc.page_content,\n",
    "                'score': doc.metadata.get('quality_score', 0.0),\n",
    "                'catalog_systems': doc.metadata.get('catalog_systems', []),\n",
    "                'scott_numbers': doc.metadata.get('scott_numbers', []),\n",
    "                'years': doc.metadata.get('years', []),\n",
    "                'colors': doc.metadata.get('colors', []),\n",
    "                'variety_classes': doc.metadata.get('variety_classes', [])\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        metadata = {\n",
    "            \"approach\": \"Advanced Compression Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"compressed_docs\": len(compressed_docs),\n",
    "            \"filters_used\": filters or {},\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response[\"context_docs_count\"]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response[\"response\"],\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"answer\": f\"❌ Advanced search error: {e}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": str(e), \"generation_time\": 0}\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def create_gradio_interface(rag_system: Dict[str, Any]) -> gr.Blocks:\n",
    "#     \"\"\"\n",
    "#     Creates the Gradio interface for dual RAG queries with sequential execution.\n",
    "#     Basic approach runs first and displays results, then Advanced approach runs.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def gradio_sequential_search(query, use_filters, catalog_system, chunk_type, has_varieties, max_results):\n",
    "#         \"\"\"\n",
    "#         Sequential search: executes Basic first, yields results, then executes Advanced.\n",
    "#         Uses yield to provide progressive updates to the UI.\n",
    "#         \"\"\"\n",
    "#         if not rag_system:\n",
    "#             error_msg = \"❌ RAG system not configured\"\n",
    "#             yield error_msg, \"\", \"\", \"⏳ Waiting...\", \"\", \"\", \"No timing data available\"\n",
    "#             return\n",
    "            \n",
    "#         if not query or not query.strip():\n",
    "#             error_msg = \"❌ Please enter a query\"\n",
    "#             yield error_msg, \"\", \"\", \"⏳ Waiting...\", \"\", \"\", \"No timing data available\"\n",
    "#             return\n",
    "\n",
    "#         try:\n",
    "#             start_total_time = time.time()\n",
    "            \n",
    "#             # ============= STEP 1: Execute Basic Search =============\n",
    "#             yield \"🔄 Running Basic Hybrid Search...\", \"\", \"\", \"⏳ Waiting for Basic search to complete...\", \"\", \"\", \"⏱️ Basic search in progress...\"\n",
    "            \n",
    "#             # Call basic search function\n",
    "#             basic_results_data = search_and_answer_basic(\n",
    "#                 query=query,\n",
    "#                 rag_system=rag_system,\n",
    "#                 use_filters=use_filters,\n",
    "#                 catalog_system=catalog_system,\n",
    "#                 chunk_type=chunk_type,\n",
    "#                 has_varieties=has_varieties,\n",
    "#                 max_results=int(max_results),\n",
    "#             )\n",
    "            \n",
    "#             # Format Basic Results\n",
    "#             basic_answer = basic_results_data[\"answer\"]\n",
    "#             basic_results = basic_results_data[\"results\"]\n",
    "#             basic_metadata = basic_results_data[\"metadata\"]\n",
    "#             basic_execution_time = basic_metadata.get(\"generation_time\", 0)\n",
    "            \n",
    "#             basic_search_output = format_search_results(basic_results, \"Basic Hybrid Search\")\n",
    "#             basic_metadata_output = format_metadata(basic_metadata, basic_execution_time)\n",
    "            \n",
    "#             # Yield Basic results with Advanced pending\n",
    "#             timing_partial = f\"\"\"**⏱️ EXECUTION TIMING (Partial)**\n",
    "\n",
    "# 🔍 **Basic Hybrid Search** ✅\n",
    "# • Processing Time: {basic_execution_time:.2f} seconds\n",
    "# • Documents Found: {len(basic_results)}\n",
    "# • Status: COMPLETED\n",
    "\n",
    "# 🚀 **Advanced Compression Search** ⏳\n",
    "# • Status: STARTING...\n",
    "\n",
    "# 📊 **Progress**\n",
    "# • Basic search completed successfully\n",
    "# • Advanced search initiating...\"\"\"\n",
    "            \n",
    "#             yield (\n",
    "#                 basic_answer,\n",
    "#                 basic_search_output,\n",
    "#                 basic_metadata_output,\n",
    "#                 \"🔄 Starting Advanced Compression Search...\",\n",
    "#                 \"\",\n",
    "#                 \"\",\n",
    "#                 timing_partial\n",
    "#             )\n",
    "            \n",
    "#             # ============= STEP 2: Execute Advanced Search =============\n",
    "#             advanced_results_data = search_and_answer_advanced(\n",
    "#                 query=query,\n",
    "#                 rag_system=rag_system,\n",
    "#                 use_filters=use_filters,\n",
    "#                 catalog_system=catalog_system,\n",
    "#                 chunk_type=chunk_type,\n",
    "#                 has_varieties=has_varieties,\n",
    "#                 max_results=int(max_results),\n",
    "#             )\n",
    "            \n",
    "#             # Format Advanced Results\n",
    "#             advanced_answer = advanced_results_data[\"answer\"]\n",
    "#             advanced_results = advanced_results_data[\"results\"]\n",
    "#             advanced_metadata = advanced_results_data[\"metadata\"]\n",
    "#             advanced_execution_time = advanced_metadata.get(\"generation_time\", 0)\n",
    "            \n",
    "#             advanced_search_output = format_search_results(advanced_results, \"Advanced Compression Search\")\n",
    "#             advanced_metadata_output = format_metadata(advanced_metadata, advanced_execution_time)\n",
    "            \n",
    "#             # Calculate total execution time\n",
    "#             total_execution_time = time.time() - start_total_time\n",
    "            \n",
    "#             # Final timing information\n",
    "#             timing_final = format_timing_display(\n",
    "#                 basic_execution_time,\n",
    "#                 advanced_execution_time,\n",
    "#                 total_execution_time,\n",
    "#                 len(basic_results),\n",
    "#                 len(advanced_results)\n",
    "#             )\n",
    "            \n",
    "#             # Yield final complete results\n",
    "#             yield (\n",
    "#                 basic_answer,\n",
    "#                 basic_search_output,\n",
    "#                 basic_metadata_output,\n",
    "#                 advanced_answer,\n",
    "#                 advanced_search_output,\n",
    "#                 advanced_metadata_output,\n",
    "#                 timing_final\n",
    "#             )\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             error_msg = f\"❌ Error during search: {str(e)}\"\n",
    "#             yield error_msg, \"\", \"\", error_msg, \"\", \"\", f\"❌ Error occurred - no timing data\"\n",
    "\n",
    "#     def format_search_results(results, approach_name):\n",
    "#         \"\"\"Format search results for display\"\"\"\n",
    "#         if not results:\n",
    "#             return f\"No results found with {approach_name}\"\n",
    "\n",
    "#         lines = []\n",
    "#         lines.append(f\"**{approach_name} Results ({len(results)} documents found)**\\n\")\n",
    "        \n",
    "#         for i, r in enumerate(results):\n",
    "#             doc_id = r.get(\"doc_id\", \"N/A\")\n",
    "#             chunk_type_val = r.get(\"chunk_type\", \"N/A\")\n",
    "#             page_number = r.get(\"page_number\", \"N/A\")\n",
    "#             score = r.get(\"score\", 0.0)\n",
    "#             catalogs = r.get(\"catalog_systems\", [])\n",
    "#             scotts = r.get(\"scott_numbers\", [])\n",
    "#             years = r.get(\"years\", [])\n",
    "\n",
    "#             # Preview text\n",
    "#             text = r.get(\"text\", \"\")\n",
    "#             preview = (text[:300] + \"...\") if len(text) > 300 else text\n",
    "\n",
    "#             block = []\n",
    "#             block.append(f\"**Result {i+1}** (Score: {score:.3f})\")\n",
    "#             block.append(f\"• Document: {doc_id}\")\n",
    "#             block.append(f\"• Type: {chunk_type_val} | Page: {page_number}\")\n",
    "#             if catalogs:\n",
    "#                 block.append(f\"• Catalogs: {', '.join(catalogs)}\")\n",
    "#             if scotts:\n",
    "#                 block.append(f\"• Scott Numbers: {', '.join(scotts)}\")\n",
    "#             if years:\n",
    "#                 block.append(f\"• Years: {', '.join(str(y) for y in years)}\")\n",
    "#             block.append(f\"• Preview: {preview}\")\n",
    "#             block.append(\"-\" * 60)\n",
    "#             lines.append(\"\\n\".join(block))\n",
    "        \n",
    "#         return \"\\n\".join(lines)\n",
    "\n",
    "#     def format_metadata(metadata, execution_time):\n",
    "#         \"\"\"Format metadata for display\"\"\"\n",
    "#         if not metadata:\n",
    "#             return \"No metadata available\"\n",
    "        \n",
    "#         output_lines = [\n",
    "#             \"**Search Metadata:**\",\n",
    "#             f\"• Approach: {metadata.get('approach', 'Unknown')}\",\n",
    "#             f\"• Query: {metadata.get('query', 'N/A')}\",\n",
    "#             f\"• Results found: {metadata.get('total_results', 0)}\",\n",
    "#             f\"• Generation time: {metadata.get('generation_time', 'N/A')} seconds\",\n",
    "#             f\"• Context documents: {metadata.get('context_docs_count', 'N/A')}\",\n",
    "#             f\"• Total execution time: {execution_time} seconds\",\n",
    "#         ]\n",
    "        \n",
    "#         if metadata.get('filters_used'):\n",
    "#             output_lines.append(f\"• Filters used: {metadata['filters_used']}\")\n",
    "        \n",
    "#         if metadata.get('compressed_docs'):\n",
    "#             output_lines.append(f\"• Compressed documents: {metadata['compressed_docs']}\")\n",
    "            \n",
    "#         if metadata.get('error'):\n",
    "#             output_lines.append(f\"• Error: {metadata['error']}\")\n",
    "        \n",
    "#         return \"\\n\".join(output_lines)\n",
    "\n",
    "#     def format_timing_display(basic_time, advanced_time, total_time, basic_results, advanced_results):\n",
    "#         \"\"\"Format timing information for prominent display\"\"\"\n",
    "#         try:\n",
    "#             basic_time = float(basic_time) if basic_time else 0\n",
    "#             advanced_time = float(advanced_time) if advanced_time else 0\n",
    "#             total_time = float(total_time) if total_time else 0\n",
    "            \n",
    "#             # Determine which approach was faster\n",
    "#             if basic_time > 0 and advanced_time > 0:\n",
    "#                 if basic_time < advanced_time:\n",
    "#                     faster = f\"🏆 Basic search was {advanced_time/basic_time:.1f}x faster\"\n",
    "#                 elif advanced_time < basic_time:\n",
    "#                     faster = f\"🏆 Advanced search was {basic_time/advanced_time:.1f}x faster\"\n",
    "#                 else:\n",
    "#                     faster = \"⚡ Both approaches took similar time\"\n",
    "#             else:\n",
    "#                 faster = \"⏱️ Timing comparison not available\"\n",
    "            \n",
    "#             # Calculate speeds safely\n",
    "#             basic_speed = f\"{basic_results/basic_time:.1f}\" if basic_time > 0 else \"N/A\"\n",
    "#             advanced_speed = f\"{advanced_results/advanced_time:.1f}\" if advanced_time > 0 else \"N/A\"\n",
    "            \n",
    "#             timing_display = f\"\"\"**⏱️ EXECUTION TIMING COMPARISON**\n",
    "\n",
    "# 🔍 **Basic Hybrid Search**\n",
    "# • Processing Time: {basic_time:.2f} seconds\n",
    "# • Documents Found: {basic_results}\n",
    "# • Speed: {basic_speed} docs/sec\n",
    "\n",
    "# 🚀 **Advanced Compression Search**  \n",
    "# • Processing Time: {advanced_time:.2f} seconds\n",
    "# • Documents Found: {advanced_results}\n",
    "# • Speed: {advanced_speed} docs/sec\n",
    "\n",
    "# 📊 **Overall Performance**\n",
    "# • Total Execution: {total_time:.2f} seconds\n",
    "# • Sequential Execution (Basic → Advanced)\n",
    "# • {faster}\n",
    "\n",
    "# 💡 **Performance Notes:**\n",
    "# • Basic search completed first for quick results\n",
    "# • Advanced search provides enhanced quality\n",
    "# • Sequential execution allows progressive viewing\"\"\"\n",
    "\n",
    "#             return timing_display\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             return f\"❌ Error formatting timing data: {e}\"\n",
    "\n",
    "#     # Set example query functions\n",
    "#     def set_example_1():\n",
    "#         return \"What Costa Rica stamps from 1907 have Scott catalog number 68?\"\n",
    "    \n",
    "#     def set_example_2():\n",
    "#         return \"Show me Costa Rica overprinted stamps with varieties or errors\"\n",
    "    \n",
    "#     def set_example_3():\n",
    "#         return \"Costa Rica airmail stamps from the 1930s with catalog values\"\n",
    "    \n",
    "#     def set_example_4():\n",
    "#         return \"What Costa Rica definitive stamps feature the coat of arms?\"\n",
    "    \n",
    "#     def set_example_5():\n",
    "#         return \"Costa Rica stamps with perforation errors or printing varieties\"\n",
    "    \n",
    "#     def set_example_6():\n",
    "#         return \"Show me Costa Rica commemorative stamps issued between 1940-1950\"\n",
    "\n",
    "#     # System information\n",
    "#     collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "#     total_docs = rag_system.get(\"total_documents\", 0)\n",
    "#     total_chunks = rag_system.get(\"total_chunks\", 0)\n",
    "#     weaviate_url = rag_system.get(\"weaviate_url\") or os.getenv(\"WEAVIATE_URL\", \"http://localhost:8080\")\n",
    "\n",
    "#     # --- UI with default theme ---\n",
    "#     with gr.Blocks(title=\"OXCART RAG - Costa Rica Philatelic System\") as interface:\n",
    "#         gr.Markdown(\n",
    "#             \"# 🇨🇷 OXCART RAG - Costa Rica Philatelic System\\n\\n\"\n",
    "#             \"Advanced search for Costa Rican stamps and postal history with sequential dual AI approaches.\"\n",
    "#         )\n",
    "\n",
    "#         with gr.Row():\n",
    "#             with gr.Column(scale=3):\n",
    "#                 # Main input\n",
    "#                 query_input = gr.Textbox(\n",
    "#                     label=\"Your Costa Rica philatelic query\",\n",
    "#                     placeholder=\"e.g., What Costa Rica stamps from 1907 have Scott number 68?\",\n",
    "#                     lines=2,\n",
    "#                 )\n",
    "\n",
    "#                 # Search button\n",
    "#                 search_btn = gr.Button(\"🔍 Search with Both Approaches (Sequential)\", variant=\"primary\")\n",
    "\n",
    "#                 # Example queries with individual functions\n",
    "#                 gr.Markdown(\"**Example Queries:**\")\n",
    "                \n",
    "#                 with gr.Row():\n",
    "#                     btn1 = gr.Button(\"📮 1907 Scott 68 stamps\", variant=\"secondary\")\n",
    "#                     btn2 = gr.Button(\"📮 Overprinted varieties\", variant=\"secondary\")\n",
    "#                     btn3 = gr.Button(\"📮 1930s airmail stamps\", variant=\"secondary\")\n",
    "                \n",
    "#                 with gr.Row():\n",
    "#                     btn4 = gr.Button(\"📮 Coat of arms definitives\", variant=\"secondary\")\n",
    "#                     btn5 = gr.Button(\"📮 Perforation errors\", variant=\"secondary\")\n",
    "#                     btn6 = gr.Button(\"📮 1940-1950 commemoratives\", variant=\"secondary\")\n",
    "\n",
    "#             with gr.Column(scale=1):\n",
    "#                 # Advanced filters\n",
    "#                 gr.Markdown(\"**Advanced Search Filters**\")\n",
    "\n",
    "#                 use_filters = gr.Checkbox(label=\"Enable specific filters\", value=False)\n",
    "\n",
    "#                 catalog_system = gr.Dropdown(\n",
    "#                     choices=[\"\", \"Scott\", \"Michel\", \"Yvert\", \"Stanley Gibbons\", \"Edifil\"],\n",
    "#                     label=\"Catalog system\",\n",
    "#                     value=\"\",\n",
    "#                 )\n",
    "\n",
    "#                 chunk_type = gr.Dropdown(\n",
    "#                     choices=[\"\", \"text\", \"table\", \"figure\", \"title\", \"header\"],\n",
    "#                     label=\"Content type\",\n",
    "#                     value=\"\",\n",
    "#                 )\n",
    "\n",
    "#                 has_varieties = gr.Checkbox(label=\"Only documents with varieties\", value=False)\n",
    "\n",
    "#                 max_results = gr.Slider(\n",
    "#                     minimum=5,\n",
    "#                     maximum=50,\n",
    "#                     value=15,\n",
    "#                     step=5,\n",
    "#                     label=\"Maximum results per approach\",\n",
    "#                 )\n",
    "\n",
    "#         # Prominent timing display section\n",
    "#         with gr.Row():\n",
    "#             with gr.Column():\n",
    "#                 timing_display = gr.Textbox(\n",
    "#                     label=\"⏱️ Performance Timing Comparison\",\n",
    "#                     lines=12,\n",
    "#                     interactive=False,\n",
    "#                     value=\"Run a search to see detailed timing comparison between approaches\"\n",
    "#                 )\n",
    "\n",
    "#         # Tabbed output interface\n",
    "#         with gr.Tabs():\n",
    "#             with gr.TabItem(\"🔍 Basic Hybrid Search\"):\n",
    "#                 gr.Markdown(\"**Combines vector similarity with keyword matching (35% vector + 65% keyword)**\")\n",
    "                \n",
    "#                 with gr.Row():\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## AI Response - Basic Approach\")\n",
    "#                         basic_answer_output = gr.Textbox(\n",
    "#                             label=\"Generated response\", \n",
    "#                             lines=10, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#                 with gr.Row():\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## Documents Found - Basic Search\")\n",
    "#                         basic_search_output = gr.Textbox(\n",
    "#                             label=\"Search results\", \n",
    "#                             lines=15, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## Metadata - Basic Search\")\n",
    "#                         basic_metadata_output = gr.Textbox(\n",
    "#                             label=\"Query information\", \n",
    "#                             lines=12, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#             with gr.TabItem(\"🚀 Advanced Compression Search\"):\n",
    "#                 gr.Markdown(\"**Multi-query ensemble retrieval with AI-powered document compression**\")\n",
    "                \n",
    "#                 with gr.Row():\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## AI Response - Advanced Approach\")\n",
    "#                         advanced_answer_output = gr.Textbox(\n",
    "#                             label=\"Generated response\", \n",
    "#                             lines=10, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#                 with gr.Row():\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## Documents Found - Advanced Search\")\n",
    "#                         advanced_search_output = gr.Textbox(\n",
    "#                             label=\"Search results with compression\", \n",
    "#                             lines=15, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#                     with gr.Column():\n",
    "#                         gr.Markdown(\"## Metadata - Advanced Search\")\n",
    "#                         advanced_metadata_output = gr.Textbox(\n",
    "#                             label=\"Query information\", \n",
    "#                             lines=12, \n",
    "#                             interactive=False\n",
    "#                         )\n",
    "\n",
    "#         # Wire up all events\n",
    "#         # Main search button with sequential execution\n",
    "#         search_btn.click(\n",
    "#             fn=gradio_sequential_search,\n",
    "#             inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "#             outputs=[\n",
    "#                 basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "#                 advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "#                 timing_display\n",
    "#             ],\n",
    "#         )\n",
    "\n",
    "#         # Enter key in search box\n",
    "#         query_input.submit(\n",
    "#             fn=gradio_sequential_search,\n",
    "#             inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "#             outputs=[\n",
    "#                 basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "#                 advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "#                 timing_display\n",
    "#             ],\n",
    "#         )\n",
    "\n",
    "#         # Example buttons\n",
    "#         btn1.click(fn=set_example_1, outputs=[query_input])\n",
    "#         btn2.click(fn=set_example_2, outputs=[query_input])\n",
    "#         btn3.click(fn=set_example_3, outputs=[query_input])\n",
    "#         btn4.click(fn=set_example_4, outputs=[query_input])\n",
    "#         btn5.click(fn=set_example_5, outputs=[query_input])\n",
    "#         btn6.click(fn=set_example_6, outputs=[query_input])\n",
    "\n",
    "#         # System information\n",
    "#         gr.Markdown(\n",
    "#             \"---\\n\"\n",
    "#             f\"**System Status:**\\n\"\n",
    "#             f\"• Collection: {collection_name}\\n\"\n",
    "#             f\"• Documents indexed: {total_docs:,}\\n\"\n",
    "#             f\"• Total chunks: {total_chunks:,}\\n\"\n",
    "#             f\"• Status: ✅ Operational\\n\\n\"\n",
    "#             f\"**Execution Mode:**\\n\"\n",
    "#             f\"• Sequential execution: Basic search completes first, then Advanced\\n\"\n",
    "#             f\"• Results display progressively as each search completes\\n\\n\"\n",
    "#             f\"**Search Approaches:**\\n\"\n",
    "#             f\"• **Basic Search**: Hybrid semantic search optimized for exact catalog numbers\\n\"\n",
    "#             f\"• **Advanced Search**: Multi-query ensemble with AI compression for complex queries\"\n",
    "#         )\n",
    "\n",
    "#     return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import markdown\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def create_gradio_interface(rag_system: Dict[str, Any]) -> gr.Blocks:\n",
    "    \"\"\"\n",
    "    Creates the Gradio interface with mixed components for better progressive updates.\n",
    "    Uses HTML for markdown content and Textbox for timing display.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Función para convertir Markdown a HTML\n",
    "    def markdown_to_html(text):\n",
    "        \"\"\"Convert markdown text to HTML\"\"\"\n",
    "        if not text:\n",
    "            return \"<p><em>No content</em></p>\"\n",
    "        return markdown.markdown(text, extensions=['tables', 'fenced_code', 'codehilite'])\n",
    "\n",
    "    def gradio_sequential_search(query, use_filters, catalog_system, chunk_type, has_varieties, max_results):\n",
    "        \"\"\"\n",
    "        Sequential search with proper component handling to avoid orange boxes.\n",
    "        \"\"\"\n",
    "        if not rag_system:\n",
    "            error_msg = \"❌ RAG system not configured\"\n",
    "            error_html = markdown_to_html(error_msg)\n",
    "            yield error_html, \"\", \"\", error_html, \"\", \"\", \"No timing data available\"\n",
    "            return\n",
    "            \n",
    "        if not query or not query.strip():\n",
    "            error_msg = \"❌ Please enter a query\"\n",
    "            error_html = markdown_to_html(error_msg)\n",
    "            yield error_html, \"\", \"\", error_html, \"\", \"\", \"No timing data available\"\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            start_total_time = time.time()\n",
    "            \n",
    "            # ============= STEP 1: Execute Basic Search =============\n",
    "            # Mensajes de estado inicial\n",
    "            loading_basic = markdown_to_html(\"*🔄 Running Basic Hybrid Search...*\")\n",
    "            loading_advanced = markdown_to_html(\"*⏳ Waiting for Basic search to complete...*\")\n",
    "            \n",
    "            yield (\n",
    "                loading_basic, \n",
    "                \"\", \n",
    "                \"\", \n",
    "                loading_advanced, \n",
    "                \"\", \n",
    "                \"\", \n",
    "                \"⏱️ Basic search in progress...\"\n",
    "            )\n",
    "            \n",
    "            # Call basic search function\n",
    "            basic_results_data = search_and_answer_basic(\n",
    "                query=query,\n",
    "                rag_system=rag_system,\n",
    "                use_filters=use_filters,\n",
    "                catalog_system=catalog_system,\n",
    "                chunk_type=chunk_type,\n",
    "                has_varieties=has_varieties,\n",
    "                max_results=int(max_results),\n",
    "            )\n",
    "            \n",
    "            # Format Basic Results\n",
    "            basic_answer = basic_results_data[\"answer\"]  # Ya viene en Markdown\n",
    "            basic_answer_html = markdown_to_html(basic_answer)\n",
    "            \n",
    "            basic_results = basic_results_data[\"results\"]\n",
    "            basic_metadata = basic_results_data[\"metadata\"]\n",
    "            basic_execution_time = basic_metadata.get(\"generation_time\", 0)\n",
    "            \n",
    "            basic_search_output = format_search_results(basic_results, \"Basic Hybrid Search\")\n",
    "            basic_search_html = markdown_to_html(basic_search_output)\n",
    "            \n",
    "            basic_metadata_output = format_metadata(basic_metadata, basic_execution_time)\n",
    "            basic_metadata_html = markdown_to_html(basic_metadata_output)\n",
    "            \n",
    "            # Timing parcial\n",
    "            timing_partial = f\"\"\"⏱️ EXECUTION TIMING (Partial)\n",
    "            \n",
    "Basic Hybrid Search: ✅ COMPLETED\n",
    "• Time: {basic_execution_time:.2f}s\n",
    "• Results: {len(basic_results)}\n",
    "\n",
    "Advanced Search: ⏳ STARTING...\n",
    "\"\"\"\n",
    "            \n",
    "            loading_advanced_2 = markdown_to_html(\"*🔄 Starting Advanced Compression Search...*\")\n",
    "            \n",
    "            yield (\n",
    "                basic_answer_html,\n",
    "                basic_search_html,\n",
    "                basic_metadata_html,\n",
    "                loading_advanced_2,\n",
    "                \"\",\n",
    "                \"\",\n",
    "                timing_partial\n",
    "            )\n",
    "            \n",
    "            # ============= STEP 2: Execute Advanced Search =============\n",
    "            advanced_results_data = search_and_answer_advanced(\n",
    "                query=query,\n",
    "                rag_system=rag_system,\n",
    "                use_filters=use_filters,\n",
    "                catalog_system=catalog_system,\n",
    "                chunk_type=chunk_type,\n",
    "                has_varieties=has_varieties,\n",
    "                max_results=int(max_results),\n",
    "            )\n",
    "            \n",
    "            # Format Advanced Results\n",
    "            advanced_answer = advanced_results_data[\"answer\"]  # Ya viene en Markdown\n",
    "            advanced_answer_html = markdown_to_html(advanced_answer)\n",
    "            \n",
    "            advanced_results = advanced_results_data[\"results\"]\n",
    "            advanced_metadata = advanced_results_data[\"metadata\"]\n",
    "            advanced_execution_time = advanced_metadata.get(\"generation_time\", 0)\n",
    "            \n",
    "            advanced_search_output = format_search_results(advanced_results, \"Advanced Compression Search\")\n",
    "            advanced_search_html = markdown_to_html(advanced_search_output)\n",
    "            \n",
    "            advanced_metadata_output = format_metadata(advanced_metadata, advanced_execution_time)\n",
    "            advanced_metadata_html = markdown_to_html(advanced_metadata_output)\n",
    "            \n",
    "            # Calculate total execution time\n",
    "            total_execution_time = time.time() - start_total_time\n",
    "            \n",
    "            # Final timing information\n",
    "            timing_final = format_timing_display(\n",
    "                basic_execution_time,\n",
    "                advanced_execution_time,\n",
    "                total_execution_time,\n",
    "                len(basic_results),\n",
    "                len(advanced_results)\n",
    "            )\n",
    "            \n",
    "            # Yield final complete results\n",
    "            yield (\n",
    "                basic_answer_html,\n",
    "                basic_search_html,\n",
    "                basic_metadata_html,\n",
    "                advanced_answer_html,\n",
    "                advanced_search_html,\n",
    "                advanced_metadata_html,\n",
    "                timing_final\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"❌ Error during search: {str(e)}\"\n",
    "            error_html = markdown_to_html(error_msg)\n",
    "            yield error_html, \"\", \"\", error_html, \"\", \"\", f\"❌ Error occurred - no timing data\"\n",
    "\n",
    "    def format_search_results(results, approach_name):\n",
    "        \"\"\"Format search results for display in Markdown\"\"\"\n",
    "        if not results:\n",
    "            return f\"*No results found with {approach_name}*\"\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"### {approach_name} Results\")\n",
    "        lines.append(f\"**Found {len(results)} documents**\\n\")\n",
    "        lines.append(\"---\")\n",
    "        \n",
    "        for i, r in enumerate(results):\n",
    "            doc_id = r.get(\"doc_id\", \"N/A\")\n",
    "            chunk_type_val = r.get(\"chunk_type\", \"N/A\")\n",
    "            page_number = r.get(\"page_number\", \"N/A\")\n",
    "            score = r.get(\"score\", 0.0)\n",
    "            catalogs = r.get(\"catalog_systems\", [])\n",
    "            scotts = r.get(\"scott_numbers\", [])\n",
    "            years = r.get(\"years\", [])\n",
    "\n",
    "            # Preview text\n",
    "            text = r.get(\"text\", \"\")\n",
    "            preview = (text[:300] + \"...\") if len(text) > 300 else text\n",
    "\n",
    "            lines.append(f\"\\n#### 📄 Result {i+1}\")\n",
    "            lines.append(f\"**Score:** `{score:.3f}`\\n\")\n",
    "            \n",
    "            # Create a table for metadata\n",
    "            lines.append(\"| Field | Value |\")\n",
    "            lines.append(\"|-------|-------|\")\n",
    "            lines.append(f\"| Document | `{doc_id}` |\")\n",
    "            lines.append(f\"| Type | {chunk_type_val} |\")\n",
    "            lines.append(f\"| Page | {page_number} |\")\n",
    "            \n",
    "            if catalogs:\n",
    "                lines.append(f\"| Catalogs | {', '.join(catalogs)} |\")\n",
    "            if scotts:\n",
    "                lines.append(f\"| Scott Numbers | **{', '.join(scotts)}** |\")\n",
    "            if years:\n",
    "                lines.append(f\"| Years | {', '.join(str(y) for y in years)} |\")\n",
    "            \n",
    "            lines.append(f\"\\n**Preview:**\")\n",
    "            lines.append(f\"> {preview}\")\n",
    "            lines.append(\"\\n---\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def format_metadata(metadata, execution_time):\n",
    "        \"\"\"Format metadata for display in Markdown\"\"\"\n",
    "        if not metadata:\n",
    "            return \"*No metadata available*\"\n",
    "        \n",
    "        output_lines = []\n",
    "        output_lines.append(\"### Search Metadata\\n\")\n",
    "        \n",
    "        # Create a table for metadata\n",
    "        output_lines.append(\"| Property | Value |\")\n",
    "        output_lines.append(\"|----------|-------|\")\n",
    "        output_lines.append(f\"| **Approach** | {metadata.get('approach', 'Unknown')} |\")\n",
    "        output_lines.append(f\"| **Query** | `{metadata.get('query', 'N/A')}` |\")\n",
    "        output_lines.append(f\"| **Results found** | {metadata.get('total_results', 0)} |\")\n",
    "        output_lines.append(f\"| **Generation time** | {metadata.get('generation_time', 'N/A'):.2f} seconds |\")\n",
    "        output_lines.append(f\"| **Context docs** | {metadata.get('context_docs_count', 'N/A')} |\")\n",
    "        output_lines.append(f\"| **Total execution** | {execution_time:.2f} seconds |\")\n",
    "        \n",
    "        if metadata.get('filters_used'):\n",
    "            filters_str = str(metadata['filters_used']).replace('{', '').replace('}', '')\n",
    "            output_lines.append(f\"| **Filters** | `{filters_str}` |\")\n",
    "        \n",
    "        if metadata.get('compressed_docs'):\n",
    "            output_lines.append(f\"| **Compressed docs** | {metadata['compressed_docs']} |\")\n",
    "            \n",
    "        if metadata.get('error'):\n",
    "            output_lines.append(f\"\\n⚠️ **Error:** `{metadata['error']}`\")\n",
    "        \n",
    "        return \"\\n\".join(output_lines)\n",
    "\n",
    "    def format_timing_display(basic_time, advanced_time, total_time, basic_results, advanced_results):\n",
    "        \"\"\"Format timing information for display in Textbox\"\"\"\n",
    "        try:\n",
    "            basic_time = float(basic_time) if basic_time else 0\n",
    "            advanced_time = float(advanced_time) if advanced_time else 0\n",
    "            total_time = float(total_time) if total_time else 0\n",
    "            \n",
    "            # Determine which approach was faster\n",
    "            if basic_time > 0 and advanced_time > 0:\n",
    "                if basic_time < advanced_time:\n",
    "                    faster = f\"🏆 Basic search was {advanced_time/basic_time:.1f}x faster\"\n",
    "                elif advanced_time < basic_time:\n",
    "                    faster = f\"🏆 Advanced search was {basic_time/advanced_time:.1f}x faster\"\n",
    "                else:\n",
    "                    faster = \"⚡ Both approaches took similar time\"\n",
    "            else:\n",
    "                faster = \"⏱️ Timing comparison not available\"\n",
    "            \n",
    "            # Calculate speeds safely\n",
    "            basic_speed = f\"{basic_results/basic_time:.1f}\" if basic_time > 0 else \"N/A\"\n",
    "            advanced_speed = f\"{advanced_results/advanced_time:.1f}\" if advanced_time > 0 else \"N/A\"\n",
    "            \n",
    "            timing_display = f\"\"\"⏱️ EXECUTION TIMING COMPARISON\n",
    "================================================\n",
    "\n",
    "🔍 BASIC HYBRID SEARCH\n",
    "• Processing Time: {basic_time:.2f} seconds\n",
    "• Documents Found: {basic_results}\n",
    "• Speed: {basic_speed} docs/sec\n",
    "• Status: ✅ Complete\n",
    "\n",
    "🚀 ADVANCED COMPRESSION SEARCH\n",
    "• Processing Time: {advanced_time:.2f} seconds\n",
    "• Documents Found: {advanced_results}\n",
    "• Speed: {advanced_speed} docs/sec\n",
    "• Status: ✅ Complete\n",
    "\n",
    "📊 OVERALL PERFORMANCE\n",
    "• Total Execution: {total_time:.2f} seconds\n",
    "• Execution Mode: Sequential (Basic → Advanced)\n",
    "• {faster}\n",
    "\n",
    "💡 PERFORMANCE NOTES:\n",
    "• Basic search completed first for quick results\n",
    "• Advanced search provides enhanced quality\n",
    "• Sequential execution allows progressive viewing\"\"\"\n",
    "\n",
    "            return timing_display\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"❌ Error formatting timing data: {e}\"\n",
    "\n",
    "    # Set example query functions\n",
    "    def set_example_1():\n",
    "        return \"What Costa Rica stamps from 1907 have Scott catalog number 68?\"\n",
    "    \n",
    "    def set_example_2():\n",
    "        return \"Show me Costa Rica overprinted stamps with varieties or errors\"\n",
    "    \n",
    "    def set_example_3():\n",
    "        return \"Costa Rica airmail stamps from the 1930s with catalog values\"\n",
    "    \n",
    "    def set_example_4():\n",
    "        return \"What Costa Rica definitive stamps feature the coat of arms?\"\n",
    "    \n",
    "    def set_example_5():\n",
    "        return \"Costa Rica stamps with perforation errors or printing varieties\"\n",
    "    \n",
    "    def set_example_6():\n",
    "        return \"Show me Costa Rica commemorative stamps issued between 1940-1950\"\n",
    "\n",
    "    # System information\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    total_docs = rag_system.get(\"total_documents\", 0)\n",
    "    total_chunks = rag_system.get(\"total_chunks\", 0)\n",
    "\n",
    "    # --- UI with mixed components ---\n",
    "    with gr.Blocks(\n",
    "        title=\"OXCART RAG - Costa Rica Philatelic System\",\n",
    "        css=\"\"\"\n",
    "        .markdown-text {\n",
    "            font-family: 'Inter', sans-serif;\n",
    "        }\n",
    "        table {\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 8px;\n",
    "            text-align: left;\n",
    "        }\n",
    "        \"\"\"\n",
    "    ) as interface:\n",
    "        gr.Markdown(\n",
    "            \"# 🇨🇷 OXCART RAG - Costa Rica Philatelic System\\n\\n\"\n",
    "            \"Advanced search for Costa Rican stamps and postal history with sequential dual AI approaches.\"\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"Your Costa Rica philatelic query\",\n",
    "                    placeholder=\"e.g., What Costa Rica stamps from 1907 have Scott number 68?\",\n",
    "                    lines=2,\n",
    "                )\n",
    "\n",
    "                search_btn = gr.Button(\"🔍 Search with Both Approaches (Sequential)\", variant=\"primary\")\n",
    "\n",
    "                gr.Markdown(\"**Example Queries:**\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    btn1 = gr.Button(\"📮 1907 Scott 68 stamps\", variant=\"secondary\")\n",
    "                    btn2 = gr.Button(\"📮 Overprinted varieties\", variant=\"secondary\")\n",
    "                    btn3 = gr.Button(\"📮 1930s airmail stamps\", variant=\"secondary\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    btn4 = gr.Button(\"📮 Coat of arms definitives\", variant=\"secondary\")\n",
    "                    btn5 = gr.Button(\"📮 Perforation errors\", variant=\"secondary\")\n",
    "                    btn6 = gr.Button(\"📮 1940-1950 commemoratives\", variant=\"secondary\")\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"**Advanced Search Filters**\")\n",
    "\n",
    "                use_filters = gr.Checkbox(label=\"Enable specific filters\", value=False)\n",
    "                catalog_system = gr.Dropdown(\n",
    "                    choices=[\"\", \"Scott\", \"Michel\", \"Yvert\", \"Stanley Gibbons\", \"Edifil\"],\n",
    "                    label=\"Catalog system\",\n",
    "                    value=\"\",\n",
    "                )\n",
    "                chunk_type = gr.Dropdown(\n",
    "                    choices=[\"\", \"text\", \"table\", \"figure\", \"title\", \"header\"],\n",
    "                    label=\"Content type\",\n",
    "                    value=\"\",\n",
    "                )\n",
    "                has_varieties = gr.Checkbox(label=\"Only documents with varieties\", value=False)\n",
    "                max_results = gr.Slider(\n",
    "                    minimum=5,\n",
    "                    maximum=50,\n",
    "                    value=15,\n",
    "                    step=5,\n",
    "                    label=\"Maximum results per approach\",\n",
    "                )\n",
    "\n",
    "        # Timing display as Textbox for better updates\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                timing_display = gr.Textbox(\n",
    "                    label=\"⏱️ Performance Timing Comparison\",\n",
    "                    lines=18,\n",
    "                    interactive=False,\n",
    "                    value=\"Run a search to see detailed timing comparison between approaches\",\n",
    "                    elem_id=\"timing-display\"\n",
    "                )\n",
    "\n",
    "        # Tabbed output with HTML components\n",
    "        with gr.Tabs():\n",
    "            with gr.TabItem(\"🔍 Basic Hybrid Search\"):\n",
    "                gr.Markdown(\"**Combines vector similarity with keyword matching (35% vector + 65% keyword)**\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## AI Response - Basic Approach\")\n",
    "                        basic_answer_output = gr.HTML(\n",
    "                            value=\"<p><em>Waiting for search...</em></p>\",\n",
    "                            elem_id=\"basic_answer\"\n",
    "                        )\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## Documents Found - Basic Search\")\n",
    "                        basic_search_output = gr.HTML(\n",
    "                            value=\"<p><em>No results yet</em></p>\",\n",
    "                            elem_id=\"basic_search\"\n",
    "                        )\n",
    "\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## Metadata - Basic Search\")\n",
    "                        basic_metadata_output = gr.HTML(\n",
    "                            value=\"<p><em>No metadata yet</em></p>\",\n",
    "                            elem_id=\"basic_metadata\"\n",
    "                        )\n",
    "\n",
    "            with gr.TabItem(\"🚀 Advanced Compression Search\"):\n",
    "                gr.Markdown(\"**Multi-query ensemble retrieval with AI-powered document compression**\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## AI Response - Advanced Approach\")\n",
    "                        advanced_answer_output = gr.HTML(\n",
    "                            value=\"<p><em>Waiting for search...</em></p>\",\n",
    "                            elem_id=\"advanced_answer\"\n",
    "                        )\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## Documents Found - Advanced Search\")\n",
    "                        advanced_search_output = gr.HTML(\n",
    "                            value=\"<p><em>No results yet</em></p>\",\n",
    "                            elem_id=\"advanced_search\"\n",
    "                        )\n",
    "\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"## Metadata - Advanced Search\")\n",
    "                        advanced_metadata_output = gr.HTML(\n",
    "                            value=\"<p><em>No metadata yet</em></p>\",\n",
    "                            elem_id=\"advanced_metadata\"\n",
    "                        )\n",
    "\n",
    "        # Wire up events\n",
    "        search_btn.click(\n",
    "            fn=gradio_sequential_search,\n",
    "            inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        query_input.submit(\n",
    "            fn=gradio_sequential_search,\n",
    "            inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Example buttons\n",
    "        btn1.click(fn=set_example_1, outputs=[query_input])\n",
    "        btn2.click(fn=set_example_2, outputs=[query_input])\n",
    "        btn3.click(fn=set_example_3, outputs=[query_input])\n",
    "        btn4.click(fn=set_example_4, outputs=[query_input])\n",
    "        btn5.click(fn=set_example_5, outputs=[query_input])\n",
    "        btn6.click(fn=set_example_6, outputs=[query_input])\n",
    "\n",
    "        # System information\n",
    "        gr.Markdown(\n",
    "            \"---\\n\"\n",
    "            f\"**System Status:**\\n\"\n",
    "            f\"• Collection: {collection_name}\\n\"\n",
    "            f\"• Documents indexed: {total_docs:,}\\n\"\n",
    "            f\"• Total chunks: {total_chunks:,}\\n\"\n",
    "            f\"• Status: ✅ Operational\\n\\n\"\n",
    "            f\"**Execution Mode:**\\n\"\n",
    "            f\"• Sequential execution: Basic search completes first, then Advanced\\n\"\n",
    "            f\"• Results display progressively as each search completes\\n\\n\"\n",
    "            f\"**Search Approaches:**\\n\"\n",
    "            f\"• **Basic Search**: Hybrid semantic search optimized for exact catalog numbers\\n\"\n",
    "            f\"• **Advanced Search**: Multi-query ensemble with AI compression for complex queries\"\n",
    "        )\n",
    "\n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Enhanced launcher ----\n",
    "if rag_system and rag_system.get(\"success\", False):\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"🚀 LAUNCHING COSTA RICA PHILATELIC RAG INTERFACE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gradio_app = create_gradio_interface(rag_system)\n",
    "\n",
    "    GRADIO_PORT = int(os.getenv(\"GRADIO_PORT\", 7860))\n",
    "    GRADIO_SHARE = os.getenv(\"GRADIO_SHARE\", \"false\").lower() == \"true\"\n",
    "\n",
    "    print(f\"⚙️ Port: {GRADIO_PORT}\")\n",
    "    print(f\"🌍 Public URL: {'⚠️ Attempting...' if GRADIO_SHARE else '❌ Disabled (more secure)'}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"🔄 Starting Gradio server...\")\n",
    "        \n",
    "        if GRADIO_SHARE:\n",
    "            print(\"⏳ Attempting to create public tunnel...\")\n",
    "            try:\n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=True,\n",
    "                    inbrowser=False,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False,\n",
    "                    quiet=False\n",
    "                )\n",
    "                \n",
    "                print(\"\\\\n🎉 SUCCESS! Public tunnel created\")\n",
    "                print(f\"🌐 AVAILABLE URLS:\")\n",
    "                print(f\"   📱 Local: http://localhost:{GRADIO_PORT}\")\n",
    "                \n",
    "                if hasattr(demo, 'share_url') and demo.share_url:\n",
    "                    print(f\"   🌍 Public: {demo.share_url}\")\n",
    "                    print(f\"\\\\n🔗 **PUBLIC URL:** {demo.share_url}\")\n",
    "                else:\n",
    "                    print(f\"   🌍 Public: Check Gradio output above ☝️\")\n",
    "                \n",
    "            except Exception as share_error:\n",
    "                print(f\"⚠️ Error creating public tunnel: {share_error}\")\n",
    "                print(\"🔄 Switching to local mode only...\")\n",
    "                \n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=False,\n",
    "                    inbrowser=True,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False\n",
    "                )\n",
    "                \n",
    "                print(f\"\\\\n✅ LOCAL SERVER OPERATIONAL:\")\n",
    "                print(f\"   📱 Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "                print(f\"   ⚠️ Public URL: Not available (tunnel error)\")\n",
    "                \n",
    "        else:\n",
    "            demo = gradio_app.launch(\n",
    "                server_port=GRADIO_PORT,\n",
    "                share=False,\n",
    "                inbrowser=True,\n",
    "                show_error=True,\n",
    "                prevent_thread_lock=False\n",
    "            )\n",
    "            \n",
    "            print(f\"\\\\n✅ LOCAL SERVER OPERATIONAL:\")\n",
    "            print(f\"   📱 Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "            print(f\"   💡 For public URL, set GRADIO_SHARE=true in .env\")\n",
    "        \n",
    "        print(f\"\\\\n📋 COSTA RICA PHILATELIC FEATURES:\")\n",
    "        print(f\"   • Specialized Costa Rica stamp queries\")\n",
    "        print(f\"   • Scott catalog number search\")\n",
    "        print(f\"   • Variety and error detection\")\n",
    "        print(f\"   • Dual search approaches for comprehensive results\")\n",
    "        print(f\"   • Performance timing comparison\")\n",
    "        print(f\"   • To stop: gr.close_all()\")\n",
    "        \n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"🇨🇷 COSTA RICA PHILATELIC RAG INTERFACE READY!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Critical error launching Gradio: {e}\")\n",
    "        print(\"\\\\n🔧 SUGGESTED SOLUTIONS:\")\n",
    "        print(\"   1. Run: gr.close_all()\")\n",
    "        print(\"   2. Change port: GRADIO_PORT=7861 in .env\")\n",
    "        print(\"   3. Verify no other services on the port\")\n",
    "        print(\"   4. Restart the notebook\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\\\n⚠️  Cannot create Gradio interface:\")\n",
    "    if not rag_system:\n",
    "        print(\"   • RAG system not configured\")\n",
    "    else:\n",
    "        print(f\"   • RAG error: {rag_system.get('error', 'Unknown error')}\")\n",
    "    print(\"\\\\n🔧 To resolve:\")\n",
    "    print(\"   1. Verify Weaviate is running\")\n",
    "    print(\"   2. Configure OPENAI_API_KEY in .env\") \n",
    "    print(\"   3. Run document indexing\")\n",
    "    print(\"   4. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-clean (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
