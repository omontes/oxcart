{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philatelic Gradio App with Weaviate\n",
    "Interactive web interface for CR Philately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "Load all the modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from datetime import datetime\n",
    "import weaviate\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "import markdown\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.retrievers import MultiQueryRetriever, EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "from philatelic_weaviate import *\n",
    "\n",
    "from philatelic_chunk_schema import *\n",
    "\n",
    "print(\"âœ… Basic imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8083')\n",
    "PHILATELIC_JSONS_DIR = os.getenv('PHILATELIC_JSONS_DIR', './results/final_jsons')\n",
    "COLLECTION_NAME = os.getenv('WEAVIATE_COLLECTION_NAME', 'Oxcart')\n",
    "\n",
    "print(f\"ğŸ”§ Configuration:\")\n",
    "print(f\"   â€¢ Weaviate URL: {WEAVIATE_URL}\")\n",
    "print(f\"   â€¢ JSONs Directory: {PHILATELIC_JSONS_DIR}\")\n",
    "print(f\"   â€¢ Collection Name: {COLLECTION_NAME}\")\n",
    "print(f\"   â€¢ OpenAI API Key: {'âœ… Configured' if OPENAI_API_KEY else 'âŒ Missing configuration'}\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"\\\\nâš ï¸  IMPORTANT: Configure your OPENAI_API_KEY in the .env file\")\n",
    "    print(\"   Copy .env.example to .env and add your API key\")\n",
    "\n",
    "# Verify that the JSONs directory exists\n",
    "if not os.path.exists(PHILATELIC_JSONS_DIR):\n",
    "    print(f\"\\\\nâš ï¸  Directory {PHILATELIC_JSONS_DIR} not found\")\n",
    "    print(\"   Make sure you have processed documents with the Dolphin parser\")\n",
    "else:\n",
    "    json_files = glob.glob(os.path.join(PHILATELIC_JSONS_DIR, '*_final.json'))\n",
    "    print(f\"\\\\nğŸ“ Found {len(json_files)} philatelic JSON files\")\n",
    "    if json_files:\n",
    "        print(\"   Examples:\")\n",
    "        for file in json_files[:3]:\n",
    "            print(f\"   â€¢ {os.path.basename(file)}\")\n",
    "        if len(json_files) > 3:\n",
    "            print(f\"   â€¢ ... and {len(json_files) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-5-nano\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=1,  # obligatorio para gpt-5-nano\n",
    "            timeout=120.0,\n",
    "            #max_completion_tokens=2500,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"medium\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            })\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# ğŸ“ RAG PROMPT TEMPLATE - Professional Philatelic Consultation\n",
    "# ========================================================================================\n",
    "\n",
    "philatelic_rag_template = \"\"\"You are a senior philatelic researcher and catalog specialist with expertise in Costa Rican stamps and postal history. Provide comprehensive, well-structured analysis based strictly on the source materials provided.\n",
    "\n",
    "SOURCE MATERIALS:\n",
    "{context}\n",
    "\n",
    "RESEARCH QUERY: {question}\n",
    "\n",
    "RESPONSE REQUIREMENTS:\n",
    "\n",
    "FORMATTING & STRUCTURE:\n",
    "â€¢ Use clear hierarchical organization with descriptive headers using markdown\n",
    "â€¢ Group related information under logical categories using ## and **bold subheadings**\n",
    "â€¢ Use bullet points (â€¢) for individual facts and varieties\n",
    "â€¢ Include relevant emojis for major sections (ğŸ” ğŸ“® ğŸ“š ğŸ¯) to enhance readability\n",
    "â€¢ Bold key terms, catalog numbers, and important details\n",
    "â€¢ KEEP SECTIONS CONCISE - avoid excessive repetition or overly detailed explanations\n",
    "â€¢ Your output is in markdown format\n",
    "\n",
    "CITATION FORMAT:\n",
    "â€¢ Every factual statement must include the name of the document (doc_id) and its page numeber like this example: (CRF 100, page 15)\n",
    "â€¢ Multiple sources: (doc_id, page number; doc_id, page number) Example: (OXCART 123, page 24 ; OXCART 25, page 15)\n",
    "â€¢ Always cite catalog numbers (scott, yvert, michell, etc), varieties, dates, quantities, and technical specifications\n",
    "â€¢ When quoting directly, use quotation marks around quoted text\n",
    "\n",
    "CONTENT ORGANIZATION:\n",
    "â€¢ Lead with the most direct answer to the query\n",
    "â€¢ Organize by catalog numbers, chronological order, or logical categories as appropriate\n",
    "â€¢ Include technical specifications: dates, quantities, colors, perforations, varieties\n",
    "â€¢ Provide brief historical context and collecting significance\n",
    "â€¢ Note relationships between issues, varieties, or catalog entries\n",
    "â€¢ Address valuation or rarity when relevant to the query\n",
    "\n",
    "RESPONSE LENGTH:\n",
    "â€¢ Aim for clear, informative responses that are thorough but not excessive\n",
    "â€¢ Eliminate redundant information and repetitive explanations\n",
    "â€¢ Focus on the most relevant information that directly answers the query\n",
    "â€¢ If information is extensive, prioritize the most important catalog entries and varieties\n",
    "\n",
    "TECHNICAL STANDARDS:\n",
    "â€¢ Use precise philatelic terminology (definitive, commemorative, variety, error, overprint, etc.)\n",
    "â€¢ Specify exact catalog numbers with proper formatting (Scott C216, not just C216)\n",
    "â€¢ Include denomination and color details when available\n",
    "â€¢ Note printing quantities, dates, and technical varieties\n",
    "â€¢ Distinguish between verified catalog facts and expert opinions\n",
    "â€¢ Flag incomplete or uncertain information clearly\n",
    "\n",
    "RESEARCH COMPLETENESS:\n",
    "â€¢ If source materials are insufficient, state: \"The provided documents do not contain sufficient information about...\"\n",
    "â€¢ Suggest what additional sources or information would be needed\n",
    "â€¢ Note any gaps in catalog coverage or missing details\n",
    "\n",
    "PROFESSIONAL TONE:\n",
    "â€¢ Maintain authoritative but accessible language\n",
    "â€¢ Present information objectively without unnecessary qualifiers\n",
    "â€¢ Use active voice and clear, direct statements\n",
    "â€¢ Avoid speculation beyond what sources support\n",
    "\n",
    "RESPONSE:\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=philatelic_rag_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# ğŸ“„ OPTIMIZED DOCUMENT FORMATTING - For Academic Citation Style\n",
    "# ========================================================================================\n",
    "\n",
    "def format_docs_for_rag(docs_results: List[Dict]) -> str:\n",
    "    \"\"\"Efficient document formatting optimized for academic citation style (Document Name, p. Page)\"\"\"\n",
    "    \n",
    "    if not docs_results:\n",
    "        return \"\\nNo source documents available.\"\n",
    "    \n",
    "    # Group and sort documents by authority\n",
    "    #doc_groups = {'catalog': [], 'literature': [], 'collection': [], 'reference': []}\n",
    "    docs = []\n",
    "    \n",
    "    for i, doc in enumerate(docs_results, 1):\n",
    "        #category, reliability = classify_document_authority(doc.metadata.get('doc_id', 'Unknown'))\n",
    "        \n",
    "        doc_info = {\n",
    "            'doc_num': i,\n",
    "            'doc_id': doc.metadata.get('doc_id', 'Unknown'),\n",
    "            'page': doc.metadata.get('page_number', 'N/A'),\n",
    "            'content': doc.page_content,\n",
    "        }\n",
    "        #doc_groups[category].append(doc_info)\n",
    "        docs.append(doc_info)\n",
    "    return docs\n",
    "\n",
    "def create_rag_response(retriever_results: List[Dict], query: str) -> Dict:\n",
    "    \"\"\"Streamlined RAG chain execution with academic citation style and token tracking\"\"\"\n",
    "    \n",
    "    if not retriever_results:\n",
    "        return {\n",
    "            \"response\": \"No documents found for this query.\", \n",
    "            \"generation_time\": 0,\n",
    "            \"context_docs_count\": 0,\n",
    "            \"context_length\": 0,\n",
    "            \"token_usage\": {\n",
    "                \"input_tokens\": 0,\n",
    "                \"output_tokens\": 0,\n",
    "                \"total_tokens\": 0\n",
    "            },\n",
    "            \"cost_info\": {\n",
    "                \"estimated_cost_usd\": 0,\n",
    "                \"input_cost\": 0,\n",
    "                \"output_cost\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Format context efficiently for academic citations\n",
    "    context = format_docs_for_rag(retriever_results)\n",
    "    \n",
    "    # Execute RAG chain with OpenAI callback for token tracking\n",
    "    rag_chain = (\n",
    "        {\"context\": lambda x: context, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use OpenAI callback to track token usage\n",
    "    with get_openai_callback() as cb:\n",
    "        response = rag_chain.invoke(query)\n",
    "        # Get token counts from callback\n",
    "        input_tokens = cb.prompt_tokens\n",
    "        output_tokens = cb.completion_tokens\n",
    "        total_tokens = cb.total_tokens\n",
    "        \n",
    "        # OpenAI callback provides cost directly, but we'll calculate our own\n",
    "        # based on GPT-5-nano pricing\n",
    "    \n",
    "    generation_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "    # Calculate costs for GPT-5-nano\n",
    "    # $0.05 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    cost_per_1m_input = 0.05\n",
    "    cost_per_1m_output = 0.40\n",
    "    \n",
    "    # Convert to cost per token\n",
    "    cost_per_input_token = cost_per_1m_input / 1_000_000\n",
    "    cost_per_output_token = cost_per_1m_output / 1_000_000\n",
    "    \n",
    "    input_cost = input_tokens * cost_per_input_token\n",
    "    output_cost = output_tokens * cost_per_output_token\n",
    "    estimated_cost = input_cost + output_cost\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"generation_time\": generation_time,\n",
    "        \"context_docs_count\": len(retriever_results),\n",
    "        \"context_length\": len(context),        \n",
    "        \"token_usage\": {\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"total_tokens\": total_tokens\n",
    "        },\n",
    "        \"cost_info\": {\n",
    "            \"estimated_cost_usd\": round(estimated_cost, 6),\n",
    "            \"input_cost\": round(input_cost, 6),\n",
    "            \"output_cost\": round(output_cost, 6)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weaviate Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Weaviate\n",
    "print(\"ğŸ”Œ Connecting to Weaviate...\")\n",
    "\n",
    "try:\n",
    "    client = create_weaviate_client(WEAVIATE_URL, OPENAI_API_KEY)\n",
    "    print(\"âœ… Connection successful\")\n",
    "    \n",
    "    # Verify that Weaviate is working\n",
    "    meta = client.get_meta()\n",
    "    print(f\"ğŸ“Š Weaviate version: {meta.get('version', 'unknown')}\")\n",
    "    \n",
    "    # Verify if collection exists\n",
    "    try:\n",
    "        collections = client.collections.list_all()\n",
    "        collection_names = [col.name for col in collections]\n",
    "        \n",
    "        if COLLECTION_NAME in collection_names:\n",
    "            collection = client.collections.get(COLLECTION_NAME)\n",
    "            total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "            print(f\"ğŸ“Š Collection '{COLLECTION_NAME}' exists with {total_objects} documents\")\n",
    "        else:\n",
    "            print(f\"ğŸ“ Collection '{COLLECTION_NAME}' does not exist (will be created during indexing)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not verify collections: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error connecting to Weaviate: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure Weaviate is running:\")\n",
    "    print(\"   docker-compose up -d\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weaviate Search Tests\n",
    "\n",
    "Test the function search_chunks_semantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_chunks_semantic(\n",
    "                client, \n",
    "                \"Costa Rica 1907 2 colones stamp with original gum. Scott 68 issue of 1907\", \n",
    "                \"Oxcart\", \n",
    "                limit=50,\n",
    "                filters=[],\n",
    "                mode = \"hybrid\",\n",
    "                alpha= 0.35\n",
    "                \n",
    "            )\n",
    "            \n",
    "print(f\"   ğŸ“Š Resultados: {len(results)}\")\n",
    "\n",
    "for j, result in enumerate(results, 1):\n",
    "    print(f\"\\n      ğŸ·ï¸ #{j} (Score: {result['score']:.3f})\")\n",
    "    print(f\"         ğŸ“„ Documento: {result['doc_id']}\")\n",
    "    print(f\"         ğŸ“‹ Tipo: {result['chunk_type']}\")\n",
    "    print(f\"         ğŸ“„ PÃ¡gina: {result['page_number']}\")\n",
    "    \n",
    "    # Mostrar metadatos relevantes\n",
    "    if result.get('catalog_systems'):\n",
    "        print(f\"         ğŸ“– CatÃ¡logos: {result['catalog_systems']}\")\n",
    "    if result.get('scott_numbers'):\n",
    "        print(f\"         ğŸ”¢ Scott: {result['scott_numbers']}\")\n",
    "    if result.get('years'):\n",
    "        print(f\"         ğŸ“… AÃ±os: {result['years']}\")\n",
    "    if result.get('colors'):\n",
    "        print(f\"         ğŸ¨ Colores: {result['colors']}\")\n",
    "    if result.get('variety_classes'):\n",
    "        print(f\"         ğŸ”€ Variedades: {result['variety_classes']}\")\n",
    "    \n",
    "    # Texto truncado\n",
    "    text = result.get('text', '')\n",
    "    # if len(text) > 200:\n",
    "    #     text = text[:200] + \"...\"\n",
    "    print(f\"         ğŸ“ Texto: {text}\")\n",
    "    print(\"**********************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advance Retriever Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "def compress_documents_simple(documents: List[Document], query: str, llm) -> Tuple[List[Document], Dict]:\n",
    "    \"\"\"\n",
    "    Simple document compression using LangChain's native batch processing with token tracking.\n",
    "    Each document is processed individually with the same prompt.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (compressed_documents, token_usage_info)\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return [], {\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "    \n",
    "    # Simple compression prompt for individual documents\n",
    "    compress_prompt_template = \"\"\"You are a philatelic expert. Extract and summary ONLY the information relevant to this query from the document below.\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Extract only information directly relevant to the query\n",
    "- Remove irrelevant content but preserve context for understanding\n",
    "\n",
    "If the document contains no relevant information, respond with exactly: NO_RELEVANT_CONTENT\n",
    "\n",
    "SUMMARY RELEVANT CONTENT:\"\"\"\n",
    "\n",
    "    # Create individual prompts for each document\n",
    "    prompts = []\n",
    "    for doc in documents:\n",
    "        prompt_text = compress_prompt_template.format(\n",
    "            query=query, \n",
    "            document=doc.page_content\n",
    "        )\n",
    "        prompts.append([(\"user\", prompt_text)])\n",
    "    \n",
    "    # Use LangChain's native batch processing with concurrency control and token tracking\n",
    "    config = RunnableConfig(max_concurrency=10)  # Process 10 documents concurrently\n",
    "    \n",
    "    try:\n",
    "        # Track token usage during compression\n",
    "        with get_openai_callback() as cb:\n",
    "            responses = llm.batch(prompts, config=config)\n",
    "            \n",
    "            # Get token counts from callback\n",
    "            compression_token_usage = {\n",
    "                \"input_tokens\": cb.prompt_tokens,\n",
    "                \"output_tokens\": cb.completion_tokens,\n",
    "                \"total_tokens\": cb.total_tokens\n",
    "            }\n",
    "        \n",
    "        # Filter and create compressed documents\n",
    "        compressed_docs = []\n",
    "        for i, response in enumerate(responses):\n",
    "            content = response.content.strip() if hasattr(response, 'content') else str(response).strip()\n",
    "            \n",
    "            # Only include documents that have relevant content\n",
    "            if content and content != \"NO_RELEVANT_CONTENT\":\n",
    "                compressed_doc = Document(\n",
    "                    page_content=content,\n",
    "                    metadata=documents[i].metadata\n",
    "                )\n",
    "                compressed_docs.append(compressed_doc)\n",
    "        \n",
    "        return compressed_docs, compression_token_usage\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch compression: {e}\")\n",
    "        # Fallback: return original documents with zero token usage\n",
    "        return documents, {\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "\n",
    "def search_stamps_with_compression(query, client, embeddings, llm, limit=100, \n",
    "                                 alpha=0.30, diversity_lambda=0.75):\n",
    "    \"\"\"\n",
    "    Optimized philatelic search with simple batch document compression using LangChain's native batch processing.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The stamp query\n",
    "        client: Weaviate client\n",
    "        embeddings: Embedding model\n",
    "        llm: Language model\n",
    "        limit (int): Maximum documents to retrieve\n",
    "        alpha (float): Hybrid search factor (0.30 = 30% vector, 70% keywords)\n",
    "        diversity_lambda (float): MMR diversity factor (0.75 = good diversity)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (compressed_docs, token_usage, cost_info)\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=COLLECTION_NAME,\n",
    "        text_key=\"text\",\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Try to create hybrid retriever\n",
    "    hybrid_kwargs = {\"k\": limit // 2}\n",
    "    if alpha is not None:\n",
    "        hybrid_kwargs[\"alpha\"] = alpha\n",
    "    \n",
    "    # 1. Precision hybrid retriever (captures exact numbers + context)\n",
    "    precision_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs=hybrid_kwargs\n",
    "    )\n",
    "    \n",
    "    # 2. Diversity MMR retriever (avoids duplicate stamps)\n",
    "    diversity_retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": limit // 2, \"lambda_mult\": diversity_lambda}\n",
    "    )\n",
    "    \n",
    "    # 3. Ensemble with dual strategy\n",
    "    base_retriever = EnsembleRetriever(\n",
    "        retrievers=[precision_retriever, diversity_retriever],\n",
    "        weights=[0.7, 0.3]  # 70% precision + 30% diversity\n",
    "    )\n",
    "    \n",
    "    # Specialized prompt for philatelic multi-query generation\n",
    "    query_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"You are a specialized philatelic researcher expert in stamp catalogues and varieties.\n",
    "Generate 3 strategically different versions of the question to capture comprehensive stamp information:\n",
    "\n",
    "ORIGINAL: {question}\n",
    "\n",
    "Create variations that target:\n",
    "1. CATALOG PRECISION: Focus on exact catalog numbers, dates, and technical specifications\n",
    "2. CONTEXTUAL SEARCH: Include related series, printings, varieties, and historical context  \n",
    "3. TERMINOLOGY ALTERNATIVES: Use alternative philatelic terms and synonyms\n",
    "\n",
    "Consider these philatelic elements:\n",
    "- Catalog systems: Scott, Michel, Yvert, SG, local catalogs\n",
    "- Technical terms: definitive/commemorative, variety/error, overprint/surcharge\n",
    "- Time references: issue dates, printing dates, first day covers\n",
    "- Denominations: face values, colors, perforations\n",
    "\n",
    "Alternative searches:\n",
    "1.\n",
    "2. \n",
    "3.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # MultiQueryRetriever with specialized prompt\n",
    "    multi_retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=base_retriever,\n",
    "        llm=llm,\n",
    "        prompt=query_prompt,\n",
    "        parser_key=\"lines\"\n",
    "    )\n",
    "    \n",
    "    # Execute initial retrieval\n",
    "    initial_results = multi_retriever.invoke(query)\n",
    "       \n",
    "    compression_llm = ChatOpenAI(\n",
    "            model=\"gpt-5-nano\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=1,  # obligatorio para gpt-5-nano\n",
    "            timeout=120.0,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"medium\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            })\n",
    "    \n",
    "    # Simple batch compression using LangChain's native batch processing with token tracking\n",
    "    compressed_results, compression_token_usage = compress_documents_simple(initial_results, query, compression_llm)\n",
    "    \n",
    "    # Calculate costs for GPT-5-nano compression\n",
    "    # $0.05 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    cost_per_1m_input = 0.05\n",
    "    cost_per_1m_output = 0.40\n",
    "    \n",
    "    # Convert to cost per token\n",
    "    cost_per_input_token = cost_per_1m_input / 1_000_000\n",
    "    cost_per_output_token = cost_per_1m_output / 1_000_000\n",
    "    \n",
    "    input_cost = compression_token_usage[\"input_tokens\"] * cost_per_input_token\n",
    "    output_cost = compression_token_usage[\"output_tokens\"] * cost_per_output_token\n",
    "    estimated_cost = input_cost + output_cost\n",
    "    \n",
    "    compression_cost_info = {\n",
    "        \"estimated_cost_usd\": round(estimated_cost, 6),\n",
    "        \"input_cost\": round(input_cost, 6),\n",
    "        \"output_cost\": round(output_cost, 6)\n",
    "    }\n",
    "    \n",
    "    # Reorder by quality_score if it exists\n",
    "    def get_quality_score(doc):\n",
    "        return getattr(doc, 'metadata', {}).get('quality_score', 0.0)\n",
    "    \n",
    "    sorted_results = sorted(compressed_results, key=get_quality_score, reverse=True)\n",
    "    return sorted_results, compression_token_usage, compression_cost_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the method search_stamps_with_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the optimized search_stamps_with_compression with batch processing\n",
    "# print(\"ğŸ§ª Testing optimized batch compression...\")\n",
    "\n",
    "# # Test query focused on specific stamps\n",
    "# test_query = \"Costa Rica 1907 2 colones stamp with original gum Scott 68\"\n",
    "\n",
    "# print(f\"ğŸ” Query: {test_query}\")\n",
    "# print(\"â±ï¸ Starting optimized search with batch compression...\")\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# try:\n",
    "#     compressed_docs = search_stamps_with_compression(\n",
    "#         query=test_query,\n",
    "#         client=client, \n",
    "#         embeddings=embeddings, \n",
    "#         limit=30,\n",
    "#         llm=llm,\n",
    "#         alpha=0.30,  # 30% vectorial, 70% keywords for exact numbers\n",
    "#         diversity_lambda=0.75  # 75% relevance, 25% diversity\n",
    "#     )\n",
    "    \n",
    "#     end_time = time.time()\n",
    "#     execution_time = end_time - start_time\n",
    "    \n",
    "#     print(f\"âœ… Batch compression completed in {execution_time:.2f} seconds\")\n",
    "#     print(f\"ğŸ“Š Retrieved and compressed {len(compressed_docs)} documents\")\n",
    "    \n",
    "#     # Show sample results\n",
    "#     for i, doc in enumerate(compressed_docs[:3], 1):\n",
    "#         print(f\"\\\\nğŸ“„ Document {i}:\")\n",
    "#         print(f\"   Metadata: {getattr(doc, 'metadata', {})}\")\n",
    "#         content = getattr(doc, 'page_content', str(doc))\n",
    "#         preview = content[:200] + \"...\" if len(content) > 200 else content\n",
    "#         print(f\"   Content: {preview}\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"âŒ Error during batch compression test: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_info() -> str:\n",
    "    \"\"\"\n",
    "    Get collection information to display in the interface.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return \"âŒ No Weaviate connection\"\n",
    "    \n",
    "    try:\n",
    "        stats = get_collection_stats(client, \"Oxcart\")\n",
    "        if stats:\n",
    "            info = f\"ğŸ“Š **Oxcart Collection Statistics:**\\\\n\\\\n\"\n",
    "            info += f\"ğŸ“¦ **Total chunks:** {stats['total_chunks']:,}\\\\n\"\n",
    "            info += f\"ğŸ“„ **Documents:** {stats['total_documents']}\\\\n\\\\n\"\n",
    "            \n",
    "            if stats.get('documents'):\n",
    "                info += \"**Indexed documents:**\\\\n\"\n",
    "                for doc_id, count in stats['documents'].items():\n",
    "                    info += f\"â€¢ {doc_id}: {count:,} chunks\\\\n\"\n",
    "            \n",
    "            return info\n",
    "        else:\n",
    "            return \"âŒ Could not retrieve statistics\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "\n",
    "print(\"âœ… RAG functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_collection_stats(client, \"Oxcart\")\n",
    "stats['total_documents']\n",
    "stats['total_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura que usan tus funciones de bÃºsqueda/respuesta\n",
    "rag_system = {\n",
    "    \"success\": True,\n",
    "    \"client\": client,                    # para que search_and_answer pueda consultar\n",
    "    \"collection_name\": COLLECTION_NAME,  # nombre de la colecciÃ³n\n",
    "    \"weaviate_url\": WEAVIATE_URL,        # info para la UI\n",
    "    \"total_documents\": stats['total_documents'],       # para mostrar estado\n",
    "    \"total_chunks\": stats['total_chunks'],        # opcional en la UI\n",
    "    \"embeddings\":embeddings,\n",
    "    \"llm\":llm,\n",
    "    # puedes aÃ±adir mÃ¡s campos que tu search_and_answer necesite\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_answer_basic(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    year_start: Optional[int] = None,\n",
    "    year_end: Optional[int] = None,\n",
    "    scott_numbers: Optional[List[str]] = None,\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Basic hybrid search approach with improved philatelic filters.\n",
    "    All filters are OPTIONAL - only applied when provided.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"âŒ Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "    \n",
    "    client_wv = rag_system[\"client\"]\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    \n",
    "    # Build philatelic filters only if values are provided\n",
    "    filters = {}\n",
    "    \n",
    "    # Year range filter - ONLY if both years are provided and valid\n",
    "    if year_start is not None and year_end is not None:\n",
    "        try:\n",
    "            # Ensure both are integers and valid\n",
    "            start = int(year_start)\n",
    "            end = int(year_end)\n",
    "            # Ensure start <= end\n",
    "            if start > end:\n",
    "                start, end = end, start\n",
    "            filters[\"year_range\"] = (start, end)\n",
    "            print(f\"[DEBUG] Year filter applied: {start}-{end}\")\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(f\"[WARNING] Invalid year values, skipping year filter: {e}\")\n",
    "    \n",
    "    # Scott numbers ONLY if provided and not empty\n",
    "    if scott_numbers:\n",
    "        print(\"Scott Numbers: \",scott_numbers)\n",
    "        filters[\"catalog_system\"] = \"Scott\"\n",
    "        filters[\"scott_numbers\"] = scott_numbers        \n",
    "    \n",
    "    # Log final filter status\n",
    "    if not filters:\n",
    "        print(\"[DEBUG] No filters applied - searching all documents\")\n",
    "    else:\n",
    "        print(f\"[DEBUG] Filters being used: {filters}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Basic semantic search with philatelic filters\n",
    "        # Pass None if no filters, not empty dict\n",
    "        results = search_chunks_semantic(\n",
    "            client=client_wv,\n",
    "            query=query,\n",
    "            collection_name=collection_name,\n",
    "            limit=int(max_results),\n",
    "            filters=filters if filters else None,  # Pass None if no filters\n",
    "            mode=\"hybrid\",\n",
    "            alpha=0.35\n",
    "        )\n",
    "        \n",
    "        # Convert to LangChain document format for RAG\n",
    "        docs_for_rag = []\n",
    "        for r in results:\n",
    "            doc = type('Document', (), {\n",
    "                'page_content': r.get('text', ''),\n",
    "                'metadata': {\n",
    "                    'doc_id': r.get('doc_id', 'N/A'),\n",
    "                    'page_number': r.get('page_number', 'N/A'),\n",
    "                    'chunk_type': r.get('chunk_type', 'N/A'),\n",
    "                    'score': r.get('score', 0.0),\n",
    "                    'scott_numbers': r.get('scott_numbers', []),\n",
    "                    'years': r.get('years', []),\n",
    "                    'catalog_systems': r.get('catalog_systems', [])\n",
    "                }\n",
    "            })()\n",
    "            docs_for_rag.append(doc)\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(docs_for_rag, query)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Build metadata with actual filters used\n",
    "        metadata = {\n",
    "            \"approach\": \"Basic Hybrid Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"max_results\": int(max_results),\n",
    "            \"filters_used\": filters if filters else \"None (searching all documents)\",\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response.get(\"context_docs_count\", len(docs_for_rag)),\n",
    "            \"context_length\": sum(len(d.page_content) for d in docs_for_rag),\n",
    "            \"token_usage\": rag_response.get(\"token_usage\", {}),\n",
    "            \"cost_info\": rag_response.get(\"cost_info\", {}),\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response.get(\"response\", \"No response generated\"),\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"[ERROR] Basic search error: {str(e)}\")\n",
    "        print(f\"[ERROR] Full traceback: {error_details}\")\n",
    "        print(f\"[ERROR] Filters attempted: {filters}\")\n",
    "        \n",
    "        return {\n",
    "            \"answer\": f\"âŒ Basic search error: {str(e)}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\n",
    "                \"error\": str(e),\n",
    "                \"generation_time\": 0,\n",
    "                \"filters_attempted\": filters if filters else \"None\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_answer_advanced(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Advanced compression search approach - filters NOT applied (as requested).\n",
    "    Now tracks both compression and RAG response token usage and costs.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"âŒ Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "\n",
    "    client_wv = rag_system[\"client\"]\n",
    "    embeddings = rag_system.get(\"embeddings\")\n",
    "    llm = rag_system.get(\"llm\")\n",
    "    \n",
    "    # NOTE: Advanced search does not apply filters as requested by user\n",
    "    # This approach uses ensemble retrieval and compression instead\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Advanced search with compression (no filters applied) - now returns token info\n",
    "        compressed_docs, compression_token_usage, compression_cost_info = search_stamps_with_compression(\n",
    "            query=query,\n",
    "            client=client_wv,\n",
    "            embeddings=embeddings,\n",
    "            llm=llm,\n",
    "            limit=max_results,\n",
    "            alpha=0.30,\n",
    "            diversity_lambda=0.75\n",
    "        )\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(compressed_docs, query)\n",
    "        \n",
    "        # Extraer y preservar figuras de los documentos originales\n",
    "        figure_pattern = r'(!\\[([^\\]]*)\\]\\([^)]+\\))'\n",
    "\n",
    "        for doc in compressed_docs:\n",
    "            # Buscar figuras en el contenido original si estÃ¡ disponible\n",
    "            original_content = doc.metadata.get('text_original', doc.page_content)\n",
    "            \n",
    "            # Extraer todas las figuras del contenido original\n",
    "            figures = re.findall(figure_pattern, original_content)\n",
    "            \n",
    "            # Eliminar duplicados manteniendo el orden\n",
    "            seen_figures = set()\n",
    "            unique_figures = []\n",
    "            for fig in figures:\n",
    "                # Usar el path de la imagen como identificador Ãºnico (ignorando el alt text)\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path:\n",
    "                    img_identifier = img_path.group(1)\n",
    "                    if img_identifier not in seen_figures:\n",
    "                        seen_figures.add(img_identifier)\n",
    "                        unique_figures.append(fig)\n",
    "            \n",
    "            # Verificar quÃ© figuras ya estÃ¡n en el contenido comprimido\n",
    "            existing_figures = set()\n",
    "            for fig in unique_figures:\n",
    "                if fig[0] in doc.page_content:\n",
    "                    img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                    if img_path:\n",
    "                        existing_figures.add(img_path.group(1))\n",
    "            \n",
    "            # Agregar solo las figuras que faltan\n",
    "            missing_figures = []\n",
    "            for fig in unique_figures:\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path and img_path.group(1) not in existing_figures:\n",
    "                    missing_figures.append(fig[0])\n",
    "            \n",
    "            # Si hay figuras faltantes, agregarlas al final\n",
    "            if missing_figures:\n",
    "                figures_text = \"\\n\\n\" + \"\\n\".join(missing_figures)\n",
    "                doc.page_content = doc.page_content + figures_text\n",
    "            \n",
    "            # Guardar las figuras Ãºnicas en metadata para acceso rÃ¡pido\n",
    "            doc.metadata['figures'] = [fig[0] for fig in unique_figures] if unique_figures else []\n",
    "            doc.metadata['has_figures'] = len(unique_figures) > 0\n",
    "        \n",
    "        # Convert compressed docs to results format for display\n",
    "        results = []\n",
    "        for i, doc in enumerate(compressed_docs):\n",
    "            result = {\n",
    "                'doc_id': doc.metadata.get('doc_id', 'N/A'),\n",
    "                'page_number': doc.metadata.get('page_number', 'N/A'),\n",
    "                'chunk_type': doc.metadata.get('chunk_type', 'N/A'),\n",
    "                'text': doc.page_content,\n",
    "                'score': doc.metadata.get('quality_score', 0.0),\n",
    "                'catalog_systems': doc.metadata.get('catalog_systems', []),\n",
    "                'scott_numbers': doc.metadata.get('scott_numbers', []),\n",
    "                'years': doc.metadata.get('years', []),\n",
    "                'colors': doc.metadata.get('colors', []),\n",
    "                'variety_classes': doc.metadata.get('variety_classes', []),\n",
    "                'has_figures': doc.metadata.get('has_figures', False),  \n",
    "                'figures': doc.metadata.get('figures', [])  \n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Combine compression and RAG token usage/costs\n",
    "        rag_token_usage = rag_response.get(\"token_usage\", {})\n",
    "        rag_cost_info = rag_response.get(\"cost_info\", {})\n",
    "        \n",
    "        # Create combined token usage structure\n",
    "        combined_token_usage = {\n",
    "            \"compression\": {\n",
    "                \"input_tokens\": compression_token_usage.get(\"input_tokens\", 0),\n",
    "                \"output_tokens\": compression_token_usage.get(\"output_tokens\", 0),\n",
    "                \"total_tokens\": compression_token_usage.get(\"total_tokens\", 0)\n",
    "            },\n",
    "            \"rag_response\": {\n",
    "                \"input_tokens\": rag_token_usage.get(\"input_tokens\", 0),\n",
    "                \"output_tokens\": rag_token_usage.get(\"output_tokens\", 0),\n",
    "                \"total_tokens\": rag_token_usage.get(\"total_tokens\", 0)\n",
    "            },\n",
    "            \"total\": {\n",
    "                \"input_tokens\": (compression_token_usage.get(\"input_tokens\", 0) + \n",
    "                               rag_token_usage.get(\"input_tokens\", 0)),\n",
    "                \"output_tokens\": (compression_token_usage.get(\"output_tokens\", 0) + \n",
    "                                rag_token_usage.get(\"output_tokens\", 0)),\n",
    "                \"total_tokens\": (compression_token_usage.get(\"total_tokens\", 0) + \n",
    "                               rag_token_usage.get(\"total_tokens\", 0))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Create combined cost info structure\n",
    "        combined_cost_info = {\n",
    "            \"compression\": {\n",
    "                \"input_cost\": compression_cost_info.get(\"input_cost\", 0.0),\n",
    "                \"output_cost\": compression_cost_info.get(\"output_cost\", 0.0),\n",
    "                \"estimated_cost_usd\": compression_cost_info.get(\"estimated_cost_usd\", 0.0)\n",
    "            },\n",
    "            \"rag_response\": {\n",
    "                \"input_cost\": rag_cost_info.get(\"input_cost\", 0.0),\n",
    "                \"output_cost\": rag_cost_info.get(\"output_cost\", 0.0),\n",
    "                \"estimated_cost_usd\": rag_cost_info.get(\"estimated_cost_usd\", 0.0)\n",
    "            },\n",
    "            \"total\": {\n",
    "                \"input_cost\": (compression_cost_info.get(\"input_cost\", 0.0) + \n",
    "                             rag_cost_info.get(\"input_cost\", 0.0)),\n",
    "                \"output_cost\": (compression_cost_info.get(\"output_cost\", 0.0) + \n",
    "                              rag_cost_info.get(\"output_cost\", 0.0)),\n",
    "                \"estimated_cost_usd\": (compression_cost_info.get(\"estimated_cost_usd\", 0.0) + \n",
    "                                     rag_cost_info.get(\"estimated_cost_usd\", 0.0))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        metadata = {\n",
    "            \"approach\": \"Advanced Compression Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"compressed_docs\": len(compressed_docs),\n",
    "            \"filters_used\": \"No filters (advanced approach)\",\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response.get(\"context_docs_count\", len(compressed_docs)),\n",
    "            \"docs_with_figures\": sum(1 for r in results if r.get('has_figures', False)),\n",
    "            \"token_usage\": combined_token_usage,\n",
    "            \"cost_info\": combined_cost_info,\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response.get(\"response\", \"No response generated\"),\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"[ERROR] Advanced search error: {str(e)}\")\n",
    "        print(f\"[ERROR] Full traceback: {error_details}\")\n",
    "        \n",
    "        return {\n",
    "            \"answer\": f\"âŒ Advanced search error: {str(e)}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\n",
    "                \"error\": str(e),\n",
    "                \"generation_time\": 0,\n",
    "                \"filters_attempted\": \"None\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Costa Rica 1907 2 colones stamp with original gum. Scott 68 issue of 1907\"\n",
    "\n",
    "# results = search_and_answer_basic(\n",
    "#     query,\n",
    "#     rag_system,\n",
    "#     None,\n",
    "#     None,\n",
    "#     [\"1\",\"2\"],\n",
    "#     10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Basic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enhanced test of search_chunks_semantic function\n",
    "# def display_search_results(results, query, filters_used=None):\n",
    "#     \"\"\"\n",
    "#     Enhanced display function for search results\n",
    "#     \"\"\"\n",
    "#     print(f\"ğŸ” SEARCH RESULTS\")\n",
    "#     print(f\"=\" * 60)\n",
    "#     print(f\"ğŸ“ Query: '{query}'\")\n",
    "#     if filters_used:\n",
    "#         print(f\"ğŸ”§ Filters applied: {filters_used}\")\n",
    "#     print(f\"ğŸ“Š Total results: {len(results)}\")\n",
    "#     print(f\"=\" * 60)\n",
    "    \n",
    "#     if not results:\n",
    "#         print(\"âŒ No results found\")\n",
    "#         return\n",
    "    \n",
    "#     for j, result in enumerate(results[:5], 1):  # Show top 5 results\n",
    "#         print(f\"\\nğŸ·ï¸ RESULT #{j} (Score: {result['score']:.4f})\")\n",
    "#         print(f\"   ğŸ“„ Document: {result['doc_id']}\")\n",
    "#         print(f\"   ğŸ“‹ Chunk Type: {result['chunk_type']}\")\n",
    "#         print(f\"   ğŸ“„ Page: {result['page_number']}\")\n",
    "        \n",
    "#         # Show metadata if available\n",
    "#         metadata_items = [\n",
    "#             ('ğŸ“– Catalog Systems', result.get('catalog_systems', [])),\n",
    "#             ('ğŸ”¢ Scott Numbers', result.get('scott_numbers', [])),\n",
    "#             ('ğŸ“… Years', result.get('years', [])),\n",
    "#             ('ğŸ¨ Colors', result.get('colors', [])),\n",
    "#             ('ğŸ”€ Variety Classes', result.get('variety_classes', [])),\n",
    "#         ]\n",
    "        \n",
    "#         for label, data in metadata_items:\n",
    "#             if data:\n",
    "#                 display_data = ', '.join(str(item) for item in data) if isinstance(data, list) else str(data)\n",
    "#                 print(f\"   {label}: {display_data}\")\n",
    "        \n",
    "#         # Boolean flags\n",
    "#         if result.get('has_varieties'):\n",
    "#             print(f\"   âœ… Has varieties\")\n",
    "#         if result.get('is_guanacaste'):\n",
    "#             print(f\"   ğŸŒ Guanacaste province\")\n",
    "#         if result.get('has_technical_specs'):\n",
    "#             print(f\"   ğŸ”§ Has technical specs\")\n",
    "            \n",
    "#         # Text preview\n",
    "#         text = result.get('text', '')\n",
    "#         preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "#         print(f\"   ğŸ“ Text preview: {preview}\")\n",
    "#         print(f\"   {'â”€' * 50}\")\n",
    "\n",
    "# # Test 1: Basic search without filters (original test enhanced)\n",
    "# print(\"ğŸ§ª TEST 1: Basic Hybrid Search (No Filters)\")\n",
    "# query = \"Costa Rica 1907 2 colones stamp with original gum. Scott 68 issue of 1907\"\n",
    "\n",
    "# results = search_chunks_semantic(\n",
    "#     client=client, \n",
    "#     query=query, \n",
    "#     collection_name=\"Oxcart\", \n",
    "#     limit=20,\n",
    "#     filters=[],  # No filters\n",
    "#     mode=\"hybrid\",\n",
    "#     alpha=0.35\n",
    "# )\n",
    "\n",
    "# display_search_results(results, query)\n",
    "\n",
    "# print(f\"\\nğŸ’¡ This test shows unfiltered results. Now let's test with specific filters...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test: Combined Filters (Advanced Testing) - UPDATED with Multiple Scott Numbers\n",
    "# print(\"ğŸ§ª TEST 6: Combined Filters (Advanced Testing)\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# # Test complex filter combinations for precise searches\n",
    "# combined_tests = [\n",
    "#     {\n",
    "#         \"name\": \"1907 stamps with varieties\",\n",
    "#         \"query\": \"1907 Costa Rica stamps with varieties or errors\",\n",
    "#         \"filters\": {\n",
    "#             \"year_range\": (1907, 1907)\n",
    "#         }\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"1934 Costa Rica stamps\",\n",
    "#         \"query\": \"List all 1934 Costa Rica Stamps\",\n",
    "#         \"filters\": {\n",
    "#             \"year_range\": (1934, 1934)\n",
    "#         }\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Costa Rica First Issue Scott 1-5 (MULTIPLE SCOTT NUMBERS TEST)\",\n",
    "#         \"query\": \"Costa Rica First Issue Scott 1 2 3 4 5\",\n",
    "#         \"filters\": {\n",
    "#             \"catalog_system\": \"Scott\",\n",
    "#             \"scott_numbers\": [\"1\", \"2\", \"3\", \"4\", \"5\"]  # TEST: Multiple Scott numbers as list\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# for i, test in enumerate(combined_tests, 1):\n",
    "#     print(f\"\\nğŸ”¬ COMBINED TEST {i}: {test['name']}\")\n",
    "#     print(f\"{'â”€' * 60}\")\n",
    "#     print(f\"ğŸ¯ Filters: {test['filters']}\")\n",
    "    \n",
    "#     # Special logging for multiple Scott numbers test\n",
    "#     if \"scott_number\" in test['filters'] and isinstance(test['filters']['scott_number'], list):\n",
    "#         print(f\"ğŸ”¢ TESTING MULTIPLE SCOTT NUMBERS: {test['filters']['scott_number']}\")\n",
    "#         print(f\"ğŸ“ Expected: Should find documents with ANY of these Scott numbers (OR logic)\")\n",
    "    \n",
    "#     # Execute search with combined filters\n",
    "#     results = search_chunks_semantic(\n",
    "#         client=client,\n",
    "#         query=test['query'],\n",
    "#         collection_name=\"Oxcart\",\n",
    "#         limit=15,  # Increased limit for multiple Scott test\n",
    "#         filters=test['filters'],\n",
    "#         mode=\"hybrid\",\n",
    "#         alpha=0.35\n",
    "#     )\n",
    "    \n",
    "#     display_search_results(results, test['query'], filters_used=test['filters'])\n",
    "    \n",
    "#     # Detailed validation of filter application\n",
    "#     if results:\n",
    "#         print(f\"\\n   ğŸ” FILTER VALIDATION:\")\n",
    "#         for filter_key, filter_value in test['filters'].items():\n",
    "#             validation_count = 0\n",
    "            \n",
    "#             # Special handling for multiple Scott numbers\n",
    "#             if filter_key == \"scott_numbers\" and isinstance(filter_value, list):\n",
    "#                 print(f\"      ğŸ”¢ Checking for ANY Scott number from: {filter_value}\")\n",
    "#                 for result in results:\n",
    "#                     result_scotts = result.get('scott_numbers', [])\n",
    "#                     # Check if ANY of the requested Scott numbers is in the result\n",
    "#                     if any(scott_num in result_scotts for scott_num in filter_value):\n",
    "#                         validation_count += 1\n",
    "#                 print(f\"      âœ… Documents with ANY requested Scott number: {validation_count}/{len(results)}\")\n",
    "                \n",
    "#                 # Show which specific Scott numbers were found\n",
    "#                 found_scotts = set()\n",
    "#                 for result in results:\n",
    "#                     found_scotts.update(result.get('scott_numbers', []))\n",
    "#                 matching_scotts = [s for s in filter_value if s in found_scotts]\n",
    "#                 print(f\"      ğŸ“‹ Requested Scott numbers found: {matching_scotts}\")\n",
    "#                 print(f\"      ğŸ“‹ All Scott numbers in results: {sorted(found_scotts)}\")\n",
    "                \n",
    "#             elif filter_key == \"year_range\":\n",
    "#                 result_years = result.get('years', [])\n",
    "#                 if any(filter_value[0] <= year <= filter_value[1] for year in result_years):\n",
    "#                     validation_count += 1\n",
    "#             elif filter_key == \"catalog_system\":\n",
    "#                 if filter_value in result.get('catalog_systems', []):\n",
    "#                     validation_count += 1\n",
    "#             elif filter_key == \"chunk_type\":\n",
    "#                 if result.get('chunk_type') == filter_value:\n",
    "#                     validation_count += 1\n",
    "#             elif filter_key in [\"has_varieties\", \"is_guanacaste\", \"has_technical_specs\"]:\n",
    "#                 if result.get(filter_key) == filter_value:\n",
    "#                     validation_count += 1\n",
    "            \n",
    "#             # Show validation for non-Scott filters\n",
    "#             if filter_key != \"scott_number\":\n",
    "#                 print(f\"      âœ… {filter_key}: {validation_count}/{len(results)} results match\")\n",
    "    \n",
    "#     print(f\"\\n{'â•' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timing_display(\n",
    "          basic_time, advanced_time, total_time,\n",
    "          basic_results, advanced_results,\n",
    "          filter_msg=\"\",\n",
    "          basic_metadata=None, advanced_metadata=None\n",
    "      ):\n",
    "    \"\"\"Enhanced timing display with cost comparison (robust casting)\"\"\"\n",
    "    try:\n",
    "        # --- helpers seguros ---\n",
    "        def as_float(x, default=0.0):\n",
    "            try:\n",
    "                return float(x)\n",
    "            except (TypeError, ValueError):\n",
    "                return default\n",
    "\n",
    "        def as_int(x, default=0):\n",
    "            try:\n",
    "                # evita ints tipo '1_234' si viniera asÃ­\n",
    "                return int(float(x))\n",
    "            except (TypeError, ValueError):\n",
    "                return default\n",
    "\n",
    "        # tiempos\n",
    "        basic_time = as_float(basic_time)\n",
    "        advanced_time = as_float(advanced_time)\n",
    "        total_time = as_float(total_time)\n",
    "\n",
    "        # costos - ARREGLO AQUÃ para manejar estructura anidada\n",
    "        basic_cost = 0.0\n",
    "        advanced_cost = 0.0\n",
    "\n",
    "        if basic_metadata and 'cost_info' in basic_metadata:\n",
    "            basic_cost = as_float(basic_metadata['cost_info'].get('estimated_cost_usd', 0))\n",
    "\n",
    "        if advanced_metadata and 'cost_info' in advanced_metadata:\n",
    "            # Detectar si es estructura anidada\n",
    "            adv_cost_info = advanced_metadata['cost_info']\n",
    "            if 'total' in adv_cost_info and isinstance(adv_cost_info['total'], dict):\n",
    "                # Estructura anidada - usar el total\n",
    "                advanced_cost = as_float(adv_cost_info['total'].get('estimated_cost_usd', 0))\n",
    "            else:\n",
    "                # Estructura simple\n",
    "                advanced_cost = as_float(adv_cost_info.get('estimated_cost_usd', 0))\n",
    "\n",
    "        total_cost = basic_cost + advanced_cost\n",
    "\n",
    "        # tokens (Â¡forzar int!) - ARREGLO AQUÃ para manejar estructura anidada\n",
    "        basic_tokens = 0\n",
    "        advanced_tokens = 0\n",
    "\n",
    "        if basic_metadata and 'token_usage' in basic_metadata:\n",
    "            basic_tokens = as_int(basic_metadata['token_usage'].get('total_tokens', 0))\n",
    "\n",
    "        if advanced_metadata and 'token_usage' in advanced_metadata:\n",
    "            # Detectar si es estructura anidada\n",
    "            adv_token_usage = advanced_metadata['token_usage']\n",
    "            if 'total' in adv_token_usage and isinstance(adv_token_usage['total'], dict):\n",
    "                # Estructura anidada - usar el total\n",
    "                advanced_tokens = as_int(adv_token_usage['total'].get('total_tokens', 0))\n",
    "            else:\n",
    "                # Estructura simple\n",
    "                advanced_tokens = as_int(adv_token_usage.get('total_tokens', 0))\n",
    "\n",
    "        total_tokens = basic_tokens + advanced_tokens\n",
    "\n",
    "        # faster\n",
    "        if basic_time > 0 and advanced_time > 0:\n",
    "            if basic_time < advanced_time:\n",
    "                faster = f\"ğŸ† Basic search was {advanced_time/basic_time:.1f}x faster\"\n",
    "            elif advanced_time < basic_time:\n",
    "                faster = f\"ğŸ† Advanced search was {basic_time/advanced_time:.1f}x faster\"\n",
    "            else:\n",
    "                faster = \"âš¡ Both approaches took similar time\"\n",
    "        else:\n",
    "            faster = \"â±ï¸ Timing comparison not available\"\n",
    "\n",
    "        # cost effectiveness\n",
    "        cost_comparison = \"\"\n",
    "        if basic_cost > 0 and advanced_cost > 0:\n",
    "            if basic_cost < advanced_cost:\n",
    "                cost_comparison = f\"ğŸ’µ Basic search was ${advanced_cost - basic_cost:.6f} cheaper\"\n",
    "            elif advanced_cost < basic_cost:\n",
    "                cost_comparison = f\"ğŸ’µ Advanced search was ${basic_cost - advanced_cost:.6f} cheaper\"\n",
    "            else:\n",
    "                cost_comparison = \"ğŸ’µ Both approaches had similar costs\"\n",
    "\n",
    "        # speeds\n",
    "        basic_speed = f\"{basic_results/basic_time:.1f}\" if basic_time > 0 else \"N/A\"\n",
    "        advanced_speed = f\"{advanced_results/advanced_time:.1f}\" if advanced_time > 0 else \"N/A\"\n",
    "\n",
    "        timing_display = f\"\"\"â±ï¸ EXECUTION TIMING & COST COMPARISON\n",
    "            ================================================\n",
    "\n",
    "            ğŸ“‹ SEARCH CONFIGURATION\n",
    "            â€¢ {filter_msg}\n",
    "\n",
    "            ğŸ” BASIC HYBRID SEARCH\n",
    "            â€¢ Processing Time: {basic_time:.2f} seconds\n",
    "            â€¢ Documents Found: {basic_results}\n",
    "            â€¢ Speed: {basic_speed} docs/sec\n",
    "            â€¢ Tokens Used: {basic_tokens:,}\n",
    "            â€¢ Cost: ${basic_cost:.6f}\n",
    "            â€¢ Status: âœ… Complete\n",
    "\n",
    "            ğŸš€ ADVANCED COMPRESSION SEARCH\n",
    "            â€¢ Processing Time: {advanced_time:.2f} seconds\n",
    "            â€¢ Documents Found: {advanced_results}\n",
    "            â€¢ Speed: {advanced_speed} docs/sec\n",
    "            â€¢ Tokens Used: {advanced_tokens:,}\n",
    "            â€¢ Cost: ${advanced_cost:.6f}\n",
    "            â€¢ Status: âœ… Complete\n",
    "\n",
    "            ğŸ“Š OVERALL PERFORMANCE\n",
    "            â€¢ Total Execution: {total_time:.2f} seconds\n",
    "            â€¢ Total Tokens: {total_tokens:,}\n",
    "            â€¢ Total Cost: ${total_cost:.6f}\n",
    "            â€¢ Execution Mode: Sequential (Basic â†’ Advanced)\n",
    "            â€¢ {faster}\n",
    "            â€¢ {cost_comparison}\n",
    "\n",
    "            ğŸ’¡ PERFORMANCE NOTES:\n",
    "            â€¢ Basic search: Fast initial results, lower cost\n",
    "            â€¢ Advanced search: Enhanced quality, higher token usage\n",
    "            â€¢ Costs shown are for GPT-5-Nano model\n",
    "            â€¢ Sequential execution allows progressive viewing\n",
    "            â€¢ Filters are optional and only applied when provided\"\"\"\n",
    "        return timing_display\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error formatting timing data: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para convertir Markdown a HTML con correcciÃ³n de rutas de imÃ¡genes\n",
    "def markdown_to_html(text):\n",
    "    \"\"\"Convert markdown text to HTML with lazy base64 loading\"\"\"\n",
    "    if not text:\n",
    "        return \"<p><em>No content</em></p>\"\n",
    "    \n",
    "    import re\n",
    "    import os\n",
    "    import base64\n",
    "    \n",
    "    base_path = r\"C:\\Users\\VM-SERVER\\Desktop\\Oxcart RAG\\results\\markdown\\figures\"\n",
    "    \n",
    "    def image_to_base64_lazy(match):\n",
    "        alt_text = match.group(1)\n",
    "        filename = match.group(2).split('/')[-1].split('\\\\')[-1]\n",
    "        full_path = os.path.join(base_path, filename)\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            try:\n",
    "                with open(full_path, \"rb\") as img_file:\n",
    "                    b64_string = base64.b64encode(img_file.read()).decode()\n",
    "                    ext = filename.split('.')[-1].lower()\n",
    "                    mime_type = f\"image/{ext}\" if ext != 'jpg' else \"image/jpeg\"\n",
    "                    return f'<img style=\"max-width: 100%; height: auto; display: block; margin: 10px auto; border: 1px solid #ddd; border-radius: 4px;\" alt=\"{alt_text}\" src=\"data:{mime_type};base64,{b64_string}\" />'\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {filename}: {e}\")\n",
    "                return f'<p>[Image not found: {filename}]</p>'\n",
    "        else:\n",
    "            return f'<p>[Image not found: {filename}]</p>'\n",
    "    \n",
    "    # Primero convertir markdown a HTML\n",
    "    html = markdown.markdown(text, extensions=['tables', 'fenced_code'])\n",
    "    \n",
    "    # Luego reemplazar las imÃ¡genes en el HTML\n",
    "    html = re.sub(\n",
    "        r'<img[^>]*alt=\"([^\"]*)\"[^>]*src=\"[^\"]*?([^/\\\\\">]+\\.(?:png|jpg|jpeg|gif))\"[^>]*>',\n",
    "        image_to_base64_lazy,\n",
    "        html\n",
    "    )\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(results, approach_name):\n",
    "    \"\"\"Format search results for display in Markdown with figure handling\"\"\"\n",
    "    if not results:\n",
    "        return f\"*No results found with {approach_name}*\"\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"### {approach_name} Results\")\n",
    "    lines.append(f\"**Found {len(results)} documents**\\n\")\n",
    "    lines.append(\"---\")\n",
    "    \n",
    "    for i, r in enumerate(results):\n",
    "        doc_id = r.get(\"doc_id\", \"N/A\")\n",
    "        chunk_type_val = r.get(\"chunk_type\", \"N/A\")\n",
    "        page_number = r.get(\"page_number\", \"N/A\")\n",
    "        score = r.get(\"score\", 0.0)\n",
    "        catalogs = r.get(\"catalog_systems\", [])\n",
    "        scotts = r.get(\"scott_numbers\", [])\n",
    "        years = r.get(\"years\", [])\n",
    "\n",
    "        # Get full text (including figures)\n",
    "        text = r.get(\"text\", \"\")\n",
    "        \n",
    "        # Check if text contains figures\n",
    "        has_figures = \"![Figure]\" in text or \"![\" in text\n",
    "        \n",
    "        # Extract just the text preview (without figures)\n",
    "        import re\n",
    "        text_without_figures = re.sub(r'!\\[([^\\]]*)\\]\\([^)]+\\)', '', text).strip()\n",
    "        preview = (text_without_figures[:300] + \"...\") if len(text_without_figures) > 300 else text_without_figures\n",
    "        \n",
    "        # Extract all figure references\n",
    "        figure_pattern = r'(!\\[([^\\]]*)\\]\\([^)]+\\))'\n",
    "        figures = re.findall(figure_pattern, text)\n",
    "\n",
    "        lines.append(f\"\\n#### ğŸ“„ Result {i+1}\")\n",
    "        lines.append(f\"**Score:** `{score:.3f}`\")\n",
    "        \n",
    "        if has_figures:\n",
    "            lines.append(\"ğŸ–¼ï¸ **This result contains figures**\\n\")\n",
    "        \n",
    "        # Create a table for metadata\n",
    "        lines.append(\"| Field | Value |\")\n",
    "        lines.append(\"|-------|-------|\")\n",
    "        lines.append(f\"| Document | `{doc_id}` |\")\n",
    "        lines.append(f\"| Type | {chunk_type_val} |\")\n",
    "        lines.append(f\"| Page | {page_number} |\")\n",
    "        \n",
    "        if catalogs:\n",
    "            lines.append(f\"| Catalogs | {', '.join(catalogs)} |\")\n",
    "        if scotts:\n",
    "            lines.append(f\"| Scott Numbers | **{', '.join(scotts)}** |\")\n",
    "        if years:\n",
    "            lines.append(f\"| Years | {', '.join(str(y) for y in years)} |\")\n",
    "        \n",
    "        # Always show preview\n",
    "        lines.append(f\"\\n**Preview:**\")\n",
    "        lines.append(f\"> {preview}\")\n",
    "        \n",
    "        # Always show figures if they exist\n",
    "        if has_figures and figures:\n",
    "            lines.append(f\"\\n**Figures in this result:**\\n\")\n",
    "            for figure_match in figures:\n",
    "                lines.append(figure_match[0])  # Add the complete figure markdown\n",
    "        \n",
    "        lines.append(\"\\n---\")\n",
    "    \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metadata(metadata, execution_time):\n",
    "    \"\"\"Format metadata for display in Markdown including token usage and costs (supports both basic and advanced structures).\"\"\"\n",
    "    if not metadata:\n",
    "        return \"*No metadata available*\"\n",
    "\n",
    "    # Helpers\n",
    "    def as_float(x, default=None):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "\n",
    "    def as_int(x, default=None):\n",
    "        try:\n",
    "            return int(float(x))\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "\n",
    "    out = []\n",
    "    out.append(\"### Search Metadata\\n\")\n",
    "\n",
    "    # Basic info\n",
    "    out.append(\"#### ğŸ“Š Search Information\\n\")\n",
    "    out.append(\"| Property | Value |\")\n",
    "    out.append(\"|----------|-------|\")\n",
    "    out.append(f\"| **Approach** | {metadata.get('approach', 'Unknown')} |\")\n",
    "    query_val = str(metadata.get('query', 'N/A')).replace(\"\\n\", \" \")\n",
    "    # (opcional) escapar pipes para no romper la tabla\n",
    "    query_val = query_val.replace(\"|\", \"\\\\|\")\n",
    "    out.append(f\"| **Query** | `{query_val}` |\")\n",
    "\n",
    "    total_results = as_int(metadata.get('total_results'), 0)\n",
    "    out.append(f\"| **Results found** | {total_results} |\")\n",
    "\n",
    "    context_docs_count = as_int(metadata.get('context_docs_count'))\n",
    "    out.append(f\"| **Context docs** | {context_docs_count if context_docs_count is not None else 'N/A'} |\")\n",
    "\n",
    "    context_length = as_int(metadata.get('context_length'))\n",
    "    out.append(\n",
    "        f\"| **Context length** | {context_length:,} chars |\"\n",
    "        if context_length is not None else\n",
    "        \"| **Context length** | N/A |\"\n",
    "    )\n",
    "\n",
    "    if metadata.get('filters_used'):\n",
    "        filters_str = str(metadata['filters_used']).replace('{', '').replace('}', '')\n",
    "        filters_str = filters_str.replace(\"|\", \"\\\\|\")\n",
    "        out.append(f\"| **Filters** | `{filters_str}` |\")\n",
    "\n",
    "    if 'compressed_docs' in metadata:\n",
    "        out.append(f\"| **Compressed docs** | {metadata['compressed_docs']} |\")\n",
    "\n",
    "    out.append(\"\")  # Add space after basic info table\n",
    "\n",
    "    # Detect token usage structure type\n",
    "    token_usage = metadata.get('token_usage') or {}\n",
    "    cost_info = metadata.get('cost_info') or {}\n",
    "\n",
    "    # Check if this is nested structure (advanced search) or simple structure (basic search)\n",
    "    is_nested = (\n",
    "        isinstance(token_usage, dict) and\n",
    "        any(key in token_usage for key in ['compression', 'rag_response', 'total'])\n",
    "    )\n",
    "\n",
    "    if token_usage:\n",
    "        if is_nested:\n",
    "            # Advanced search - nested structure\n",
    "            out.append(\"#### ğŸ¯ Token Usage Breakdown\\n\")\n",
    "\n",
    "            # Compression tokens\n",
    "            compression_tokens = token_usage.get('compression', {})\n",
    "            if compression_tokens:\n",
    "                comp_in = as_int(compression_tokens.get('input_tokens'), 0)\n",
    "                comp_out = as_int(compression_tokens.get('output_tokens'), 0)\n",
    "                comp_total = as_int(compression_tokens.get('total_tokens'), (comp_in or 0) + (comp_out or 0))\n",
    "\n",
    "                out.append(\"**Document Compression:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| Input tokens | {comp_in:,} |\")\n",
    "                out.append(f\"| Output tokens | {comp_out:,} |\")\n",
    "                out.append(f\"| Total tokens | {comp_total:,} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # RAG response tokens\n",
    "            rag_tokens = token_usage.get('rag_response', {})\n",
    "            if rag_tokens:\n",
    "                rag_in = as_int(rag_tokens.get('input_tokens'), 0)\n",
    "                rag_out = as_int(rag_tokens.get('output_tokens'), 0)\n",
    "                rag_total = as_int(rag_tokens.get('total_tokens'), (rag_in or 0) + (rag_out or 0))\n",
    "\n",
    "                out.append(\"**RAG Response Generation:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| Input tokens | {rag_in:,} |\")\n",
    "                out.append(f\"| Output tokens | {rag_out:,} |\")\n",
    "                out.append(f\"| Total tokens | {rag_total:,} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # Total tokens\n",
    "            total_tokens = token_usage.get('total', {})\n",
    "            if total_tokens:\n",
    "                total_in = as_int(total_tokens.get('input_tokens'), 0)\n",
    "                total_out = as_int(total_tokens.get('output_tokens'), 0)\n",
    "                total_total = as_int(total_tokens.get('total_tokens'), (total_in or 0) + (total_out or 0))\n",
    "\n",
    "                out.append(\"**Combined Total:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| **Total input tokens** | **{total_in:,}** |\")\n",
    "                out.append(f\"| **Total output tokens** | **{total_out:,}** |\")\n",
    "                out.append(f\"| **Grand total tokens** | **{total_total:,}** |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "        else:\n",
    "            # Basic search - simple structure\n",
    "            in_tok = as_int(token_usage.get('input_tokens'), 0)\n",
    "            out_tok = as_int(token_usage.get('output_tokens'), 0)\n",
    "            tot_tok = as_int(token_usage.get('total_tokens'), (in_tok or 0) + (out_tok or 0))\n",
    "\n",
    "            out.append(\"#### ğŸ¯ Token Usage\\n\")\n",
    "            out.append(\"| Token Type | Count |\")\n",
    "            out.append(\"|------------|-------|\")\n",
    "            out.append(f\"| **Input tokens** | {in_tok:,} |\")\n",
    "            out.append(f\"| **Output tokens** | {out_tok:,} |\")\n",
    "            out.append(f\"| **Total tokens** | {tot_tok:,} |\")\n",
    "            out.append(\"\")  # Add space after table\n",
    "\n",
    "    # Cost info - handle both nested and simple structures\n",
    "    if cost_info:\n",
    "        is_cost_nested = (\n",
    "            isinstance(cost_info, dict) and\n",
    "            any(key in cost_info for key in ['compression', 'rag_response', 'total'])\n",
    "        )\n",
    "\n",
    "        if is_cost_nested:\n",
    "            # Advanced search - nested cost structure\n",
    "            out.append(\"#### ğŸ’° Cost Analysis Breakdown\\n\")\n",
    "\n",
    "            # Compression costs\n",
    "            compression_cost = cost_info.get('compression', {})\n",
    "            if compression_cost:\n",
    "                comp_in_cost = as_float(compression_cost.get('input_cost'), 0.0)\n",
    "                comp_out_cost = as_float(compression_cost.get('output_cost'), 0.0)\n",
    "                comp_total_cost = as_float(compression_cost.get('estimated_cost_usd'),\n",
    "                                        (comp_in_cost or 0.0) + (comp_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**Document Compression:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| Input cost | ${comp_in_cost:.6f} |\")\n",
    "                out.append(f\"| Output cost | ${comp_out_cost:.6f} |\")\n",
    "                out.append(f\"| Subtotal | ${comp_total_cost:.6f} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # RAG response costs\n",
    "            rag_cost = cost_info.get('rag_response', {})\n",
    "            if rag_cost:\n",
    "                rag_in_cost = as_float(rag_cost.get('input_cost'), 0.0)\n",
    "                rag_out_cost = as_float(rag_cost.get('output_cost'), 0.0)\n",
    "                rag_total_cost = as_float(rag_cost.get('estimated_cost_usd'),\n",
    "                                        (rag_in_cost or 0.0) + (rag_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**RAG Response Generation:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| Input cost | ${rag_in_cost:.6f} |\")\n",
    "                out.append(f\"| Output cost | ${rag_out_cost:.6f} |\")\n",
    "                out.append(f\"| Subtotal | ${rag_total_cost:.6f} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # Total costs\n",
    "            total_cost = cost_info.get('total', {})\n",
    "            if total_cost:\n",
    "                total_in_cost = as_float(total_cost.get('input_cost'), 0.0)\n",
    "                total_out_cost = as_float(total_cost.get('output_cost'), 0.0)\n",
    "                total_total_cost = as_float(total_cost.get('estimated_cost_usd'),\n",
    "                                        (total_in_cost or 0.0) + (total_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**Combined Total:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| **Total input cost** | **${total_in_cost:.6f}** |\")\n",
    "                out.append(f\"| **Total output cost** | **${total_out_cost:.6f}** |\")\n",
    "                out.append(f\"| **Grand total cost** | **${total_total_cost:.6f}** |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "        else:\n",
    "            # Basic search - simple cost structure\n",
    "            in_cost = as_float(cost_info.get('input_cost'), 0.0)\n",
    "            out_cost = as_float(cost_info.get('output_cost'), 0.0)\n",
    "            est_cost = as_float(cost_info.get('estimated_cost_usd'), (in_cost or 0.0) + (out_cost or 0.0))\n",
    "\n",
    "            out.append(\"#### ğŸ’° Cost Analysis\\n\")\n",
    "            out.append(\"| Cost Component | USD |\")\n",
    "            out.append(\"|----------------|-----|\")\n",
    "            out.append(f\"| **Input cost** | ${in_cost:.6f} |\")\n",
    "            out.append(f\"| **Output cost** | ${out_cost:.6f} |\")\n",
    "            out.append(f\"| **Total cost** | **${est_cost:.6f}** |\")\n",
    "            out.append(\"\")  # Add space after table\n",
    "\n",
    "    # Performance\n",
    "    out.append(\"#### â±ï¸ Performance\\n\")\n",
    "    out.append(\"| Metric | Time |\")\n",
    "    out.append(\"|--------|------|\")\n",
    "\n",
    "    gen_time = as_float(metadata.get('generation_time'))\n",
    "    if gen_time is not None:\n",
    "        out.append(f\"| **Generation time** | {gen_time:.2f}s |\")\n",
    "\n",
    "    # Error handling\n",
    "    if metadata.get('error'):\n",
    "        err = str(metadata['error']).replace(\"`\", \"'\")\n",
    "        out.append(f\"\\nâš ï¸ **Error:** `{err}`\")\n",
    "\n",
    "    return \"\\n\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_card(title: str, percent: int, note: str = \"\") -> str:\n",
    "    pct = max(0, min(100, int(percent)))\n",
    "    note_html = f'<div class=\"vf-note\">{note}</div>' if note else \"\"\n",
    "    return f\"\"\"\n",
    "    <div class=\"vf-progress-card\" role=\"status\" aria-live=\"polite\" aria-atomic=\"true\">\n",
    "      <div class=\"vf-title\">{title}</div>\n",
    "      <progress class=\"vf-progress\" value=\"{pct}\" max=\"100\"></progress>\n",
    "      {note_html}\n",
    "    </div>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_search(\n",
    "    query: str,\n",
    "    year_start: Optional[str],\n",
    "    year_end: Optional[str],\n",
    "    scott_numbers: Optional[str],\n",
    "    max_results: int,\n",
    "    st_ctx: Dict[str, Any],                # gr.State dict para pasar datos a la fase 2\n",
    "    progress: gr.Progress = gr.Progress(track_tqdm=True),\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta SOLO la bÃºsqueda bÃ¡sica, pinta resultados rÃ¡pidos y deja todo listo\n",
    "    para que la avanzada continÃºe en un job separado.\n",
    "    Devuelve 7 outputs visibles + 1 estado (st_ctx).\n",
    "    \"\"\"\n",
    "    # Validaciones mÃ­nimas\n",
    "    progress(0.02, desc=\"Validandoâ€¦\")\n",
    "    if not query or not query.strip():\n",
    "        err = markdown_to_html(\"âŒ Please enter a query\")\n",
    "        return err, \"\", \"\", err, \"\", \"\", \"No timing data available\", st_ctx\n",
    "\n",
    "    # Filtrado opcional (idÃ©ntico a tu lÃ³gica original, pero resumido aquÃ­)\n",
    "    processed_year_start = None\n",
    "    processed_year_end = None\n",
    "    if year_start and year_end:\n",
    "        try:\n",
    "            ys = int(str(year_start).strip())\n",
    "            ye = int(str(year_end).strip())\n",
    "            if 1800 <= ys <= 2025 and 1800 <= ye <= 2025:\n",
    "                processed_year_start, processed_year_end = ys, ye\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    processed_scott_numbers = None\n",
    "    if scott_numbers and str(scott_numbers).strip():\n",
    "        nums = [s.strip() for s in str(scott_numbers).split(\",\") if s.strip()]\n",
    "        processed_scott_numbers = nums or None\n",
    "\n",
    "    filters_status = []\n",
    "    if processed_year_start and processed_year_end:\n",
    "        filters_status.append(f\"Years: {processed_year_start}-{processed_year_end}\")\n",
    "    if processed_scott_numbers:\n",
    "        filters_status.append(f\"Scott: {', '.join(processed_scott_numbers)}\")\n",
    "    filter_msg = \"Filters applied: \" + (\", \".join(filters_status) if filters_status else \"None (searching all documents)\")\n",
    "    st_ctx = {\n",
    "        \"t0\": time.time(),\n",
    "        \"filter_msg\": filter_msg,\n",
    "    }\n",
    "\n",
    "    # Mensajes iniciales\n",
    "    progress(0.08, desc=\"Inicializando bÃºsquedaâ€¦\")\n",
    "    gr.Info(\"Iniciando bÃºsqueda rÃ¡pidaâ€¦\")\n",
    "\n",
    "    loading_basic = progress_card(\"ğŸ”„ Running Basic Hybrid Searchâ€¦\", 10, filter_msg)\n",
    "    loading_advanced = progress_card(\"â³ Waiting for Basic to completeâ€¦\", 5, \"Deep Analysis will start automatically.\")\n",
    "\n",
    "\n",
    "    # Un primer retorno (stream) para pintar \"waiting\"\n",
    "    yield (\n",
    "        loading_basic,  # basic_answer_html\n",
    "        \"\",             # basic_search_html\n",
    "        \"\",             # basic_metadata_html\n",
    "        loading_advanced,  # advanced_answer_html (placeholder)\n",
    "        \"\",             # advanced_search_html\n",
    "        \"\",             # advanced_metadata_html\n",
    "        f\"â±ï¸ Basic search in progress...\\n{filter_msg}\",  # timing\n",
    "        st_ctx          # state\n",
    "    )\n",
    "\n",
    "    # --------- Ejecutar BÃšSQUEDA BÃSICA ----------\n",
    "    progress(0.35, desc=\"BÃºsqueda rÃ¡pidaâ€¦\")\n",
    "    t_basic_start = time.time()\n",
    "    # Llama a tu funciÃ³n real:\n",
    "    basic_results_data = search_and_answer_basic(  # type: ignore[name-defined]\n",
    "        query=query,\n",
    "        rag_system=rag_system,                     # usa el capturado en create_gradio_interface\n",
    "        year_start=processed_year_start,\n",
    "        year_end=processed_year_end,\n",
    "        scott_numbers=processed_scott_numbers,\n",
    "        max_results=int(max_results),\n",
    "    )\n",
    "    t_basic_end = time.time()\n",
    "\n",
    "    basic_answer = basic_results_data[\"answer\"]\n",
    "    basic_results = basic_results_data[\"results\"]\n",
    "    basic_metadata = basic_results_data[\"metadata\"]\n",
    "    basic_execution_time = basic_metadata.get(\"generation_time\", t_basic_end - t_basic_start)\n",
    "\n",
    "    # Render\n",
    "    basic_answer_html = markdown_to_html(basic_answer)\n",
    "    basic_search_html = markdown_to_html(format_search_results(basic_results, \"Basic Hybrid Search\"))\n",
    "    basic_metadata_html = markdown_to_html(format_metadata(basic_metadata, basic_execution_time))\n",
    "\n",
    "    timing_partial = (\n",
    "        \"â±ï¸ EXECUTION TIMING (Partial)\\n\\n\"\n",
    "        \"Basic Hybrid Search: âœ… COMPLETED\\n\"\n",
    "        f\"â€¢ Time: {basic_execution_time:.2f}s\\n\"\n",
    "        f\"â€¢ Results: {len(basic_results)}\\n\"\n",
    "        f\"â€¢ {filter_msg}\\n\\n\"\n",
    "        \"Advanced Search: â³ STARTING...\\n\"\n",
    "    )\n",
    "    progress(0.6, desc=\"Crafting the deep researchâ€¦\")\n",
    "    gr.Info(\"Done Quick Search âœ… â€” Beginning advanced researchâ€¦\")\n",
    "\n",
    "    # Actualiza el state para la fase 2\n",
    "    st_ctx.update({\n",
    "        \"basic_metadata\": basic_metadata,\n",
    "        \"basic_exec\": float(basic_execution_time),\n",
    "        \"basic_results_count\": int(len(basic_results)),\n",
    "    })\n",
    "\n",
    "    # Devuelve resultados bÃ¡sicos + placeholder para avanzada\n",
    "    yield (\n",
    "        basic_answer_html,\n",
    "        basic_search_html,\n",
    "        basic_metadata_html,\n",
    "        progress_card(\"ğŸš€ Deep Analysis runningâ€¦\", 70, filter_msg),\n",
    "        \"\",\n",
    "        \"\",\n",
    "        timing_partial,\n",
    "        st_ctx\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_advanced_search(\n",
    "    query: str,\n",
    "    max_results: int,\n",
    "    st_ctx: Dict[str, Any],\n",
    "    progress: gr.Progress = gr.Progress(track_tqdm=True),\n",
    "):\n",
    "    progress(0.05, desc=\"Beginning deep researchâ€¦\")\n",
    "    if not query or not query.strip():\n",
    "        err = markdown_to_html(\"âŒ Please enter a query\")\n",
    "        # frame final directo (sin dejar pending)\n",
    "        yield err, \"\", \"\", \"No timing data available\", st_ctx\n",
    "        return\n",
    "\n",
    "    t0 = st_ctx.get(\"t0\", time.time())\n",
    "    filter_msg = st_ctx.get(\"filter_msg\", \"Filters applied: None\")\n",
    "    basic_metadata = st_ctx.get(\"basic_metadata\", {})\n",
    "    basic_exec = float(st_ctx.get(\"basic_exec\", 0.0))\n",
    "    basic_results_count = int(st_ctx.get(\"basic_results_count\", 0))\n",
    "\n",
    "    # ğŸ‘‰ placeholder visible (reemplaza lo anterior)\n",
    "    yield (\n",
    "        progress_card(\"ğŸš€ Deep Analysis runningâ€¦\", 70, filter_msg),\n",
    "        \"\",  # advanced_search_html\n",
    "        \"\",  # advanced_metadata_html\n",
    "        f\"â±ï¸ EXECUTION TIMING (Partial)\\n\\nBasic: âœ… {basic_exec:.2f}s  |  Advanced: â³ runningâ€¦\\n{filter_msg}\",\n",
    "        st_ctx\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # --------- Ejecutar BÃšSQUEDA AVANZADA ----------\n",
    "        progress(0.4, desc=\"Deep analysisâ€¦\")\n",
    "        t_adv_start = time.time()\n",
    "        advanced_results_data = search_and_answer_advanced(  # type: ignore[name-defined]\n",
    "            query=query,\n",
    "            rag_system=rag_system,\n",
    "            max_results=int(max_results),\n",
    "        )\n",
    "        t_adv_end = time.time()\n",
    "\n",
    "        advanced_answer = advanced_results_data.get(\"answer\", \"\")\n",
    "        advanced_results = advanced_results_data.get(\"results\", [])\n",
    "        advanced_metadata = advanced_results_data.get(\"metadata\", {})\n",
    "        advanced_execution_time = advanced_metadata.get(\"generation_time\", t_adv_end - t_adv_start)\n",
    "\n",
    "        # Render\n",
    "        advanced_answer_html = markdown_to_html(advanced_answer or \"â„¹ï¸ No answer produced.\")\n",
    "        advanced_search_html = markdown_to_html(format_search_results(advanced_results, \"Advanced Compression Search\"))\n",
    "        advanced_metadata_html = markdown_to_html(format_metadata(advanced_metadata, advanced_execution_time))\n",
    "\n",
    "        total_execution_time = time.time() - t0\n",
    "        timing_final = format_timing_display(\n",
    "            basic_exec,\n",
    "            float(advanced_execution_time),\n",
    "            float(total_execution_time),\n",
    "            basic_results_count,\n",
    "            len(advanced_results),\n",
    "            filter_msg,\n",
    "            basic_metadata,\n",
    "            advanced_metadata\n",
    "        )\n",
    "\n",
    "        progress(1.0, desc=\"Completado\")\n",
    "        gr.Info(\"AnÃ¡lisis profundo completado âœ…\")\n",
    "\n",
    "        # âœ… FRAME FINAL: usa YIELD (no return) para reemplazar la barra\n",
    "        yield (\n",
    "            advanced_answer_html,\n",
    "            advanced_search_html,\n",
    "            advanced_metadata_html,\n",
    "            timing_final,\n",
    "            st_ctx\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # âœ… Si algo falla, reemplaza tambiÃ©n el placeholder\n",
    "        err_html = markdown_to_html(f\"âŒ Advanced phase failed:\\n\\n```\\n{e}\\n```\")\n",
    "        yield err_html, \"\", \"\", \"Advanced phase failed â€” see error above.\", st_ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THEME - Solo lo bÃ¡sico (paleta \"sage\")\n",
    "philatelic_theme = gr.themes.Soft().set(\n",
    "    button_primary_background_fill=\"#6b8e7f\",\n",
    "    button_primary_background_fill_hover=\"#4a6558\",\n",
    "    button_primary_text_color=\"#ffffff\",\n",
    "    button_secondary_background_fill=\"#f5f5f5\",\n",
    "    button_secondary_background_fill_hover=\"#e8e8e8\",\n",
    "    button_secondary_text_color=\"#1f2937\",\n",
    "    body_background_fill=\"#ffffff\",\n",
    "    input_background_fill=\"#ffffff\",\n",
    "    input_border_color=\"#bfc8c3\",\n",
    "    slider_color=\"#6b8e7f\",\n",
    "    # opcionales si tu versiÃ³n lo permite:\n",
    "    # link_text_color=\"#4a6558\",\n",
    "    # link_text_color_hover=\"#2c5530\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "/* ========================================\n",
    "   CONFIGURACIÃ“N BASE - TEMA FILATELIA\n",
    "   ======================================== */\n",
    "\n",
    "/* Paleta base */\n",
    ":root{\n",
    "  --vf-ink:#1f2937;           /* texto principal */\n",
    "  --vf-muted:#475569;         /* texto secundario */\n",
    "  --vf-accent:#6b8e7f;        /* verde suave (primario) */\n",
    "  --vf-accent-dark:#4a6558;   /* verde oscuro (hover/foco) */\n",
    "  --vf-surface:#f3f4f6;       /* superficies suaves */\n",
    "  --vf-border:#cfd8d4;        /* bordes suaves */\n",
    "}\n",
    "\n",
    "/* Reset & tipografÃ­a base */\n",
    "body, .gradio-container{\n",
    "  font-family:'Georgia','Times New Roman',serif !important;\n",
    "  font-size:20px !important;\n",
    "  color:var(--vf-ink) !important;\n",
    "  line-height:1.6 !important;\n",
    "  -webkit-font-smoothing:antialiased !important;\n",
    "  -moz-osx-font-smoothing:grayscale !important;\n",
    "  text-rendering:optimizeLegibility !important;\n",
    "}\n",
    ".gradio-container *{ font-size:inherit !important; }\n",
    ".gradio-container svg{ font-size:initial !important; }\n",
    "\n",
    "/* Enlaces (por si los usas en Markdown) */\n",
    "a{ color:var(--vf-accent) !important; text-decoration:none !important; }\n",
    "a:hover{ text-decoration:underline !important; }\n",
    "\n",
    "/* ========================================\n",
    "   ENCABEZADOS\n",
    "   ======================================== */\n",
    "h1{\n",
    "  color:var(--vf-ink) !important;\n",
    "  font-weight:700 !important;\n",
    "  font-size:36px !important;\n",
    "  margin:0 0 20px !important;\n",
    "  letter-spacing:.2px !important; /* nitidez en Windows */\n",
    "}\n",
    "h2,h3{\n",
    "  color:var(--vf-ink) !important;\n",
    "  font-weight:700 !important;\n",
    "  font-size:26px !important;\n",
    "  margin:20px 0 12px !important;\n",
    "  letter-spacing:.2px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   TEXTO GENERAL\n",
    "   ======================================== */\n",
    "p,.markdown-text{ color:var(--vf-ink) !important; font-size:22px !important; line-height:1.7 !important; }\n",
    "label{\n",
    "  font-size:22px !important; font-weight:700 !important; color:var(--vf-ink) !important;\n",
    "  margin-bottom:8px !important; display:block !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   INPUTS Y FORMULARIOS\n",
    "   ======================================== */\n",
    "input[type=\"text\"], textarea{\n",
    "  font-size:22px !important; padding:16px !important; color:var(--vf-ink) !important;\n",
    "  background:#fff !important; border:2px solid var(--vf-border) !important; border-radius:8px !important;\n",
    "  transition:border-color .2s ease, box-shadow .2s ease !important;\n",
    "}\n",
    "input[type=\"text\"]:focus, textarea:focus{\n",
    "  border-color:var(--vf-accent) !important;\n",
    "  outline:none !important;\n",
    "  box-shadow:0 0 0 3px rgba(107,142,127,.18) !important;\n",
    "}\n",
    "input::placeholder, textarea::placeholder{ color:#9ca3af !important; font-size:20px !important; }\n",
    "select{\n",
    "  font-size:20px !important; padding:14px !important; color:var(--vf-ink) !important;\n",
    "  background:#fff !important; border:2px solid var(--vf-border) !important; border-radius:8px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   SLIDER\n",
    "   ======================================== */\n",
    ".gr-box:has(input[type=\"range\"]) > .block > .wrap > span:first-child{\n",
    "  font-size:20px !important; font-weight:700 !important; display:block !important; margin-bottom:10px !important;\n",
    "}\n",
    ".gr-box:has(input[type=\"range\"]) .wrap{\n",
    "  display:flex !important; flex-direction:row !important; align-items:center !important; gap:15px !important; width:100% !important;\n",
    "}\n",
    ".gr-box input[type=\"number\"]{\n",
    "  width:80px !important; height:40px !important; padding:8px !important; font-size:18px !important;\n",
    "  border:1px solid var(--vf-border) !important; border-radius:6px !important; background:#fff !important; font-weight:700 !important; text-align:center !important;\n",
    "}\n",
    "input[type=\"range\"]{\n",
    "  flex:1 !important; -webkit-appearance:none !important; height:8px !important;\n",
    "  background:#e5e7eb !important; border-radius:9999px !important; outline:none !important;\n",
    "}\n",
    "input[type=\"range\"]::-webkit-slider-thumb{\n",
    "  -webkit-appearance:none !important; width:20px !important; height:20px !important;\n",
    "  background:var(--vf-accent) !important; border-radius:50% !important; cursor:pointer !important;\n",
    "  transition:transform .15s ease, background .15s ease !important;\n",
    "}\n",
    "input[type=\"range\"]::-webkit-slider-thumb:hover{ background:#5a7a6b !important; transform:scale(1.03) !important; }\n",
    "input[type=\"range\"]::-moz-range-thumb{\n",
    "  width:20px !important; height:20px !important; background:var(--vf-accent) !important;\n",
    "  border-radius:50% !important; border:none !important; cursor:pointer !important;\n",
    "}\n",
    ".gr-box:has(input[type=\"range\"]) input[readonly],\n",
    ".gr-box:has(input[type=\"range\"]) span:last-child{\n",
    "  font-size:20px !important; font-weight:700 !important; color:var(--vf-ink) !important;\n",
    "  background:#f5f5f5 !important; padding:10px 14px !important; border:1px solid var(--vf-border) !important; border-radius:6px !important; text-align:center !important; min-width:72px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   BOTONES\n",
    "   ======================================== */\n",
    "button{\n",
    "  font-size:22px !important; font-weight:700 !important; padding:16px 32px !important; border-radius:10px !important;\n",
    "  transition:transform .15s ease, box-shadow .15s ease, background .2s ease !important; cursor:pointer !important;\n",
    "}\n",
    "#main-search-btn, button.primary{\n",
    "  background:linear-gradient(135deg, var(--vf-accent) 0%, #5a7a6b 100%) !important;\n",
    "  color:#fff !important; border:2px solid #5a7a6b !important; letter-spacing:.3px !important;\n",
    "}\n",
    "#main-search-btn:hover, button.primary:hover{\n",
    "  transform:translateY(-2px) !important; box-shadow:0 6px 12px rgba(107,142,127,.3) !important;\n",
    "  background:linear-gradient(135deg, #5a7a6b 0%, var(--vf-accent-dark) 100%) !important;\n",
    "}\n",
    "button.secondary, button:not(.primary):not([role=\"tab\"]):not([aria-expanded]){\n",
    "  background:#f5f5f5 !important; color:var(--vf-ink) !important; border:2px solid var(--vf-border) !important;\n",
    "}\n",
    "button.secondary:hover, button:not(.primary):not([role=\"tab\"]):not([aria-expanded]):hover{\n",
    "  background:#e8e8e8 !important; border-color:var(--vf-accent) !important;\n",
    "}\n",
    "/* Focus visible (accesible) */\n",
    "button:focus-visible, input:focus-visible, textarea:focus-visible, select:focus-visible{\n",
    "  outline:3px solid rgba(107,142,127,.45) !important; outline-offset:2px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   TABS\n",
    "   ======================================== */\n",
    "button[role=\"tab\"]{\n",
    "  background:#f5f5f5 !important; color:var(--vf-ink) !important; border:1px solid var(--vf-border) !important;\n",
    "  font-size:20px !important; padding:14px 20px !important; margin-right:4px !important; border-radius:10px 10px 0 0 !important;\n",
    "}\n",
    "button[role=\"tab\"][aria-selected=\"true\"]{\n",
    "  background:var(--vf-accent) !important; color:#fff !important; border-color:var(--vf-accent) !important;\n",
    "}\n",
    "button[role=\"tab\"]:hover:not([aria-selected=\"true\"]){ background:#e8e8e8 !important; }\n",
    "\n",
    "/* ========================================\n",
    "   ACCORDIONS\n",
    "   ======================================== */\n",
    ".accordion{\n",
    "  border:1px solid #e5e7eb !important; border-radius:12px !important; margin:16px 0 !important; background:#fff !important; overflow:hidden !important;\n",
    "}\n",
    "button[aria-expanded]{\n",
    "  background:#fafafa !important; border:none !important; padding:16px 24px !important; width:100% !important; text-align:left !important;\n",
    "  font-size:20px !important; font-weight:700 !important; color:var(--vf-ink) !important; transition:background .2s !important;\n",
    "}\n",
    "button[aria-expanded]:hover{ background:#f0f0f0 !important; }\n",
    "button[aria-expanded=\"true\"]{\n",
    "  background:linear-gradient(135deg, #f0f5f3 0%, #e5ede9 100%) !important; color:#2c5530 !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   PROGRESS Y ESTADOS\n",
    "   ======================================== */\n",
    ".progress-bar{\n",
    "  background:linear-gradient(90deg, var(--vf-accent) 0%, #8fa89e 50%, var(--vf-accent) 100%) !important;\n",
    "  height:4px !important; border-radius:2px !important; opacity:.95 !important;\n",
    "}\n",
    ".progress-container{ background:var(--vf-surface) !important; border-radius:6px !important; margin:10px 0 !important; }\n",
    ".progress-text{ color:#4b5563 !important; font-size:16px !important; font-weight:600 !important; margin:8px 0 !important; }\n",
    "\n",
    "/* <progress> nativo (para progress_card) */\n",
    "progress{\n",
    "  appearance:none; -webkit-appearance:none; width:100%; height:10px; border:none; background:transparent;\n",
    "}\n",
    "progress::-webkit-progress-bar{ background:#e5e7eb; border-radius:6px; }\n",
    "progress::-webkit-progress-value{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)); border-radius:6px; }\n",
    "progress::-moz-progress-bar{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)); border-radius:6px; }\n",
    "\n",
    "/* Estado â€œgeneratingâ€ */\n",
    ".generating{\n",
    "  border:2px solid var(--vf-accent) !important;\n",
    "  background:linear-gradient(135deg, #f0f5f3 0%, #e5ede9 100%) !important;\n",
    "  animation:pulse-border 2s infinite !important;\n",
    "}\n",
    "@keyframes pulse-border{\n",
    "  0%,100%{ border-color:var(--vf-accent); box-shadow:0 0 0 0 rgba(107,142,127,.4); }\n",
    "  50%{ border-color:#8fa89e; box-shadow:0 0 0 4px rgba(107,142,127,.1); }\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   INDICADORES Y MISC\n",
    "   ======================================== */\n",
    "#status-indicator{\n",
    "  background:linear-gradient(135deg, var(--vf-accent) 0%, #5a7a6b 100%) !important;\n",
    "  color:#fff !important; padding:20px !important; border-radius:12px !important; text-align:center !important;\n",
    "  font-size:18px !important; font-weight:700 !important; margin:20px 0 !important; box-shadow:0 4px 8px rgba(107,142,127,.2) !important;\n",
    "}\n",
    "#status-indicator.success{ background:linear-gradient(135deg, #7fb069 0%, #6b9956 100%) !important; }\n",
    ".timer-display{\n",
    "  font-family:'Courier New',monospace !important; font-size:16px !important; color:var(--vf-ink) !important;\n",
    "  padding:10px !important; background:var(--vf-surface) !important; border-radius:6px !important; text-align:center !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   UTILIDADES\n",
    "   ======================================== */\n",
    ".loading-text{ color:var(--vf-muted) !important; font-style:normal !important; font-size:18px !important; }\n",
    "hr{ border:none !important; border-top:2px solid #e5e7eb !important; margin:30px 0 !important; }\n",
    ".group{ background:#fff !important; border-radius:10px !important; padding:20px !important; margin:10px 0 !important; }\n",
    "input[type=\"checkbox\"]+label, input[type=\"radio\"]+label{ font-size:20px !important; margin-left:8px !important; }\n",
    ".results-container{ padding:20px !important; background:#fafafa !important; border-radius:10px !important; margin:10px 0 !important; }\n",
    "\n",
    "/* Progress-card con contraste alto */\n",
    ".vf-progress-card{ color:var(--vf-ink) !important; }\n",
    ".vf-progress-card .vf-title{ font-weight:600; letter-spacing:.2px; margin-bottom:6px; color:var(--vf-ink) !important; }\n",
    ".vf-progress-card .vf-note{ margin-top:6px; font-size:16px; color:var(--vf-ink) !important; opacity:.9 !important; }\n",
    ".vf-progress{ width:100%; height:10px; background:transparent; appearance:none; -webkit-appearance:none; }\n",
    ".vf-progress::-webkit-progress-bar{ background:#e7eeea !important; border-radius:6px; }\n",
    ".vf-progress::-webkit-progress-value{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)) !important; border-radius:6px; }\n",
    ".vf-progress::-moz-progress-bar{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)) !important; border-radius:6px; }\n",
    "\n",
    "/* Quita panel gris SOLO al H2 del Step 1 (Group .input-section) */\n",
    ".input-section .gr-box:has(.gr-markdown){\n",
    "  background:transparent !important; border:none !important; box-shadow:none !important; padding:0 !important;\n",
    "}\n",
    ".input-section .gr-markdown h2, .input-section .gr-markdown h3{ margin-top:0 !important; color:var(--vf-ink) !important; }\n",
    "\n",
    "/* Quitar pill azul de labels de inputs (Soft theme) */\n",
    ".gradio-container label,\n",
    ".gradio-container label span,\n",
    ".gradio-container .label,\n",
    ".gradio-container .label span,\n",
    ".gradio-container .wrap > label,\n",
    ".gradio-container .block .wrap > label {\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* Ajuste fino del texto del label */\n",
    ".gradio-container label span,\n",
    ".gradio-container .label span {\n",
    "  padding: 0 !important;\n",
    "  border-radius: 0 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  font-weight: 700 !important;\n",
    "  letter-spacing: .2px !important; /* mejora nitidez en Windows */\n",
    "}\n",
    "\n",
    "/* --- Quitar la barra gris del Step 1 (Group: .input-section) --- */\n",
    "\n",
    "/* Aplana cualquier caja/panel que Gradio mete dentro del Group */\n",
    ".input-section .gr-box,\n",
    ".input-section .gr-panel,\n",
    ".input-section .gr-box > .form,\n",
    ".input-section .gr-box > .container,\n",
    ".input-section .prose {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* El bloque especÃ­fico que contiene el Markdown del tÃ­tulo */\n",
    ".input-section .gr-box:has(.gr-markdown){\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "}\n",
    "\n",
    "/* Opcional: un separador sutil debajo del H2 para que no se vea â€œflotandoâ€ */\n",
    ".input-section .gr-markdown h2{\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* Evita â€œpÃ­ldorasâ€ o fondos raros en labels dentro del Step 1 */\n",
    ".input-section label,\n",
    ".input-section label span {\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "  padding: 0 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "}\n",
    "\n",
    "\n",
    "/* Tarjeta blanca suave para el Ã¡rea de Step 1 (opcional) */\n",
    ".input-section{\n",
    "  background: #fff !important;\n",
    "  border: 1px solid #eef2f0 !important;\n",
    "  border-radius: 12px !important;\n",
    "  padding: 16px !important;\n",
    "}\n",
    "\n",
    "/* --- Alto contraste para Markdown: evita itÃ¡lica gris en .prose --- */\n",
    ".gradio-container .prose em,\n",
    ".gradio-container .prose i {\n",
    "  font-style: normal !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "}\n",
    ".gradio-container .prose strong { color: var(--vf-ink) !important; }\n",
    "\n",
    "/* --- Progress plano (sin degradado) y mÃ¡s visible --- */\n",
    ":root{\n",
    "  --vf-progress-bg:#e1e7e4;      /* pista */\n",
    "  --vf-progress-fill:#5f7f72;    /* relleno sÃ³lido */\n",
    "}\n",
    "\n",
    ".vf-progress{\n",
    "  width:100%; height:10px;\n",
    "  appearance:none; -webkit-appearance:none;\n",
    "  background:transparent; border:none;\n",
    "}\n",
    ".vf-progress::-webkit-progress-bar{\n",
    "  background: var(--vf-progress-bg) !important;\n",
    "  border-radius: 6px;\n",
    "}\n",
    ".vf-progress::-webkit-progress-value{\n",
    "  background: var(--vf-progress-fill) !important;   /* <- sÃ³lido */\n",
    "  border-radius: 6px;\n",
    "}\n",
    ".vf-progress::-moz-progress-bar{\n",
    "  background: var(--vf-progress-fill) !important;   /* <- sÃ³lido */\n",
    "  border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* Por si algÃºn progress sin clase aparece, aplica el mismo estilo */\n",
    "progress{\n",
    "  appearance:none; -webkit-appearance:none;\n",
    "  width:100%; height:10px; background:transparent; border:none;\n",
    "}\n",
    "progress::-webkit-progress-bar{ background: var(--vf-progress-bg); border-radius:6px; }\n",
    "progress::-webkit-progress-value{ background: var(--vf-progress-fill); border-radius:6px; }\n",
    "progress::-moz-progress-bar{ background: var(--vf-progress-fill); border-radius:6px; }\n",
    "\n",
    "/* TÃ­tulos/nota del card bien nÃ­tidos */\n",
    ".vf-progress-card .vf-title{\n",
    "  font-weight:600; letter-spacing:.2px; margin-bottom:6px; color:var(--vf-ink) !important;\n",
    "}\n",
    ".vf-progress-card .vf-note{\n",
    "  margin-top:6px; font-size:16px; color:var(--vf-ink) !important; opacity:.92 !important;\n",
    "}\n",
    "\n",
    "/* El panel gris viene del .gr-box que envuelve el Markdown dentro del Group.\n",
    "   Lo aplanamos SOLO cuando contiene #step1_title */\n",
    ".input-section .gr-box:has(#step1_title) {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "}\n",
    "/* Opcional: separador sutil bajo el H2 */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* Fuerza alto contraste SOLO en los outputs donde metes el progress_card */\n",
    "#basic_answer .vf-progress-card,\n",
    "#advanced_answer .vf-progress-card,\n",
    "#basic_answer .vf-progress-card *,\n",
    "#advanced_answer .vf-progress-card * {\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "  font-style: normal !important;\n",
    "  text-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* Barra de progreso sÃ³lida y visible */\n",
    ":root{\n",
    "  --vf-progress-bg: #d9e3df;   /* pista */\n",
    "  --vf-progress-fill: #3f5f52; /* relleno */\n",
    "}\n",
    "#basic_answer .vf-progress,\n",
    "#advanced_answer .vf-progress {\n",
    "  appearance: none; -webkit-appearance: none;\n",
    "  width: 100%; height: 10px; border: none; background: transparent;\n",
    "  opacity: 1 !important; filter: none !important;\n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-bar,\n",
    "#advanced_answer .vf-progress::-webkit-progress-bar { \n",
    "  background: var(--vf-progress-bg) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-value,\n",
    "#advanced_answer .vf-progress::-webkit-progress-value { \n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-moz-progress-bar,\n",
    "#advanced_answer .vf-progress::-moz-progress-bar {\n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* === Quitar fade de Gradio en outputs mientras estÃ¡n \"pending\" === */\n",
    "#basic_answer .html-container.pending,\n",
    "#advanced_answer .html-container.pending,\n",
    "#basic_answer .pending,\n",
    "#advanced_answer .pending {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* Asegura que el wrapper de markdown tampoco reduzca contraste */\n",
    "#basic_answer .prose,\n",
    "#advanced_answer .prose {\n",
    "  opacity: 1 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "}\n",
    "\n",
    "/* Por si el progress queda afectado por herencia/opacidad */\n",
    "#basic_answer .vf-progress,\n",
    "#advanced_answer .vf-progress {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* ==== STEP 1: elimina la franja gris del wrapper .styler y del block del tÃ­tulo ==== */\n",
    "\n",
    "/* Apaga los â€œgapsâ€ grises solo en el styler que contiene #step1_title */\n",
    ".styler:has(#step1_title) {\n",
    "  --layout-gap: 0px !important;\n",
    "  --form-gap-width: 0px !important;\n",
    "}\n",
    "\n",
    "/* Aplana cualquier fondo/sombra que el theme ponga alrededor del tÃ­tulo y sus contenedores */\n",
    "#step1_title.block,\n",
    "#step1_title.block .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* El .form de Step 1 (el Ã¡rea del textarea) tambiÃ©n sin fondo */\n",
    ".styler:has(#step1_title) .form {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* TÃ­tulo con separador sutil (opcional) */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* ==== PROGRESS CARD: mata el fade del wrapper â€œpendingâ€ y sube contraste ==== */\n",
    "\n",
    "/* Gradio desvanece outputs con .pending: quÃ­talo donde pintas el progress_card */\n",
    "#basic_answer .html-container.pending,\n",
    "#advanced_answer .html-container.pending,\n",
    "#basic_answer .pending,\n",
    "#advanced_answer .pending {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* Evita que .prose herede opacidad baja/itÃ¡lica del theme */\n",
    "#basic_answer .prose, #advanced_answer .prose {\n",
    "  opacity: 1 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  font-style: normal !important;\n",
    "  text-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* Fuerza contraste dentro del card */\n",
    "#basic_answer .vf-progress-card,\n",
    "#advanced_answer .vf-progress-card,\n",
    "#basic_answer .vf-progress-card * ,\n",
    "#advanced_answer .vf-progress-card * {\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "  font-style: normal !important;\n",
    "}\n",
    "\n",
    "/* Barra sÃ³lida (sin degradado), mÃ¡s oscura para que se note bien */\n",
    ":root{\n",
    "  --vf-progress-bg: #cbd7d2;   /* pista un poco mÃ¡s marcada */\n",
    "  --vf-progress-fill: #2f4a41; /* relleno sÃ³lido oscuro */\n",
    "}\n",
    "#basic_answer .vf-progress, #advanced_answer .vf-progress {\n",
    "  appearance: none; -webkit-appearance: none;\n",
    "  width: 100%; height: 10px; border: none; background: transparent;\n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-bar,\n",
    "#advanced_answer .vf-progress::-webkit-progress-bar { \n",
    "  background: var(--vf-progress-bg) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-value,\n",
    "#advanced_answer .vf-progress::-webkit-progress-value { \n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-moz-progress-bar,\n",
    "#advanced_answer .vf-progress::-moz-progress-bar {\n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* === STEP 1: mata la franja gris del bloque del tÃ­tulo === */\n",
    "\n",
    "/* 1) Anula cualquier fondo/borde/sombra del bloque #step1_title */\n",
    "#step1_title.block {\n",
    "  /* variables que usa el Soft theme para pintar paneles */\n",
    "  --block-background-fill: transparent !important;\n",
    "  --panel-background-fill: transparent !important;\n",
    "  --section-background-fill: transparent !important;\n",
    "  --block-label-background-fill: transparent !important;\n",
    "  --block-title-background-fill: transparent !important;\n",
    "  --block-border-width: 0px !important;\n",
    "\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;     /* el .padded agrega relleno */\n",
    "  margin: 0 !important;\n",
    "  overflow: visible !important; /* evita â€œtirasâ€ de fondo por overflow */\n",
    "}\n",
    "\n",
    "/* 2) Por si el tema usa pseudo-elementos para el panel */\n",
    "#step1_title.block::before,\n",
    "#step1_title.block::after {\n",
    "  content: none !important;\n",
    "  display: none !important;\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* 3) Aplana wrappers internos que en tu DOM rodean al h2 */\n",
    "#step1_title .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* 4) Si el gris venÃ­a del â€œgapâ€ del layout, desactÃ­valo en este bloque */\n",
    "#step1_title.block[style*=\"--block-border-width\"] {\n",
    "  --block-border-width: 0px !important;\n",
    "}\n",
    "#step1_title.block {\n",
    "  --layout-gap: 0px !important;\n",
    "  --form-gap-width: 0px !important;\n",
    "}\n",
    "\n",
    "/* 5) La clase .padded puede dar fondo en algunos temas */\n",
    "#step1_title.padded { background: transparent !important; }\n",
    "\n",
    "/* 6) (Opcional) separador sutil bajo el H2 para no dejarlo â€œflotandoâ€ */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* ==== 1) Mata el gap/fondo del contenedor que rodea al Step 1 ==== */\n",
    "/* Pinta el contenedor en blanco y pone gap=0 para que no se vea una franja */\n",
    ".styler:has(#step1_title) {\n",
    "  background: #fff !important;\n",
    "  gap: 0 !important;\n",
    "  row-gap: 0 !important;\n",
    "  column-gap: 0 !important;\n",
    "  --layout-gap: 0 !important;\n",
    "  --form-gap-width: 0 !important;\n",
    "}\n",
    ".styler:has(#step1_title)::before,\n",
    ".styler:has(#step1_title)::after {\n",
    "  content: none !important;\n",
    "  background: #fff !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* ==== 2) Aplana el panel del propio bloque del tÃ­tulo ==== */\n",
    "#step1_title {\n",
    "  /* Si el theme usa variables para fondos/bordes del bloque, anÃºlalas aquÃ­ */\n",
    "  --block-background-fill: transparent !important;\n",
    "  --panel-background-fill: transparent !important;\n",
    "  --section-background-fill: transparent !important;\n",
    "  --block-label-background-fill: transparent !important;\n",
    "  --block-title-background-fill: transparent !important;\n",
    "  --block-border-width: 0px !important;\n",
    "\n",
    "  background: #fff !important;        /* el bloque en sÃ­, blanco sÃ³lido */\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;               /* .padded suele meter relleno */\n",
    "  margin: 0 !important;\n",
    "  overflow: visible !important;\n",
    "}\n",
    "#step1_title::before,\n",
    "#step1_title::after {\n",
    "  content: none !important;\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* Wrappers internos del markdown del H2: sin fondo alguno */\n",
    "#step1_title .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* (Opcional) separador sutil bajo el H2 */\n",
    "#step1_title .prose h2{\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(rag_system: Dict[str, Any]) -> gr.Blocks:\n",
    "    \"\"\"\n",
    "    UI con dos fases encadenadas: rÃ¡pida -> avanzada.\n",
    "    Progress bar visible pero no intrusivo, accordions colapsables.\n",
    "    \"\"\"\n",
    "    # Tema/CSS con fallback\n",
    "    try:\n",
    "        theme = philatelic_theme  # type: ignore[name-defined]\n",
    "    except NameError:\n",
    "        theme = gr.themes.Soft()\n",
    "\n",
    "    try:\n",
    "        css_styles = css\n",
    "    except NameError:\n",
    "        css_styles = \"\"\"\n",
    "        .progress-bar {\n",
    "            background: #3b82f6 !important;\n",
    "            height: 4px !important;\n",
    "        }\n",
    "        .generating {\n",
    "            border: 2px solid #3b82f6 !important;\n",
    "            background: #f0f9ff !important;\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    # Ejemplos\n",
    "    def set_example_1(): return \"Tell me about the Costa Rica 1907 inverted centers\"\n",
    "    def set_example_2(): return \"Show me Costa Rican overprinted stamps with varieties or errors\"\n",
    "    def set_example_3(): return \"1934 airmail definitive issue with catalog values C15-C27\"\n",
    "    def set_example_4(): return \"Tell me about the first issue crack plate varieties\"\n",
    "    def set_example_5(): return \"Costa Rican stamps with perforation errors or printing varieties\"\n",
    "    def set_example_6(): return \"Research mirror impression stamps from Costa Rica\"\n",
    "\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    total_docs = rag_system.get(\"total_documents\", 0)\n",
    "    total_chunks = rag_system.get(\"total_chunks\", 0)\n",
    "\n",
    "    with gr.Blocks(title=\"Costa Rica Philatelic Research System\", theme=theme, css=css_styles) as interface:\n",
    "        gr.Markdown(\n",
    "            \"# ğŸ” Costa Rica Philatelic Research System\\n\"\n",
    "            \"**The smart way to research stamps** - AI-driven exploration of Costa Rican philately\"\n",
    "        )\n",
    "\n",
    "        # =================== STEP 1: Query ===================\n",
    "        with gr.Group(elem_classes=[\"input-section\"]):\n",
    "            gr.Markdown(\"## ğŸ“ Step 1: Enter Your Question\", elem_id=\"step1_title\")\n",
    "            query_input = gr.Textbox(\n",
    "                label=\"What would you like to know about Costa Rican stamps?\",\n",
    "                placeholder=\"Type your question here... (e.g., What are the Guanacaste vertical overprints?)\",\n",
    "                lines=3,\n",
    "                elem_id=\"main-query-input\"\n",
    "            )\n",
    "            search_btn = gr.Button(\"ğŸ” SEARCH NOW\", variant=\"primary\", size=\"lg\", elem_id=\"main-search-btn\")\n",
    "\n",
    "            with gr.Accordion(\"ğŸ’¡ Need ideas? Click here for example questions\", open=False):\n",
    "                gr.Markdown(\"Click any example below to use it:\")\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        btn1 = gr.Button(\"ğŸ“® 1907 inverted centers\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn2 = gr.Button(\"ğŸ“® Overprinted varieties\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn3 = gr.Button(\"ğŸ“® 1934 airmail stamps\", variant=\"secondary\", size=\"sm\")\n",
    "                    with gr.Column():\n",
    "                        btn4 = gr.Button(\"ğŸ“® First issue crack plate\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn5 = gr.Button(\"ğŸ“® Perforation errors\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn6 = gr.Button(\"ğŸ“® Mirror impression stamps\", variant=\"secondary\", size=\"sm\")\n",
    "\n",
    "        # =================== Advanced Options ===================\n",
    "        with gr.Accordion(\"âš™ï¸ Advanced Options (Optional - Click to expand)\", open=False, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"**These filters are completely optional.** Leave them empty to search all documents.\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    year_start = gr.Textbox(label=\"Filter by Start Year\", value=\"\", placeholder=\"e.g., 1907 (optional)\")\n",
    "                    year_end = gr.Textbox(label=\"Filter by End Year\", value=\"\", placeholder=\"e.g., 1910 (optional)\")\n",
    "                with gr.Column():\n",
    "                    scott_numbers = gr.Textbox(\n",
    "                        label=\"Filter by Scott Numbers\",\n",
    "                        placeholder=\"e.g., 1,2,3 or C15 (optional)\",\n",
    "                        value=\"\"\n",
    "                    )\n",
    "                    max_results = gr.Slider(\n",
    "                        minimum=20, maximum=100, value=30, step=10,\n",
    "                        label=\"Number of results to show\",\n",
    "                        elem_id=\"max-results-slider\"\n",
    "                    )\n",
    "\n",
    "        # =================== Results Section ===================\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"## ğŸ“Š Step 2: View Your Results\")\n",
    "\n",
    "        # =================== QUICK SEARCH RESULTS (ACCORDION) ===================\n",
    "        with gr.Accordion(\"ğŸ“„ Quick Search Results - Fast vector & keyword matching\", open=True, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"### ğŸ’¬ AI Answer:\")\n",
    "            basic_answer_output = gr.HTML(\n",
    "                value=\"<p class='loading-text'>Answer will appear here after search</p>\",\n",
    "                elem_id=\"basic_answer\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### ğŸ“š Source Documents:\")\n",
    "                    basic_search_output = gr.HTML(\n",
    "                        \"<p class='loading-text'>Documents will appear here</p>\",\n",
    "                        elem_id=\"basic_search\"\n",
    "                    )\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### â„¹ï¸ Search Details:\")\n",
    "                    basic_metadata_output = gr.HTML(\n",
    "                        \"<p class='loading-text'>Details will appear here</p>\",\n",
    "                        elem_id=\"basic_metadata\"\n",
    "                    )\n",
    "\n",
    "        # =================== DEEP ANALYSIS RESULTS (ACCORDION) ===================  \n",
    "        with gr.Accordion(\"ğŸš€ Deep Analysis Results - Comprehensive AI-powered analysis\", open=True, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"### ğŸ’¬ AI Answer:\")\n",
    "            advanced_answer_output = gr.HTML(\n",
    "                value=\"<p class='loading-text'>Answer will appear here after search</p>\",\n",
    "                elem_id=\"advanced_answer\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### ğŸ“š Source Documents:\")\n",
    "                    advanced_search_output = gr.HTML(\n",
    "                        \"<p class='loading-text' style='color: #6b7280; font-style: italic;'>Documents will appear here</p>\",\n",
    "                        elem_id=\"advanced_search\"\n",
    "                    )\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### â„¹ï¸ Search Details:\")\n",
    "                    advanced_metadata_output = gr.HTML(\n",
    "                        \"<p class='loading-text' style='color: #6b7280; font-style: italic;'>Details will appear here</p>\",\n",
    "                        elem_id=\"advanced_metadata\"\n",
    "                    )\n",
    "\n",
    "        # =================== Additional Information ===================\n",
    "        with gr.Accordion(\"ğŸ“ˆ Search Performance & Cost Details\", open=False, elem_classes=[\"accordion\"]):\n",
    "            timing_display = gr.Textbox(\n",
    "                label=\"Detailed Timing & Cost Analysis\",\n",
    "                lines=30,\n",
    "                interactive=False,\n",
    "                value=\"Performance metrics will appear here after search...\",\n",
    "                elem_id=\"timing-display\"\n",
    "            )\n",
    "\n",
    "        with gr.Accordion(\"â„¹ï¸ System Information\", open=False, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\n",
    "                f\"**System Status:** âœ… Operational\\n\\n\"\n",
    "                f\"â€¢ **Collection:** {collection_name}\\n\"\n",
    "                f\"â€¢ **Documents:** {total_docs:,}\\n\"\n",
    "                f\"â€¢ **Chunks:** {total_chunks:,}\\n\\n\"\n",
    "                f\"**About the Search Methods:**\\n\"\n",
    "                f\"â€¢ **Quick Results**: Fast hybrid search, good for specific catalog numbers\\n\"\n",
    "                f\"â€¢ **Deep Analysis**: Thorough AI analysis, best for complex research questions\\n\\n\"\n",
    "                f\"**Tips for best results:**\\n\"\n",
    "                f\"â€¢ Most searches work best without filters\\n\"\n",
    "                f\"â€¢ Results appear automatically after clicking SEARCH\\n\"\n",
    "                f\"â€¢ Both search methods run to give you the best possible answers\"\n",
    "            )\n",
    "\n",
    "        # ---------- Estados para pasar info entre fases ----------\n",
    "        st_ctx = gr.State({})\n",
    "\n",
    "        # ---------- Eventos SIN progress bar de Gradio ----------\n",
    "        # Click en botÃ³n de bÃºsqueda\n",
    "        search_btn.click(\n",
    "            fn=run_basic_search,\n",
    "            inputs=[query_input, year_start, year_end, scott_numbers, max_results, st_ctx],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display, st_ctx\n",
    "            ],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        ).then(\n",
    "            fn=run_advanced_search,\n",
    "            inputs=[query_input, max_results, st_ctx],\n",
    "            outputs=[advanced_answer_output, advanced_search_output, advanced_metadata_output, timing_display, st_ctx],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        )\n",
    "\n",
    "        # Enter en textbox\n",
    "        query_input.submit(\n",
    "            fn=run_basic_search,\n",
    "            inputs=[query_input, year_start, year_end, scott_numbers, max_results, st_ctx],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display, st_ctx\n",
    "            ],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        ).then(\n",
    "            fn=run_advanced_search,\n",
    "            inputs=[query_input, max_results, st_ctx],\n",
    "            outputs=[advanced_answer_output, advanced_search_output, advanced_metadata_output, timing_display, st_ctx],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        )\n",
    "\n",
    "        # Botones de ejemplo\n",
    "        btn1.click(fn=set_example_1, outputs=[query_input])\n",
    "        btn2.click(fn=set_example_2, outputs=[query_input])\n",
    "        btn3.click(fn=set_example_3, outputs=[query_input])\n",
    "        btn4.click(fn=set_example_4, outputs=[query_input])\n",
    "        btn5.click(fn=set_example_5, outputs=[query_input])\n",
    "        btn6.click(fn=set_example_6, outputs=[query_input])\n",
    "\n",
    "        # Habilitar cola para mejor manejo de eventos\n",
    "        interface.queue()\n",
    "\n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Enhanced launcher ----\n",
    "if rag_system and rag_system.get(\"success\", False):\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸš€ LAUNCHING COSTA RICA PHILATELIC RAG INTERFACE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gradio_app = create_gradio_interface(rag_system)\n",
    "\n",
    "    GRADIO_PORT = int(os.getenv(\"GRADIO_PORT\", 7860))\n",
    "    GRADIO_SHARE = os.getenv(\"GRADIO_SHARE\", \"false\").lower() == \"true\"\n",
    "\n",
    "    print(f\"âš™ï¸ Port: {GRADIO_PORT}\")\n",
    "    print(f\"ğŸŒ Public URL: {'âš ï¸ Attempting...' if GRADIO_SHARE else 'âŒ Disabled (more secure)'}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ”„ Starting Gradio server...\")\n",
    "        \n",
    "        if GRADIO_SHARE:\n",
    "            print(\"â³ Attempting to create public tunnel...\")\n",
    "            try:\n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=True,\n",
    "                    inbrowser=False,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False,\n",
    "                    quiet=False,\n",
    "                )\n",
    "                \n",
    "                print(\"\\\\nğŸ‰ SUCCESS! Public tunnel created\")\n",
    "                print(f\"ğŸŒ AVAILABLE URLS:\")\n",
    "                print(f\"   ğŸ“± Local: http://localhost:{GRADIO_PORT}\")\n",
    "                \n",
    "                if hasattr(demo, 'share_url') and demo.share_url:\n",
    "                    print(f\"   ğŸŒ Public: {demo.share_url}\")\n",
    "                    print(f\"\\\\nğŸ”— **PUBLIC URL:** {demo.share_url}\")\n",
    "                else:\n",
    "                    print(f\"   ğŸŒ Public: Check Gradio output above â˜ï¸\")\n",
    "                \n",
    "            except Exception as share_error:\n",
    "                print(f\"âš ï¸ Error creating public tunnel: {share_error}\")\n",
    "                print(\"ğŸ”„ Switching to local mode only...\")\n",
    "                \n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=False,\n",
    "                    inbrowser=True,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False\n",
    "                )\n",
    "                \n",
    "                print(f\"\\\\nâœ… LOCAL SERVER OPERATIONAL:\")\n",
    "                print(f\"   ğŸ“± Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "                print(f\"   âš ï¸ Public URL: Not available (tunnel error)\")\n",
    "                \n",
    "        else:\n",
    "            demo = gradio_app.launch(\n",
    "                server_port=GRADIO_PORT,\n",
    "                share=False,\n",
    "                inbrowser=True,\n",
    "                show_error=True,\n",
    "                prevent_thread_lock=False\n",
    "            )\n",
    "            \n",
    "            print(f\"\\\\nâœ… LOCAL SERVER OPERATIONAL:\")\n",
    "            print(f\"   ğŸ“± Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "            print(f\"   ğŸ’¡ For public URL, set GRADIO_SHARE=true in .env\")\n",
    "        \n",
    "        print(f\"\\\\nğŸ“‹ COSTA RICA PHILATELIC FEATURES:\")\n",
    "        print(f\"   â€¢ Specialized Costa Rica stamp queries\")\n",
    "        print(f\"   â€¢ Scott catalog number search\")\n",
    "        print(f\"   â€¢ Variety and error detection\")\n",
    "        print(f\"   â€¢ Dual search approaches for comprehensive results\")\n",
    "        print(f\"   â€¢ Performance timing comparison\")\n",
    "        print(f\"   â€¢ To stop: gr.close_all()\")\n",
    "        \n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"ğŸ‡¨ğŸ‡· COSTA RICA PHILATELIC RAG INTERFACE READY!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Critical error launching Gradio: {e}\")\n",
    "        print(\"\\\\nğŸ”§ SUGGESTED SOLUTIONS:\")\n",
    "        print(\"   1. Run: gr.close_all()\")\n",
    "        print(\"   2. Change port: GRADIO_PORT=7861 in .env\")\n",
    "        print(\"   3. Verify no other services on the port\")\n",
    "        print(\"   4. Restart the notebook\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\\\nâš ï¸  Cannot create Gradio interface:\")\n",
    "    if not rag_system:\n",
    "        print(\"   â€¢ RAG system not configured\")\n",
    "    else:\n",
    "        print(f\"   â€¢ RAG error: {rag_system.get('error', 'Unknown error')}\")\n",
    "    print(\"\\\\nğŸ”§ To resolve:\")\n",
    "    print(\"   1. Verify Weaviate is running\")\n",
    "    print(\"   2. Configure OPENAI_API_KEY in .env\") \n",
    "    print(\"   3. Run document indexing\")\n",
    "    print(\"   4. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-clean (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
