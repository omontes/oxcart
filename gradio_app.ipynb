{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philatelic Gradio App with Weaviate\n",
    "Interactive web interface for CR Philately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "Load all the modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mena issue\n",
    "from pathlib import Path\n",
    "import json\n",
    "PATH = Path(\"C:/Users/VM-SERVER/Desktop/Oxcart RAG/results/parsed_catalogues/mena_all_with_raw.json\")\n",
    "\n",
    "# Cargar\n",
    "with PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    mena_parsed_catalog = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "import re, time, math, hashlib\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from datetime import datetime\n",
    "import weaviate\n",
    "from weaviate.classes import query as wv_query\n",
    "from weaviate.classes.query import Filter as WvFilter\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "from neo4j_utils.neo4j_search import *\n",
    "#from neo4j_utils.neo4j_gradio_VIS import *\n",
    "\n",
    "import time\n",
    "\n",
    "import markdown\n",
    "\n",
    "# Load environment variables\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import AuthError\n",
    "from neo4j.graph import Node, Relationship, Path\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.retrievers import MultiQueryRetriever, EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "from philatelic_weaviate import *\n",
    "\n",
    "from philatelic_chunk_schema import *\n",
    "\n",
    "print(\"‚úÖ Basic imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8083')\n",
    "PHILATELIC_JSONS_DIR = os.getenv('PHILATELIC_JSONS_DIR', './results/final_jsons')\n",
    "COLLECTION_NAME = os.getenv('WEAVIATE_COLLECTION_NAME', 'Oxcart')\n",
    "\n",
    "print(f\"üîß Configuration:\")\n",
    "print(f\"   ‚Ä¢ Weaviate URL: {WEAVIATE_URL}\")\n",
    "print(f\"   ‚Ä¢ JSONs Directory: {PHILATELIC_JSONS_DIR}\")\n",
    "print(f\"   ‚Ä¢ Collection Name: {COLLECTION_NAME}\")\n",
    "print(f\"   ‚Ä¢ OpenAI API Key: {'‚úÖ Configured' if OPENAI_API_KEY else '‚ùå Missing configuration'}\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"\\\\n‚ö†Ô∏è  IMPORTANT: Configure your OPENAI_API_KEY in the .env file\")\n",
    "    print(\"   Copy .env.example to .env and add your API key\")\n",
    "\n",
    "# Verify that the JSONs directory exists\n",
    "if not os.path.exists(PHILATELIC_JSONS_DIR):\n",
    "    print(f\"\\\\n‚ö†Ô∏è  Directory {PHILATELIC_JSONS_DIR} not found\")\n",
    "    print(\"   Make sure you have processed documents with the Dolphin parser\")\n",
    "else:\n",
    "    json_files = glob.glob(os.path.join(PHILATELIC_JSONS_DIR, '*_final.json'))\n",
    "    print(f\"\\\\nüìÅ Found {len(json_files)} philatelic JSON files\")\n",
    "    if json_files:\n",
    "        print(\"   Examples:\")\n",
    "        for file in json_files[:3]:\n",
    "            print(f\"   ‚Ä¢ {os.path.basename(file)}\")\n",
    "        if len(json_files) > 3:\n",
    "            print(f\"   ‚Ä¢ ... and {len(json_files) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-5-mini\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=1,  # 1 obligatorio para gpt-5-mini\n",
    "            timeout=120.0,\n",
    "            max_completion_tokens=2500,\n",
    "            model_kwargs={\n",
    "                \"verbosity\": \"low\",\n",
    "                \"reasoning_effort\" : \"low\"\n",
    "            }\n",
    "            )\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# üìù RAG PROMPT TEMPLATE - Professional Philatelic Consultation\n",
    "# ========================================================================================\n",
    "\n",
    "philatelic_rag_template = \"\"\"You are a distinguished philatelic researcher specializing in Costa Rican stamps and postal history. Provide authoritative, well-structured analysis based exclusively on the provided source materials.\n",
    "\n",
    "## ‚ùì RESEARCH QUERY  \n",
    "{question}\n",
    "    \n",
    "## üìÆ KNOWLEDGE PHILATELIC ISSUE INFO (THE MOST ACCURATE INFO)\n",
    "{graph_data}\n",
    "\n",
    "## üìö SOURCE MATERIALS (FROM CHUNKS OF TEXT OF ARTICLES OR JOURNAL RELATED TO THE QUERY)\n",
    "{context}\n",
    "\n",
    "\n",
    "## üìã RESPONSE FRAMEWORK\n",
    "\n",
    "### üéØ **READABILITY REQUIREMENTS**\n",
    "\n",
    "**LENGTH CONTROL:**\n",
    "‚Ä¢ Target 800-1200 words maximum for comprehensive topics\n",
    "‚Ä¢ Use 400-600 words for straightforward queries\n",
    "‚Ä¢ Eliminate redundant explanations between sections\n",
    "‚Ä¢ Prioritize the most important information that directly answers the query\n",
    "\n",
    "**CONCISE WRITING STYLE:**\n",
    "‚Ä¢ Use clear, direct sentences (15-20 words maximum per sentence)\n",
    "‚Ä¢ Avoid unnecessary qualifying phrases (\"it should be noted that\", \"it is important to mention\")\n",
    "‚Ä¢ Lead with conclusions, then provide supporting details\n",
    "‚Ä¢ Use active voice: \"Scott C216 exists in two varieties\" not \"Two varieties of Scott C216 can be found\"\n",
    "\n",
    "**INFORMATION HIERARCHY:**\n",
    "‚Ä¢ Start with the most direct answer to the query\n",
    "‚Ä¢ Group related information to avoid scattering details\n",
    "‚Ä¢ Use parallel structure in lists and sections\n",
    "‚Ä¢ Eliminate overlapping content between sections\n",
    "\n",
    "**FORMATTING & STRUCTURE:**\n",
    "- Use clear hierarchical organization with descriptive headers using markdown\n",
    "- Group related information under logical categories using ## and **bold subheadings**\n",
    "- Use bullet points (‚Ä¢) for individual facts and varieties\n",
    "- Include relevant emojis for major sections (üîç üìÆ üìö üéØ) to enhance readability\n",
    "- Bold key terms, catalog numbers, and important details\n",
    "- Your output is in markdown format\n",
    "\n",
    "### üìù **STRUCTURAL ORGANIZATION**\n",
    "\n",
    "**1. EXECUTIVE SUMMARY (Required)**\n",
    "‚Ä¢ 2-3 sentences maximum\n",
    "‚Ä¢ Direct answer to the query\n",
    "‚Ä¢ Key finding or conclusion upfront\n",
    "\n",
    "**2. CORE ANALYSIS SECTIONS**\n",
    "Use these section headers as appropriate (not all required):\n",
    "‚Ä¢ **Catalog Details** - for Scott/Yvert numbers, varieties, specifications\n",
    "‚Ä¢ **Historical Context** - for background and significance  \n",
    "‚Ä¢ **Technical Specifications** - for printing, perforations, paper types\n",
    "‚Ä¢ **Collecting Notes** - for rarity, valuation, market insights\n",
    "‚Ä¢ **Related Issues** - for connections to other stamps or series\n",
    "\n",
    "**3. KEY FINDINGS (Required)**\n",
    "‚Ä¢ Bullet points summarizing main discoveries\n",
    "‚Ä¢ Include specific catalog numbers and varieties\n",
    "‚Ä¢ Note any gaps in available information\n",
    "\n",
    "### üîó **ENHANCED CITATION FORMAT**\n",
    "‚Ä¢ Every factual claim: (Source_Name, page XX)\n",
    "‚Ä¢ Multiple sources: (Source_A, page XX; Source_B, page YY)\n",
    "‚Ä¢ Direct quotes: \"quoted text\" (Source_Name, page XX)\n",
    "‚Ä¢ Uncertain information: \"According to [Source], this appears to be...\" (Source_Name, page XX)\n",
    "\n",
    "### ‚ö° **WRITING EFFICIENCY RULES**\n",
    "\n",
    "**ELIMINATE THESE PATTERNS:**\n",
    "‚Ä¢ \"It is worth noting that...\"\n",
    "‚Ä¢ \"It should be mentioned that...\"\n",
    "‚Ä¢ \"Furthermore, it is important to understand...\"\n",
    "‚Ä¢ \"In addition to the above information...\"\n",
    "‚Ä¢ Repetitive introductory phrases\n",
    "\n",
    "**USE THESE PATTERNS:**\n",
    "‚Ä¢ \"Scott C216 exists in two varieties:\" (direct statement)\n",
    "‚Ä¢ \"The 1963 issue includes:\" (immediate specifics)\n",
    "‚Ä¢ \"Collectors should note:\" (actionable information)\n",
    "‚Ä¢ \"Sources differ on:\" (clear conflict acknowledgment)\n",
    "\n",
    "**PARAGRAPH STRUCTURE:**\n",
    "‚Ä¢ Topic sentence with main point\n",
    "‚Ä¢ 1-2 supporting sentences with specifics\n",
    "‚Ä¢ Citation at end of factual claims\n",
    "‚Ä¢ Maximum 4 sentences per paragraph\n",
    "\n",
    "### üìä **SECTION LENGTH GUIDELINES**\n",
    "‚Ä¢ Executive Summary: 50-75 words\n",
    "‚Ä¢ Each analysis section: 150-250 words maximum\n",
    "‚Ä¢ Key Findings: 75-100 words\n",
    "‚Ä¢ Total response: Stay within word count targets above\n",
    "\n",
    "### üéØ **TECHNICAL PRECISION**\n",
    "‚Ä¢ Lead with catalog numbers: \"Scott C216 (10¬¢ green)\" not \"The 10¬¢ green stamp, cataloged as Scott C216\"\n",
    "‚Ä¢ Use parallel structure: \"Scott C216a (perf 12), Scott C216b (perf 11¬Ω)\" \n",
    "‚Ä¢ Group similar information: List all varieties together, not scattered\n",
    "‚Ä¢ Specific dates: \"Issued March 15, 1963\" not \"Issued in early 1963\"\n",
    "\n",
    "### ‚úÖ **QUALITY CONTROL CHECKLIST**\n",
    "Before finalizing response, verify:\n",
    "- [ ] Executive summary answers the query directly\n",
    "- [ ] No redundant information between sections\n",
    "- [ ] All sections stay within length limits\n",
    "- [ ] Citations are complete and properly formatted\n",
    "- [ ] Technical details are grouped logically\n",
    "- [ ] Conclusion reinforces key findings without repetition\n",
    "\n",
    "## üö´ **CRITICAL RESTRICTIONS**\n",
    "‚Ä¢ **NO speculation** beyond source materials\n",
    "‚Ä¢ **NO redundant explanations** - if mentioned once, don't repeat\n",
    "‚Ä¢ **NO excessive hedging** - state facts confidently when sources support them\n",
    "‚Ä¢ **NO filler phrases** - every sentence must add value\n",
    "‚Ä¢ **NO circular explanations** - don't explain the same point multiple ways\n",
    "\n",
    "---\n",
    "\n",
    "**RESPONSE:**\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=philatelic_rag_template,\n",
    "    input_variables=[\"question\", \"context\", \"graph_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# üìÑ OPTIMIZED DOCUMENT FORMATTING - For Academic Citation Style\n",
    "# ========================================================================================\n",
    "\n",
    "def format_docs_for_rag(docs_results: List[Dict]) -> str:\n",
    "    \"\"\"Efficient document formatting optimized for academic citation style (Document Name, p. Page)\"\"\"\n",
    "    \n",
    "    if not docs_results:\n",
    "        return \"\\nNo source documents available.\"\n",
    "    \n",
    "    # Group and sort documents by authority\n",
    "    #doc_groups = {'catalog': [], 'literature': [], 'collection': [], 'reference': []}\n",
    "    docs = []\n",
    "    \n",
    "    for i, doc in enumerate(docs_results, 1):\n",
    "        #category, reliability = classify_document_authority(doc.metadata.get('doc_id', 'Unknown'))\n",
    "        \n",
    "        doc_info = {\n",
    "            'doc_num': i,\n",
    "            'doc_id': doc.metadata.get('doc_id', 'Unknown'),\n",
    "            'page': doc.metadata.get('page_number', 'N/A'),\n",
    "            'content': doc.page_content,\n",
    "        }\n",
    "        #doc_groups[category].append(doc_info)\n",
    "        docs.append(doc_info)\n",
    "    return docs\n",
    "\n",
    "def create_rag_response(retriever_results: List[Dict], query: str) -> Dict:\n",
    "    \"\"\"Streamlined RAG chain execution with academic citation style and token tracking\"\"\"\n",
    "    \n",
    "    if not retriever_results:\n",
    "        return {\n",
    "            \"response\": \"No documents found for this query.\", \n",
    "            \"generation_time\": 0,\n",
    "            \"context_docs_count\": 0,\n",
    "            \"context_length\": 0,\n",
    "            \"token_usage\": {\n",
    "                \"input_tokens\": 0,\n",
    "                \"output_tokens\": 0,\n",
    "                \"total_tokens\": 0\n",
    "            },\n",
    "            \"cost_info\": {\n",
    "                \"estimated_cost_usd\": 0,\n",
    "                \"input_cost\": 0,\n",
    "                \"output_cost\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Format context efficiently for academic citations\n",
    "    context = format_docs_for_rag(retriever_results)\n",
    "    \n",
    "    # Get Graph Knowledge Data\n",
    "    graph_knowledge_data = getGraphKnowledgeData(query)\n",
    "    print(graph_knowledge_data)\n",
    "    \n",
    "    \n",
    "    # Execute RAG chain with OpenAI callback for token tracking\n",
    "    rag_chain = (\n",
    "        {\"question\": RunnablePassthrough(), \"context\": lambda x: context, \"graph_data\": lambda y: graph_knowledge_data}\n",
    "        | rag_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use OpenAI callback to track token usage\n",
    "    with get_openai_callback() as cb:\n",
    "        response = rag_chain.invoke(query)\n",
    "        # Get token counts from callback\n",
    "        input_tokens = cb.prompt_tokens\n",
    "        output_tokens = cb.completion_tokens\n",
    "        total_tokens = cb.total_tokens\n",
    "        \n",
    "        # OpenAI callback provides cost directly, but we'll calculate our own\n",
    "        # based on GPT-5-mini pricing\n",
    "    \n",
    "    generation_time = round(time.time() - start_time, 2)\n",
    "    \n",
    "    # Calculate costs for GPT-5-mini\n",
    "    # $0.05 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    cost_per_1m_input = 0.250\n",
    "    cost_per_1m_output = 2.0\n",
    "    \n",
    "    # Calculate costs for GPT-4.1-nano\n",
    "    # $0.10 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    # cost_per_1m_input = 0.10\n",
    "    # cost_per_1m_output = 0.40\n",
    "    \n",
    "    # Convert to cost per token\n",
    "    cost_per_input_token = cost_per_1m_input / 1_000_000\n",
    "    cost_per_output_token = cost_per_1m_output / 1_000_000\n",
    "    \n",
    "    input_cost = input_tokens * cost_per_input_token\n",
    "    output_cost = output_tokens * cost_per_output_token\n",
    "    estimated_cost = input_cost + output_cost\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"generation_time\": generation_time,\n",
    "        \"context_docs_count\": len(retriever_results),\n",
    "        \"context_length\": len(context),        \n",
    "        \"token_usage\": {\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"total_tokens\": total_tokens\n",
    "        },\n",
    "        \"cost_info\": {\n",
    "            \"estimated_cost_usd\": round(estimated_cost, 6),\n",
    "            \"input_cost\": round(input_cost, 6),\n",
    "            \"output_cost\": round(output_cost, 6)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weaviate Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Weaviate\n",
    "print(\"üîå Connecting to Weaviate...\")\n",
    "\n",
    "try:\n",
    "    client = create_weaviate_client(WEAVIATE_URL, OPENAI_API_KEY)\n",
    "    print(\"‚úÖ Connection successful\")\n",
    "    \n",
    "    # Verify that Weaviate is working\n",
    "    meta = client.get_meta()\n",
    "    print(f\"üìä Weaviate version: {meta.get('version', 'unknown')}\")\n",
    "    \n",
    "    # Verify if collection exists\n",
    "    try:\n",
    "        collections = client.collections.list_all()\n",
    "        collection_names = [col.name for col in collections]\n",
    "        \n",
    "        if COLLECTION_NAME in collection_names:\n",
    "            collection = client.collections.get(COLLECTION_NAME)\n",
    "            total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "            print(f\"üìä Collection '{COLLECTION_NAME}' exists with {total_objects} documents\")\n",
    "        else:\n",
    "            print(f\"üìù Collection '{COLLECTION_NAME}' does not exist (will be created during indexing)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not verify collections: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Weaviate: {e}\")\n",
    "    print(\"üí° Make sure Weaviate is running:\")\n",
    "    print(\"   docker-compose up -d\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weaviate Search Tests\n",
    "\n",
    "Test the function search_chunks_semantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_chunks_semantic(\n",
    "                client, \n",
    "                \"Costa Rica 1907 2 colones stamp with original gum. Scott 68 issue of 1907\", \n",
    "                \"Oxcart\", \n",
    "                limit=50,\n",
    "                filters=[],\n",
    "                mode = \"hybrid\",\n",
    "                alpha= 0.35\n",
    "                \n",
    "            )\n",
    "            \n",
    "print(f\"   üìä Resultados: {len(results)}\")\n",
    "\n",
    "for j, result in enumerate(results, 1):\n",
    "    print(f\"\\n      üè∑Ô∏è #{j} (Score: {result['score']:.3f})\")\n",
    "    print(f\"         üìÑ Documento: {result['doc_id']}\")\n",
    "    print(f\"         üìã Tipo: {result['chunk_type']}\")\n",
    "    print(f\"         üìÑ P√°gina: {result['page_number']}\")\n",
    "    \n",
    "    # Mostrar metadatos relevantes\n",
    "    if result.get('catalog_systems'):\n",
    "        print(f\"         üìñ Cat√°logos: {result['catalog_systems']}\")\n",
    "    if result.get('scott_numbers'):\n",
    "        print(f\"         üî¢ Scott: {result['scott_numbers']}\")\n",
    "    if result.get('years'):\n",
    "        print(f\"         üìÖ A√±os: {result['years']}\")\n",
    "    if result.get('colors'):\n",
    "        print(f\"         üé® Colores: {result['colors']}\")\n",
    "    if result.get('variety_classes'):\n",
    "        print(f\"         üîÄ Variedades: {result['variety_classes']}\")\n",
    "    \n",
    "    # Texto truncado\n",
    "    text = result.get('text', '')\n",
    "    # if len(text) > 200:\n",
    "    #     text = text[:200] + \"...\"\n",
    "    print(f\"         üìù Texto: {text}\")\n",
    "    print(\"**********************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get a Lucene Query for the Graph using the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucene_query_builder_optimized.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LLM-driven Lucene Query Builder (ES/EN) ‚Äî optimized for Costa Rica philately\n",
    "- Input: user natural-language query (string)\n",
    "- Output: ONE Lucene query string (single line) for Neo4j FULLTEXT\n",
    "- Stack: LangChain + OpenAI Chat model (few-shot + strict system rules)\n",
    "- Optimization:\n",
    "    * The domain is already Costa Rica philately ‚Üí DO NOT force \"Costa Rica\".\n",
    "    * Do NOT force generic anchors like \"stamps/sellos\" (too common).\n",
    "    * Use two complementary subqueries merged into a single string: (Q1) OR (Q2).\n",
    "\"\"\"\n",
    "\n",
    "import os, re\n",
    "from typing import Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "def find_by_issue_id(catalog: List[Dict[str, Any]], target_id: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    for i, item in enumerate(catalog):\n",
    "        issue_id = item.get('issue_data', {}).get('issue_id')\n",
    "        if issue_id == target_id:\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "def _escape_jinja(s: str) -> str:\n",
    "    return s.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# System Prompt (optimized v2)\n",
    "# =========================\n",
    "_SYSTEM_PROMPT_RAW = \"\"\"\n",
    "You are a LuceneQueryBuilder for Neo4j FULLTEXT focused on Costa Rica philately.\n",
    "\n",
    "Goal:\n",
    "- Transform a user natural-language query into ONE single-line Lucene string.\n",
    "- Return ONLY the Lucene string (no code fences, no JSON, no commentary).\n",
    "\n",
    "Critical domain constraints:\n",
    "- The corpus is ALREADY restricted to Costa Rica stamps ‚Üí DO NOT add \"Costa Rica\" unless the user asks for a DIFFERENT country/region.\n",
    "- \"stamps\"/\"sellos\" are generic and ubiquitous in this domain ‚Üí DO NOT force them as required terms.\n",
    "- Prefer concise, high-signal terms: themes, varieties/errors, denominations, years, techniques, fauna/flora, dishes, perforations, colors, overprints/surcharges.\n",
    "\n",
    "Construction rules:\n",
    "- Build TWO complementary subqueries and combine into ONE string: (Q1) OR (Q2)\n",
    "  ‚Ä¢ Q1 (precise): strict AND using '+'; quote multi-word key phrases; when the user lists alternatives, require \"at least one\" with +(<a> OR <b> ...).\n",
    "  ‚Ä¢ Q2 (broader): OR groups with light wildcards/fuzzy for recall; can drop some constraints but keep the topic intact.\n",
    "- Use ES/EN bilingual terminology when it increases recall (e.g., \"inverted center\" OR \"centro invertido\").\n",
    "- Use Unicode and diacritics when relevant (e.g., 10¬Ω, oc√©ano).\n",
    "- Keep it safe and unambiguous; no fielded search, only generic Lucene syntax.\n",
    "\n",
    "‚ÄúAt least one‚Äù requirement:\n",
    "- If the user lists several candidate items (animals, dishes, colors, values...), require AT LEAST ONE via a single must-have OR-bucket:\n",
    "  +(<term1> OR <term2> OR <term3>)\n",
    "\n",
    "Exclusions:\n",
    "- If the user says \"not X\", \"except X\", or \"without X\", add negative terms:\n",
    "  -<token> or -(\"multi word\")\n",
    "  Examples: -specimen* -\"first day cover\" -ensayo* -prueba*\n",
    "\n",
    "Year handling (critical):\n",
    "- If the user mentions a year range (e.g., \"1952-53\", \"1952‚Äì53\", \"1952/53\", \"1952 to 1953\"):\n",
    "  1) Normalize to (start_year, end_year). Short \"1952-53\" means 1952‚Äì1953.\n",
    "  2) In Q1 (precise), require BOTH endpoints with AND:\n",
    "       +1952 +1953\n",
    "     AND ALSO include common range spellings in an OR bucket:\n",
    "       +(\"1952-53\" OR \"1952‚Äì53\" OR \"1952/53\" OR \"1952 to 1953\")\n",
    "  3) In Q2 (broader), allow any of: 1952 OR 1953 OR the range spellings.\n",
    "- If only one year is present, include that year as-is.\n",
    "- Never add years that are not implied by the query.\n",
    "\n",
    "Denominations & ‚ÄúX on Y‚Äù (surcharges):\n",
    "- Include denominations literally if present (e.g., \"65c\", \"3 col\", \"3c\").\n",
    "- For surcharges/overprints like \"2c on ¬Ωr\", include both \"2c on ¬Ωr\" and \"2c on 1/2r\".\n",
    "- Use bilingual overprint/surcharge buckets when relevant:\n",
    "  (\"overprint\" OR \"surcharge\" OR \"sobreimpresi√≥n\" OR \"sobrecarga\")\n",
    "\n",
    "Perforations & colors:\n",
    "- Perforations: (perfor* OR \"perf\" OR \"perforaci√≥n\" OR \"10.5\" OR \"10¬Ω\")\n",
    "- Colors: allow ES/EN variants in OR buckets when they are key filters.\n",
    "\n",
    "Helpful bilingual buckets (only when relevant to the user query):\n",
    "- Marine life: (\"sea animals\" OR \"marine life\" OR \"sea life\" OR \"vida marina\" OR marino*)\n",
    "               (fish OR fishes OR pez* OR tortuga* OR turtle* OR coral* OR reef* OR ocean* OR oc√©ano* OR mar*)\n",
    "- Errors/Varieties: (error* OR variety OR varieties OR variedad* OR \"printing error\")\n",
    "- Inverted center: (\"inverted center\" OR \"inverted centre\" OR \"centro invertido\" OR \"invertido de centro\")\n",
    "- Farm animals: (\"farm animals\" OR \"animales de granja\" OR granja* OR av√≠cola* OR poultry*)\n",
    "                (chicken* OR pollo OR gallina* OR gallo* OR rooster* OR roaster* OR pig* OR cerdo* OR puerco*)\n",
    "- Food / local dishes: (\"local dishes\" OR \"platos t√≠picos\" OR \"platos tipicos\" OR \"comida t√≠pica\" OR \"comida tipica\")\n",
    "                       (\"gallo pinto\" OR \"olla de carne\" OR \"vegetales\" OR \"frijoles\" OR chicken* OR pollo)\n",
    "- Postal tax (CT/RA context): (\"postal tax\" OR \"impuesto postal\" OR navidad OR christmas)\n",
    "\n",
    "Adaptive thematic expansion (general rule):\n",
    "\n",
    "    When the user query implies a theme (fauna, flora, food, sports, maps, coats of arms, charities, UPU, anniversaries, etc.), build two buckets with ES/EN coverage, accents, plurals, and common variants:\n",
    "\n",
    "    Q1 (must-have, at least one): +( <THEME_CORE_OR> )\n",
    "\n",
    "    Q2 (broader recall): ( <THEME_CORE_OR> OR <THEME_EXTRAS_OR> )\n",
    "\n",
    "    Theme bucket construction guide (apply only if relevant):\n",
    "\n",
    "    Core nouns & stems for the theme in ES/EN, with accents + unaccented forms, plurals via *.\n",
    "\n",
    "    Use forms like p√°jaro* / pajaro*, tuc√°n* / tucan*, √°guila* / aguila*, mar* / oc√©ano* / ocean*, etc.\n",
    "\n",
    "    Representative subtypes / exemplars (species, dishes, sports terms, organizations), again ES/EN with variants.\n",
    "\n",
    "    If the user enumerates items (e.g., ‚Äúchicken, pig, rooster‚Äù): require at least one with +(a OR b OR c) inside Q1.\n",
    "\n",
    "    If negatives appear (‚Äúnot X / without X / except X‚Äù): add -token or -(\"multi word\").\n",
    "\n",
    "    Do not add unrelated themes. Keep buckets concise and high-signal.\n",
    "\n",
    "    Examples of forms to include:\n",
    "\n",
    "    Accents & variants: tuc√°n* OR tucan*, √°guila* OR aguila*, p√°jaro* OR pajaro*.\n",
    "\n",
    "    Plurals/stems: ave OR aves, flower* OR flor*, butterfl* OR mariposa*.\n",
    "\n",
    "    Synonyms: \"bird of prey\", avifauna; \"postal tax\" OR \"impuesto postal\", etc.\n",
    "\n",
    "Output MUST be a single line like (illustrative structure):\n",
    "+( \"inverted center\" OR \"centro invertido\" ) +1952 +1953 +(\"1952-53\" OR \"1952‚Äì53\") OR ( inverted* AND (center* OR centre* OR centro*) AND (1952 OR 1953) )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = _escape_jinja(_SYSTEM_PROMPT_RAW)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Few-shot Examples (optimized to avoid boilerplate like \"Costa Rica\" and \"stamps\")\n",
    "# =========================\n",
    "\n",
    "# A) Marine life (no boilerplate like \"Costa Rica\"/\"stamps\")\n",
    "FS_IN_A  = 'Costa Rica Sea Animals stamps like fish, turtles, corals'\n",
    "FS_OUT_A = '(+(\"sea animals\" OR \"marine life\" OR \"sea life\" OR \"vida marina\" OR marino*) +(fish OR fishes OR pez* OR tortuga* OR turtle* OR coral* OR reef* OR ocean* OR oc√©ano* OR mar*)) OR ((sea* OR marine* OR mar* OR oc√©ano* OR ocean*) AND (fish OR pez* OR turtle* OR tortuga* OR coral* OR reef*))'\n",
    "\n",
    "# B) Inverted center\n",
    "FS_IN_B  = 'tell me all about center inverted stamps'\n",
    "FS_OUT_B = '(+(\"inverted center\" OR \"inverted centre\" OR \"centro invertido\" OR \"invertido de centro\")) OR (inverted* AND (center* OR centre* OR centro*))'\n",
    "\n",
    "# C) President portraits 1986 blue perforation 10.5\n",
    "FS_IN_C  = 'Costa Rica President Portraits 1986 blue perforation 10.5'\n",
    "FS_OUT_C = '(+(\"President Portraits\" OR \"Presidentes\" OR retratos) +(1986) +(blue OR azul) +(\"10.5\" OR \"10¬Ω\" OR perfor*)) OR ((president* OR presidente* OR retrato*) AND (1986) AND (blue OR azul) AND (perfor* OR \"10.5\" OR \"10¬Ω\"))'\n",
    "\n",
    "# D) Postal tax / Navidad\n",
    "FS_IN_D  = 'Christmas postal tax Costa Rica'\n",
    "FS_OUT_D = '(+(\"postal tax\" OR \"impuesto postal\" OR navidad OR christmas)) OR ((\"postal tax\" OR \"impuesto postal\") AND (navidad OR christmas))'\n",
    "\n",
    "# E) Farm animals ‚Äî require AT LEAST ONE animal (your chicken case fits here)\n",
    "FS_IN_E  = 'farm animals like chicken, pigs, rooster'\n",
    "FS_OUT_E = '(+(\"farm animals\" OR \"animales de granja\" OR granja* OR av√≠cola* OR poultry*) +(chicken* OR pollo OR gallina* OR gallo* OR rooster* OR roaster* OR pig* OR cerdo* OR puerco*)) OR ((farm* OR granja* OR av√≠cola* OR poultry*) AND (chicken* OR pollo OR gallina* OR gallo* OR rooster* OR roaster* OR pig* OR cerdo* OR puerco*))'\n",
    "\n",
    "# F) Airmail Definitive issue of 1952-53 ‚Äî years expanded\n",
    "FS_IN_F  = 'Airmail Definitive issue of 1952-53'\n",
    "FS_OUT_F = '(+(\"airmail\" OR \"correo a√©reo\" OR \"correo aereo\") +(\"definitive\" OR \"definitivos\" OR \"emisi√≥n definitiva\" OR \"serie definitiva\") +1952 +1953 +(\"1952-53\" OR \"1952‚Äì53\" OR \"1952/53\" OR \"1952 to 1953\")) OR ((airmail OR \"correo a√©reo\" OR \"correo aereo\") AND (definitive OR definitivos OR \"emisi√≥n definitiva\" OR \"serie definitiva\") AND (1952 OR 1953 OR \"1952-53\" OR \"1952‚Äì53\" OR \"1952/53\" OR \"1952 to 1953\"))'\n",
    "\n",
    "# G) Overprint/Surcharge with denomination pattern (2c on ¬Ωr) + year\n",
    "FS_IN_G  = '1881 surcharge 2c on 1/2r overprint issues'\n",
    "FS_OUT_G = '(+1881 +(\"overprint\" OR \"surcharge\" OR \"sobreimpresi√≥n\" OR \"sobrecarga\") +(\"2c on 1/2r\" OR \"2c on ¬Ωr\")) OR ((1881) AND (\"overprint\" OR \"surcharge\" OR \"sobreimpresi√≥n\" OR \"sobrecarga\") AND (\"2c on 1/2r\" OR \"2c on ¬Ωr\"))'\n",
    "\n",
    "# H) Perforation + color filter\n",
    "FS_IN_H  = 'blue stamps perforation 13.5'\n",
    "FS_OUT_H = '(+(blue OR azul) +(\"13.5\" OR \"10¬Ω\" OR perfor*)) OR ((blue OR azul) AND (perfor* OR \"13.5\" OR \"10¬Ω\"))'\n",
    "\n",
    "# I) Exclusion example\n",
    "FS_IN_I  = 'errors 1962 not specimen'\n",
    "FS_OUT_I = '(+1962 +(error* OR variedad* OR \"printing error\") -specimen* -\"muestra\") OR ((1962) AND (error* OR variedad* OR \"printing error\") AND -specimen* AND -\"muestra\")'\n",
    "\n",
    "# J) Local dishes (2014 food set; chicken is one of the values)\n",
    "FS_IN_J  = 'local dishes chicken 2014'\n",
    "FS_OUT_J = '(+(\"local dishes\" OR \"platos t√≠picos\" OR \"platos tipicos\" OR \"comida t√≠pica\" OR \"comida tipica\") +(\"chicken\" OR pollo) +2014) OR ((\"local dishes\" OR \"platos t√≠picos\" OR \"platos tipicos\" OR \"comida t√≠pica\" OR \"comida tipica\") AND (chicken OR pollo) AND (2014))'\n",
    "\n",
    "# K) Thematic: Birds ‚Äî avoid adding \"Costa Rica\" or \"stamps\" boilerplate\n",
    "FS_IN_K  = 'bird stamps of costa rica'\n",
    "FS_OUT_K = '(+(bird* OR birds OR \"bird of prey\" OR avifauna OR ave OR aves OR p√°jaro* OR pajaro* OR colibr* OR \"hummingbird\" OR tuc√°n* OR tucan* OR quetzal* OR √°guila* OR aguila* OR garza* OR ibis* OR loro* OR perico* OR guacamaya* OR halc√≥n* OR halcon* OR b√∫ho* OR buho*)) OR ((bird* OR birds OR avifauna OR ave* OR p√°jaro* OR pajaro*) OR (colibr* OR \"hummingbird\" OR tuc√°n* OR tucan* OR quetzal* OR √°guila* OR aguila* OR garza* OR ibis* OR loro* OR perico* OR guacamaya* OR halc√≥n* OR halcon* OR b√∫ho* OR buho*))'\n",
    "\n",
    "def _few_shot_block():\n",
    "    example_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ])\n",
    "    return FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=[\n",
    "            {\"input\": FS_IN_A, \"output\": FS_OUT_A},\n",
    "            {\"input\": FS_IN_B, \"output\": FS_OUT_B},\n",
    "            {\"input\": FS_IN_C, \"output\": FS_OUT_C},\n",
    "            {\"input\": FS_IN_D, \"output\": FS_OUT_D},\n",
    "            {\"input\": FS_IN_E, \"output\": FS_OUT_E},\n",
    "            {\"input\": FS_IN_F, \"output\": FS_OUT_F},\n",
    "            {\"input\": FS_IN_G, \"output\": FS_OUT_G},\n",
    "            {\"input\": FS_IN_H, \"output\": FS_OUT_H},\n",
    "            {\"input\": FS_IN_I, \"output\": FS_OUT_I},\n",
    "            {\"input\": FS_IN_J, \"output\": FS_OUT_J},\n",
    "            {\"input\": FS_IN_K, \"output\": FS_OUT_K},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "class LuceneQueryBuilder:\n",
    "    \"\"\"\n",
    "    Builds ONE concise ES/EN Lucene query for Neo4j FULLTEXT, optimized for Costa Rica philately.\n",
    "    - Avoids boilerplate: does NOT force \"Costa Rica\" or \"stamps/sellos\".\n",
    "    - Returns a single-line string \"(Q1) OR (Q2)\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_api_key: str,\n",
    "        model_name: str = \"gpt-5-nano\",   # set your preferred model\n",
    "        temperature: float = 0.0,         # deterministic\n",
    "        timeout: float = 90.0,\n",
    "    ):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            api_key=openai_api_key,\n",
    "            temperature=temperature,\n",
    "            timeout=timeout,\n",
    "            model_kwargs={\"verbosity\": \"low\", \"reasoning_effort\": \"low\"},\n",
    "        )\n",
    "        self.parser = StrOutputParser()\n",
    "        self.chain = self._create_chain()\n",
    "\n",
    "        # Optional hard filters to strip boilerplate if the LLM slips\n",
    "        self._boilerplate_patterns = [\n",
    "            r'\\+\\s*\"Costa Rica\"',                        # + \"Costa Rica\"\n",
    "            r'\"Costa Rica\"',                             # \"Costa Rica\"\n",
    "            r'\\(\\s*stamps\\s+OR\\s+sellos[^\\)]*\\)',        # (stamps OR sellos ...)\n",
    "            r'\\+\\(\\s*stamps\\s+OR\\s+sellos[^\\)]*\\)',      # +(stamps OR sellos ...)\n",
    "            r'\\bstamps\\b|\\bsellos\\b|\\bsello\\*\\b',        # plain stamps/sellos terms\n",
    "        ]\n",
    "\n",
    "    def _create_chain(self):\n",
    "        few = _few_shot_block()\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", SYSTEM_PROMPT),\n",
    "            few,\n",
    "            (\"human\", \"{user_query}\"),\n",
    "        ])\n",
    "        return prompt | self.llm | self.parser\n",
    "\n",
    "    def _sanitize(self, q: str) -> str:\n",
    "        # Remove unwanted boilerplate if present, while keeping Lucene balanced\n",
    "        s = q\n",
    "        for pat in self._boilerplate_patterns:\n",
    "            s = re.sub(pat, \"\", s, flags=re.IGNORECASE)\n",
    "        # Collapse extra spaces and clean redundant OR/AND artifacts\n",
    "        s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "        s = re.sub(r\"\\(\\s+\\)\", \"\", s)\n",
    "        s = s.strip()\n",
    "        # Ensure outer OR structure looks clean: ( ... ) OR ( ... )\n",
    "        # If the model returned without parentheses, leave as-is (valid Lucene too).\n",
    "        return s\n",
    "\n",
    "    def build(self, user_query: str) -> str:\n",
    "        with get_openai_callback() as cb:\n",
    "            out = self.chain.invoke({\"user_query\": user_query or \"\"})\n",
    "\n",
    "        q = (out or \"\").strip()\n",
    "        q = q.replace(\"`\", \"\")         # no fences\n",
    "        q = \" \".join(q.split())        # one line\n",
    "        q = self._sanitize(q)\n",
    "        return q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "lucene_builder = LuceneQueryBuilder(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# tests = [\n",
    "#     'Can you tell me all about frog stamps? ',\n",
    "# ]\n",
    "# for t in tests:\n",
    "#     q = lucene_builder.build(t)\n",
    "#     q = q.replace(\"\\\"\", \"\\\\'\")\n",
    "#     print(f\"\\nUSER: {t}\\nQ: {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Get Mena Catalog For Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getGraphKnowledgeData(user_query):\n",
    "    lucene_query =  lucene_builder.build(user_query)\n",
    "    print(\"q_lucene\",lucene_query)\n",
    "    search_q = lucene_query\n",
    "    search_text = user_query\n",
    "    result = run_search(\n",
    "        mode =\"hybrid\",\n",
    "        q=search_q,\n",
    "        text=search_text,\n",
    "        alpha=0.5,\n",
    "        k=10,\n",
    "        include_graph=False,\n",
    "        graph_limit=2000,\n",
    "        min_score=0.4,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n== {result['mode'].upper()} ==\")\n",
    "    for row in result[\"results\"]:\n",
    "        print(row)\n",
    "\n",
    "    # Capture issues so we can feed them into the graph builder\n",
    "    issues = result[\"results\"]\n",
    "\n",
    "    graph_knowledge_data = []\n",
    "    for issue in issues:\n",
    "        graph = {}    \n",
    "        graph[issue['issue_id']] = find_by_issue_id(mena_parsed_catalog, issue['issue_id'])\n",
    "        graph_knowledge_data.append(graph)\n",
    "    \n",
    "    return graph_knowledge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCypherFromUserQuery(user_query):\n",
    "    lucene_query =  lucene_builder.build(user_query)\n",
    "    \n",
    "    search_q = lucene_query\n",
    "    search_text = user_query\n",
    "    \n",
    "    result = run_search(\n",
    "        mode =\"hybrid\",\n",
    "        q=search_q,\n",
    "        text=search_text,\n",
    "        alpha=0.5,\n",
    "        k=10,\n",
    "        include_graph=False,\n",
    "        graph_limit=2000,\n",
    "        min_score=0.7,\n",
    "    )\n",
    "\n",
    "    # Capture issues so we can feed them into the graph builder\n",
    "    issues = result[\"results\"]\n",
    "\n",
    "    return build_issue_graph_cypher(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Neo4j Graph Visualization Functions ========\n",
    "# Configuration\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"neo4j://127.0.0.1:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"xyz12345\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n",
    "GRAPH_CANVAS_HEIGHT = 700  # px\n",
    "\n",
    "GRAPH_PALETTE = {\n",
    "    \"Stamp\": \"#4e79a7\",\n",
    "    \"Issue\": \"#f28e2b\",\n",
    "    \"Person\": \"#59a14f\",\n",
    "    \"Printer\": \"#e15759\",\n",
    "    \"LegalAct\": \"#76b7b2\",\n",
    "    \"Variety\": \"#edc948\",\n",
    "    \"Specimen\": \"#b07aa1\",\n",
    "    \"Plate\": \"#ff9da7\",\n",
    "    \"PlatePosition\": \"#9c755f\",\n",
    "    \"Proof\": \"#bab0ac\",\n",
    "    \"DieProof\": \"#d4a6c8\",\n",
    "    \"PlateProof\": \"#fabfd2\",\n",
    "    \"ColorProof\": \"#d7b5a6\",\n",
    "    \"ProductionOrder\": \"#79706e\",\n",
    "    \"Quantity\": \"#bcbd22\",\n",
    "    \"RemaindersEvent\": \"#17becf\",\n",
    "    \"Essay\": \"#8c564b\"\n",
    "}\n",
    "\n",
    "def _serialize_value(val):\n",
    "    \"\"\"Convert Neo4j types to JSON-serializable values\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    if hasattr(val, 'iso_format'):\n",
    "        return val.iso_format()\n",
    "    if hasattr(val, 'x') and hasattr(val, 'y'):\n",
    "        return f\"Point({val.x}, {val.y})\"\n",
    "    if hasattr(val, 'months') and hasattr(val, 'days'):\n",
    "        return str(val)\n",
    "    if hasattr(val, '__dict__') and not isinstance(val, (str, int, float, bool, list, dict)):\n",
    "        return str(val)\n",
    "    return val\n",
    "\n",
    "def _serialize_properties(props: dict) -> dict:\n",
    "    \"\"\"Convert all properties to JSON-serializable format\"\"\"\n",
    "    serialized = {}\n",
    "    for key, val in props.items():\n",
    "        try:\n",
    "            if isinstance(val, list):\n",
    "                serialized[key] = [_serialize_value(v) for v in val]\n",
    "            else:\n",
    "                serialized[key] = _serialize_value(val)\n",
    "        except Exception:\n",
    "            serialized[key] = str(val)\n",
    "    return serialized\n",
    "\n",
    "def _create_tooltip(node: dict) -> str:\n",
    "    \"\"\"Create a clean tooltip for nodes\"\"\"\n",
    "    props = _serialize_properties(node[\"_props\"])\n",
    "    group = node[\"group\"]\n",
    "    \n",
    "    lines = [f\"<b>{group}</b>\"]\n",
    "    for key in sorted(props.keys())[:5]:\n",
    "        value = props[key]\n",
    "        if value is not None and str(value).strip():\n",
    "            lines.append(f\"{key}: {value}\")\n",
    "    \n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "def _safe_eid(obj, fallback_prefix=\"x\"):\n",
    "    \"\"\"Return element_id if available; otherwise a stable fallback string\"\"\"\n",
    "    if obj is None:\n",
    "        return f\"{fallback_prefix}_none\"\n",
    "    eid = getattr(obj, \"element_id\", None)\n",
    "    if eid:\n",
    "        return str(eid)\n",
    "    for attr in (\"start_node_element_id\", \"end_node_element_id\"):\n",
    "        if hasattr(obj, attr):\n",
    "            try:\n",
    "                val = getattr(obj, attr)\n",
    "                if val:\n",
    "                    return str(val)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return f\"{fallback_prefix}_{abs(hash(repr(obj)))%10**12}\"\n",
    "\n",
    "def _add_node(n: Node, nodes_map: dict):\n",
    "    \"\"\"Add a node to the nodes map\"\"\"\n",
    "    nid = _safe_eid(n, \"n\")\n",
    "    if nid in nodes_map:\n",
    "        return\n",
    "    \n",
    "    labels = list(getattr(n, \"labels\", []))\n",
    "    main_label = labels[0] if labels else \"Node\"\n",
    "    props = dict(n)\n",
    "    \n",
    "    # Select the most relevant field based on node type\n",
    "    caption_full = None\n",
    "    \n",
    "    if main_label == \"Stamp\":\n",
    "        caption_full = props.get(\"catalog_no\")\n",
    "    elif main_label == \"Variety\":\n",
    "        base = props.get(\"base_catalog_no\", \"\")\n",
    "        suffix = props.get(\"suffix\", \"\")\n",
    "        if base and suffix:\n",
    "            caption_full = f\"{base}{suffix}\"\n",
    "        elif base:\n",
    "            caption_full = base\n",
    "    elif main_label in (\"Specimen\", \"Essay\"):\n",
    "        caption_full = props.get(\"code\")\n",
    "    elif main_label in (\"Proof\", \"DieProof\", \"PlateProof\", \"ColorProof\"):\n",
    "        caption_full = props.get(\"code\")\n",
    "    elif main_label == \"Issue\":\n",
    "        caption_full = props.get(\"title\") or props.get(\"issue_id\")\n",
    "    elif main_label == \"Person\":\n",
    "        caption_full = props.get(\"name\")\n",
    "    elif main_label == \"Printer\":\n",
    "        caption_full = props.get(\"name\")\n",
    "    elif main_label == \"LegalAct\":\n",
    "        doc_type = props.get(\"type\", \"\")\n",
    "        doc_id = props.get(\"id\", \"\")\n",
    "        if doc_type and doc_id:\n",
    "            caption_full = f\"{doc_type} {doc_id}\"\n",
    "        else:\n",
    "            caption_full = doc_type or doc_id\n",
    "    elif main_label == \"Plate\":\n",
    "        denom = props.get(\"denomination\", \"\")\n",
    "        plate_no = props.get(\"no\", \"\")\n",
    "        if denom and plate_no:\n",
    "            caption_full = f\"Plate {plate_no} ({denom})\"\n",
    "        elif plate_no:\n",
    "            caption_full = f\"Plate {plate_no}\"\n",
    "    elif main_label == \"PlatePosition\":\n",
    "        pos = props.get(\"pos\")\n",
    "        if pos:\n",
    "            caption_full = f\"Pos {pos}\"\n",
    "    elif main_label == \"ProductionOrder\":\n",
    "        caption_full = props.get(\"date\")\n",
    "    elif main_label == \"Quantity\":\n",
    "        caption_full = props.get(\"plate_desc\") or f\"Qty: {props.get('quantity', '')}\"\n",
    "    elif main_label == \"RemaindersEvent\":\n",
    "        caption_full = props.get(\"date\") or \"Remainders\"\n",
    "    \n",
    "    # Fallback to generic field search if nothing found\n",
    "    if not caption_full:\n",
    "        for key in [\"name\", \"title\", \"code\", \"id\"]:\n",
    "            if key in props and props[key]:\n",
    "                caption_full = str(props[key])\n",
    "                break\n",
    "    \n",
    "    # Final fallback to label\n",
    "    if not caption_full:\n",
    "        caption_full = main_label\n",
    "    \n",
    "    # Convert to string and create short version\n",
    "    caption_full = str(caption_full)\n",
    "    caption_short = caption_full\n",
    "    if len(caption_full) > 30:\n",
    "        caption_short = caption_full[:28] + \"‚Ä¶\"\n",
    "    \n",
    "    # Get color\n",
    "    color = GRAPH_PALETTE.get(main_label, \"#8892a6\")\n",
    "    \n",
    "    nodes_map[nid] = {\n",
    "        \"id\": nid,\n",
    "        \"caption\": caption_short,\n",
    "        \"caption_full\": caption_full,\n",
    "        \"group\": main_label,\n",
    "        \"color\": color,\n",
    "        \"_props\": props\n",
    "    }\n",
    "\n",
    "def _add_rel(r: Relationship, rels_map: dict):\n",
    "    \"\"\"Add a relationship to the rels map (avoids duplicates)\"\"\"\n",
    "    try:\n",
    "        start_node = getattr(r, \"start_node\", None)\n",
    "        end_node = getattr(r, \"end_node\", None)\n",
    "    except Exception:\n",
    "        start_node = end_node = None\n",
    "    \n",
    "    s_id = _safe_eid(start_node, \"s\")\n",
    "    e_id = _safe_eid(end_node, \"t\")\n",
    "    rid = _safe_eid(r, \"r\")\n",
    "    \n",
    "    # Check if relationship already exists\n",
    "    if rid in rels_map:\n",
    "        return  # Skip duplicate\n",
    "    \n",
    "    rtype = getattr(r, \"type\", \"\")\n",
    "    props = dict(r)\n",
    "    \n",
    "    serialized_props = _serialize_properties(props)\n",
    "    \n",
    "    title_parts = [f\"<b>{rtype}</b>\"]\n",
    "    for k, v in serialized_props.items():\n",
    "        if v is not None:\n",
    "            title_parts.append(f\"{k}: {v}\")\n",
    "    \n",
    "    rels_map[rid] = {\n",
    "        \"id\": rid,\n",
    "        \"from\": s_id,\n",
    "        \"to\": e_id,\n",
    "        \"label\": rtype,\n",
    "        \"title\": \"<br>\".join(title_parts),\n",
    "        \"properties\": serialized_props\n",
    "    }\n",
    "\n",
    "def _generate_vis_html(nodes_map: dict, rels_map: dict) -> str:\n",
    "    \"\"\"Generate HTML using vis.js with modern styling\"\"\"\n",
    "    \n",
    "    # Calculate degree for node sizing\n",
    "    degree = {k: 0 for k in nodes_map.keys()}\n",
    "    for e in rels_map.values():\n",
    "        if e[\"from\"] in degree: \n",
    "            degree[e[\"from\"]] += 1\n",
    "        if e[\"to\"] in degree: \n",
    "            degree[e[\"to\"]] += 1\n",
    "    \n",
    "    # Prepare nodes data\n",
    "    vis_nodes = []\n",
    "    for nid, node in nodes_map.items():\n",
    "        node_degree = degree.get(nid, 1)\n",
    "        size = 30 + (node_degree * 3)\n",
    "        \n",
    "        props = node.get(\"_props\", {}) or {}\n",
    "        # Exclude any property keys that mention 'embedding' or 'search_corpus' (case-insensitive)\n",
    "        filtered_props = {\n",
    "            k: v for k, v in props.items()\n",
    "            if not any(sub in k.lower() for sub in ('embedding', 'search_corpus'))\n",
    "        }\n",
    "        serialized_props = _serialize_properties(filtered_props)\n",
    "        \n",
    "        vis_nodes.append({\n",
    "            \"id\": nid,\n",
    "            \"label\": node[\"caption\"],\n",
    "            \"labelFull\": node.get(\"caption_full\", node[\"caption\"]),\n",
    "            \"color\": node[\"color\"],\n",
    "            \"size\": size,\n",
    "            \"font\": {\n",
    "                \"color\": \"#ffffff\",\n",
    "                \"size\": 13,\n",
    "                \"face\": \"Inter, sans-serif\",\n",
    "                \"bold\": \"600\"\n",
    "            },\n",
    "            \"group\": node[\"group\"],\n",
    "            \"title\": _create_tooltip(node),\n",
    "            \"properties\": serialized_props\n",
    "        })\n",
    "    \n",
    "    # Prepare edges data\n",
    "    vis_edges = []\n",
    "    for rel in rels_map.values():\n",
    "        rel_props = rel.get(\"properties\", {})\n",
    "        \n",
    "        vis_edges.append({\n",
    "            \"from\": rel[\"from\"],\n",
    "            \"to\": rel[\"to\"],\n",
    "            \"label\": rel[\"label\"],\n",
    "            \"arrows\": \"to\",\n",
    "            \"title\": rel.get(\"title\", \"\"),\n",
    "            \"color\": {\n",
    "                \"color\": \"rgba(150, 166, 186, 0.5)\",\n",
    "                \"highlight\": \"rgba(156, 192, 255, 0.8)\"\n",
    "            },\n",
    "            \"width\": 2,\n",
    "            \"font\": {\n",
    "                \"size\": 11,\n",
    "                \"color\": \"#97a6ba\",\n",
    "                \"background\": \"rgba(12, 17, 23, 0.85)\",\n",
    "                \"strokeWidth\": 0\n",
    "            },\n",
    "            \"properties\": rel_props\n",
    "        })\n",
    "    \n",
    "    nodes_json = json.dumps(vis_nodes, indent=2)\n",
    "    edges_json = json.dumps(vis_edges, indent=2)\n",
    "    palette_json = json.dumps(GRAPH_PALETTE)\n",
    "    \n",
    "    # Get used groups for legend\n",
    "    used_groups = sorted(list(set(n[\"group\"] for n in nodes_map.values() if n[\"group\"])))\n",
    "    legend_items = \"\".join(\n",
    "        f'<div class=\"legend-item\"><span class=\"legend-color\" style=\"background:{GRAPH_PALETTE.get(g, \"#8892a6\")}\"></span>{g}</div>'\n",
    "        for g in used_groups\n",
    "    )\n",
    "    \n",
    "    html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Neo4j Graph Visualization</title>\n",
    "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\"></script>\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        * {{\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
    "            background: #0a0e14;\n",
    "            color: #e6eef8;\n",
    "            overflow: hidden;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            width: 100%;\n",
    "            height: 100vh;\n",
    "        }}\n",
    "        \n",
    "        body.expanded {{\n",
    "            position: fixed;\n",
    "            top: 0;\n",
    "            left: 0;\n",
    "            right: 0;\n",
    "            bottom: 0;\n",
    "            z-index: 9999;\n",
    "        }}\n",
    "        \n",
    "        #network {{\n",
    "            width: 100%;\n",
    "            height: 100vh;\n",
    "            background: #0a0e14;\n",
    "        }}\n",
    "        \n",
    "        #legend {{\n",
    "            position: fixed;\n",
    "            top: 20px;\n",
    "            right: 20px;\n",
    "            background: rgba(12, 17, 23, 0.95);\n",
    "            backdrop-filter: blur(10px);\n",
    "            border: 1px solid #2b3240;\n",
    "            border-radius: 12px;\n",
    "            padding: 16px;\n",
    "            max-width: 260px;\n",
    "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);\n",
    "            z-index: 1000;\n",
    "        }}\n",
    "        \n",
    "        #legend h3 {{\n",
    "            font-size: 14px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 12px;\n",
    "            color: #9cc0ff;\n",
    "            letter-spacing: 0.3px;\n",
    "        }}\n",
    "        \n",
    "        .legend-item {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 10px;\n",
    "            margin: 8px 0;\n",
    "            font-size: 13px;\n",
    "            color: #e6eef8;\n",
    "        }}\n",
    "        \n",
    "        .legend-color {{\n",
    "            width: 16px;\n",
    "            height: 16px;\n",
    "            border-radius: 50%;\n",
    "            border: 2px solid rgba(255, 255, 255, 0.1);\n",
    "            flex-shrink: 0;\n",
    "        }}\n",
    "        \n",
    "        #controls {{\n",
    "            position: fixed;\n",
    "            bottom: 20px;\n",
    "            left: 20px;\n",
    "            display: flex;\n",
    "            gap: 10px;\n",
    "            z-index: 1000;\n",
    "        }}\n",
    "        \n",
    "        .control-btn {{\n",
    "            background: rgba(22, 32, 51, 0.95);\n",
    "            backdrop-filter: blur(10px);\n",
    "            color: #e6eef8;\n",
    "            border: 1px solid #2b3240;\n",
    "            border-radius: 8px;\n",
    "            padding: 10px 16px;\n",
    "            font-size: 13px;\n",
    "            font-weight: 600;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.2s;\n",
    "            box-shadow: 0 4px 14px rgba(0, 0, 0, 0.25);\n",
    "        }}\n",
    "        \n",
    "        .control-btn:hover {{\n",
    "            background: rgba(27, 39, 64, 0.95);\n",
    "            transform: translateY(-1px);\n",
    "            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);\n",
    "        }}\n",
    "        \n",
    "        .control-btn:active {{\n",
    "            transform: translateY(0);\n",
    "        }}\n",
    "        \n",
    "        #info {{\n",
    "            position: fixed;\n",
    "            bottom: 80px;\n",
    "            left: 20px;\n",
    "            background: rgba(12, 17, 23, 0.95);\n",
    "            backdrop-filter: blur(10px);\n",
    "            border: 1px solid #2b3240;\n",
    "            border-radius: 12px;\n",
    "            padding: 16px;\n",
    "            max-width: 380px;\n",
    "            max-height: 400px;\n",
    "            overflow-y: auto;\n",
    "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);\n",
    "            z-index: 1000;\n",
    "            display: none;\n",
    "        }}\n",
    "        \n",
    "        #info.active {{\n",
    "            display: block;\n",
    "        }}\n",
    "        \n",
    "        #info h3 {{\n",
    "            font-size: 15px;\n",
    "            font-weight: 700;\n",
    "            margin-bottom: 10px;\n",
    "            color: #9cc0ff;\n",
    "        }}\n",
    "        \n",
    "        #info table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            font-size: 12px;\n",
    "        }}\n",
    "        \n",
    "        #info th {{\n",
    "            text-align: left;\n",
    "            padding: 6px 8px;\n",
    "            color: #97a6ba;\n",
    "            font-weight: 600;\n",
    "            border-bottom: 1px solid #1f2632;\n",
    "        }}\n",
    "        \n",
    "        #info td {{\n",
    "            padding: 6px 8px;\n",
    "            color: #e6eef8;\n",
    "            border-bottom: 1px solid #1f2632;\n",
    "            word-break: break-word;\n",
    "        }}\n",
    "        \n",
    "        #info tr:last-child td {{\n",
    "            border-bottom: none;\n",
    "        }}\n",
    "        \n",
    "        .stats {{\n",
    "            position: fixed;\n",
    "            top: 20px;\n",
    "            left: 20px;\n",
    "            background: rgba(12, 17, 23, 0.95);\n",
    "            backdrop-filter: blur(10px);\n",
    "            border: 1px solid #2b3240;\n",
    "            border-radius: 12px;\n",
    "            padding: 12px 16px;\n",
    "            font-size: 12px;\n",
    "            color: #97a6ba;\n",
    "            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);\n",
    "            z-index: 1000;\n",
    "        }}\n",
    "        \n",
    "        .stats span {{\n",
    "            color: #9cc0ff;\n",
    "            font-weight: 700;\n",
    "        }}\n",
    "\n",
    "        .vis-tooltip {{\n",
    "            background: rgba(16, 21, 27, 0.98) !important;\n",
    "            border: 1px solid #2b3240 !important;\n",
    "            border-radius: 8px !important;\n",
    "            color: #e6eef8 !important;\n",
    "            font-family: 'Inter', sans-serif !important;\n",
    "            font-size: 12px !important;\n",
    "            padding: 10px 12px !important;\n",
    "            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.35) !important;\n",
    "            max-width: 400px !important;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"network\"></div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        Nodes: <span id=\"nodeCount\">{len(nodes_map)}</span> | Relationships: <span id=\"relCount\">{len(rels_map)}</span>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"legend\">\n",
    "        <h3>Node Types</h3>\n",
    "        {legend_items}\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"controls\">\n",
    "        <button class=\"control-btn\" onclick=\"resetView()\">üîÑ Reset View</button>\n",
    "        <button class=\"control-btn\" id=\"physicsBtn\" onclick=\"togglePhysics()\">‚è∏ Pause Physics</button>\n",
    "        <button class=\"control-btn\" id=\"fullscreenBtn\" onclick=\"toggleFullscreen()\">‚õ∂ Fullscreen</button>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"info\">\n",
    "        <h3 id=\"infoTitle\">Node Details</h3>\n",
    "        <table id=\"infoTable\"></table>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        const nodes = new vis.DataSet({nodes_json});\n",
    "        const edges = new vis.DataSet({edges_json});\n",
    "        \n",
    "        const container = document.getElementById('network');\n",
    "        const data = {{ nodes: nodes, edges: edges }};\n",
    "        \n",
    "        const options = {{\n",
    "            nodes: {{\n",
    "                shape: 'dot',\n",
    "                borderWidth: 2,\n",
    "                borderWidthSelected: 3,\n",
    "                shadow: {{\n",
    "                    enabled: true,\n",
    "                    color: 'rgba(0,0,0,0.3)',\n",
    "                    size: 8,\n",
    "                    x: 0,\n",
    "                    y: 2\n",
    "                }},\n",
    "                font: {{\n",
    "                    color: '#ffffff',\n",
    "                    size: 13,\n",
    "                    face: 'Inter, sans-serif',\n",
    "                    bold: '600'\n",
    "                }}\n",
    "            }},\n",
    "            edges: {{\n",
    "                width: 2,\n",
    "                color: {{\n",
    "                    color: 'rgba(150, 166, 186, 0.5)',\n",
    "                    highlight: 'rgba(156, 192, 255, 0.8)',\n",
    "                    hover: 'rgba(156, 192, 255, 0.6)'\n",
    "                }},\n",
    "                arrows: {{\n",
    "                    to: {{\n",
    "                        enabled: true,\n",
    "                        scaleFactor: 0.8\n",
    "                    }}\n",
    "                }},\n",
    "                smooth: {{\n",
    "                    type: 'dynamic',\n",
    "                    roundness: 0.5\n",
    "                }},\n",
    "                font: {{\n",
    "                    size: 11,\n",
    "                    color: '#97a6ba',\n",
    "                    background: 'rgba(12, 17, 23, 0.85)',\n",
    "                    strokeWidth: 0,\n",
    "                    align: 'horizontal'\n",
    "                }}\n",
    "            }},\n",
    "            physics: {{\n",
    "                enabled: true,\n",
    "                stabilization: {{\n",
    "                    enabled: true,\n",
    "                    iterations: 250,\n",
    "                    updateInterval: 25,\n",
    "                    fit: true\n",
    "                }},\n",
    "                barnesHut: {{\n",
    "                    gravitationalConstant: -10000,\n",
    "                    centralGravity: 0.3,\n",
    "                    springLength: 180,\n",
    "                    springConstant: 0.04,\n",
    "                    damping: 0.5,\n",
    "                    avoidOverlap: 0.3\n",
    "                }},\n",
    "                minVelocity: 0.75,\n",
    "                maxVelocity: 50\n",
    "            }},\n",
    "            interaction: {{\n",
    "                hover: true,\n",
    "                navigationButtons: false,\n",
    "                keyboard: true,\n",
    "                tooltipDelay: 100,\n",
    "                hideEdgesOnDrag: false,\n",
    "                hideEdgesOnZoom: false\n",
    "            }}\n",
    "        }};\n",
    "        \n",
    "        const network = new vis.Network(container, data, options);\n",
    "        \n",
    "        let physicsEnabled = true;\n",
    "        let selectedNodeId = null;\n",
    "        \n",
    "        // Auto-stop physics after stabilization\n",
    "        network.once('stabilizationIterationsDone', function() {{\n",
    "            setTimeout(() => {{\n",
    "                network.setOptions({{ physics: false }});\n",
    "                physicsEnabled = false;\n",
    "                document.getElementById('physicsBtn').textContent = '‚ñ∂ Play Physics';\n",
    "            }}, 15000);\n",
    "        }});\n",
    "        \n",
    "        // Handle node clicks - FIX: Preserve color when updating\n",
    "        network.on('click', function(params) {{\n",
    "            if (params.nodes.length > 0) {{\n",
    "                const nodeId = params.nodes[0];\n",
    "                const node = nodes.get(nodeId);\n",
    "                \n",
    "                // Restore previous node label (preserving color)\n",
    "                if (selectedNodeId && selectedNodeId !== nodeId) {{\n",
    "                    const prevNode = nodes.get(selectedNodeId);\n",
    "                    if (prevNode && prevNode.labelFull) {{\n",
    "                        const shortLabel = prevNode.labelFull.length > 30 \n",
    "                            ? prevNode.labelFull.substring(0, 28) + '‚Ä¶' \n",
    "                            : prevNode.labelFull;\n",
    "                        // FIX: Preserve color when updating\n",
    "                        nodes.update({{\n",
    "                            id: selectedNodeId, \n",
    "                            label: shortLabel,\n",
    "                            color: prevNode.color  // ‚úÖ Mantener el color original\n",
    "                        }});\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "                // Expand current node label (preserving color)\n",
    "                if (node && node.labelFull) {{\n",
    "                    // FIX: Preserve color when updating\n",
    "                    nodes.update({{\n",
    "                        id: nodeId, \n",
    "                        label: node.labelFull,\n",
    "                        color: node.color  // ‚úÖ Mantener el color original\n",
    "                    }});\n",
    "                    selectedNodeId = nodeId;\n",
    "                }}\n",
    "                \n",
    "                showNodeInfo(node);\n",
    "            }} else {{\n",
    "                // Click on canvas - restore labels (preserving colors)\n",
    "                if (selectedNodeId) {{\n",
    "                    const node = nodes.get(selectedNodeId);\n",
    "                    if (node && node.labelFull) {{\n",
    "                        const shortLabel = node.labelFull.length > 30 \n",
    "                            ? node.labelFull.substring(0, 28) + '‚Ä¶' \n",
    "                            : node.labelFull;\n",
    "                        // FIX: Preserve color when updating\n",
    "                        nodes.update({{\n",
    "                            id: selectedNodeId, \n",
    "                            label: shortLabel,\n",
    "                            color: node.color  // ‚úÖ Mantener el color original\n",
    "                        }});\n",
    "                    }}\n",
    "                    selectedNodeId = null;\n",
    "                }}\n",
    "                document.getElementById('info').classList.remove('active');\n",
    "            }}\n",
    "        }});\n",
    "        \n",
    "        function showNodeInfo(node) {{\n",
    "            const info = document.getElementById('info');\n",
    "            const title = document.getElementById('infoTitle');\n",
    "            const table = document.getElementById('infoTable');\n",
    "            \n",
    "            const fullLabel = node.labelFull || node.label;\n",
    "            title.textContent = `${{node.group}}: ${{fullLabel}}`;\n",
    "            \n",
    "            let rows = '';\n",
    "            if (node.properties) {{\n",
    "                const props = Object.keys(node.properties).sort();\n",
    "                props.forEach(key => {{\n",
    "                    const value = node.properties[key];\n",
    "                    if (value !== null && value !== undefined) {{\n",
    "                        rows += `<tr><th>${{key}}</th><td>${{value}}</td></tr>`;\n",
    "                    }}\n",
    "                }});\n",
    "            }}\n",
    "            \n",
    "            table.innerHTML = rows || '<tr><td colspan=\"2\" style=\"text-align:center;color:#97a6ba;\">No properties</td></tr>';\n",
    "            info.classList.add('active');\n",
    "        }}\n",
    "        \n",
    "        function resetView() {{\n",
    "            network.fit({{\n",
    "                animation: {{\n",
    "                    duration: 500,\n",
    "                    easingFunction: 'easeInOutQuad'\n",
    "                }}\n",
    "            }});\n",
    "        }}\n",
    "        \n",
    "        function togglePhysics() {{\n",
    "            physicsEnabled = !physicsEnabled;\n",
    "            network.setOptions({{ physics: physicsEnabled }});\n",
    "            const btn = document.getElementById('physicsBtn');\n",
    "            btn.textContent = physicsEnabled ? '‚è∏ Pause Physics' : '‚ñ∂ Play Physics';\n",
    "        }}\n",
    "        \n",
    "        function toggleFullscreen() {{\n",
    "            const btn = document.getElementById('fullscreenBtn');\n",
    "            \n",
    "            // Try native fullscreen first\n",
    "            if (!document.fullscreenElement && document.documentElement.requestFullscreen) {{\n",
    "                document.documentElement.requestFullscreen()\n",
    "                    .then(() => {{\n",
    "                        btn.textContent = '‚õ∂ Exit Fullscreen';\n",
    "                    }})\n",
    "                    .catch(err => {{\n",
    "                        // Fallback: use expanded mode\n",
    "                        console.log('Fullscreen not available, using expanded mode');\n",
    "                        toggleExpandedMode();\n",
    "                    }});\n",
    "            }} else if (document.fullscreenElement) {{\n",
    "                document.exitFullscreen()\n",
    "                    .then(() => {{\n",
    "                        btn.textContent = '‚õ∂ Fullscreen';\n",
    "                    }})\n",
    "                    .catch(err => {{\n",
    "                        console.error('Error exiting fullscreen:', err);\n",
    "                    }});\n",
    "            }} else {{\n",
    "                // Fullscreen not supported, use expanded mode\n",
    "                toggleExpandedMode();\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        let isExpanded = false;\n",
    "        function toggleExpandedMode() {{\n",
    "            const btn = document.getElementById('fullscreenBtn');\n",
    "            isExpanded = !isExpanded;\n",
    "            \n",
    "            if (isExpanded) {{\n",
    "                document.body.classList.add('expanded');\n",
    "                btn.textContent = '‚õ∂ Exit Expand';\n",
    "            }} else {{\n",
    "                document.body.classList.remove('expanded');\n",
    "                btn.textContent = '‚õ∂ Fullscreen';\n",
    "            }}\n",
    "            \n",
    "            // Trigger network resize\n",
    "            setTimeout(() => {{\n",
    "                network.fit();\n",
    "            }}, 100);\n",
    "        }}\n",
    "        \n",
    "        // Listen for fullscreen changes (e.g., ESC key)\n",
    "        document.addEventListener('fullscreenchange', function() {{\n",
    "            const btn = document.getElementById('fullscreenBtn');\n",
    "            if (btn) {{\n",
    "                btn.textContent = document.fullscreenElement ? '‚õ∂ Exit Fullscreen' : '‚õ∂ Fullscreen';\n",
    "            }}\n",
    "        }});\n",
    "        \n",
    "        document.addEventListener('keydown', function(e) {{\n",
    "            if (e.code === 'Space' && e.target.tagName !== 'INPUT') {{\n",
    "                e.preventDefault();\n",
    "                togglePhysics();\n",
    "            }}\n",
    "            // F key for fullscreen/expand\n",
    "            if (e.code === 'KeyF' && !e.ctrlKey && !e.metaKey && e.target.tagName !== 'INPUT') {{\n",
    "                e.preventDefault();\n",
    "                toggleFullscreen();\n",
    "            }}\n",
    "            // ESC key for expanded mode\n",
    "            if (e.code === 'Escape' && isExpanded) {{\n",
    "                toggleExpandedMode();\n",
    "            }}\n",
    "        }});\n",
    "        \n",
    "        setTimeout(() => {{\n",
    "            network.fit();\n",
    "        }}, 100);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "def run_cypher(cypher_text: str):\n",
    "    \"\"\"Execute Cypher and return animated HTML graph with vis.js\"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    except AuthError as e:\n",
    "        return f\"<pre>‚ùå AuthError: {e}</pre>\"\n",
    "\n",
    "    nodes_map = {}  # element_id -> dict (avoid duplicates)\n",
    "    rels_map = {}   # element_id -> dict (avoid duplicates)\n",
    "\n",
    "    try:\n",
    "        session_kwargs = {}\n",
    "        if NEO4J_DATABASE:\n",
    "            session_kwargs[\"database\"] = NEO4J_DATABASE\n",
    "\n",
    "        with driver.session(**session_kwargs) as session:\n",
    "            result = session.run(cypher_text)\n",
    "\n",
    "            for record in result:\n",
    "                for val in record.values():\n",
    "                    if isinstance(val, Node):\n",
    "                        _add_node(val, nodes_map)\n",
    "                    elif isinstance(val, Relationship):\n",
    "                        _add_rel(val, rels_map)\n",
    "                        _add_node(val.start_node, nodes_map)\n",
    "                        _add_node(val.end_node, nodes_map)\n",
    "                    elif isinstance(val, Path):\n",
    "                        for n in val.nodes:\n",
    "                            _add_node(n, nodes_map)\n",
    "                        for r in val.relationships:\n",
    "                            _add_rel(r, rels_map)\n",
    "                    elif isinstance(val, list) or isinstance(val, tuple):\n",
    "                        for x in val:\n",
    "                            if isinstance(x, Node):\n",
    "                                _add_node(x, nodes_map)\n",
    "                            elif isinstance(x, Relationship):\n",
    "                                _add_rel(x, rels_map)\n",
    "                                _add_node(x.start_node, nodes_map)\n",
    "                                _add_node(x.end_node, nodes_map)\n",
    "                            elif isinstance(x, Path):\n",
    "                                for n in x.nodes:\n",
    "                                    _add_node(n, nodes_map)\n",
    "                                for r in x.relationships:\n",
    "                                    _add_rel(r, rels_map)\n",
    "\n",
    "    except AuthError as e:\n",
    "        return f\"<pre>‚ùå AuthError: {e}</pre>\"\n",
    "    except Exception as e:\n",
    "        return f\"<pre>‚ùå Error running Cypher: {e}</pre>\"\n",
    "    finally:\n",
    "        driver.close()\n",
    "\n",
    "    if not nodes_map and not rels_map:\n",
    "        return (\n",
    "            \"<div style='padding:1rem;border-radius:8px;background:#111;color:#eee;'>\"\n",
    "            \"No nodes or relationships were returned. The query completed but returned no graph data.\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    # Build visualization HTML\n",
    "    html = _generate_vis_html(nodes_map, rels_map)\n",
    "    \n",
    "    # Wrap inside iframe\n",
    "    b64 = base64.b64encode(html.encode(\"utf-8\")).decode(\"ascii\")\n",
    "    iframe = (\n",
    "        f'<iframe style=\"width:100%;height:{GRAPH_CANVAS_HEIGHT}px;border:0;border-radius:10px;\" '\n",
    "        f'sandbox=\"allow-scripts allow-same-origin allow-fullscreen\" '\n",
    "        f'allowfullscreen '\n",
    "        f'src=\"data:text/html;charset=utf-8;base64,{b64}\"></iframe>'\n",
    "    )\n",
    "    return iframe\n",
    "\n",
    "def generate_graph_from_query(query: str):\n",
    "    \"\"\"Generate graph visualization from user query\"\"\"\n",
    "    try:\n",
    "        if not query or not query.strip():\n",
    "            return \"<p style='padding:1rem;color:#97a6ba;'>Enter a query and click Search to generate the knowledge graph.</p>\"\n",
    "        \n",
    "        # Get the Cypher query from user input\n",
    "        cypher = getCypherFromUserQuery(query)\n",
    "        print(\"--------------------CYPHER----------------\\n\",cypher)\n",
    "        if not cypher or not cypher.strip():\n",
    "            return \"<p style='padding:1rem;color:#e59a00;'>No graph data available for this query.</p>\"\n",
    "        \n",
    "        # Execute and visualize\n",
    "        return run_cypher(cypher)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"<p style='padding:1rem;color:#ff6b6b;'>Error generating graph: {str(e)}</p>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucene_query =  \"+((snake* OR serpiente* OR serpents OR cobra* OR viper* OR boa* OR piton* OR pit√≥n* OR culebra* OR culebr*)) OR ((snake* OR serpiente* OR serpents OR cobra* OR viper* OR rattlesnake* OR python* OR piton* OR pit√≥n* OR culebra* OR culebr*) OR (reptile*))\"\n",
    "# user_query = \"Tell me all about snake stamps of costa rica\"\n",
    "\n",
    "\n",
    "# search_q = lucene_query\n",
    "# search_text = user_query\n",
    "# result = run_search(\n",
    "#     mode =\"hybrid\",\n",
    "#     q=search_q,\n",
    "#     text=search_text,\n",
    "#     alpha=0.5,\n",
    "#     k=10,\n",
    "#     include_graph=False,\n",
    "#     graph_limit=2000,\n",
    "#     min_score=0.4,\n",
    "# )\n",
    "\n",
    "# print(f\"\\n== {result['mode'].upper()} ==\")\n",
    "# for row in result[\"results\"]:\n",
    "#     print(row)\n",
    "\n",
    "# # Capture issues so we can feed them into the graph builder\n",
    "# issues = result[\"results\"]\n",
    "\n",
    "# graph_knowledge_data = {}\n",
    "# for issue in issues:    \n",
    "#     graph_knowledge_data[issue['issue_id']] = find_by_issue_id(mena_parsed_catalog, issue['issue_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advance Retriever Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "def compress_documents_simple(documents: List[Document], query: str, llm) -> Tuple[List[Document], Dict]:\n",
    "    \"\"\"\n",
    "    Simple document compression using LangChain's native batch processing with token tracking.\n",
    "    Each document is processed individually with the same prompt.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (compressed_documents, token_usage_info)\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return [], {\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "    \n",
    "    # Simple compression prompt for individual documents\n",
    "    # Optimized compression prompt for philatelic documents\n",
    "    compress_prompt_template = \"\"\"You are an expert philatelist. Extract and summarize ONLY information that directly relates to the specific stamp or philatelic issue mentioned in the query.\n",
    "\n",
    "    QUERY: {query}\n",
    "\n",
    "    DOCUMENT:\n",
    "    {document}\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. The query is asking about a SPECIFIC stamp, stamp issue, or philatelic item\n",
    "    2. ONLY extract information if the document explicitly discusses that exact stamp/issue\n",
    "    3. If the document discusses different stamps, different countries, different years, or different issues than what the query asks for - this is NOT relevant\n",
    "    4. Do NOT extract general philatelic information unless it directly explains the queried stamp/issue\n",
    "    5. Do NOT make connections or assumptions - the stamp/issue must be explicitly mentioned in the document\n",
    "\n",
    "    WHAT TO EXTRACT (only if the specific stamp/issue is discussed):\n",
    "    - Catalog numbers (Scott, Stanley Gibbons, Michel, etc.)\n",
    "    - Denominations, colors, and design descriptions\n",
    "    - Issue dates and printing details\n",
    "    - Watermarks, perforations, and paper types\n",
    "    - Varieties, errors, and printing methods\n",
    "    - Historical context specific to this stamp/issue\n",
    "    - Rarity, usage, or collecting information\n",
    "\n",
    "    WHAT NOT TO DO:\n",
    "    - Do NOT add facts about similar but different stamps\n",
    "    - Do NOT include information about the same country but different issues\n",
    "    - Do NOT generalize from other stamps to the one being queried\n",
    "    - Do NOT assume anything not explicitly stated in the document\n",
    "\n",
    "    If the document does NOT discuss the specific stamp or issue from the query, respond with exactly:\n",
    "    NO_RELEVANT_CONTENT\n",
    "\n",
    "    If the document DOES discuss the queried stamp/issue, respond with:\n",
    "    RELEVANT CONTENT:\n",
    "    [Your extracted summary here, covering ONLY the specific stamp/issue from the query]\"\"\"\n",
    "\n",
    "    # Create individual prompts for each document\n",
    "    prompts = []\n",
    "    for doc in documents:\n",
    "        prompt_text = compress_prompt_template.format(\n",
    "            query=query, \n",
    "            document=doc.page_content\n",
    "        )\n",
    "        prompts.append([(\"user\", prompt_text)])\n",
    "    \n",
    "    # Use LangChain's native batch processing with concurrency control and token tracking\n",
    "    config = RunnableConfig(max_concurrency=10)  # Process 10 documents concurrently\n",
    "    \n",
    "    try:\n",
    "        # Track token usage during compression\n",
    "        with get_openai_callback() as cb:\n",
    "            responses = llm.batch(prompts, config=config)\n",
    "            \n",
    "            # Get token counts from callback\n",
    "            compression_token_usage = {\n",
    "                \"input_tokens\": cb.prompt_tokens,\n",
    "                \"output_tokens\": cb.completion_tokens,\n",
    "                \"total_tokens\": cb.total_tokens\n",
    "            }\n",
    "        \n",
    "        # Filter and create compressed documents\n",
    "        compressed_docs = []\n",
    "        for i, response in enumerate(responses):\n",
    "            content = response.content.strip() if hasattr(response, 'content') else str(response).strip()\n",
    "            \n",
    "            # Only include documents that have relevant content\n",
    "            if content and content != \"NO_RELEVANT_CONTENT\":\n",
    "                compressed_doc = Document(\n",
    "                    page_content=content,\n",
    "                    metadata=documents[i].metadata\n",
    "                )\n",
    "                compressed_docs.append(compressed_doc)\n",
    "        \n",
    "        return compressed_docs, compression_token_usage\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch compression: {e}\")\n",
    "        # Fallback: return original documents with zero token usage\n",
    "        return documents, {\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"total_tokens\": 0\n",
    "        }\n",
    "\n",
    "def search_stamps_with_compression(query, client, embeddings, llm, limit=100, \n",
    "                                 alpha=0.30, diversity_lambda=0.75):\n",
    "    \"\"\"\n",
    "    Optimized philatelic search with simple batch document compression using LangChain's native batch processing.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The stamp query\n",
    "        client: Weaviate client\n",
    "        embeddings: Embedding model\n",
    "        llm: Language model\n",
    "        limit (int): Maximum documents to retrieve\n",
    "        alpha (float): Hybrid search factor (0.30 = 30% vector, 70% keywords)\n",
    "        diversity_lambda (float): MMR diversity factor (0.75 = good diversity)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (compressed_docs, token_usage, cost_info)\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=COLLECTION_NAME,\n",
    "        text_key=\"text\",\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Try to create hybrid retriever\n",
    "    hybrid_kwargs = {\"k\": limit // 2}\n",
    "    if alpha is not None:\n",
    "        hybrid_kwargs[\"alpha\"] = alpha\n",
    "    \n",
    "    # 1. Precision hybrid retriever (captures exact numbers + context)\n",
    "    precision_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs=hybrid_kwargs\n",
    "    )\n",
    "    \n",
    "    # 2. Diversity MMR retriever (avoids duplicate stamps)\n",
    "    diversity_retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": limit // 2, \"lambda_mult\": diversity_lambda}\n",
    "    )\n",
    "    \n",
    "    # 3. Ensemble with dual strategy\n",
    "    base_retriever = EnsembleRetriever(\n",
    "        retrievers=[precision_retriever, diversity_retriever],\n",
    "        weights=[0.7, 0.3]  # 70% precision + 30% diversity\n",
    "    )\n",
    "    \n",
    "    # Specialized prompt for philatelic multi-query generation\n",
    "    query_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"You are a specialized philatelic researcher expert in stamp catalogues and varieties.\n",
    "Generate 3 strategically different versions of the question to capture comprehensive stamp information:\n",
    "\n",
    "ORIGINAL: {question}\n",
    "\n",
    "Create variations that target:\n",
    "1. CATALOG PRECISION: Focus on exact catalog numbers, dates, and technical specifications\n",
    "2. CONTEXTUAL SEARCH: Include related series, printings, varieties, and historical context  \n",
    "3. TERMINOLOGY ALTERNATIVES: Use alternative philatelic terms, synonyms or related philatelic concepts\n",
    "\n",
    "Consider these philatelic elements:\n",
    "- Catalog systems: Scott, Michel, Yvert, SG, local catalogs\n",
    "- Technical terms: definitive/commemorative, variety/error, overprint/surcharge\n",
    "- Time references: issue dates, printing dates, first day covers\n",
    "- Denominations: face values, colors, perforations\n",
    "\n",
    "Alternative searches:\n",
    "1.\n",
    "2. \n",
    "3.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # multiquery_llm = ChatOpenAI(\n",
    "    #         model=\"gpt-5-nano\", \n",
    "    #         api_key=OPENAI_API_KEY, \n",
    "    #         temperature=1,  # obligatorio para gpt-5-nano\n",
    "    #         timeout=120.0,\n",
    "    #         #max_completion_tokens=2500,\n",
    "    #         model_kwargs={\n",
    "    #             \"verbosity\": \"low\",\n",
    "    #         })\n",
    "    \n",
    "    multiquery_llm = ChatOpenAI(\n",
    "            model=\"gpt-4.1-nano\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=0.2,\n",
    "            timeout=120.0,\n",
    "           )\n",
    "    \n",
    "    # MultiQueryRetriever with specialized prompt\n",
    "    multi_retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=base_retriever,\n",
    "        llm=multiquery_llm,\n",
    "        prompt=query_prompt,\n",
    "        parser_key=\"lines\"\n",
    "    )\n",
    "    \n",
    "    # Execute initial retrieval\n",
    "    initial_results = multi_retriever.invoke(query)\n",
    "       \n",
    "    # compression_llm = ChatOpenAI(\n",
    "    #         model=\"gpt-5-nano\", \n",
    "    #         api_key=OPENAI_API_KEY, \n",
    "    #         temperature=1,  # obligatorio para gpt-5-nano\n",
    "    #         timeout=120.0,\n",
    "    #         model_kwargs={\n",
    "    #             \"verbosity\": \"low\",\n",
    "    #         })\n",
    "    \n",
    "    compression_llm = ChatOpenAI(\n",
    "            model=\"gpt-4.1-mini\", \n",
    "            api_key=OPENAI_API_KEY, \n",
    "            temperature=0.1,\n",
    "            timeout=120.0\n",
    "            )\n",
    "    \n",
    "    # Simple batch compression using LangChain's native batch processing with token tracking\n",
    "    compressed_results, compression_token_usage = compress_documents_simple(initial_results, query, compression_llm)\n",
    "    \n",
    "    # Calculate costs for GPT-5-nano compression\n",
    "    # $0.05 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    # cost_per_1m_input = 0.05\n",
    "    # cost_per_1m_output = 0.40\n",
    "    \n",
    "    # Calculate costs for GPT-4.1-nano compression\n",
    "    # $0.10 per 1M input tokens, $0.40 per 1M output tokens\n",
    "    cost_per_1m_input = 0.10\n",
    "    cost_per_1m_output = 0.40\n",
    "    \n",
    "    # Convert to cost per token\n",
    "    cost_per_input_token = cost_per_1m_input / 1_000_000\n",
    "    cost_per_output_token = cost_per_1m_output / 1_000_000\n",
    "    \n",
    "    input_cost = compression_token_usage[\"input_tokens\"] * cost_per_input_token\n",
    "    output_cost = compression_token_usage[\"output_tokens\"] * cost_per_output_token\n",
    "    estimated_cost = input_cost + output_cost\n",
    "    \n",
    "    compression_cost_info = {\n",
    "        \"estimated_cost_usd\": round(estimated_cost, 6),\n",
    "        \"input_cost\": round(input_cost, 6),\n",
    "        \"output_cost\": round(output_cost, 6)\n",
    "    }\n",
    "    \n",
    "    # Reorder by quality_score if it exists\n",
    "    def get_quality_score(doc):\n",
    "        return getattr(doc, 'metadata', {}).get('quality_score', 0.0)\n",
    "    \n",
    "    sorted_results = sorted(compressed_results, key=get_quality_score, reverse=True)\n",
    "    return sorted_results, compression_token_usage, compression_cost_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the method search_stamps_with_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the optimized search_stamps_with_compression with batch processing\n",
    "# print(\"üß™ Testing optimized batch compression...\")\n",
    "\n",
    "# # Test query focused on specific stamps\n",
    "# test_query = \"Costa Rica 1907 2 colones stamp with original gum Scott 68\"\n",
    "\n",
    "# print(f\"üîç Query: {test_query}\")\n",
    "# print(\"‚è±Ô∏è Starting optimized search with batch compression...\")\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# try:\n",
    "#     compressed_docs = search_stamps_with_compression(\n",
    "#         query=test_query,\n",
    "#         client=client, \n",
    "#         embeddings=embeddings, \n",
    "#         limit=30,\n",
    "#         llm=llm,\n",
    "#         alpha=0.30,  # 30% vectorial, 70% keywords for exact numbers\n",
    "#         diversity_lambda=0.75  # 75% relevance, 25% diversity\n",
    "#     )\n",
    "    \n",
    "#     end_time = time.time()\n",
    "#     execution_time = end_time - start_time\n",
    "    \n",
    "#     print(f\"‚úÖ Batch compression completed in {execution_time:.2f} seconds\")\n",
    "#     print(f\"üìä Retrieved and compressed {len(compressed_docs)} documents\")\n",
    "    \n",
    "#     # Show sample results\n",
    "#     for i, doc in enumerate(compressed_docs[:3], 1):\n",
    "#         print(f\"\\\\nüìÑ Document {i}:\")\n",
    "#         print(f\"   Metadata: {getattr(doc, 'metadata', {})}\")\n",
    "#         content = getattr(doc, 'page_content', str(doc))\n",
    "#         preview = content[:200] + \"...\" if len(content) > 200 else content\n",
    "#         print(f\"   Content: {preview}\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Error during batch compression test: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_info() -> str:\n",
    "    \"\"\"\n",
    "    Get collection information to display in the interface.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return \"‚ùå No Weaviate connection\"\n",
    "    \n",
    "    try:\n",
    "        stats = get_collection_stats(client, \"Oxcart\")\n",
    "        if stats:\n",
    "            info = f\"üìä **Oxcart Collection Statistics:**\\\\n\\\\n\"\n",
    "            info += f\"üì¶ **Total chunks:** {stats['total_chunks']:,}\\\\n\"\n",
    "            info += f\"üìÑ **Documents:** {stats['total_documents']}\\\\n\\\\n\"\n",
    "            \n",
    "            if stats.get('documents'):\n",
    "                info += \"**Indexed documents:**\\\\n\"\n",
    "                for doc_id, count in stats['documents'].items():\n",
    "                    info += f\"‚Ä¢ {doc_id}: {count:,} chunks\\\\n\"\n",
    "            \n",
    "            return info\n",
    "        else:\n",
    "            return \"‚ùå Could not retrieve statistics\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ RAG functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_collection_stats(client, \"Oxcart\")\n",
    "stats['total_documents']\n",
    "stats['total_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura que usan tus funciones de b√∫squeda/respuesta\n",
    "rag_system = {\n",
    "    \"success\": True,\n",
    "    \"client\": client,                    # para que search_and_answer pueda consultar\n",
    "    \"collection_name\": COLLECTION_NAME,  # nombre de la colecci√≥n\n",
    "    \"weaviate_url\": WEAVIATE_URL,        # info para la UI\n",
    "    \"total_documents\": stats['total_documents'],       # para mostrar estado\n",
    "    \"total_chunks\": stats['total_chunks'],        # opcional en la UI\n",
    "    \"embeddings\":embeddings,\n",
    "    \"llm\":llm,\n",
    "    # puedes a√±adir m√°s campos que tu search_and_answer necesite\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Thresholded + boosted + diversified Weaviate retrieval\n",
    "- Adds: min_score gating, domain boosts (Scott/year/quality), dedup, MMR, multi-mode fallback\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utility helpers\n",
    "# =========================\n",
    "\n",
    "def _distance_to_similarity(distance: Optional[float], metric: str = \"cosine\") -> Optional[float]:\n",
    "    if distance is None:\n",
    "        return None\n",
    "    d = float(distance)\n",
    "    if metric == \"cosine\":\n",
    "        return max(0.0, min(1.0, 1.0 - d))  # cosine distance -> similarity in [0..1]\n",
    "    elif metric in (\"l2\", \"euclidean\"):\n",
    "        return 1.0 / (1.0 + d)\n",
    "    elif metric == \"dot\":  # heuristic\n",
    "        return 1.0 - (d / 2.0)\n",
    "    return None\n",
    "\n",
    "def _norm_score(raw: Optional[float]) -> float:\n",
    "    \"\"\"Normalize to [0,1]. Weaviate hybrid/bm25 'score' is usually [0..1]; vector similarity from our converter is also [0..1].\"\"\"\n",
    "    if raw is None:\n",
    "        return 0.0\n",
    "    return max(0.0, min(1.0, float(raw)))\n",
    "\n",
    "def _text_hash(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def _extract_query_years(query: str) -> List[int]:\n",
    "    years = []\n",
    "    for y in re.findall(r\"\\b(18\\d{2}|19\\d{2}|20\\d{2})\\b\", query):\n",
    "        try:\n",
    "            years.append(int(y))\n",
    "        except:\n",
    "            pass\n",
    "    return years\n",
    "\n",
    "def _year_overlap(query_years: List[int], hit_years: List[int]) -> bool:\n",
    "    if not query_years or not hit_years:\n",
    "        return False\n",
    "    qs = set(int(y) for y in query_years if str(y).isdigit())\n",
    "    hs = set(int(y) for y in hit_years if str(y).isdigit())\n",
    "    return len(qs.intersection(hs)) > 0\n",
    "\n",
    "def _boosts(hit: Dict[str, Any], query: str, requested_scotts: Optional[List[str]], query_years: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    Domain-aware boosts capped to 0.30 total.\n",
    "    - Scott exact match: +0.15\n",
    "    - Year overlap     : +0.08\n",
    "    - Chunk quality    : up to +0.07\n",
    "    \"\"\"\n",
    "    boost = 0.0\n",
    "\n",
    "    # Scott boost\n",
    "    if requested_scotts:\n",
    "        scotts = {str(s).strip().lower() for s in (hit.get(\"scott_numbers\") or [])}\n",
    "        want   = {str(s).strip().lower() for s in requested_scotts}\n",
    "        if scotts & want:\n",
    "            boost += 0.15\n",
    "\n",
    "    # Year overlap boost\n",
    "    if _year_overlap(query_years, hit.get(\"years\") or []):\n",
    "        boost += 0.08\n",
    "\n",
    "    # Quality boost\n",
    "    q = hit.get(\"quality_score\", 0.0)\n",
    "    try:\n",
    "        qn = max(0.0, min(1.0, float(q)))\n",
    "        boost += 0.07 * qn\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return min(boost, 0.30)\n",
    "\n",
    "def _passes_content_gates(hit: Dict[str, Any], min_chars: int) -> Tuple[bool, str]:\n",
    "    t = (hit.get(\"text\") or \"\").strip()\n",
    "    if len(t) < min_chars:\n",
    "        return False, f\"too_short<{min_chars}\"\n",
    "    # Gentle philately guard to prevent off-topic noise\n",
    "    if not re.search(r\"\\bstamp\\b|\\bperforat|\\bwatermark|\\bscott\\b|\\bsurcharge|\\bissue\\b\", t, flags=re.I):\n",
    "        return False, \"weak_domain_signal\"\n",
    "    return True, \"ok\"\n",
    "\n",
    "def _dedup(hits: List[Dict[str, Any]], max_per_doc: int = 2) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Cap to N per (doc_id, page_number) and deduplicate by text hash.\"\"\"\n",
    "    by_doc = defaultdict(int)\n",
    "    seen_hash = set()\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        key = (h.get(\"doc_id\"), h.get(\"page_number\"))\n",
    "        hsh = _text_hash(h.get(\"text\") or \"\")\n",
    "        if hsh in seen_hash:\n",
    "            h[\"_reject_reason\"] = \"dup_text\"\n",
    "            continue\n",
    "        if by_doc[key] >= max_per_doc:\n",
    "            h[\"_reject_reason\"] = \"doc_cap\"\n",
    "            continue\n",
    "        by_doc[key] += 1\n",
    "        seen_hash.add(hsh)\n",
    "        out.append(h)\n",
    "    return out\n",
    "\n",
    "def _mmr_select(candidates: List[Dict[str, Any]], k: int, lambda_diversity: float = 0.7) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Lightweight MMR using Jaccard similarity on token sets.\n",
    "    Assumes 'final_score' exists.\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return []\n",
    "    chosen, rest = [], candidates[:]\n",
    "    for c in rest:\n",
    "        toks = set(re.findall(r\"[a-z0-9]+\", (c.get(\"text\") or \"\").lower()))\n",
    "        c[\"_tokset\"] = toks\n",
    "    while rest and len(chosen) < k:\n",
    "        best, best_val = None, -1e9\n",
    "        for c in rest:\n",
    "            relevance = float(c.get(\"final_score\", 0.0))\n",
    "            diversity_bonus = 0.0\n",
    "            if chosen:\n",
    "                max_sim = 0.0\n",
    "                for p in chosen:\n",
    "                    inter = len(c[\"_tokset\"].intersection(p[\"_tokset\"]))\n",
    "                    union = len(c[\"_tokset\"].union(p[\"_tokset\"])) or 1\n",
    "                    jacc = inter / union\n",
    "                    max_sim = max(max_sim, jacc)\n",
    "                diversity_bonus = (1 - max_sim)  # prefer lower similarity\n",
    "            val = lambda_diversity * relevance + (1 - lambda_diversity) * diversity_bonus\n",
    "            if val > best_val:\n",
    "                best, best_val = c, val\n",
    "        chosen.append(best)\n",
    "        rest.remove(best)\n",
    "    for c in chosen:\n",
    "        c.pop(\"_tokset\", None)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Filters (Weaviate v4)\n",
    "# =========================\n",
    "\n",
    "def _build_filters(filters: Optional[Dict[str, Any]]) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Build Weaviate v4 Filter (where clause) from your light dict.\n",
    "    Supported keys in `filters`:\n",
    "      - \"year_range\": (start:int, end:int)\n",
    "      - \"scott_numbers\": List[str]   (TEXT_ARRAY containsAny)\n",
    "      - \"catalog_system\": \"Scott\"    (TEXT eq)\n",
    "      - you can extend as needed\n",
    "    \"\"\"\n",
    "    if not filters:\n",
    "        return None\n",
    "    clauses = []\n",
    "\n",
    "    if \"year_range\" in filters and isinstance(filters[\"year_range\"], (tuple, list)) and len(filters[\"year_range\"]) == 2:\n",
    "        ys, ye = filters[\"year_range\"]\n",
    "        # Prefer range-capable fields if present in your schema; if not, this will still work if you added year_start/year_end.\n",
    "        try:\n",
    "            c1 = WvFilter.by_property(\"year_start\").greater_than_equal(ys)\n",
    "            c2 = WvFilter.by_property(\"year_end\").less_than_equal(ye)\n",
    "            clauses.append(c1)\n",
    "            clauses.append(c2)\n",
    "        except Exception:\n",
    "            # Fallback: if you only have INT_ARRAY 'years', we approximate with containsAny of all years in range (coarse)\n",
    "            year_list = list(range(int(ys), int(ye) + 1))\n",
    "            clauses.append(WvFilter.by_property(\"years\").contains_any(year_list))\n",
    "\n",
    "    if filters.get(\"catalog_system\"):\n",
    "        clauses.append(WvFilter.by_property(\"catalog_systems\").contains_any([filters[\"catalog_system\"]]))\n",
    "\n",
    "    if filters.get(\"scott_numbers\"):\n",
    "        clauses.append(WvFilter.by_property(\"scott_numbers\").contains_any(list(filters[\"scott_numbers\"])))\n",
    "\n",
    "    if not clauses:\n",
    "        return None\n",
    "\n",
    "    # AND all clauses\n",
    "    where = clauses[0]\n",
    "    for c in clauses[1:]:\n",
    "        where = where & c\n",
    "    return where\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main: thresholded + diversified retrieval\n",
    "# =========================\n",
    "\n",
    "def search_chunks_semantic(\n",
    "    client,\n",
    "    query: str,\n",
    "    collection_name: str = \"Oxcart\",\n",
    "    limit: int = 5,\n",
    "    filters: Optional[Dict[str, Any]] = None,\n",
    "    mode: str = \"vector\",          # kept for backward-compat; now we may try multi-stage if needed\n",
    "    alpha: float = 0.35,           # for hybrid\n",
    "    distance_metric: str = \"cosine\",\n",
    "    # --- New safety/quality knobs (tunable) ---\n",
    "    min_score: float = 0.55,       # threshold AFTER boosts (0..1)\n",
    "    min_chars: int = 280,          # tiny snippet filter\n",
    "    mmr_lambda: float = 0.7,       # 0.5..0.8 usually fine\n",
    "    overfetch_factor: int = 3,     # fetch N√ólimit then gate\n",
    "    k_min: int = 3,                # minimum contexts needed\n",
    "    requested_scotts: Optional[List[str]] = None,  # domain boost\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Advanced retrieval with thresholding, boosts, dedup, MMR and multi-stage fallback.\n",
    "    Returns a list of results with 'final_score' and 'stage' annotations.\n",
    "    \"\"\"\n",
    "    # Prepare\n",
    "    coll = client.collections.get(collection_name)\n",
    "    f = _build_filters(filters)\n",
    "    query_years = _extract_query_years(query)\n",
    "    rejected_reasons = defaultdict(int)\n",
    "\n",
    "    def _run(mode_local: str, label: str, hard_limit: int) -> List[Dict[str, Any]]:\n",
    "        # Query Weaviate\n",
    "        if mode_local == \"hybrid\":\n",
    "            resp = coll.query.hybrid(\n",
    "                query=query,\n",
    "                alpha=alpha,\n",
    "                limit=hard_limit,\n",
    "                filters=f,\n",
    "                return_properties=[\n",
    "                    \"chunk_id\",\"chunk_type\",\"text\",\"text_original\",\"doc_id\",\"page_number\",\n",
    "                    \"catalog_systems\",\"catalog_numbers\",\"scott_numbers\",\"years\",\"colors\",\n",
    "                    \"topics_primary\",\"variety_classes\",\"has_catalog\",\"has_prices\",\"has_varieties\",\n",
    "                    \"is_guanacaste\",\"quality_score\"\n",
    "                ],\n",
    "                return_metadata=wv_query.MetadataQuery(score=True, distance=True),\n",
    "            )\n",
    "        elif mode_local == \"bm25\":\n",
    "            resp = coll.query.bm25(\n",
    "                query=query,\n",
    "                limit=hard_limit,\n",
    "                filters=f,\n",
    "                return_properties=[\n",
    "                    \"chunk_id\",\"chunk_type\",\"text\",\"text_original\",\"doc_id\",\"page_number\",\n",
    "                    \"catalog_systems\",\"catalog_numbers\",\"scott_numbers\",\"years\",\"colors\",\n",
    "                    \"topics_primary\",\"variety_classes\",\"has_catalog\",\"has_prices\",\"has_varieties\",\n",
    "                    \"is_guanacaste\",\"quality_score\"\n",
    "                ],\n",
    "                return_metadata=wv_query.MetadataQuery(score=True),\n",
    "            )\n",
    "        else:\n",
    "            resp = coll.query.near_text(\n",
    "                query=query,\n",
    "                limit=hard_limit,\n",
    "                filters=f,\n",
    "                return_properties=[\n",
    "                    \"chunk_id\",\"chunk_type\",\"text\",\"text_original\",\"doc_id\",\"page_number\",\n",
    "                    \"catalog_systems\",\"catalog_numbers\",\"scott_numbers\",\"years\",\"colors\",\n",
    "                    \"topics_primary\",\"variety_classes\",\"has_catalog\",\"has_prices\",\"has_varieties\",\n",
    "                    \"is_guanacaste\",\"quality_score\"\n",
    "                ],\n",
    "                return_metadata=wv_query.MetadataQuery(distance=True),\n",
    "            )\n",
    "\n",
    "        raw_out = []\n",
    "        for obj in (resp.objects or []):\n",
    "            props = obj.properties or {}\n",
    "            meta = getattr(obj, \"metadata\", None)\n",
    "            distance = getattr(meta, \"distance\", None) if meta else None\n",
    "            hybrid_score = getattr(meta, \"score\", None) if meta else None\n",
    "\n",
    "            similarity = _distance_to_similarity(distance, metric=distance_metric)\n",
    "            base_score = hybrid_score if hybrid_score is not None else (similarity if similarity is not None else 0.0)\n",
    "\n",
    "            # De-duplicate figure markdown inside text_original (your original logic, preserved)\n",
    "            figure_pattern = r'(!\\[([^\\]]*)\\]\\([^)]+\\))'\n",
    "            original_content = props.get(\"text_original\", \"\") or props.get(\"text\", \"\") or \"\"\n",
    "\n",
    "            figures = re.findall(figure_pattern, original_content)\n",
    "            seen_figures = set()\n",
    "            unique_figures = []\n",
    "            for fig in figures:\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path:\n",
    "                    img_identifier = img_path.group(1)\n",
    "                    if img_identifier not in seen_figures:\n",
    "                        seen_figures.add(img_identifier)\n",
    "                        unique_figures.append(fig)\n",
    "\n",
    "            existing_figures = set()\n",
    "            for fig in unique_figures:\n",
    "                if fig[0] in original_content:\n",
    "                    img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                    if img_path:\n",
    "                        existing_figures.add(img_path.group(1))\n",
    "\n",
    "            missing_figures = []\n",
    "            for fig in unique_figures:\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path and img_path.group(1) not in existing_figures:\n",
    "                    missing_figures.append(fig[0])\n",
    "\n",
    "            if missing_figures:\n",
    "                figures_text = \"\\n\\n\" + \"\\n\".join(missing_figures)\n",
    "                original_content = original_content + figures_text\n",
    "\n",
    "            raw_out.append({\n",
    "                \"uuid\": str(obj.uuid),\n",
    "                \"score\": base_score,             # original score (hybrid/bm25) or similarity (vector)\n",
    "                \"similarity\": similarity,\n",
    "                \"distance\": distance,\n",
    "                \"chunk_id\": props.get(\"chunk_id\", \"\"),\n",
    "                \"chunk_type\": props.get(\"chunk_type\", \"\"),\n",
    "                \"text\": original_content,\n",
    "                \"doc_id\": props.get(\"doc_id\", \"\"),\n",
    "                \"page_number\": props.get(\"page_number\", 0),\n",
    "                \"catalog_systems\": props.get(\"catalog_systems\", []),\n",
    "                \"catalog_numbers\": props.get(\"catalog_numbers\", []),\n",
    "                \"scott_numbers\": props.get(\"scott_numbers\", []),\n",
    "                \"years\": props.get(\"years\", []),\n",
    "                \"colors\": props.get(\"colors\", []),\n",
    "                \"topics_primary\": props.get(\"topics_primary\", \"\"),\n",
    "                \"variety_classes\": props.get(\"variety_classes\", []),\n",
    "                \"has_catalog\": props.get(\"has_catalog\", False),\n",
    "                \"has_prices\": props.get(\"has_prices\", False),\n",
    "                \"has_varieties\": props.get(\"has_varieties\", False),\n",
    "                \"is_guanacaste\": props.get(\"is_guanacaste\", False),\n",
    "                \"quality_score\": props.get(\"quality_score\", 0.0),\n",
    "                \"mode\": mode_local,\n",
    "                \"stage\": label,\n",
    "            })\n",
    "        return raw_out\n",
    "\n",
    "    def _gate_and_rank(raw_hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        gated = []\n",
    "        for h in raw_hits:\n",
    "            s_norm = _norm_score(h.get(\"score\"))\n",
    "            b = _boosts(h, query, requested_scotts, query_years)\n",
    "            final = max(0.0, min(1.0, s_norm + b))\n",
    "            ok, reason = _passes_content_gates(h, min_chars=min_chars)\n",
    "            if not ok:\n",
    "                h[\"_reject_reason\"] = reason\n",
    "                rejected_reasons[reason] += 1\n",
    "                continue\n",
    "            if final < min_score:\n",
    "                h[\"_reject_reason\"] = f\"below_threshold<{min_score:.2f}>\"\n",
    "                rejected_reasons[h[\"_reject_reason\"]] += 1\n",
    "                continue\n",
    "\n",
    "            h[\"norm_score\"] = s_norm\n",
    "            h[\"boost\"] = b\n",
    "            h[\"final_score\"] = final\n",
    "            gated.append(h)\n",
    "\n",
    "        # dedup per doc & by text hash\n",
    "        deduped = _dedup(gated, max_per_doc=2)\n",
    "        # diversify with MMR\n",
    "        diversified = _mmr_select(\n",
    "            sorted(deduped, key=lambda x: x[\"final_score\"], reverse=True),\n",
    "            k=min(limit, len(deduped)),\n",
    "            lambda_diversity=mmr_lambda\n",
    "        )\n",
    "        return diversified\n",
    "\n",
    "    # -------------------------\n",
    "    # Multi-stage retrieval\n",
    "    # -------------------------\n",
    "    # 1) Try the user-requested mode first (keeps backward compatibility)\n",
    "    modes_order = [mode]\n",
    "    for m in (\"hybrid\", \"bm25\", \"vector\"):\n",
    "        if m not in modes_order:\n",
    "            modes_order.append(m)\n",
    "\n",
    "    gathered: List[Dict[str, Any]] = []\n",
    "    for mi, m in enumerate(modes_order):\n",
    "        raw = _run(m, f\"S{mi+1}:{m}+filters\", hard_limit=limit * overfetch_factor)\n",
    "        gated = _gate_and_rank(raw)\n",
    "\n",
    "        # Merge by uuid, keep best final_score\n",
    "        heap = {g[\"uuid\"]: g for g in gathered}\n",
    "        for g in gated:\n",
    "            if g[\"uuid\"] not in heap or g[\"final_score\"] > heap[g[\"uuid\"]][\"final_score\"]:\n",
    "                heap[g[\"uuid\"]] = g\n",
    "        gathered = list(heap.values())\n",
    "        gathered.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
    "        gathered = gathered[:limit]\n",
    "        if len(gathered) >= k_min:\n",
    "            break\n",
    "\n",
    "    # 2) Relax filters if still not enough (drop Scott, then year)\n",
    "    if len(gathered) < k_min and filters:\n",
    "        relaxed = dict(filters)\n",
    "        if \"scott_numbers\" in relaxed:\n",
    "            relaxed.pop(\"scott_numbers\")\n",
    "        elif \"year_range\" in relaxed:\n",
    "            relaxed.pop(\"year_range\")\n",
    "\n",
    "        f_relaxed = _build_filters(relaxed)\n",
    "        if f_relaxed is not None:\n",
    "            for mi, m in enumerate(modes_order):\n",
    "                # temporarily replace f for this pass\n",
    "                _old_f = f\n",
    "                try:\n",
    "                    f = f_relaxed\n",
    "                    raw = _run(m, f\"Rx{mi+1}:{m}+relaxed\", hard_limit=limit * overfetch_factor)\n",
    "                    gated = _gate_and_rank(raw)\n",
    "                    heap = {g[\"uuid\"]: g for g in gathered}\n",
    "                    for g in gated:\n",
    "                        if g[\"uuid\"] not in heap or g[\"final_score\"] > heap[g[\"uuid\"]][\"final_score\"]:\n",
    "                            heap[g[\"uuid\"]] = g\n",
    "                    gathered = list(heap.values())\n",
    "                    gathered.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
    "                    gathered = gathered[:limit]\n",
    "                    if len(gathered) >= k_min:\n",
    "                        break\n",
    "                finally:\n",
    "                    f = _old_f  # restore\n",
    "\n",
    "    # You can inspect `rejected_reasons` here for debugging if needed.\n",
    "    return gathered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_answer_basic(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    year_start: Optional[int] = None,\n",
    "    year_end: Optional[int] = None,\n",
    "    scott_numbers: Optional[List[str]] = None,\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Basic hybrid search approach with improved philatelic filters.\n",
    "    All filters are OPTIONAL - only applied when provided.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"‚ùå Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "    \n",
    "    client_wv = rag_system[\"client\"]\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    \n",
    "    # Build philatelic filters only if values are provided\n",
    "    filters = {}\n",
    "    \n",
    "    # Year range filter - ONLY if both years are provided and valid\n",
    "    if year_start is not None and year_end is not None:\n",
    "        try:\n",
    "            # Ensure both are integers and valid\n",
    "            start = int(year_start)\n",
    "            end = int(year_end)\n",
    "            # Ensure start <= end\n",
    "            if start > end:\n",
    "                start, end = end, start\n",
    "            filters[\"year_range\"] = (start, end)\n",
    "            print(f\"[DEBUG] Year filter applied: {start}-{end}\")\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(f\"[WARNING] Invalid year values, skipping year filter: {e}\")\n",
    "    \n",
    "    # Scott numbers ONLY if provided and not empty\n",
    "    if scott_numbers:\n",
    "        print(\"Scott Numbers: \",scott_numbers)\n",
    "        filters[\"catalog_system\"] = \"Scott\"\n",
    "        filters[\"scott_numbers\"] = scott_numbers        \n",
    "    \n",
    "    # Log final filter status\n",
    "    if not filters:\n",
    "        print(\"[DEBUG] No filters applied - searching all documents\")\n",
    "    else:\n",
    "        print(f\"[DEBUG] Filters being used: {filters}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Basic semantic search with philatelic filters\n",
    "        # Pass None if no filters, not empty dict\n",
    "        results = search_chunks_semantic(\n",
    "            client=client_wv,\n",
    "            query=query,\n",
    "            collection_name=collection_name,\n",
    "            limit=int(max_results),\n",
    "            filters=filters if filters else None,  # Pass None if no filters\n",
    "            mode=\"hybrid\",\n",
    "            alpha=0.35,\n",
    "            min_score=0.55,\n",
    "            min_chars=280,\n",
    "            k_min=3,\n",
    "        )\n",
    "        \n",
    "        # Convert to LangChain document format for RAG\n",
    "        docs_for_rag = []\n",
    "        for r in results:\n",
    "            doc = type('Document', (), {\n",
    "                'page_content': r.get('text', ''),\n",
    "                'metadata': {\n",
    "                    'doc_id': r.get('doc_id', 'N/A'),\n",
    "                    'page_number': r.get('page_number', 'N/A'),\n",
    "                    'chunk_type': r.get('chunk_type', 'N/A'),\n",
    "                    'score': r.get('score', 0.0),\n",
    "                    'scott_numbers': r.get('scott_numbers', []),\n",
    "                    'years': r.get('years', []),\n",
    "                    'catalog_systems': r.get('catalog_systems', [])\n",
    "                }\n",
    "            })()\n",
    "            docs_for_rag.append(doc)\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(docs_for_rag, query)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Build metadata with actual filters used\n",
    "        metadata = {\n",
    "            \"approach\": \"Basic Hybrid Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"max_results\": int(max_results),\n",
    "            \"filters_used\": filters if filters else \"None (searching all documents)\",\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response.get(\"context_docs_count\", len(docs_for_rag)),\n",
    "            \"context_length\": sum(len(d.page_content) for d in docs_for_rag),\n",
    "            \"token_usage\": rag_response.get(\"token_usage\", {}),\n",
    "            \"cost_info\": rag_response.get(\"cost_info\", {}),\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response.get(\"response\", \"No response generated\"),\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"[ERROR] Basic search error: {str(e)}\")\n",
    "        print(f\"[ERROR] Full traceback: {error_details}\")\n",
    "        print(f\"[ERROR] Filters attempted: {filters}\")\n",
    "        \n",
    "        return {\n",
    "            \"answer\": f\"‚ùå Basic search error: {str(e)}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\n",
    "                \"error\": str(e),\n",
    "                \"generation_time\": 0,\n",
    "                \"filters_attempted\": filters if filters else \"None\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_answer_advanced(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    max_results: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Advanced compression search approach - filters NOT applied (as requested).\n",
    "    Now tracks both compression and RAG response token usage and costs.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        return {\n",
    "            \"answer\": \"‚ùå Error: No Weaviate connection\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\"error\": \"No Weaviate connection\"}\n",
    "        }\n",
    "\n",
    "    client_wv = rag_system[\"client\"]\n",
    "    embeddings = rag_system.get(\"embeddings\")\n",
    "    llm = rag_system.get(\"llm\")\n",
    "    \n",
    "    # NOTE: Advanced search does not apply filters as requested by user\n",
    "    # This approach uses ensemble retrieval and compression instead\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Advanced search with compression (no filters applied) - now returns token info\n",
    "        compressed_docs, compression_token_usage, compression_cost_info = search_stamps_with_compression(\n",
    "            query=query,\n",
    "            client=client_wv,\n",
    "            embeddings=embeddings,\n",
    "            llm=llm,\n",
    "            limit=max_results,\n",
    "            alpha=0.30,\n",
    "            diversity_lambda=0.75\n",
    "        )\n",
    "        \n",
    "        # Generate RAG response using LangChain\n",
    "        rag_response = create_rag_response(compressed_docs, query)\n",
    "        \n",
    "        # Extraer y preservar figuras de los documentos originales\n",
    "        figure_pattern = r'(!\\[([^\\]]*)\\]\\([^)]+\\))'\n",
    "\n",
    "        for doc in compressed_docs:\n",
    "            # Buscar figuras en el contenido original si est√° disponible\n",
    "            original_content = doc.metadata.get('text_original', doc.page_content)\n",
    "            \n",
    "            # Extraer todas las figuras del contenido original\n",
    "            figures = re.findall(figure_pattern, original_content)\n",
    "            \n",
    "            # Eliminar duplicados manteniendo el orden\n",
    "            seen_figures = set()\n",
    "            unique_figures = []\n",
    "            for fig in figures:\n",
    "                # Usar el path de la imagen como identificador √∫nico (ignorando el alt text)\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path:\n",
    "                    img_identifier = img_path.group(1)\n",
    "                    if img_identifier not in seen_figures:\n",
    "                        seen_figures.add(img_identifier)\n",
    "                        unique_figures.append(fig)\n",
    "            \n",
    "            # Verificar qu√© figuras ya est√°n en el contenido comprimido\n",
    "            existing_figures = set()\n",
    "            for fig in unique_figures:\n",
    "                if fig[0] in doc.page_content:\n",
    "                    img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                    if img_path:\n",
    "                        existing_figures.add(img_path.group(1))\n",
    "            \n",
    "            # Agregar solo las figuras que faltan\n",
    "            missing_figures = []\n",
    "            for fig in unique_figures:\n",
    "                img_path = re.search(r'\\]\\(([^)]+)\\)', fig[0])\n",
    "                if img_path and img_path.group(1) not in existing_figures:\n",
    "                    missing_figures.append(fig[0])\n",
    "            \n",
    "            # Si hay figuras faltantes, agregarlas al final\n",
    "            if missing_figures:\n",
    "                figures_text = \"\\n\\n\" + \"\\n\".join(missing_figures)\n",
    "                doc.page_content = doc.page_content + figures_text\n",
    "            \n",
    "            # Guardar las figuras √∫nicas en metadata para acceso r√°pido\n",
    "            doc.metadata['figures'] = [fig[0] for fig in unique_figures] if unique_figures else []\n",
    "            doc.metadata['has_figures'] = len(unique_figures) > 0\n",
    "        \n",
    "        # Convert compressed docs to results format for display\n",
    "        results = []\n",
    "        for i, doc in enumerate(compressed_docs):\n",
    "            result = {\n",
    "                'doc_id': doc.metadata.get('doc_id', 'N/A'),\n",
    "                'page_number': doc.metadata.get('page_number', 'N/A'),\n",
    "                'chunk_type': doc.metadata.get('chunk_type', 'N/A'),\n",
    "                'text': doc.page_content,\n",
    "                'score': doc.metadata.get('quality_score', 0.0),\n",
    "                'catalog_systems': doc.metadata.get('catalog_systems', []),\n",
    "                'scott_numbers': doc.metadata.get('scott_numbers', []),\n",
    "                'years': doc.metadata.get('years', []),\n",
    "                'colors': doc.metadata.get('colors', []),\n",
    "                'variety_classes': doc.metadata.get('variety_classes', []),\n",
    "                'has_figures': doc.metadata.get('has_figures', False),  \n",
    "                'figures': doc.metadata.get('figures', [])  \n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Combine compression and RAG token usage/costs\n",
    "        rag_token_usage = rag_response.get(\"token_usage\", {})\n",
    "        rag_cost_info = rag_response.get(\"cost_info\", {})\n",
    "        \n",
    "        # Create combined token usage structure\n",
    "        combined_token_usage = {\n",
    "            \"compression\": {\n",
    "                \"input_tokens\": compression_token_usage.get(\"input_tokens\", 0),\n",
    "                \"output_tokens\": compression_token_usage.get(\"output_tokens\", 0),\n",
    "                \"total_tokens\": compression_token_usage.get(\"total_tokens\", 0)\n",
    "            },\n",
    "            \"rag_response\": {\n",
    "                \"input_tokens\": rag_token_usage.get(\"input_tokens\", 0),\n",
    "                \"output_tokens\": rag_token_usage.get(\"output_tokens\", 0),\n",
    "                \"total_tokens\": rag_token_usage.get(\"total_tokens\", 0)\n",
    "            },\n",
    "            \"total\": {\n",
    "                \"input_tokens\": (compression_token_usage.get(\"input_tokens\", 0) + \n",
    "                               rag_token_usage.get(\"input_tokens\", 0)),\n",
    "                \"output_tokens\": (compression_token_usage.get(\"output_tokens\", 0) + \n",
    "                                rag_token_usage.get(\"output_tokens\", 0)),\n",
    "                \"total_tokens\": (compression_token_usage.get(\"total_tokens\", 0) + \n",
    "                               rag_token_usage.get(\"total_tokens\", 0))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Create combined cost info structure\n",
    "        combined_cost_info = {\n",
    "            \"compression\": {\n",
    "                \"input_cost\": compression_cost_info.get(\"input_cost\", 0.0),\n",
    "                \"output_cost\": compression_cost_info.get(\"output_cost\", 0.0),\n",
    "                \"estimated_cost_usd\": compression_cost_info.get(\"estimated_cost_usd\", 0.0)\n",
    "            },\n",
    "            \"rag_response\": {\n",
    "                \"input_cost\": rag_cost_info.get(\"input_cost\", 0.0),\n",
    "                \"output_cost\": rag_cost_info.get(\"output_cost\", 0.0),\n",
    "                \"estimated_cost_usd\": rag_cost_info.get(\"estimated_cost_usd\", 0.0)\n",
    "            },\n",
    "            \"total\": {\n",
    "                \"input_cost\": (compression_cost_info.get(\"input_cost\", 0.0) + \n",
    "                             rag_cost_info.get(\"input_cost\", 0.0)),\n",
    "                \"output_cost\": (compression_cost_info.get(\"output_cost\", 0.0) + \n",
    "                              rag_cost_info.get(\"output_cost\", 0.0)),\n",
    "                \"estimated_cost_usd\": (compression_cost_info.get(\"estimated_cost_usd\", 0.0) + \n",
    "                                     rag_cost_info.get(\"estimated_cost_usd\", 0.0))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        metadata = {\n",
    "            \"approach\": \"Advanced Compression Search\",\n",
    "            \"query\": query,\n",
    "            \"total_results\": len(results),\n",
    "            \"compressed_docs\": len(compressed_docs),\n",
    "            \"filters_used\": \"No filters (advanced approach)\",\n",
    "            \"generation_time\": execution_time,\n",
    "            \"context_docs_count\": rag_response.get(\"context_docs_count\", len(compressed_docs)),\n",
    "            \"docs_with_figures\": sum(1 for r in results if r.get('has_figures', False)),\n",
    "            \"token_usage\": combined_token_usage,\n",
    "            \"cost_info\": combined_cost_info,\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"answer\": rag_response.get(\"response\", \"No response generated\"),\n",
    "            \"results\": results,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"[ERROR] Advanced search error: {str(e)}\")\n",
    "        print(f\"[ERROR] Full traceback: {error_details}\")\n",
    "        \n",
    "        return {\n",
    "            \"answer\": f\"‚ùå Advanced search error: {str(e)}\",\n",
    "            \"results\": [],\n",
    "            \"metadata\": {\n",
    "                \"error\": str(e),\n",
    "                \"generation_time\": 0,\n",
    "                \"filters_attempted\": \"None\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timing_display(\n",
    "          basic_time, advanced_time, total_time,\n",
    "          basic_results, advanced_results,\n",
    "          filter_msg=\"\",\n",
    "          basic_metadata=None, advanced_metadata=None\n",
    "      ):\n",
    "    \"\"\"Enhanced timing display with cost comparison (robust casting)\"\"\"\n",
    "    try:\n",
    "        # --- helpers seguros ---\n",
    "        def as_float(x, default=0.0):\n",
    "            try:\n",
    "                return float(x)\n",
    "            except (TypeError, ValueError):\n",
    "                return default\n",
    "\n",
    "        def as_int(x, default=0):\n",
    "            try:\n",
    "                # evita ints tipo '1_234' si viniera as√≠\n",
    "                return int(float(x))\n",
    "            except (TypeError, ValueError):\n",
    "                return default\n",
    "\n",
    "        # tiempos\n",
    "        basic_time = as_float(basic_time)\n",
    "        advanced_time = as_float(advanced_time)\n",
    "        total_time = as_float(total_time)\n",
    "\n",
    "        # costos - ARREGLO AQU√ç para manejar estructura anidada\n",
    "        basic_cost = 0.0\n",
    "        advanced_cost = 0.0\n",
    "\n",
    "        if basic_metadata and 'cost_info' in basic_metadata:\n",
    "            basic_cost = as_float(basic_metadata['cost_info'].get('estimated_cost_usd', 0))\n",
    "\n",
    "        if advanced_metadata and 'cost_info' in advanced_metadata:\n",
    "            # Detectar si es estructura anidada\n",
    "            adv_cost_info = advanced_metadata['cost_info']\n",
    "            if 'total' in adv_cost_info and isinstance(adv_cost_info['total'], dict):\n",
    "                # Estructura anidada - usar el total\n",
    "                advanced_cost = as_float(adv_cost_info['total'].get('estimated_cost_usd', 0))\n",
    "            else:\n",
    "                # Estructura simple\n",
    "                advanced_cost = as_float(adv_cost_info.get('estimated_cost_usd', 0))\n",
    "\n",
    "        total_cost = basic_cost + advanced_cost\n",
    "\n",
    "        # tokens (¬°forzar int!) - ARREGLO AQU√ç para manejar estructura anidada\n",
    "        basic_tokens = 0\n",
    "        advanced_tokens = 0\n",
    "\n",
    "        if basic_metadata and 'token_usage' in basic_metadata:\n",
    "            basic_tokens = as_int(basic_metadata['token_usage'].get('total_tokens', 0))\n",
    "\n",
    "        if advanced_metadata and 'token_usage' in advanced_metadata:\n",
    "            # Detectar si es estructura anidada\n",
    "            adv_token_usage = advanced_metadata['token_usage']\n",
    "            if 'total' in adv_token_usage and isinstance(adv_token_usage['total'], dict):\n",
    "                # Estructura anidada - usar el total\n",
    "                advanced_tokens = as_int(adv_token_usage['total'].get('total_tokens', 0))\n",
    "            else:\n",
    "                # Estructura simple\n",
    "                advanced_tokens = as_int(adv_token_usage.get('total_tokens', 0))\n",
    "\n",
    "        total_tokens = basic_tokens + advanced_tokens\n",
    "\n",
    "        # faster\n",
    "        if basic_time > 0 and advanced_time > 0:\n",
    "            if basic_time < advanced_time:\n",
    "                faster = f\"üèÜ Basic search was {advanced_time/basic_time:.1f}x faster\"\n",
    "            elif advanced_time < basic_time:\n",
    "                faster = f\"üèÜ Advanced search was {basic_time/advanced_time:.1f}x faster\"\n",
    "            else:\n",
    "                faster = \"‚ö° Both approaches took similar time\"\n",
    "        else:\n",
    "            faster = \"‚è±Ô∏è Timing comparison not available\"\n",
    "\n",
    "        # cost effectiveness\n",
    "        cost_comparison = \"\"\n",
    "        if basic_cost > 0 and advanced_cost > 0:\n",
    "            if basic_cost < advanced_cost:\n",
    "                cost_comparison = f\"üíµ Basic search was ${advanced_cost - basic_cost:.6f} cheaper\"\n",
    "            elif advanced_cost < basic_cost:\n",
    "                cost_comparison = f\"üíµ Advanced search was ${basic_cost - advanced_cost:.6f} cheaper\"\n",
    "            else:\n",
    "                cost_comparison = \"üíµ Both approaches had similar costs\"\n",
    "\n",
    "        # speeds\n",
    "        basic_speed = f\"{basic_results/basic_time:.1f}\" if basic_time > 0 else \"N/A\"\n",
    "        advanced_speed = f\"{advanced_results/advanced_time:.1f}\" if advanced_time > 0 else \"N/A\"\n",
    "\n",
    "        timing_display = f\"\"\"‚è±Ô∏è EXECUTION TIMING & COST COMPARISON\n",
    "            ================================================\n",
    "\n",
    "            üìã SEARCH CONFIGURATION\n",
    "            ‚Ä¢ {filter_msg}\n",
    "\n",
    "            üîç BASIC HYBRID SEARCH\n",
    "            ‚Ä¢ Processing Time: {basic_time:.2f} seconds\n",
    "            ‚Ä¢ Documents Found: {basic_results}\n",
    "            ‚Ä¢ Speed: {basic_speed} docs/sec\n",
    "            ‚Ä¢ Tokens Used: {basic_tokens:,}\n",
    "            ‚Ä¢ Cost: ${basic_cost:.6f}\n",
    "            ‚Ä¢ Status: ‚úÖ Complete\n",
    "\n",
    "            üöÄ ADVANCED COMPRESSION SEARCH\n",
    "            ‚Ä¢ Processing Time: {advanced_time:.2f} seconds\n",
    "            ‚Ä¢ Documents Found: {advanced_results}\n",
    "            ‚Ä¢ Speed: {advanced_speed} docs/sec\n",
    "            ‚Ä¢ Tokens Used: {advanced_tokens:,}\n",
    "            ‚Ä¢ Cost: ${advanced_cost:.6f}\n",
    "            ‚Ä¢ Status: ‚úÖ Complete\n",
    "\n",
    "            üìä OVERALL PERFORMANCE\n",
    "            ‚Ä¢ Total Execution: {total_time:.2f} seconds\n",
    "            ‚Ä¢ Total Tokens: {total_tokens:,}\n",
    "            ‚Ä¢ Total Cost: ${total_cost:.6f}\n",
    "            ‚Ä¢ Execution Mode: Sequential (Basic ‚Üí Advanced)\n",
    "            ‚Ä¢ {faster}\n",
    "            ‚Ä¢ {cost_comparison}\n",
    "\n",
    "            üí° PERFORMANCE NOTES:\n",
    "            ‚Ä¢ Basic search: Fast initial results, lower cost\n",
    "            ‚Ä¢ Advanced search: Enhanced quality, higher token usage\n",
    "            ‚Ä¢ Costs shown are for GPT-4.1-Nano(advanced seach with multiquery and compression) & GPT-5-mini (generation phase) models\n",
    "            ‚Ä¢ Sequential execution allows progressive viewing\n",
    "            ‚Ä¢ Filters are optional and only applied when provided\"\"\"\n",
    "        return timing_display\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error formatting timing data: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para convertir Markdown a HTML con correcci√≥n de rutas de im√°genes\n",
    "def markdown_to_html(text):\n",
    "    \"\"\"Convert markdown text to HTML with lazy base64 loading\"\"\"\n",
    "    if not text:\n",
    "        return \"<p><em>No content</em></p>\"\n",
    "    \n",
    "    import re\n",
    "    import os\n",
    "    import base64\n",
    "    \n",
    "    base_path = r\"C:\\Users\\VM-SERVER\\Desktop\\Oxcart RAG\\results\\markdown\\figures\"\n",
    "    \n",
    "    def image_to_base64_lazy(match):\n",
    "        alt_text = match.group(1)\n",
    "        filename = match.group(2).split('/')[-1].split('\\\\')[-1]\n",
    "        full_path = os.path.join(base_path, filename)\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            try:\n",
    "                with open(full_path, \"rb\") as img_file:\n",
    "                    b64_string = base64.b64encode(img_file.read()).decode()\n",
    "                    ext = filename.split('.')[-1].lower()\n",
    "                    mime_type = f\"image/{ext}\" if ext != 'jpg' else \"image/jpeg\"\n",
    "                    return f'<img style=\"max-width: 100%; height: auto; display: block; margin: 10px auto; border: 1px solid #ddd; border-radius: 4px;\" alt=\"{alt_text}\" src=\"data:{mime_type};base64,{b64_string}\" />'\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {filename}: {e}\")\n",
    "                return f'<p>[Image not found: {filename}]</p>'\n",
    "        else:\n",
    "            return f'<p>[Image not found: {filename}]</p>'\n",
    "    \n",
    "    # Primero convertir markdown a HTML\n",
    "    html = markdown.markdown(text, extensions=['tables', 'fenced_code'])\n",
    "    \n",
    "    # Luego reemplazar las im√°genes en el HTML\n",
    "    html = re.sub(\n",
    "        r'<img[^>]*alt=\"([^\"]*)\"[^>]*src=\"[^\"]*?([^/\\\\\">]+\\.(?:png|jpg|jpeg|gif))\"[^>]*>',\n",
    "        image_to_base64_lazy,\n",
    "        html\n",
    "    )\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(results, approach_name):\n",
    "    \"\"\"Format search results for display in Markdown with figure handling\"\"\"\n",
    "    if not results:\n",
    "        return f\"*No results found with {approach_name}*\"\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"### {approach_name} Results\")\n",
    "    lines.append(f\"**Found {len(results)} documents**\\n\")\n",
    "    lines.append(\"---\")\n",
    "    \n",
    "    for i, r in enumerate(results):\n",
    "        doc_id = r.get(\"doc_id\", \"N/A\")\n",
    "        chunk_type_val = r.get(\"chunk_type\", \"N/A\")\n",
    "        page_number = r.get(\"page_number\", \"N/A\")\n",
    "        score = r.get(\"score\", 0.0)\n",
    "        catalogs = r.get(\"catalog_systems\", [])\n",
    "        scotts = r.get(\"scott_numbers\", [])\n",
    "        years = r.get(\"years\", [])\n",
    "\n",
    "        # Get full text (including figures)\n",
    "        text = r.get(\"text\", \"\")\n",
    "        \n",
    "        # Check if text contains figures\n",
    "        has_figures = \"![Figure]\" in text or \"![\" in text\n",
    "        \n",
    "        # Extract just the text preview (without figures)\n",
    "        import re\n",
    "        text_without_figures = re.sub(r'!\\[([^\\]]*)\\]\\([^)]+\\)', '', text).strip()\n",
    "        preview = (text_without_figures[:300] + \"...\") if len(text_without_figures) > 300 else text_without_figures\n",
    "        \n",
    "        # Extract all figure references\n",
    "        figure_pattern = r'(!\\[([^\\]]*)\\]\\([^)]+\\))'\n",
    "        figures = re.findall(figure_pattern, text)\n",
    "\n",
    "        lines.append(f\"\\n#### üìÑ Result {i+1}\")\n",
    "        lines.append(f\"**Score:** `{score:.3f}`\")\n",
    "        \n",
    "        if has_figures:\n",
    "            lines.append(\"üñºÔ∏è **This result contains figures**\\n\")\n",
    "        \n",
    "        # Create a table for metadata\n",
    "        lines.append(\"| Field | Value |\")\n",
    "        lines.append(\"|-------|-------|\")\n",
    "        lines.append(f\"| Document | `{doc_id}` |\")\n",
    "        lines.append(f\"| Type | {chunk_type_val} |\")\n",
    "        lines.append(f\"| Page | {page_number} |\")\n",
    "        \n",
    "        if catalogs:\n",
    "            lines.append(f\"| Catalogs | {', '.join(catalogs)} |\")\n",
    "        if scotts:\n",
    "            lines.append(f\"| Scott Numbers | **{', '.join(scotts)}** |\")\n",
    "        if years:\n",
    "            lines.append(f\"| Years | {', '.join(str(y) for y in years)} |\")\n",
    "        \n",
    "        # Always show preview\n",
    "        lines.append(f\"\\n**Preview:**\")\n",
    "        lines.append(f\"> {preview}\")\n",
    "        \n",
    "        # Always show figures if they exist\n",
    "        if has_figures and figures:\n",
    "            lines.append(f\"\\n**Figures in this result:**\\n\")\n",
    "            for figure_match in figures:\n",
    "                lines.append(figure_match[0])  # Add the complete figure markdown\n",
    "        \n",
    "        lines.append(\"\\n---\")\n",
    "    \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metadata(metadata, execution_time):\n",
    "    \"\"\"Format metadata for display in Markdown including token usage and costs (supports both basic and advanced structures).\"\"\"\n",
    "    if not metadata:\n",
    "        return \"*No metadata available*\"\n",
    "\n",
    "    # Helpers\n",
    "    def as_float(x, default=None):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "\n",
    "    def as_int(x, default=None):\n",
    "        try:\n",
    "            return int(float(x))\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "\n",
    "    out = []\n",
    "    out.append(\"### Search Metadata\\n\")\n",
    "\n",
    "    # Basic info\n",
    "    out.append(\"#### üìä Search Information\\n\")\n",
    "    out.append(\"| Property | Value |\")\n",
    "    out.append(\"|----------|-------|\")\n",
    "    out.append(f\"| **Approach** | {metadata.get('approach', 'Unknown')} |\")\n",
    "    query_val = str(metadata.get('query', 'N/A')).replace(\"\\n\", \" \")\n",
    "    # (opcional) escapar pipes para no romper la tabla\n",
    "    query_val = query_val.replace(\"|\", \"\\\\|\")\n",
    "    out.append(f\"| **Query** | `{query_val}` |\")\n",
    "\n",
    "    total_results = as_int(metadata.get('total_results'), 0)\n",
    "    out.append(f\"| **Results found** | {total_results} |\")\n",
    "\n",
    "    context_docs_count = as_int(metadata.get('context_docs_count'))\n",
    "    out.append(f\"| **Context docs** | {context_docs_count if context_docs_count is not None else 'N/A'} |\")\n",
    "\n",
    "    context_length = as_int(metadata.get('context_length'))\n",
    "    out.append(\n",
    "        f\"| **Context length** | {context_length:,} chars |\"\n",
    "        if context_length is not None else\n",
    "        \"| **Context length** | N/A |\"\n",
    "    )\n",
    "\n",
    "    if metadata.get('filters_used'):\n",
    "        filters_str = str(metadata['filters_used']).replace('{', '').replace('}', '')\n",
    "        filters_str = filters_str.replace(\"|\", \"\\\\|\")\n",
    "        out.append(f\"| **Filters** | `{filters_str}` |\")\n",
    "\n",
    "    if 'compressed_docs' in metadata:\n",
    "        out.append(f\"| **Compressed docs** | {metadata['compressed_docs']} |\")\n",
    "\n",
    "    out.append(\"\")  # Add space after basic info table\n",
    "\n",
    "    # Detect token usage structure type\n",
    "    token_usage = metadata.get('token_usage') or {}\n",
    "    cost_info = metadata.get('cost_info') or {}\n",
    "\n",
    "    # Check if this is nested structure (advanced search) or simple structure (basic search)\n",
    "    is_nested = (\n",
    "        isinstance(token_usage, dict) and\n",
    "        any(key in token_usage for key in ['compression', 'rag_response', 'total'])\n",
    "    )\n",
    "\n",
    "    if token_usage:\n",
    "        if is_nested:\n",
    "            # Advanced search - nested structure\n",
    "            out.append(\"#### üéØ Token Usage Breakdown\\n\")\n",
    "\n",
    "            # Compression tokens\n",
    "            compression_tokens = token_usage.get('compression', {})\n",
    "            if compression_tokens:\n",
    "                comp_in = as_int(compression_tokens.get('input_tokens'), 0)\n",
    "                comp_out = as_int(compression_tokens.get('output_tokens'), 0)\n",
    "                comp_total = as_int(compression_tokens.get('total_tokens'), (comp_in or 0) + (comp_out or 0))\n",
    "\n",
    "                out.append(\"**Document Compression:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| Input tokens | {comp_in:,} |\")\n",
    "                out.append(f\"| Output tokens | {comp_out:,} |\")\n",
    "                out.append(f\"| Total tokens | {comp_total:,} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # RAG response tokens\n",
    "            rag_tokens = token_usage.get('rag_response', {})\n",
    "            if rag_tokens:\n",
    "                rag_in = as_int(rag_tokens.get('input_tokens'), 0)\n",
    "                rag_out = as_int(rag_tokens.get('output_tokens'), 0)\n",
    "                rag_total = as_int(rag_tokens.get('total_tokens'), (rag_in or 0) + (rag_out or 0))\n",
    "\n",
    "                out.append(\"**RAG Response Generation:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| Input tokens | {rag_in:,} |\")\n",
    "                out.append(f\"| Output tokens | {rag_out:,} |\")\n",
    "                out.append(f\"| Total tokens | {rag_total:,} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # Total tokens\n",
    "            total_tokens = token_usage.get('total', {})\n",
    "            if total_tokens:\n",
    "                total_in = as_int(total_tokens.get('input_tokens'), 0)\n",
    "                total_out = as_int(total_tokens.get('output_tokens'), 0)\n",
    "                total_total = as_int(total_tokens.get('total_tokens'), (total_in or 0) + (total_out or 0))\n",
    "\n",
    "                out.append(\"**Combined Total:**\\n\")\n",
    "                out.append(\"| Token Type | Count |\")\n",
    "                out.append(\"|------------|-------|\")\n",
    "                out.append(f\"| **Total input tokens** | **{total_in:,}** |\")\n",
    "                out.append(f\"| **Total output tokens** | **{total_out:,}** |\")\n",
    "                out.append(f\"| **Grand total tokens** | **{total_total:,}** |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "        else:\n",
    "            # Basic search - simple structure\n",
    "            in_tok = as_int(token_usage.get('input_tokens'), 0)\n",
    "            out_tok = as_int(token_usage.get('output_tokens'), 0)\n",
    "            tot_tok = as_int(token_usage.get('total_tokens'), (in_tok or 0) + (out_tok or 0))\n",
    "\n",
    "            out.append(\"#### üéØ Token Usage\\n\")\n",
    "            out.append(\"| Token Type | Count |\")\n",
    "            out.append(\"|------------|-------|\")\n",
    "            out.append(f\"| **Input tokens** | {in_tok:,} |\")\n",
    "            out.append(f\"| **Output tokens** | {out_tok:,} |\")\n",
    "            out.append(f\"| **Total tokens** | {tot_tok:,} |\")\n",
    "            out.append(\"\")  # Add space after table\n",
    "\n",
    "    # Cost info - handle both nested and simple structures\n",
    "    if cost_info:\n",
    "        is_cost_nested = (\n",
    "            isinstance(cost_info, dict) and\n",
    "            any(key in cost_info for key in ['compression', 'rag_response', 'total'])\n",
    "        )\n",
    "\n",
    "        if is_cost_nested:\n",
    "            # Advanced search - nested cost structure\n",
    "            out.append(\"#### üí∞ Cost Analysis Breakdown\\n\")\n",
    "\n",
    "            # Compression costs\n",
    "            compression_cost = cost_info.get('compression', {})\n",
    "            if compression_cost:\n",
    "                comp_in_cost = as_float(compression_cost.get('input_cost'), 0.0)\n",
    "                comp_out_cost = as_float(compression_cost.get('output_cost'), 0.0)\n",
    "                comp_total_cost = as_float(compression_cost.get('estimated_cost_usd'),\n",
    "                                        (comp_in_cost or 0.0) + (comp_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**Document Compression:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| Input cost | ${comp_in_cost:.6f} |\")\n",
    "                out.append(f\"| Output cost | ${comp_out_cost:.6f} |\")\n",
    "                out.append(f\"| Subtotal | ${comp_total_cost:.6f} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # RAG response costs\n",
    "            rag_cost = cost_info.get('rag_response', {})\n",
    "            if rag_cost:\n",
    "                rag_in_cost = as_float(rag_cost.get('input_cost'), 0.0)\n",
    "                rag_out_cost = as_float(rag_cost.get('output_cost'), 0.0)\n",
    "                rag_total_cost = as_float(rag_cost.get('estimated_cost_usd'),\n",
    "                                        (rag_in_cost or 0.0) + (rag_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**RAG Response Generation:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| Input cost | ${rag_in_cost:.6f} |\")\n",
    "                out.append(f\"| Output cost | ${rag_out_cost:.6f} |\")\n",
    "                out.append(f\"| Subtotal | ${rag_total_cost:.6f} |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "            # Total costs\n",
    "            total_cost = cost_info.get('total', {})\n",
    "            if total_cost:\n",
    "                total_in_cost = as_float(total_cost.get('input_cost'), 0.0)\n",
    "                total_out_cost = as_float(total_cost.get('output_cost'), 0.0)\n",
    "                total_total_cost = as_float(total_cost.get('estimated_cost_usd'),\n",
    "                                        (total_in_cost or 0.0) + (total_out_cost or 0.0))\n",
    "\n",
    "                out.append(\"**Combined Total:**\\n\")\n",
    "                out.append(\"| Cost Component | USD |\")\n",
    "                out.append(\"|----------------|-----|\")\n",
    "                out.append(f\"| **Total input cost** | **${total_in_cost:.6f}** |\")\n",
    "                out.append(f\"| **Total output cost** | **${total_out_cost:.6f}** |\")\n",
    "                out.append(f\"| **Grand total cost** | **${total_total_cost:.6f}** |\")\n",
    "                out.append(\"\")  # Add space after table\n",
    "\n",
    "        else:\n",
    "            # Basic search - simple cost structure\n",
    "            in_cost = as_float(cost_info.get('input_cost'), 0.0)\n",
    "            out_cost = as_float(cost_info.get('output_cost'), 0.0)\n",
    "            est_cost = as_float(cost_info.get('estimated_cost_usd'), (in_cost or 0.0) + (out_cost or 0.0))\n",
    "\n",
    "            out.append(\"#### üí∞ Cost Analysis\\n\")\n",
    "            out.append(\"| Cost Component | USD |\")\n",
    "            out.append(\"|----------------|-----|\")\n",
    "            out.append(f\"| **Input cost** | ${in_cost:.6f} |\")\n",
    "            out.append(f\"| **Output cost** | ${out_cost:.6f} |\")\n",
    "            out.append(f\"| **Total cost** | **${est_cost:.6f}** |\")\n",
    "            out.append(\"\")  # Add space after table\n",
    "\n",
    "    # Performance\n",
    "    out.append(\"#### ‚è±Ô∏è Performance\\n\")\n",
    "    out.append(\"| Metric | Time |\")\n",
    "    out.append(\"|--------|------|\")\n",
    "\n",
    "    gen_time = as_float(metadata.get('generation_time'))\n",
    "    if gen_time is not None:\n",
    "        out.append(f\"| **Generation time** | {gen_time:.2f}s |\")\n",
    "\n",
    "    # Error handling\n",
    "    if metadata.get('error'):\n",
    "        err = str(metadata['error']).replace(\"`\", \"'\")\n",
    "        out.append(f\"\\n‚ö†Ô∏è **Error:** `{err}`\")\n",
    "\n",
    "    return \"\\n\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_card(title: str, percent: int, note: str = \"\") -> str:\n",
    "    pct = max(0, min(100, int(percent)))\n",
    "    note_html = f'<div class=\"vf-note\">{note}</div>' if note else \"\"\n",
    "    return f\"\"\"\n",
    "    <div class=\"vf-progress-card\" role=\"status\" aria-live=\"polite\" aria-atomic=\"true\">\n",
    "      <div class=\"vf-title\">{title}</div>\n",
    "      <progress class=\"vf-progress\" value=\"{pct}\" max=\"100\"></progress>\n",
    "      {note_html}\n",
    "    </div>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_search(\n",
    "    query: str,\n",
    "    year_start: Optional[str],\n",
    "    year_end: Optional[str],\n",
    "    scott_numbers: Optional[str],\n",
    "    max_results: int,\n",
    "    st_ctx: Dict[str, Any],                # gr.State dict para pasar datos a la fase 2\n",
    "    progress: gr.Progress = gr.Progress(track_tqdm=True),\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta SOLO la b√∫squeda b√°sica, pinta resultados r√°pidos y deja todo listo\n",
    "    para que la avanzada contin√∫e en un job separado.\n",
    "    Devuelve 7 outputs visibles + 1 estado (st_ctx).\n",
    "    \"\"\"\n",
    "    # Validaciones m√≠nimas\n",
    "    progress(0.02, desc=\"Validating...\")\n",
    "    if not query or not query.strip():\n",
    "        err = markdown_to_html(\"‚ùå Please enter a query\")\n",
    "        return err, \"\", \"\", err, \"\", \"\", \"No timing data available\", st_ctx\n",
    "\n",
    "    # Filtrado opcional (id√©ntico a tu l√≥gica original, pero resumido aqu√≠)\n",
    "    processed_year_start = None\n",
    "    processed_year_end = None\n",
    "    if year_start and year_end:\n",
    "        try:\n",
    "            ys = int(str(year_start).strip())\n",
    "            ye = int(str(year_end).strip())\n",
    "            if 1800 <= ys <= 2025 and 1800 <= ye <= 2025:\n",
    "                processed_year_start, processed_year_end = ys, ye\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    processed_scott_numbers = None\n",
    "    if scott_numbers and str(scott_numbers).strip():\n",
    "        nums = [s.strip() for s in str(scott_numbers).split(\",\") if s.strip()]\n",
    "        processed_scott_numbers = nums or None\n",
    "\n",
    "    filters_status = []\n",
    "    if processed_year_start and processed_year_end:\n",
    "        filters_status.append(f\"Years: {processed_year_start}-{processed_year_end}\")\n",
    "    if processed_scott_numbers:\n",
    "        filters_status.append(f\"Scott: {', '.join(processed_scott_numbers)}\")\n",
    "    filter_msg = \"Filters applied: \" + (\", \".join(filters_status) if filters_status else \"None (searching all documents)\")\n",
    "    st_ctx = {\n",
    "        \"t0\": time.time(),\n",
    "        \"filter_msg\": filter_msg,\n",
    "    }\n",
    "\n",
    "    # Mensajes iniciales\n",
    "    progress(0.08, desc=\"Preparing search‚Ä¶\")\n",
    "    gr.Info(\"Starting quick search...\\n (wait time less than 60 seconds)\")\n",
    "\n",
    "    loading_basic = progress_card(\"üîÑ Running Basic Hybrid Search‚Ä¶\", 10, filter_msg)\n",
    "    loading_advanced = progress_card(\"‚è≥ Waiting for Basic to complete‚Ä¶\", 5, \"Deep Analysis will start automatically.\")\n",
    "\n",
    "\n",
    "    # Un primer retorno (stream) para pintar \"waiting\"\n",
    "    yield (\n",
    "        loading_basic,  # basic_answer_html\n",
    "        \"\",             # basic_search_html\n",
    "        \"\",             # basic_metadata_html\n",
    "        loading_advanced,  # advanced_answer_html (placeholder)\n",
    "        \"\",             # advanced_search_html\n",
    "        \"\",             # advanced_metadata_html\n",
    "        f\"‚è±Ô∏è Basic search in progress...\\n{filter_msg}\",  # timing\n",
    "        st_ctx          # state\n",
    "    )\n",
    "\n",
    "    # --------- Ejecutar B√öSQUEDA B√ÅSICA ----------\n",
    "    progress(0.35, desc=\"Quick Search‚Ä¶\")\n",
    "    t_basic_start = time.time()\n",
    "    # Llama a tu funci√≥n real:\n",
    "    basic_results_data = search_and_answer_basic(  # type: ignore[name-defined]\n",
    "        query=query,\n",
    "        rag_system=rag_system,                     # usa el capturado en create_gradio_interface\n",
    "        year_start=processed_year_start,\n",
    "        year_end=processed_year_end,\n",
    "        scott_numbers=processed_scott_numbers,\n",
    "        max_results=int(max_results),\n",
    "    )\n",
    "    t_basic_end = time.time()\n",
    "\n",
    "    basic_answer = basic_results_data[\"answer\"]\n",
    "    basic_results = basic_results_data[\"results\"]\n",
    "    basic_metadata = basic_results_data[\"metadata\"]\n",
    "    basic_execution_time = basic_metadata.get(\"generation_time\", t_basic_end - t_basic_start)\n",
    "\n",
    "    # Render\n",
    "    basic_answer_html = markdown_to_html(basic_answer)\n",
    "    basic_search_html = markdown_to_html(format_search_results(basic_results, \"Basic Hybrid Search\"))\n",
    "    basic_metadata_html = markdown_to_html(format_metadata(basic_metadata, basic_execution_time))\n",
    "\n",
    "    timing_partial = (\n",
    "        \"‚è±Ô∏è EXECUTION TIMING (Partial)\\n\\n\"\n",
    "        \"Basic Hybrid Search: ‚úÖ COMPLETED\\n\"\n",
    "        f\"‚Ä¢ Time: {basic_execution_time:.2f}s\\n\"\n",
    "        f\"‚Ä¢ Results: {len(basic_results)}\\n\"\n",
    "        f\"‚Ä¢ {filter_msg}\\n\\n\"\n",
    "        \"Advanced Search: ‚è≥ STARTING...\\n\"\n",
    "    )\n",
    "    progress(0.6, desc=\"Crafting the Deep Research‚Ä¶\")\n",
    "    gr.Info(\"Done Quick Search \\n Beginning advanced research (wait 3-5 minutes) ‚Ä¶\")\n",
    "\n",
    "    # Actualiza el state para la fase 2\n",
    "    st_ctx.update({\n",
    "        \"basic_metadata\": basic_metadata,\n",
    "        \"basic_exec\": float(basic_execution_time),\n",
    "        \"basic_results_count\": int(len(basic_results)),\n",
    "    })\n",
    "\n",
    "    # Devuelve resultados b√°sicos + placeholder para avanzada\n",
    "    yield (\n",
    "        basic_answer_html,\n",
    "        basic_search_html,\n",
    "        basic_metadata_html,\n",
    "        progress_card(\"üöÄ Deep Analysis running‚Ä¶\", 70, filter_msg),\n",
    "        \"\",\n",
    "        \"\",\n",
    "        timing_partial,\n",
    "        st_ctx\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_advanced_search(\n",
    "    query: str,\n",
    "    max_results: int,\n",
    "    st_ctx: Dict[str, Any],\n",
    "    progress: gr.Progress = gr.Progress(track_tqdm=True),\n",
    "):\n",
    "    progress(0.05, desc=\"Beginning deep research‚Ä¶\")\n",
    "    if not query or not query.strip():\n",
    "        err = markdown_to_html(\"‚ùå Please enter a query\")\n",
    "        # frame final directo (sin dejar pending)\n",
    "        yield err, \"\", \"\", \"No timing data available\", st_ctx\n",
    "        return\n",
    "\n",
    "    t0 = st_ctx.get(\"t0\", time.time())\n",
    "    filter_msg = st_ctx.get(\"filter_msg\", \"Filters applied: None\")\n",
    "    basic_metadata = st_ctx.get(\"basic_metadata\", {})\n",
    "    basic_exec = float(st_ctx.get(\"basic_exec\", 0.0))\n",
    "    basic_results_count = int(st_ctx.get(\"basic_results_count\", 0))\n",
    "\n",
    "    # üëâ placeholder visible (reemplaza lo anterior)\n",
    "    yield (\n",
    "        progress_card(\"üöÄ Deep Analysis running‚Ä¶\", 70, filter_msg),\n",
    "        \"\",  # advanced_search_html\n",
    "        \"\",  # advanced_metadata_html\n",
    "        f\"‚è±Ô∏è EXECUTION TIMING (Partial)\\n\\nBasic: ‚úÖ {basic_exec:.2f}s  |  Advanced: ‚è≥ running‚Ä¶\\n{filter_msg}\",\n",
    "        st_ctx\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # --------- Ejecutar B√öSQUEDA AVANZADA ----------\n",
    "        progress(0.4, desc=\"Deep analysis‚Ä¶\")\n",
    "        t_adv_start = time.time()\n",
    "        advanced_results_data = search_and_answer_advanced(  # type: ignore[name-defined]\n",
    "            query=query,\n",
    "            rag_system=rag_system,\n",
    "            max_results=int(max_results),\n",
    "        )\n",
    "        t_adv_end = time.time()\n",
    "\n",
    "        advanced_answer = advanced_results_data.get(\"answer\", \"\")\n",
    "        advanced_results = advanced_results_data.get(\"results\", [])\n",
    "        advanced_metadata = advanced_results_data.get(\"metadata\", {})\n",
    "        advanced_execution_time = advanced_metadata.get(\"generation_time\", t_adv_end - t_adv_start)\n",
    "\n",
    "        # Render\n",
    "        advanced_answer_html = markdown_to_html(advanced_answer or \"‚ÑπÔ∏è No answer produced.\")\n",
    "        advanced_search_html = markdown_to_html(format_search_results(advanced_results, \"Advanced Compression Search\"))\n",
    "        advanced_metadata_html = markdown_to_html(format_metadata(advanced_metadata, advanced_execution_time))\n",
    "\n",
    "        total_execution_time = time.time() - t0\n",
    "        timing_final = format_timing_display(\n",
    "            basic_exec,\n",
    "            float(advanced_execution_time),\n",
    "            float(total_execution_time),\n",
    "            basic_results_count,\n",
    "            len(advanced_results),\n",
    "            filter_msg,\n",
    "            basic_metadata,\n",
    "            advanced_metadata\n",
    "        )\n",
    "\n",
    "        progress(1.0, desc=\"Done\")\n",
    "        gr.Info(\"In-depth analysis completed ‚úÖ\")\n",
    "\n",
    "        # ‚úÖ FRAME FINAL: usa YIELD (no return) para reemplazar la barra\n",
    "        yield (\n",
    "            advanced_answer_html,\n",
    "            advanced_search_html,\n",
    "            advanced_metadata_html,\n",
    "            timing_final,\n",
    "            st_ctx\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # ‚úÖ Si algo falla, reemplaza tambi√©n el placeholder\n",
    "        err_html = markdown_to_html(f\"‚ùå Advanced phase failed:\\n\\n```\\n{e}\\n```\")\n",
    "        yield err_html, \"\", \"\", \"Advanced phase failed ‚Äî see error above.\", st_ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THEME - Solo lo b√°sico (paleta \"sage\")\n",
    "philatelic_theme = gr.themes.Soft().set(\n",
    "    button_primary_background_fill=\"#6b8e7f\",\n",
    "    button_primary_background_fill_hover=\"#4a6558\",\n",
    "    button_primary_text_color=\"#ffffff\",\n",
    "    button_secondary_background_fill=\"#f5f5f5\",\n",
    "    button_secondary_background_fill_hover=\"#e8e8e8\",\n",
    "    button_secondary_text_color=\"#1f2937\",\n",
    "    body_background_fill=\"#ffffff\",\n",
    "    input_background_fill=\"#ffffff\",\n",
    "    input_border_color=\"#bfc8c3\",\n",
    "    slider_color=\"#6b8e7f\",\n",
    "    # opcionales si tu versi√≥n lo permite:\n",
    "    # link_text_color=\"#4a6558\",\n",
    "    # link_text_color_hover=\"#2c5530\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "/* ========================================\n",
    "   CONFIGURACI√ìN BASE - TEMA FILATELIA\n",
    "   ======================================== */\n",
    "\n",
    "/* Paleta base */\n",
    ":root{\n",
    "  --vf-ink:#1f2937;           /* texto principal */\n",
    "  --vf-muted:#475569;         /* texto secundario */\n",
    "  --vf-accent:#6b8e7f;        /* verde suave (primario) */\n",
    "  --vf-accent-dark:#4a6558;   /* verde oscuro (hover/foco) */\n",
    "  --vf-surface:#f3f4f6;       /* superficies suaves */\n",
    "  --vf-border:#cfd8d4;        /* bordes suaves */\n",
    "}\n",
    "\n",
    "/* Reset & tipograf√≠a base */\n",
    "body, .gradio-container{\n",
    "  font-family:'Georgia','Times New Roman',serif !important;\n",
    "  font-size:20px !important;\n",
    "  color:var(--vf-ink) !important;\n",
    "  line-height:1.6 !important;\n",
    "  -webkit-font-smoothing:antialiased !important;\n",
    "  -moz-osx-font-smoothing:grayscale !important;\n",
    "  text-rendering:optimizeLegibility !important;\n",
    "}\n",
    ".gradio-container *{ font-size:inherit !important; }\n",
    ".gradio-container svg{ font-size:initial !important; }\n",
    "\n",
    "/* Enlaces (por si los usas en Markdown) */\n",
    "a{ color:var(--vf-accent) !important; text-decoration:none !important; }\n",
    "a:hover{ text-decoration:underline !important; }\n",
    "\n",
    "/* ========================================\n",
    "   ENCABEZADOS\n",
    "   ======================================== */\n",
    "h1{\n",
    "  color:var(--vf-ink) !important;\n",
    "  font-weight:700 !important;\n",
    "  font-size:36px !important;\n",
    "  margin:0 0 20px !important;\n",
    "  letter-spacing:.2px !important; /* nitidez en Windows */\n",
    "}\n",
    "h2,h3{\n",
    "  color:var(--vf-ink) !important;\n",
    "  font-weight:700 !important;\n",
    "  font-size:26px !important;\n",
    "  margin:20px 0 12px !important;\n",
    "  letter-spacing:.2px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   TEXTO GENERAL\n",
    "   ======================================== */\n",
    "p,.markdown-text{ color:var(--vf-ink) !important; font-size:22px !important; line-height:1.7 !important; }\n",
    "label{\n",
    "  font-size:22px !important; font-weight:700 !important; color:var(--vf-ink) !important;\n",
    "  margin-bottom:8px !important; display:block !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   INPUTS Y FORMULARIOS\n",
    "   ======================================== */\n",
    "input[type=\"text\"], textarea{\n",
    "  font-size:22px !important; padding:16px !important; color:var(--vf-ink) !important;\n",
    "  background:#fff !important; border:2px solid var(--vf-border) !important; border-radius:8px !important;\n",
    "  transition:border-color .2s ease, box-shadow .2s ease !important;\n",
    "}\n",
    "input[type=\"text\"]:focus, textarea:focus{\n",
    "  border-color:var(--vf-accent) !important;\n",
    "  outline:none !important;\n",
    "  box-shadow:0 0 0 3px rgba(107,142,127,.18) !important;\n",
    "}\n",
    "input::placeholder, textarea::placeholder{ color:#9ca3af !important; font-size:20px !important; }\n",
    "select{\n",
    "  font-size:20px !important; padding:14px !important; color:var(--vf-ink) !important;\n",
    "  background:#fff !important; border:2px solid var(--vf-border) !important; border-radius:8px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   SLIDER\n",
    "   ======================================== */\n",
    ".gr-box:has(input[type=\"range\"]) > .block > .wrap > span:first-child{\n",
    "  font-size:20px !important; font-weight:700 !important; display:block !important; margin-bottom:10px !important;\n",
    "}\n",
    ".gr-box:has(input[type=\"range\"]) .wrap{\n",
    "  display:flex !important; flex-direction:row !important; align-items:center !important; gap:15px !important; width:100% !important;\n",
    "}\n",
    ".gr-box input[type=\"number\"]{\n",
    "  width:80px !important; height:40px !important; padding:8px !important; font-size:18px !important;\n",
    "  border:1px solid var(--vf-border) !important; border-radius:6px !important; background:#fff !important; font-weight:700 !important; text-align:center !important;\n",
    "}\n",
    "input[type=\"range\"]{\n",
    "  flex:1 !important; -webkit-appearance:none !important; height:8px !important;\n",
    "  background:#e5e7eb !important; border-radius:9999px !important; outline:none !important;\n",
    "}\n",
    "input[type=\"range\"]::-webkit-slider-thumb{\n",
    "  -webkit-appearance:none !important; width:20px !important; height:20px !important;\n",
    "  background:var(--vf-accent) !important; border-radius:50% !important; cursor:pointer !important;\n",
    "  transition:transform .15s ease, background .15s ease !important;\n",
    "}\n",
    "input[type=\"range\"]::-webkit-slider-thumb:hover{ background:#5a7a6b !important; transform:scale(1.03) !important; }\n",
    "input[type=\"range\"]::-moz-range-thumb{\n",
    "  width:20px !important; height:20px !important; background:var(--vf-accent) !important;\n",
    "  border-radius:50% !important; border:none !important; cursor:pointer !important;\n",
    "}\n",
    ".gr-box:has(input[type=\"range\"]) input[readonly],\n",
    ".gr-box:has(input[type=\"range\"]) span:last-child{\n",
    "  font-size:20px !important; font-weight:700 !important; color:var(--vf-ink) !important;\n",
    "  background:#f5f5f5 !important; padding:10px 14px !important; border:1px solid var(--vf-border) !important; border-radius:6px !important; text-align:center !important; min-width:72px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   BOTONES\n",
    "   ======================================== */\n",
    "button{\n",
    "  font-size:22px !important; font-weight:700 !important; padding:16px 32px !important; border-radius:10px !important;\n",
    "  transition:transform .15s ease, box-shadow .15s ease, background .2s ease !important; cursor:pointer !important;\n",
    "}\n",
    "#main-search-btn, button.primary{\n",
    "  background:linear-gradient(135deg, var(--vf-accent) 0%, #5a7a6b 100%) !important;\n",
    "  color:#fff !important; border:2px solid #5a7a6b !important; letter-spacing:.3px !important;\n",
    "}\n",
    "#main-search-btn:hover, button.primary:hover{\n",
    "  transform:translateY(-2px) !important; box-shadow:0 6px 12px rgba(107,142,127,.3) !important;\n",
    "  background:linear-gradient(135deg, #5a7a6b 0%, var(--vf-accent-dark) 100%) !important;\n",
    "}\n",
    "button.secondary, button:not(.primary):not([role=\"tab\"]):not([aria-expanded]){\n",
    "  background:#f5f5f5 !important; color:var(--vf-ink) !important; border:2px solid var(--vf-border) !important;\n",
    "}\n",
    "button.secondary:hover, button:not(.primary):not([role=\"tab\"]):not([aria-expanded]):hover{\n",
    "  background:#e8e8e8 !important; border-color:var(--vf-accent) !important;\n",
    "}\n",
    "/* Focus visible (accesible) */\n",
    "button:focus-visible, input:focus-visible, textarea:focus-visible, select:focus-visible{\n",
    "  outline:3px solid rgba(107,142,127,.45) !important; outline-offset:2px !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   TABS\n",
    "   ======================================== */\n",
    "button[role=\"tab\"]{\n",
    "  background:#f5f5f5 !important; color:var(--vf-ink) !important; border:1px solid var(--vf-border) !important;\n",
    "  font-size:20px !important; padding:14px 20px !important; margin-right:4px !important; border-radius:10px 10px 0 0 !important;\n",
    "}\n",
    "button[role=\"tab\"][aria-selected=\"true\"]{\n",
    "  background:var(--vf-accent) !important; color:#fff !important; border-color:var(--vf-accent) !important;\n",
    "}\n",
    "button[role=\"tab\"]:hover:not([aria-selected=\"true\"]){ background:#e8e8e8 !important; }\n",
    "\n",
    "/* ========================================\n",
    "   ACCORDIONS\n",
    "   ======================================== */\n",
    ".accordion{\n",
    "  border:1px solid #e5e7eb !important; border-radius:12px !important; margin:16px 0 !important; background:#fff !important; overflow:hidden !important;\n",
    "}\n",
    "button[aria-expanded]{\n",
    "  background:#fafafa !important; border:none !important; padding:16px 24px !important; width:100% !important; text-align:left !important;\n",
    "  font-size:20px !important; font-weight:700 !important; color:var(--vf-ink) !important; transition:background .2s !important;\n",
    "}\n",
    "button[aria-expanded]:hover{ background:#f0f0f0 !important; }\n",
    "button[aria-expanded=\"true\"]{\n",
    "  background:linear-gradient(135deg, #f0f5f3 0%, #e5ede9 100%) !important; color:#2c5530 !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   PROGRESS Y ESTADOS\n",
    "   ======================================== */\n",
    ".progress-bar{\n",
    "  background:linear-gradient(90deg, var(--vf-accent) 0%, #8fa89e 50%, var(--vf-accent) 100%) !important;\n",
    "  height:4px !important; border-radius:2px !important; opacity:.95 !important;\n",
    "}\n",
    ".progress-container{ background:var(--vf-surface) !important; border-radius:6px !important; margin:10px 0 !important; }\n",
    ".progress-text{ color:#4b5563 !important; font-size:16px !important; font-weight:600 !important; margin:8px 0 !important; }\n",
    "\n",
    "/* <progress> nativo (para progress_card) */\n",
    "progress{\n",
    "  appearance:none; -webkit-appearance:none; width:100%; height:10px; border:none; background:transparent;\n",
    "}\n",
    "progress::-webkit-progress-bar{ background:#e5e7eb; border-radius:6px; }\n",
    "progress::-webkit-progress-value{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)); border-radius:6px; }\n",
    "progress::-moz-progress-bar{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)); border-radius:6px; }\n",
    "\n",
    "/* Estado ‚Äúgenerating‚Äù */\n",
    ".generating{\n",
    "  border:2px solid var(--vf-accent) !important;\n",
    "  background:linear-gradient(135deg, #f0f5f3 0%, #e5ede9 100%) !important;\n",
    "  animation:pulse-border 2s infinite !important;\n",
    "}\n",
    "@keyframes pulse-border{\n",
    "  0%,100%{ border-color:var(--vf-accent); box-shadow:0 0 0 0 rgba(107,142,127,.4); }\n",
    "  50%{ border-color:#8fa89e; box-shadow:0 0 0 4px rgba(107,142,127,.1); }\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   INDICADORES Y MISC\n",
    "   ======================================== */\n",
    "#status-indicator{\n",
    "  background:linear-gradient(135deg, var(--vf-accent) 0%, #5a7a6b 100%) !important;\n",
    "  color:#fff !important; padding:20px !important; border-radius:12px !important; text-align:center !important;\n",
    "  font-size:18px !important; font-weight:700 !important; margin:20px 0 !important; box-shadow:0 4px 8px rgba(107,142,127,.2) !important;\n",
    "}\n",
    "#status-indicator.success{ background:linear-gradient(135deg, #7fb069 0%, #6b9956 100%) !important; }\n",
    ".timer-display{\n",
    "  font-family:'Courier New',monospace !important; font-size:16px !important; color:var(--vf-ink) !important;\n",
    "  padding:10px !important; background:var(--vf-surface) !important; border-radius:6px !important; text-align:center !important;\n",
    "}\n",
    "\n",
    "/* ========================================\n",
    "   UTILIDADES\n",
    "   ======================================== */\n",
    ".loading-text{ color:var(--vf-muted) !important; font-style:normal !important; font-size:18px !important; }\n",
    "hr{ border:none !important; border-top:2px solid #e5e7eb !important; margin:30px 0 !important; }\n",
    ".group{ background:#fff !important; border-radius:10px !important; padding:20px !important; margin:10px 0 !important; }\n",
    "input[type=\"checkbox\"]+label, input[type=\"radio\"]+label{ font-size:20px !important; margin-left:8px !important; }\n",
    ".results-container{ padding:20px !important; background:#fafafa !important; border-radius:10px !important; margin:10px 0 !important; }\n",
    "\n",
    "/* Progress-card con contraste alto */\n",
    ".vf-progress-card{ color:var(--vf-ink) !important; }\n",
    ".vf-progress-card .vf-title{ font-weight:600; letter-spacing:.2px; margin-bottom:6px; color:var(--vf-ink) !important; }\n",
    ".vf-progress-card .vf-note{ margin-top:6px; font-size:16px; color:var(--vf-ink) !important; opacity:.9 !important; }\n",
    ".vf-progress{ width:100%; height:10px; background:transparent; appearance:none; -webkit-appearance:none; }\n",
    ".vf-progress::-webkit-progress-bar{ background:#e7eeea !important; border-radius:6px; }\n",
    ".vf-progress::-webkit-progress-value{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)) !important; border-radius:6px; }\n",
    ".vf-progress::-moz-progress-bar{ background:linear-gradient(90deg, var(--vf-accent), var(--vf-accent-dark)) !important; border-radius:6px; }\n",
    "\n",
    "/* Quita panel gris SOLO al H2 del Step 1 (Group .input-section) */\n",
    ".input-section .gr-box:has(.gr-markdown){\n",
    "  background:transparent !important; border:none !important; box-shadow:none !important; padding:0 !important;\n",
    "}\n",
    ".input-section .gr-markdown h2, .input-section .gr-markdown h3{ margin-top:0 !important; color:var(--vf-ink) !important; }\n",
    "\n",
    "/* Quitar pill azul de labels de inputs (Soft theme) */\n",
    ".gradio-container label,\n",
    ".gradio-container label span,\n",
    ".gradio-container .label,\n",
    ".gradio-container .label span,\n",
    ".gradio-container .wrap > label,\n",
    ".gradio-container .block .wrap > label {\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* Ajuste fino del texto del label */\n",
    ".gradio-container label span,\n",
    ".gradio-container .label span {\n",
    "  padding: 0 !important;\n",
    "  border-radius: 0 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  font-weight: 700 !important;\n",
    "  letter-spacing: .2px !important; /* mejora nitidez en Windows */\n",
    "}\n",
    "\n",
    "/* --- Quitar la barra gris del Step 1 (Group: .input-section) --- */\n",
    "\n",
    "/* Aplana cualquier caja/panel que Gradio mete dentro del Group */\n",
    ".input-section .gr-box,\n",
    ".input-section .gr-panel,\n",
    ".input-section .gr-box > .form,\n",
    ".input-section .gr-box > .container,\n",
    ".input-section .prose {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* El bloque espec√≠fico que contiene el Markdown del t√≠tulo */\n",
    ".input-section .gr-box:has(.gr-markdown){\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "}\n",
    "\n",
    "/* Opcional: un separador sutil debajo del H2 para que no se vea ‚Äúflotando‚Äù */\n",
    ".input-section .gr-markdown h2{\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* Evita ‚Äúp√≠ldoras‚Äù o fondos raros en labels dentro del Step 1 */\n",
    ".input-section label,\n",
    ".input-section label span {\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "  padding: 0 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "}\n",
    "\n",
    "\n",
    "/* Tarjeta blanca suave para el √°rea de Step 1 (opcional) */\n",
    ".input-section{\n",
    "  background: #fff !important;\n",
    "  border: 1px solid #eef2f0 !important;\n",
    "  border-radius: 12px !important;\n",
    "  padding: 16px !important;\n",
    "}\n",
    "\n",
    "/* --- Alto contraste para Markdown: evita it√°lica gris en .prose --- */\n",
    ".gradio-container .prose em,\n",
    ".gradio-container .prose i {\n",
    "  font-style: normal !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "}\n",
    ".gradio-container .prose strong { color: var(--vf-ink) !important; }\n",
    "\n",
    "/* --- Progress plano (sin degradado) y m√°s visible --- */\n",
    ":root{\n",
    "  --vf-progress-bg:#e1e7e4;      /* pista */\n",
    "  --vf-progress-fill:#5f7f72;    /* relleno s√≥lido */\n",
    "}\n",
    "\n",
    ".vf-progress{\n",
    "  width:100%; height:10px;\n",
    "  appearance:none; -webkit-appearance:none;\n",
    "  background:transparent; border:none;\n",
    "}\n",
    ".vf-progress::-webkit-progress-bar{\n",
    "  background: var(--vf-progress-bg) !important;\n",
    "  border-radius: 6px;\n",
    "}\n",
    ".vf-progress::-webkit-progress-value{\n",
    "  background: var(--vf-progress-fill) !important;   /* <- s√≥lido */\n",
    "  border-radius: 6px;\n",
    "}\n",
    ".vf-progress::-moz-progress-bar{\n",
    "  background: var(--vf-progress-fill) !important;   /* <- s√≥lido */\n",
    "  border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* Por si alg√∫n progress sin clase aparece, aplica el mismo estilo */\n",
    "progress{\n",
    "  appearance:none; -webkit-appearance:none;\n",
    "  width:100%; height:10px; background:transparent; border:none;\n",
    "}\n",
    "progress::-webkit-progress-bar{ background: var(--vf-progress-bg); border-radius:6px; }\n",
    "progress::-webkit-progress-value{ background: var(--vf-progress-fill); border-radius:6px; }\n",
    "progress::-moz-progress-bar{ background: var(--vf-progress-fill); border-radius:6px; }\n",
    "\n",
    "/* T√≠tulos/nota del card bien n√≠tidos */\n",
    ".vf-progress-card .vf-title{\n",
    "  font-weight:600; letter-spacing:.2px; margin-bottom:6px; color:var(--vf-ink) !important;\n",
    "}\n",
    ".vf-progress-card .vf-note{\n",
    "  margin-top:6px; font-size:16px; color:var(--vf-ink) !important; opacity:.92 !important;\n",
    "}\n",
    "\n",
    "/* El panel gris viene del .gr-box que envuelve el Markdown dentro del Group.\n",
    "   Lo aplanamos SOLO cuando contiene #step1_title */\n",
    ".input-section .gr-box:has(#step1_title) {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "}\n",
    "/* Opcional: separador sutil bajo el H2 */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* Fuerza alto contraste SOLO en los outputs donde metes el progress_card */\n",
    "#basic_answer .vf-progress-card,\n",
    "#advanced_answer .vf-progress-card,\n",
    "#basic_answer .vf-progress-card *,\n",
    "#advanced_answer .vf-progress-card * {\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "  font-style: normal !important;\n",
    "  text-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* Barra de progreso s√≥lida y visible */\n",
    ":root{\n",
    "  --vf-progress-bg: #d9e3df;   /* pista */\n",
    "  --vf-progress-fill: #3f5f52; /* relleno */\n",
    "}\n",
    "#basic_answer .vf-progress,\n",
    "#advanced_answer .vf-progress {\n",
    "  appearance: none; -webkit-appearance: none;\n",
    "  width: 100%; height: 10px; border: none; background: transparent;\n",
    "  opacity: 1 !important; filter: none !important;\n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-bar,\n",
    "#advanced_answer .vf-progress::-webkit-progress-bar { \n",
    "  background: var(--vf-progress-bg) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-value,\n",
    "#advanced_answer .vf-progress::-webkit-progress-value { \n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-moz-progress-bar,\n",
    "#advanced_answer .vf-progress::-moz-progress-bar {\n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* === Quitar fade de Gradio en outputs mientras est√°n \"pending\" === */\n",
    "#basic_answer .html-container.pending,\n",
    "#advanced_answer .html-container.pending,\n",
    "#basic_answer .pending,\n",
    "#advanced_answer .pending {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* Asegura que el wrapper de markdown tampoco reduzca contraste */\n",
    "#basic_answer .prose,\n",
    "#advanced_answer .prose {\n",
    "  opacity: 1 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "}\n",
    "\n",
    "/* Por si el progress queda afectado por herencia/opacidad */\n",
    "#basic_answer .vf-progress,\n",
    "#advanced_answer .vf-progress {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* ==== STEP 1: elimina la franja gris del wrapper .styler y del block del t√≠tulo ==== */\n",
    "\n",
    "/* Apaga los ‚Äúgaps‚Äù grises solo en el styler que contiene #step1_title */\n",
    ".styler:has(#step1_title) {\n",
    "  --layout-gap: 0px !important;\n",
    "  --form-gap-width: 0px !important;\n",
    "}\n",
    "\n",
    "/* Aplana cualquier fondo/sombra que el theme ponga alrededor del t√≠tulo y sus contenedores */\n",
    "#step1_title.block,\n",
    "#step1_title.block .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* El .form de Step 1 (el √°rea del textarea) tambi√©n sin fondo */\n",
    ".styler:has(#step1_title) .form {\n",
    "  background: transparent !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* T√≠tulo con separador sutil (opcional) */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* ==== PROGRESS CARD: mata el fade del wrapper ‚Äúpending‚Äù y sube contraste ==== */\n",
    "\n",
    "/* Gradio desvanece outputs con .pending: qu√≠talo donde pintas el progress_card */\n",
    "#basic_answer .html-container.pending,\n",
    "#advanced_answer .html-container.pending,\n",
    "#basic_answer .pending,\n",
    "#advanced_answer .pending {\n",
    "  opacity: 1 !important;\n",
    "  filter: none !important;\n",
    "}\n",
    "\n",
    "/* Evita que .prose herede opacidad baja/it√°lica del theme */\n",
    "#basic_answer .prose, #advanced_answer .prose {\n",
    "  opacity: 1 !important;\n",
    "  color: var(--vf-ink) !important;\n",
    "  font-style: normal !important;\n",
    "  text-shadow: none !important;\n",
    "}\n",
    "\n",
    "/* Fuerza contraste dentro del card */\n",
    "#basic_answer .vf-progress-card,\n",
    "#advanced_answer .vf-progress-card,\n",
    "#basic_answer .vf-progress-card * ,\n",
    "#advanced_answer .vf-progress-card * {\n",
    "  color: var(--vf-ink) !important;\n",
    "  opacity: 1 !important;\n",
    "  font-style: normal !important;\n",
    "}\n",
    "\n",
    "/* Barra s√≥lida (sin degradado), m√°s oscura para que se note bien */\n",
    ":root{\n",
    "  --vf-progress-bg: #cbd7d2;   /* pista un poco m√°s marcada */\n",
    "  --vf-progress-fill: #2f4a41; /* relleno s√≥lido oscuro */\n",
    "}\n",
    "#basic_answer .vf-progress, #advanced_answer .vf-progress {\n",
    "  appearance: none; -webkit-appearance: none;\n",
    "  width: 100%; height: 10px; border: none; background: transparent;\n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-bar,\n",
    "#advanced_answer .vf-progress::-webkit-progress-bar { \n",
    "  background: var(--vf-progress-bg) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-webkit-progress-value,\n",
    "#advanced_answer .vf-progress::-webkit-progress-value { \n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px; \n",
    "}\n",
    "#basic_answer .vf-progress::-moz-progress-bar,\n",
    "#advanced_answer .vf-progress::-moz-progress-bar {\n",
    "  background: var(--vf-progress-fill) !important; border-radius: 6px;\n",
    "}\n",
    "\n",
    "/* === STEP 1: mata la franja gris del bloque del t√≠tulo === */\n",
    "\n",
    "/* 1) Anula cualquier fondo/borde/sombra del bloque #step1_title */\n",
    "#step1_title.block {\n",
    "  /* variables que usa el Soft theme para pintar paneles */\n",
    "  --block-background-fill: transparent !important;\n",
    "  --panel-background-fill: transparent !important;\n",
    "  --section-background-fill: transparent !important;\n",
    "  --block-label-background-fill: transparent !important;\n",
    "  --block-title-background-fill: transparent !important;\n",
    "  --block-border-width: 0px !important;\n",
    "\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;     /* el .padded agrega relleno */\n",
    "  margin: 0 !important;\n",
    "  overflow: visible !important; /* evita ‚Äútiras‚Äù de fondo por overflow */\n",
    "}\n",
    "\n",
    "/* 2) Por si el tema usa pseudo-elementos para el panel */\n",
    "#step1_title.block::before,\n",
    "#step1_title.block::after {\n",
    "  content: none !important;\n",
    "  display: none !important;\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* 3) Aplana wrappers internos que en tu DOM rodean al h2 */\n",
    "#step1_title .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* 4) Si el gris ven√≠a del ‚Äúgap‚Äù del layout, desact√≠valo en este bloque */\n",
    "#step1_title.block[style*=\"--block-border-width\"] {\n",
    "  --block-border-width: 0px !important;\n",
    "}\n",
    "#step1_title.block {\n",
    "  --layout-gap: 0px !important;\n",
    "  --form-gap-width: 0px !important;\n",
    "}\n",
    "\n",
    "/* 5) La clase .padded puede dar fondo en algunos temas */\n",
    "#step1_title.padded { background: transparent !important; }\n",
    "\n",
    "/* 6) (Opcional) separador sutil bajo el H2 para no dejarlo ‚Äúflotando‚Äù */\n",
    "#step1_title .prose h2 {\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "/* ==== 1) Mata el gap/fondo del contenedor que rodea al Step 1 ==== */\n",
    "/* Pinta el contenedor en blanco y pone gap=0 para que no se vea una franja */\n",
    ".styler:has(#step1_title) {\n",
    "  background: #fff !important;\n",
    "  gap: 0 !important;\n",
    "  row-gap: 0 !important;\n",
    "  column-gap: 0 !important;\n",
    "  --layout-gap: 0 !important;\n",
    "  --form-gap-width: 0 !important;\n",
    "}\n",
    ".styler:has(#step1_title)::before,\n",
    ".styler:has(#step1_title)::after {\n",
    "  content: none !important;\n",
    "  background: #fff !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* ==== 2) Aplana el panel del propio bloque del t√≠tulo ==== */\n",
    "#step1_title {\n",
    "  /* Si el theme usa variables para fondos/bordes del bloque, an√∫lalas aqu√≠ */\n",
    "  --block-background-fill: transparent !important;\n",
    "  --panel-background-fill: transparent !important;\n",
    "  --section-background-fill: transparent !important;\n",
    "  --block-label-background-fill: transparent !important;\n",
    "  --block-title-background-fill: transparent !important;\n",
    "  --block-border-width: 0px !important;\n",
    "\n",
    "  background: #fff !important;        /* el bloque en s√≠, blanco s√≥lido */\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;               /* .padded suele meter relleno */\n",
    "  margin: 0 !important;\n",
    "  overflow: visible !important;\n",
    "}\n",
    "#step1_title::before,\n",
    "#step1_title::after {\n",
    "  content: none !important;\n",
    "  background: transparent !important;\n",
    "  box-shadow: none !important;\n",
    "  border: none !important;\n",
    "}\n",
    "\n",
    "/* Wrappers internos del markdown del H2: sin fondo alguno */\n",
    "#step1_title .svelte-vuh1yp,\n",
    "#step1_title [data-testid=\"markdown\"],\n",
    "#step1_title [data-testid=\"markdown\"] .prose,\n",
    "#step1_title [data-testid=\"markdown\"] .md {\n",
    "  background: transparent !important;\n",
    "  background-image: none !important;\n",
    "  border: none !important;\n",
    "  box-shadow: none !important;\n",
    "  padding: 0 !important;\n",
    "  margin: 0 !important;\n",
    "}\n",
    "\n",
    "/* (Opcional) separador sutil bajo el H2 */\n",
    "#step1_title .prose h2{\n",
    "  margin: 0 0 8px !important;\n",
    "  padding-bottom: 8px !important;\n",
    "  border-bottom: 1px solid #e5e7eb !important;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(rag_system: Dict[str, Any]) -> gr.Blocks:\n",
    "    \"\"\"\n",
    "    UI con dos fases encadenadas: r√°pida -> avanzada.\n",
    "    Progress bar visible pero no intrusivo, accordions colapsables.\n",
    "    \"\"\"\n",
    "    # Tema/CSS con fallback\n",
    "    try:\n",
    "        theme = philatelic_theme  # type: ignore[name-defined]\n",
    "    except NameError:\n",
    "        theme = gr.themes.Soft()\n",
    "\n",
    "    try:\n",
    "        css_styles = css\n",
    "    except NameError:\n",
    "        css_styles = \"\"\"\n",
    "        .progress-bar {\n",
    "            background: #3b82f6 !important;\n",
    "            height: 4px !important;\n",
    "        }\n",
    "        .generating {\n",
    "            border: 2px solid #3b82f6 !important;\n",
    "            background: #f0f9ff !important;\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    # Ejemplos\n",
    "    def set_example_1(): return \"Tell me about the Costa Rica 1907 inverted centers\"\n",
    "    def set_example_2(): return \"Show me Costa Rican overprinted stamps with varieties or errors\"\n",
    "    def set_example_3(): return \"1934 airmail definitive issue with catalog values C15-C27\"\n",
    "    def set_example_4(): return \"Tell me about the first issue crack plate varieties\"\n",
    "    def set_example_5(): return \"Costa Rican stamps with perforation errors or printing varieties\"\n",
    "    def set_example_6(): return \"Research mirror impression stamps from Costa Rica\"\n",
    "\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    total_docs = rag_system.get(\"total_documents\", 0)\n",
    "    total_chunks = rag_system.get(\"total_chunks\", 0)\n",
    "\n",
    "    with gr.Blocks(title=\"Costa Rica Philatelic Research System\", theme=theme, css=css_styles) as interface:\n",
    "        gr.Markdown(\n",
    "            \"# üîç Costa Rica Philatelic Research System\\n\"\n",
    "            \"**The smart way to research stamps** - AI-driven exploration of Costa Rican philately\"\n",
    "        )\n",
    "\n",
    "        # =================== STEP 1: Query ===================\n",
    "        with gr.Group(elem_classes=[\"input-section\"]):\n",
    "            gr.Markdown(\"## üìù Step 1: Enter Your Question\", elem_id=\"step1_title\")\n",
    "            query_input = gr.Textbox(\n",
    "                label=\"What would you like to know about Costa Rican stamps?\",\n",
    "                placeholder=\"Type your question here... (e.g., What are the Guanacaste vertical overprints?)\",\n",
    "                lines=3,\n",
    "                elem_id=\"main-query-input\"\n",
    "            )\n",
    "            search_btn = gr.Button(\"üîç SEARCH NOW\", variant=\"primary\", size=\"lg\", elem_id=\"main-search-btn\")\n",
    "\n",
    "            with gr.Accordion(\"üí° Need ideas? Click here for example questions\", open=False):\n",
    "                gr.Markdown(\"Click any example below to use it:\")\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        btn1 = gr.Button(\"üìÆ 1907 inverted centers\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn2 = gr.Button(\"üìÆ Overprinted varieties\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn3 = gr.Button(\"üìÆ 1934 airmail stamps\", variant=\"secondary\", size=\"sm\")\n",
    "                    with gr.Column():\n",
    "                        btn4 = gr.Button(\"üìÆ First issue crack plate\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn5 = gr.Button(\"üìÆ Perforation errors\", variant=\"secondary\", size=\"sm\")\n",
    "                        btn6 = gr.Button(\"üìÆ Mirror impression stamps\", variant=\"secondary\", size=\"sm\")\n",
    "\n",
    "        # =================== Advanced Options ===================\n",
    "        with gr.Accordion(\"‚öôÔ∏è Advanced Options (Optional - Click to expand)\", open=False, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"**These filters are completely optional.** Leave them empty to search all documents.\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    year_start = gr.Textbox(label=\"Filter by Start Year\", value=\"\", placeholder=\"e.g., 1907 (optional)\")\n",
    "                    year_end = gr.Textbox(label=\"Filter by End Year\", value=\"\", placeholder=\"e.g., 1910 (optional)\")\n",
    "                with gr.Column():\n",
    "                    scott_numbers = gr.Textbox(\n",
    "                        label=\"Filter by Scott Numbers\",\n",
    "                        placeholder=\"e.g., 1,2,3 or C15 (optional)\",\n",
    "                        value=\"\"\n",
    "                    )\n",
    "                    max_results = gr.Slider(\n",
    "                        minimum=20, maximum=100, value=60, step=10,\n",
    "                        label=\"Number of results to show\",\n",
    "                        elem_id=\"max-results-slider\"\n",
    "                    )\n",
    "\n",
    "        # =================== Results Section ===================\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"## üìä Step 2: View Your Results\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # =================== KNOWLEDGE GRAPH VISUALIZATION ===================\n",
    "        with gr.Accordion(\"üé® Knowledge Graph Visualization\", open=True, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"### üï∏Ô∏è Interactive Graph Explorer\")\n",
    "            gr.Markdown(\"Explore the relationships between stamps, issues, varieties, and other philatelic entities in your search results.\")\n",
    "            graph_output = gr.HTML(\n",
    "                value=\"<p style='padding:1rem;color:#97a6ba;text-align:center;'>üîç Run a search to see the knowledge graph</p>\",\n",
    "                elem_id=\"graph-visualization\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # =================== QUICK SEARCH RESULTS (ACCORDION) ===================\n",
    "        with gr.Accordion(\"üìÑ Quick Search Results - Fast vector & keyword matching\", open=True, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"### üí¨ AI Answer:\")\n",
    "            basic_answer_output = gr.HTML(\n",
    "                value=\"<p class='loading-text'>Answer will appear here after search</p>\",\n",
    "                elem_id=\"basic_answer\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### üìö Source Documents:\")\n",
    "                    basic_search_output = gr.HTML(\n",
    "                        \"<p class='loading-text'>Documents will appear here</p>\",\n",
    "                        elem_id=\"basic_search\"\n",
    "                    )\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### ‚ÑπÔ∏è Search Details:\")\n",
    "                    basic_metadata_output = gr.HTML(\n",
    "                        \"<p class='loading-text'>Details will appear here</p>\",\n",
    "                        elem_id=\"basic_metadata\"\n",
    "                    )\n",
    "\n",
    "        # =================== DEEP ANALYSIS RESULTS (ACCORDION) ===================  \n",
    "        with gr.Accordion(\"üöÄ Deep Analysis Results - Comprehensive AI-powered analysis\", open=True, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\"### üí¨ AI Answer:\")\n",
    "            advanced_answer_output = gr.HTML(\n",
    "                value=\"<p class='loading-text'>Answer will appear here after search</p>\",\n",
    "                elem_id=\"advanced_answer\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### üìö Source Documents:\")\n",
    "                    advanced_search_output = gr.HTML(\n",
    "                        \"<p class='loading-text' style='color: #6b7280; font-style: italic;'>Documents will appear here</p>\",\n",
    "                        elem_id=\"advanced_search\"\n",
    "                    )\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"### ‚ÑπÔ∏è Search Details:\")\n",
    "                    advanced_metadata_output = gr.HTML(\n",
    "                        \"<p class='loading-text' style='color: #6b7280; font-style: italic;'>Details will appear here</p>\",\n",
    "                        elem_id=\"advanced_metadata\"\n",
    "                    )\n",
    "\n",
    "        # =================== Additional Information ===================\n",
    "        with gr.Accordion(\"üìà Search Performance & Cost Details\", open=False, elem_classes=[\"accordion\"]):\n",
    "            timing_display = gr.Textbox(\n",
    "                label=\"Detailed Timing & Cost Analysis\",\n",
    "                lines=30,\n",
    "                interactive=False,\n",
    "                value=\"Performance metrics will appear here after search...\",\n",
    "                elem_id=\"timing-display\"\n",
    "            )\n",
    "\n",
    "        with gr.Accordion(\"‚ÑπÔ∏è System Information\", open=False, elem_classes=[\"accordion\"]):\n",
    "            gr.Markdown(\n",
    "                f\"**System Status:** ‚úÖ Operational\\n\\n\"\n",
    "                f\"‚Ä¢ **Collection:** {collection_name}\\n\"\n",
    "                f\"‚Ä¢ **Documents:** {total_docs:,}\\n\"\n",
    "                f\"‚Ä¢ **Chunks:** {total_chunks:,}\\n\\n\"\n",
    "                f\"**About the Search Methods:**\\n\"\n",
    "                f\"‚Ä¢ **Quick Results**: Fast hybrid search, good for specific catalog numbers\\n\"\n",
    "                f\"‚Ä¢ **Deep Analysis**: Thorough AI analysis, best for complex research questions\\n\\n\"\n",
    "                f\"**Tips for best results:**\\n\"\n",
    "                f\"‚Ä¢ Most searches work best without filters\\n\"\n",
    "                f\"‚Ä¢ Results appear automatically after clicking SEARCH\\n\"\n",
    "                f\"‚Ä¢ Both search methods run to give you the best possible answers\"\n",
    "            )\n",
    "\n",
    "        # ---------- Estados para pasar info entre fases ----------\n",
    "        st_ctx = gr.State({})\n",
    "\n",
    "        # ---------- Eventos SIN progress bar de Gradio ----------\n",
    "        # Click en bot√≥n de b√∫squeda\n",
    "        search_btn.click(\n",
    "            fn=run_basic_search,\n",
    "            inputs=[query_input, year_start, year_end, scott_numbers, max_results, st_ctx],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display, st_ctx\n",
    "            ],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        ).then(\n",
    "            fn=generate_graph_from_query,\n",
    "            inputs=[query_input],\n",
    "            outputs=[graph_output],\n",
    "            show_progress=False\n",
    "        ).then(\n",
    "            fn=run_advanced_search,\n",
    "            inputs=[query_input, max_results, st_ctx],\n",
    "            outputs=[advanced_answer_output, advanced_search_output, advanced_metadata_output, timing_display, st_ctx],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        )\n",
    "\n",
    "        # Enter en textbox\n",
    "        query_input.submit(\n",
    "            fn=run_basic_search,\n",
    "            inputs=[query_input, year_start, year_end, scott_numbers, max_results, st_ctx],\n",
    "            outputs=[\n",
    "                basic_answer_output, basic_search_output, basic_metadata_output,\n",
    "                advanced_answer_output, advanced_search_output, advanced_metadata_output,\n",
    "                timing_display, st_ctx\n",
    "            ],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        ).then(\n",
    "            fn=generate_graph_from_query,\n",
    "            inputs=[query_input],\n",
    "            outputs=[graph_output],\n",
    "            show_progress=False\n",
    "        ).then(\n",
    "            fn=run_advanced_search,\n",
    "            inputs=[query_input, max_results, st_ctx],\n",
    "            outputs=[advanced_answer_output, advanced_search_output, advanced_metadata_output, timing_display, st_ctx],\n",
    "            show_progress=False  # DESHABILITAMOS completamente el progress bar\n",
    "        )\n",
    "\n",
    "        # Botones de ejemplo\n",
    "        btn1.click(fn=set_example_1, outputs=[query_input])\n",
    "        btn2.click(fn=set_example_2, outputs=[query_input])\n",
    "        btn3.click(fn=set_example_3, outputs=[query_input])\n",
    "        btn4.click(fn=set_example_4, outputs=[query_input])\n",
    "        btn5.click(fn=set_example_5, outputs=[query_input])\n",
    "        btn6.click(fn=set_example_6, outputs=[query_input])\n",
    "\n",
    "        # Habilitar cola para mejor manejo de eventos\n",
    "        interface.queue()\n",
    "\n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Enhanced launcher ----\n",
    "if rag_system and rag_system.get(\"success\", False):\n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"üöÄ LAUNCHING COSTA RICA PHILATELIC RAG INTERFACE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gradio_app = create_gradio_interface(rag_system)\n",
    "\n",
    "    GRADIO_PORT = int(os.getenv(\"GRADIO_PORT\", 7860))\n",
    "    GRADIO_SHARE = os.getenv(\"GRADIO_SHARE\", \"false\").lower() == \"true\"\n",
    "\n",
    "    print(f\"‚öôÔ∏è Port: {GRADIO_PORT}\")\n",
    "    print(f\"üåç Public URL: {'‚ö†Ô∏è Attempting...' if GRADIO_SHARE else '‚ùå Disabled (more secure)'}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Starting Gradio server...\")\n",
    "        \n",
    "        if GRADIO_SHARE:\n",
    "            print(\"‚è≥ Attempting to create public tunnel...\")\n",
    "            try:\n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=True,\n",
    "                    inbrowser=False,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False,\n",
    "                    quiet=False,\n",
    "                )\n",
    "                \n",
    "                print(\"\\\\nüéâ SUCCESS! Public tunnel created\")\n",
    "                print(f\"üåê AVAILABLE URLS:\")\n",
    "                print(f\"   üì± Local: http://localhost:{GRADIO_PORT}\")\n",
    "                \n",
    "                if hasattr(demo, 'share_url') and demo.share_url:\n",
    "                    print(f\"   üåç Public: {demo.share_url}\")\n",
    "                    print(f\"\\\\nüîó **PUBLIC URL:** {demo.share_url}\")\n",
    "                else:\n",
    "                    print(f\"   üåç Public: Check Gradio output above ‚òùÔ∏è\")\n",
    "                \n",
    "            except Exception as share_error:\n",
    "                print(f\"‚ö†Ô∏è Error creating public tunnel: {share_error}\")\n",
    "                print(\"üîÑ Switching to local mode only...\")\n",
    "                \n",
    "                demo = gradio_app.launch(\n",
    "                    server_port=GRADIO_PORT,\n",
    "                    share=False,\n",
    "                    inbrowser=True,\n",
    "                    show_error=True,\n",
    "                    prevent_thread_lock=False\n",
    "                )\n",
    "                \n",
    "                print(f\"\\\\n‚úÖ LOCAL SERVER OPERATIONAL:\")\n",
    "                print(f\"   üì± Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "                print(f\"   ‚ö†Ô∏è Public URL: Not available (tunnel error)\")\n",
    "                \n",
    "        else:\n",
    "            demo = gradio_app.launch(\n",
    "                server_port=GRADIO_PORT,\n",
    "                share=False,\n",
    "                inbrowser=True,\n",
    "                show_error=True,\n",
    "                prevent_thread_lock=False\n",
    "            )\n",
    "            \n",
    "            print(f\"\\\\n‚úÖ LOCAL SERVER OPERATIONAL:\")\n",
    "            print(f\"   üì± Local URL: http://localhost:{GRADIO_PORT}\")\n",
    "            print(f\"   üí° For public URL, set GRADIO_SHARE=true in .env\")\n",
    "        \n",
    "        print(f\"\\\\nüìã COSTA RICA PHILATELIC FEATURES:\")\n",
    "        print(f\"   ‚Ä¢ Specialized Costa Rica stamp queries\")\n",
    "        print(f\"   ‚Ä¢ Scott catalog number search\")\n",
    "        print(f\"   ‚Ä¢ Variety and error detection\")\n",
    "        print(f\"   ‚Ä¢ Dual search approaches for comprehensive results\")\n",
    "        print(f\"   ‚Ä¢ Performance timing comparison\")\n",
    "        print(f\"   ‚Ä¢ To stop: gr.close_all()\")\n",
    "        \n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\"üá®üá∑ COSTA RICA PHILATELIC RAG INTERFACE READY!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Critical error launching Gradio: {e}\")\n",
    "        print(\"\\\\nüîß SUGGESTED SOLUTIONS:\")\n",
    "        print(\"   1. Run: gr.close_all()\")\n",
    "        print(\"   2. Change port: GRADIO_PORT=7861 in .env\")\n",
    "        print(\"   3. Verify no other services on the port\")\n",
    "        print(\"   4. Restart the notebook\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\\\n‚ö†Ô∏è  Cannot create Gradio interface:\")\n",
    "    if not rag_system:\n",
    "        print(\"   ‚Ä¢ RAG system not configured\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ RAG error: {rag_system.get('error', 'Unknown error')}\")\n",
    "    print(\"\\\\nüîß To resolve:\")\n",
    "    print(\"   1. Verify Weaviate is running\")\n",
    "    print(\"   2. Configure OPENAI_API_KEY in .env\") \n",
    "    print(\"   3. Run document indexing\")\n",
    "    print(\"   4. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
