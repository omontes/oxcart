{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# OXCART Philatelic RAG System\n",
    "\n",
    "Sistema completo de indexaci√≥n y b√∫squeda sem√°ntica para documentos filat√©licos.\n",
    "\n",
    "**Funcionalidades:**\n",
    "- üìÑ Indexaci√≥n autom√°tica de todos los JSONs philatelic\n",
    "- üîç B√∫squeda sem√°ntica avanzada con filtros filat√©licos\n",
    "- ü§ñ RAG b√°sico con LLM para responder preguntas\n",
    "- üìä Dashboard de estad√≠sticas y validaci√≥n\n",
    "- üåê Interfaz Gradio para consultas interactivas\n",
    "\n",
    "**Requisitos:**\n",
    "- Weaviate corriendo en Docker: `docker-compose up -d`\n",
    "- OpenAI API key configurada en `.env`\n",
    "- JSONs philatelic en `results/final_jsons/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_section",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuraci√≥n\n",
    "\n",
    "Configuraci√≥n inicial del entorno y carga de librer√≠as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30693326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Imports de terceros\n",
    "import pandas as pd\n",
    "\n",
    "print(\"‚úÖ Imports b√°sicos completados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar variables de entorno\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8083')\n",
    "PHILATELIC_JSONS_DIR = os.getenv('PHILATELIC_JSONS_DIR', './results/final_jsons')\n",
    "COLLECTION_NAME = os.getenv('WEAVIATE_COLLECTION_NAME', 'Oxcart')\n",
    "\n",
    "print(f\"üîß Configuraci√≥n:\")\n",
    "print(f\"   ‚Ä¢ Weaviate URL: {WEAVIATE_URL}\")\n",
    "print(f\"   ‚Ä¢ JSONs Directory: {PHILATELIC_JSONS_DIR}\")\n",
    "print(f\"   ‚Ä¢ Collection Name: {COLLECTION_NAME}\")\n",
    "print(f\"   ‚Ä¢ OpenAI API Key: {'‚úÖ Configurada' if OPENAI_API_KEY else '‚ùå Falta configurar'}\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"\\\\n‚ö†Ô∏è  IMPORTANTE: Configura tu OPENAI_API_KEY en el archivo .env\")\n",
    "    print(\"   Copia .env.example a .env y agrega tu API key\")\n",
    "\n",
    "# Verificar que el directorio de JSONs existe\n",
    "if not os.path.exists(PHILATELIC_JSONS_DIR):\n",
    "    print(f\"\\\\n‚ö†Ô∏è  Directorio {PHILATELIC_JSONS_DIR} no encontrado\")\n",
    "    print(\"   Aseg√∫rate de haber procesado documentos con el Dolphin parser\")\n",
    "else:\n",
    "    json_files = glob.glob(os.path.join(PHILATELIC_JSONS_DIR, '*_final.json'))\n",
    "    print(f\"\\\\nüìÅ Encontrados {len(json_files)} archivos JSON filat√©licos\")\n",
    "    if json_files:\n",
    "        print(\"   Ejemplos:\")\n",
    "        for file in json_files[:3]:\n",
    "            print(f\"   ‚Ä¢ {os.path.basename(file)}\")\n",
    "        if len(json_files) > 3:\n",
    "            print(f\"   ‚Ä¢ ... y {len(json_files) - 3} m√°s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_modules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar m√≥dulos del sistema OXCART\n",
    "from philatelic_weaviate import (\n",
    "    create_weaviate_client,\n",
    "    create_oxcart_collection,\n",
    "    index_philatelic_document,\n",
    "    search_chunks_semantic,\n",
    "    get_collection_stats,\n",
    "    transform_chunk_to_weaviate\n",
    ")\n",
    "\n",
    "from philatelic_chunk_schema import (\n",
    "    PhilatelicDocument,\n",
    "    PhilatelicChunk,\n",
    "    validate_chunk_structure,\n",
    "    get_chunk_summary\n",
    ")\n",
    "\n",
    "print(\"‚úÖ M√≥dulos OXCART cargados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery_section",
   "metadata": {},
   "source": [
    "## 2. Descubrimiento de Documentos\n",
    "\n",
    "Escanear autom√°ticamente todos los archivos JSON philatelic disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j1ap3dktty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_philatelic_jsons(directory: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Descubrir todos los archivos JSON philatelic en el directorio.\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con informaci√≥n de cada archivo\n",
    "    \"\"\"\n",
    "    json_files = []\n",
    "    \n",
    "    # Buscar archivos *_final.json\n",
    "    pattern = os.path.join(directory, \"*_final.json\")\n",
    "    philatelic_files = glob.glob(pattern)\n",
    "    \n",
    "    print(f\"üîç Buscando archivos en: {directory}\")\n",
    "    print(f\"üìã Patr√≥n de b√∫squeda: *_final.json\")\n",
    "    \n",
    "    for file_path in philatelic_files:\n",
    "        try:\n",
    "            # Obtener informaci√≥n del archivo\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "            file_name = os.path.basename(file_path)\n",
    "            doc_id = file_name.replace(\"_final.json\", \"\")\n",
    "            \n",
    "            # Cargar archivo para obtener estad√≠sticas b√°sicas\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            chunks = data.get(\"chunks\", [])\n",
    "            page_count = data.get(\"page_count\", len(chunks))  # Estimado si no est√° disponible\n",
    "            \n",
    "            # Calcular estad√≠sticas b√°sicas\n",
    "            total_text_length = 0\n",
    "            chunk_types = {}\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk.get(\"text\", \"\") or chunk.get(\"content\", \"\")\n",
    "                total_text_length += len(chunk_text)\n",
    "                \n",
    "                chunk_type = chunk.get(\"chunk_type\", \"text\")\n",
    "                chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1\n",
    "            \n",
    "            avg_chunk_length = total_text_length / len(chunks) if chunks else 0\n",
    "            \n",
    "            json_files.append({\n",
    "                \"file_path\": file_path,\n",
    "                \"file_name\": file_name,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"file_size_mb\": round(file_size, 2),\n",
    "                \"chunks_count\": len(chunks),\n",
    "                \"page_count\": page_count,\n",
    "                \"total_text_length\": total_text_length,\n",
    "                \"avg_chunk_length\": round(avg_chunk_length, 1),\n",
    "                \"chunk_types\": chunk_types,\n",
    "                \"data\": data  # Guardar datos para indexaci√≥n\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ {file_name}: {len(chunks)} chunks, {page_count} p√°ginas\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error procesando {file_path}: {e}\")\n",
    "    \n",
    "    return json_files\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de descubrimiento definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discover_documents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descubrir archivos\n",
    "discovered_files = discover_philatelic_jsons(PHILATELIC_JSONS_DIR)\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DE DESCUBRIMIENTO:\")\n",
    "print(f\"   üìÑ Archivos encontrados: {len(discovered_files)}\")\n",
    "if discovered_files:\n",
    "    total_chunks = sum(f[\"chunks_count\"] for f in discovered_files)\n",
    "    total_pages = sum(f[\"page_count\"] for f in discovered_files)\n",
    "    total_size = sum(f[\"file_size_mb\"] for f in discovered_files)\n",
    "    \n",
    "    print(f\"   üì¶ Total chunks: {total_chunks:,}\")\n",
    "    print(f\"   üìÑ Total p√°ginas: {total_pages:,}\")\n",
    "    print(f\"   üíæ Tama√±o total: {total_size:.1f} MB\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è No se encontraron archivos *_philatelic.json en {PHILATELIC_JSONS_DIR}\")\n",
    "    print(f\"   üí° Aseg√∫rate de haber procesado documentos con philatelic_patterns.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_files_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tabla resumen de archivos\n",
    "if discovered_files:\n",
    "    files_df = pd.DataFrame([\n",
    "        {\n",
    "            \"Documento\": f[\"doc_id\"],\n",
    "            \"Chunks\": f[\"chunks_count\"],\n",
    "            \"P√°ginas\": f[\"page_count\"],\n",
    "            \"Tama√±o (MB)\": f[\"file_size_mb\"],\n",
    "            \"Promedio chunk\": f[\"avg_chunk_length\"],\n",
    "            \"Tipos principales\": \", \".join([f\"{k}: {v}\" for k, v in list(f[\"chunk_types\"].items())[:3]])\n",
    "        }\n",
    "        for f in discovered_files\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìã DOCUMENTOS ENCONTRADOS:\")\n",
    "    print(files_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚ùå No hay documentos para mostrar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weaviate_section",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n de Weaviate\n",
    "\n",
    "Conectar a Weaviate y crear la colecci√≥n con esquema optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f854f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "weaviate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect_weaviate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a Weaviate\n",
    "print(\"üîå Conectando a Weaviate...\")\n",
    "\n",
    "try:\n",
    "    client = create_weaviate_client(WEAVIATE_URL, OPENAI_API_KEY)\n",
    "    print(\"‚úÖ Conexi√≥n exitosa\")\n",
    "    \n",
    "    # Verificar que Weaviate est√© funcionando\n",
    "    meta = client.get_meta()\n",
    "    print(f\"üìä Weaviate versi√≥n: {meta.get('version', 'unknown')}\")\n",
    "    \n",
    "    # Verificar si la colecci√≥n existe\n",
    "    try:\n",
    "        collections = client.collections.list_all()\n",
    "        collection_names = [col.name for col in collections]\n",
    "        \n",
    "        if COLLECTION_NAME in collection_names:\n",
    "            collection = client.collections.get(COLLECTION_NAME)\n",
    "            total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "            print(f\"üìä Colecci√≥n '{COLLECTION_NAME}' existe con {total_objects} documentos\")\n",
    "        else:\n",
    "            print(f\"üìù Colecci√≥n '{COLLECTION_NAME}' no existe (se crear√° durante la indexaci√≥n)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è No se pudo verificar colecciones: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error conectando a Weaviate: {e}\")\n",
    "    print(\"üí° Aseg√∫rate de que Weaviate est√© corriendo:\")\n",
    "    print(\"   docker-compose up -d\")\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.collections.delete(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear colecci√≥n Oxcart\n",
    "if client:\n",
    "    print(\"\\nüèóÔ∏è Configurando colecci√≥n Oxcart...\")\n",
    "    \n",
    "    collection_created = create_oxcart_collection(client, COLLECTION_NAME)\n",
    "    \n",
    "    if collection_created:\n",
    "        print(\"‚úÖ Colecci√≥n lista para indexaci√≥n\")\n",
    "        \n",
    "        # Mostrar estad√≠sticas de la colecci√≥n\n",
    "        stats = get_collection_stats(client, COLLECTION_NAME)\n",
    "        if stats:\n",
    "            print(f\"üìä Chunks actuales en Weaviate: {stats.get('total_chunks', 0)}\")\n",
    "            if stats.get('documents'):\n",
    "                print(f\"üìÑ Documentos indexados: {list(stats['documents'].keys())}\")\n",
    "    else:\n",
    "        print(\"‚ùå Error configurando colecci√≥n\")\n",
    "        client = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Saltando configuraci√≥n de colecci√≥n (sin conexi√≥n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indexing_section",
   "metadata": {},
   "source": [
    "## 4. Indexaci√≥n Autom√°tica\n",
    "\n",
    "Indexar autom√°ticamente todos los documentos philatelic en Weaviate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indexing_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_all_documents(client, discovered_files: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Indexar todos los documentos descubiertos en Weaviate.\n",
    "    \n",
    "    Returns:\n",
    "        Dict con resultados de indexaci√≥n\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return {\"error\": \"No hay conexi√≥n a Weaviate\"}\n",
    "    \n",
    "    if not discovered_files:\n",
    "        return {\"error\": \"No hay documentos para indexar\"}\n",
    "    \n",
    "    print(f\"üöÄ INICIANDO INDEXACI√ìN MASIVA\")\n",
    "    print(f\"üìÑ Documentos a procesar: {len(discovered_files)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    indexing_results = []\n",
    "    total_chunks_indexed = 0\n",
    "    total_chunks_failed = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, file_info in enumerate(discovered_files, 1):\n",
    "        doc_id = file_info[\"doc_id\"]\n",
    "        document = file_info[\"data\"]\n",
    "        chunks_count = file_info[\"chunks_count\"]\n",
    "        \n",
    "        print(f\"\\nüìÑ [{i}/{len(discovered_files)}] Procesando: {doc_id}\")\n",
    "        print(f\"   üìä Chunks: {chunks_count}\")\n",
    "        \n",
    "        try:\n",
    "            # Indexar documento usando la funci√≥n correcta\n",
    "            result = index_philatelic_document(client, document, COLLECTION_NAME)\n",
    "            \n",
    "            # Guardar resultado\n",
    "            chunks_indexed = result.get(\"successful\", 0)\n",
    "            chunks_failed = len(result.get(\"errors\", []))\n",
    "            \n",
    "            indexing_results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"success\": chunks_indexed > 0,\n",
    "                \"chunks_indexed\": chunks_indexed,\n",
    "                \"chunks_failed\": chunks_failed,\n",
    "                \"errors\": result.get(\"errors\", [])\n",
    "            })\n",
    "            \n",
    "            total_chunks_indexed += chunks_indexed\n",
    "            total_chunks_failed += chunks_failed\n",
    "            \n",
    "            # Progreso\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_time_per_doc = elapsed / i\n",
    "            remaining_docs = len(discovered_files) - i\n",
    "            eta_seconds = remaining_docs * avg_time_per_doc\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è Tiempo transcurrido: {elapsed:.1f}s\")\n",
    "            print(f\"   üîÆ ETA restante: {eta_seconds:.1f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error indexando {doc_id}: {e}\")\n",
    "            indexing_results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Resumen final\n",
    "    successful_docs = sum(1 for r in indexing_results if r.get(\"success\", False))\n",
    "    \n",
    "    summary = {\n",
    "        \"total_documents\": len(discovered_files),\n",
    "        \"successful_documents\": successful_docs,\n",
    "        \"failed_documents\": len(discovered_files) - successful_docs,\n",
    "        \"total_chunks_indexed\": total_chunks_indexed,\n",
    "        \"total_chunks_failed\": total_chunks_failed,\n",
    "        \"total_time_seconds\": total_time,\n",
    "        \"avg_time_per_document\": total_time / len(discovered_files) if discovered_files else 0,\n",
    "        \"chunks_per_second\": total_chunks_indexed / total_time if total_time > 0 else 0,\n",
    "        \"results\": indexing_results\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä RESUMEN FINAL DE INDEXACI√ìN:\")\n",
    "    print(f\"   ‚úÖ Documentos indexados: {successful_docs}/{len(discovered_files)}\")\n",
    "    print(f\"   üì¶ Chunks indexados: {total_chunks_indexed:,}\")\n",
    "    print(f\"   ‚ùå Chunks fallidos: {total_chunks_failed:,}\")\n",
    "    print(f\"   ‚è±Ô∏è Tiempo total: {total_time:.1f} segundos\")\n",
    "    print(f\"   üöÄ Velocidad: {summary['chunks_per_second']:.1f} chunks/segundo\")\n",
    "    \n",
    "    success_rate = (total_chunks_indexed / (total_chunks_indexed + total_chunks_failed)) * 100 if (total_chunks_indexed + total_chunks_failed) > 0 else 0\n",
    "    print(f\"   üìà Tasa de √©xito: {success_rate:.1f}%\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de indexaci√≥n definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_indexing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar indexaci√≥n\n",
    "if client and discovered_files:\n",
    "    print(\"üéØ ¬øProceder con la indexaci√≥n?\")\n",
    "    print(f\"   üìÑ Se indexar√°n {len(discovered_files)} documentos\")\n",
    "    total_chunks = sum(f[\"chunks_count\"] for f in discovered_files)\n",
    "    print(f\"   üì¶ Total de chunks: {total_chunks:,}\")\n",
    "    \n",
    "    # Estimar tiempo (aproximadamente 100 chunks por minuto con OpenAI embeddings)\n",
    "    estimated_minutes = total_chunks / 100\n",
    "    print(f\"   ‚è±Ô∏è Tiempo estimado: {estimated_minutes:.1f} minutos\")\n",
    "    \n",
    "    \n",
    "    indexing_summary = index_all_documents(client, discovered_files)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_file = \"indexing_results.json\"\n",
    "    with open(results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(indexing_summary, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nüíæ Resultados guardados en: {results_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se puede proceder con la indexaci√≥n:\")\n",
    "    if not client:\n",
    "        print(\"   - Sin conexi√≥n a Weaviate\")\n",
    "    if not discovered_files:\n",
    "        print(\"   - No hay documentos para indexar\")\n",
    "    indexing_summary = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_section",
   "metadata": {},
   "source": [
    "## 5. Validaci√≥n y Estad√≠sticas\n",
    "\n",
    "Verificar que la indexaci√≥n fue exitosa y mostrar estad√≠sticas detalladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_indexing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar indexaci√≥n\n",
    "if client:\n",
    "    print(\"üîç VALIDANDO INDEXACI√ìN...\")\n",
    "    \n",
    "    # Obtener estad√≠sticas actuales\n",
    "    current_stats = get_collection_stats(client, COLLECTION_NAME)\n",
    "    \n",
    "    if current_stats:\n",
    "        print(f\"\\nüìä ESTAD√çSTICAS DE WEAVIATE:\")\n",
    "        print(f\"   üì¶ Total chunks indexados: {current_stats.get('total_chunks', 0):,}\")\n",
    "        print(f\"   üìÑ Documentos √∫nicos: {current_stats.get('total_documents', 0)}\")\n",
    "        \n",
    "        # Mostrar documentos indexados\n",
    "        if current_stats.get('documents'):\n",
    "            print(f\"\\nüìã DOCUMENTOS EN WEAVIATE:\")\n",
    "            for doc_id, chunk_count in current_stats['documents'].items():\n",
    "                print(f\"   ‚Ä¢ {doc_id}: {chunk_count:,} chunks\")\n",
    "        \n",
    "        # Mostrar tipos de chunks\n",
    "        if current_stats.get('chunk_types'):\n",
    "            print(f\"\\nüè∑Ô∏è TIPOS DE CHUNKS:\")\n",
    "            for chunk_type, count in current_stats['chunk_types'].items():\n",
    "                print(f\"   ‚Ä¢ {chunk_type}: {count:,}\")\n",
    "        \n",
    "        # Comparar con archivos originales\n",
    "        if 'discovered_files' in locals() and discovered_files:\n",
    "            expected_chunks = sum(f[\"chunks_count\"] for f in discovered_files)\n",
    "            indexed_chunks = current_stats.get('total_chunks', 0)\n",
    "            \n",
    "            print(f\"\\nüîÑ COMPARACI√ìN:\")\n",
    "            print(f\"   üì• Chunks esperados: {expected_chunks:,}\")\n",
    "            print(f\"   üì§ Chunks indexados: {indexed_chunks:,}\")\n",
    "            \n",
    "            if indexed_chunks == expected_chunks:\n",
    "                print(f\"   ‚úÖ ¬°Indexaci√≥n completa al 100%!\")\n",
    "            elif indexed_chunks > 0:\n",
    "                coverage = (indexed_chunks / expected_chunks) * 100\n",
    "                print(f\"   üìä Cobertura: {coverage:.1f}%\")\n",
    "                if coverage < 100:\n",
    "                    missing = expected_chunks - indexed_chunks\n",
    "                    print(f\"   ‚ö†Ô∏è Faltan {missing:,} chunks\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå No hay chunks indexados\")\n",
    "    else:\n",
    "        print(\"‚ùå No se pudieron obtener estad√≠sticas de Weaviate\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Sin conexi√≥n a Weaviate para validaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search_testing_section",
   "metadata": {},
   "source": [
    "## 6. Pruebas de B√∫squeda Sem√°ntica\n",
    "\n",
    "Probar el sistema de b√∫squeda sem√°ntica con consultas filat√©licas espec√≠ficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_searches",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_philatelic_searches(client) -> None:\n",
    "    \"\"\"\n",
    "    Ejecutar b√∫squedas de prueba para validar el sistema.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        print(\"‚ùå Sin conexi√≥n a Weaviate\")\n",
    "        return\n",
    "    \n",
    "    # Consultas de prueba filat√©licas\n",
    "    test_queries = [\n",
    "        {\n",
    "            \"name\": \"B√∫squeda general de sellos\",\n",
    "            \"query\": \"stamps Scott catalog Costa Rica\",\n",
    "            \"filters\": None\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Cat√°logo Scott espec√≠fico\",\n",
    "            \"query\": \"Scott catalog numbers\",\n",
    "            \"filters\": {\"catalog_system\": \"Scott\"}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Sobrecargas y variedades\",\n",
    "            \"query\": \"overprint surcharge variety error\",\n",
    "            \"filters\": {\"has_varieties\": True}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Periodo Guanacaste\",\n",
    "            \"query\": \"Guanacaste overprint historical Costa Rica\",\n",
    "            \"filters\": {\"is_guanacaste\": True}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Especificaciones t√©cnicas\",\n",
    "            \"query\": \"perforation paper printing watermark\",\n",
    "            \"filters\": {\"has_technical_specs\": True}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Tablas con datos\",\n",
    "            \"query\": \"catalog table prices values\",\n",
    "            \"filters\": {\"chunk_type\": \"table\"}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"üîç EJECUTANDO B√öSQUEDAS DE PRUEBA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, test in enumerate(test_queries, 1):\n",
    "        print(f\"\\nüîé [{i}/{len(test_queries)}] {test['name']}\")\n",
    "        print(f\"   Query: \\\"{test['query']}\\\"\")\n",
    "        if test['filters']:\n",
    "            print(f\"   Filtros: {test['filters']}\")\n",
    "        \n",
    "        try:\n",
    "            results = search_chunks_semantic(\n",
    "                client, \n",
    "                test[\"query\"], \n",
    "                \"Oxcart\", \n",
    "                limit=3,\n",
    "                filters=test[\"filters\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"   üìä Resultados: {len(results)}\")\n",
    "            \n",
    "            for j, result in enumerate(results, 1):\n",
    "                print(f\"\\n      üè∑Ô∏è #{j} (Score: {result['score']:.3f})\")\n",
    "                print(f\"         üìÑ Documento: {result['doc_id']}\")\n",
    "                print(f\"         üìã Tipo: {result['chunk_type']}\")\n",
    "                print(f\"         üìÑ P√°gina: {result['page_number']}\")\n",
    "                \n",
    "                # Mostrar metadatos relevantes\n",
    "                if result.get('catalog_systems'):\n",
    "                    print(f\"         üìñ Cat√°logos: {result['catalog_systems']}\")\n",
    "                if result.get('scott_numbers'):\n",
    "                    print(f\"         üî¢ Scott: {result['scott_numbers']}\")\n",
    "                if result.get('years'):\n",
    "                    print(f\"         üìÖ A√±os: {result['years']}\")\n",
    "                if result.get('colors'):\n",
    "                    print(f\"         üé® Colores: {result['colors']}\")\n",
    "                if result.get('variety_classes'):\n",
    "                    print(f\"         üîÄ Variedades: {result['variety_classes']}\")\n",
    "                \n",
    "                # Texto truncado\n",
    "                text = result.get('text', '')\n",
    "                if len(text) > 200:\n",
    "                    text = text[:200] + \"...\"\n",
    "                print(f\"         üìù Texto: {text}\")\n",
    "            \n",
    "            if not results:\n",
    "                print(f\"   ‚ö†Ô∏è No se encontraron resultados\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error en b√∫squeda: {e}\")\n",
    "        \n",
    "        print(\"   \" + \"-\" * 50)\n",
    "\n",
    "# # Ejecutar pruebas de b√∫squeda\n",
    "# if client:\n",
    "#     test_philatelic_searches(client)\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è No se pueden ejecutar b√∫squedas sin conexi√≥n a Weaviate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79867c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_chunks_semantic(\n",
    "                client, \n",
    "                \"Costa Rica first issue (1862-1863) stamp. First stamp of Costa Rica.\", \n",
    "                \"Oxcart\", \n",
    "                limit=20,\n",
    "                filters=[],\n",
    "                mode = \"hybrid\",\n",
    "                alpha= 0.35\n",
    "                \n",
    "            )\n",
    "            \n",
    "print(f\"   üìä Resultados: {len(results)}\")\n",
    "\n",
    "for j, result in enumerate(results, 1):\n",
    "    print(f\"\\n      üè∑Ô∏è #{j} (Score: {result['score']:.3f})\")\n",
    "    print(f\"         üìÑ Documento: {result['doc_id']}\")\n",
    "    print(f\"         üìã Tipo: {result['chunk_type']}\")\n",
    "    print(f\"         üìÑ P√°gina: {result['page_number']}\")\n",
    "    \n",
    "    # Mostrar metadatos relevantes\n",
    "    if result.get('catalog_systems'):\n",
    "        print(f\"         üìñ Cat√°logos: {result['catalog_systems']}\")\n",
    "    if result.get('scott_numbers'):\n",
    "        print(f\"         üî¢ Scott: {result['scott_numbers']}\")\n",
    "    if result.get('years'):\n",
    "        print(f\"         üìÖ A√±os: {result['years']}\")\n",
    "    if result.get('colors'):\n",
    "        print(f\"         üé® Colores: {result['colors']}\")\n",
    "    if result.get('variety_classes'):\n",
    "        print(f\"         üîÄ Variedades: {result['variety_classes']}\")\n",
    "    \n",
    "    # Texto truncado\n",
    "    text = result.get('text', '')\n",
    "    if len(text) > 200:\n",
    "        text = text[:200] + \"...\"\n",
    "    print(f\"         üìù Texto: {text}\")\n",
    "    print(\"**********************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradio_section",
   "metadata": {},
   "source": [
    "## 7. Interfaz Gradio para RAG\n",
    "\n",
    "Interfaz web interactiva para b√∫squedas sem√°nticas y consultas RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "gradio_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio disponible\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import gradio as gr\n",
    "    import openai\n",
    "    gradio_available = True\n",
    "    print(\"‚úÖ Gradio disponible\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Gradio no est√° instalado\")\n",
    "    print(\"üí° Para instalar: pip install gradio\")\n",
    "    gradio_available = False\n",
    "\n",
    "# Configurar OpenAI para RAG\n",
    "if OPENAI_API_KEY:\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    openai_available = True\n",
    "else:\n",
    "    openai_available = False\n",
    "    print(\"‚ö†Ô∏è OpenAI API key no configurada para RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "rag_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def search_and_answer(\n",
    "    query: str,\n",
    "    rag_system: Dict[str, Any],\n",
    "    use_filters: bool = False,\n",
    "    catalog_system: str = \"\",\n",
    "    chunk_type: str = \"\",\n",
    "    has_varieties: bool = False,\n",
    "    max_results: int = 10,\n",
    ") -> Tuple[str, List[Dict[str, Any]], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    B√∫squeda sem√°ntica + RAG (OpenAI >= 1.0, modelo gpt-4o-mini).\n",
    "    Devuelve: (respuesta_rag, resultados(lista de dicts), metadatos(dict))\n",
    "    \"\"\"\n",
    "    # Validaci√≥n de conexi√≥n\n",
    "    if not rag_system or not rag_system.get(\"client\"):\n",
    "        meta = {\"query\": query, \"total_results\": 0, \"max_results\": max_results, \"filters_used\": {}, \"context_length\": 0}\n",
    "        return \"‚ùå Error: Sin conexi√≥n a Weaviate\", [], meta\n",
    "\n",
    "    client_wv = rag_system[\"client\"]\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "\n",
    "    # Construir filtros\n",
    "    filt = None\n",
    "    if use_filters:\n",
    "        filt = {}\n",
    "        if catalog_system:\n",
    "            filt[\"catalog_system\"] = catalog_system\n",
    "        if chunk_type:\n",
    "            filt[\"chunk_type\"] = chunk_type\n",
    "        if has_varieties:\n",
    "            filt[\"has_varieties\"] = True\n",
    "\n",
    "    # B√∫squeda sem√°ntica (usa tu funci√≥n ya definida)\n",
    "    results = search_chunks_semantic(\n",
    "        client=client_wv,\n",
    "        query=query,\n",
    "        collection_name=collection_name,\n",
    "        limit=int(max_results),\n",
    "        filters=filt,\n",
    "        mode = \"hybrid\",\n",
    "        alpha= 0.35\n",
    "    )\n",
    "\n",
    "    # Preparar contexto para RAG (top 3)\n",
    "    top = results[:3]\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Documento {r.get('doc_id', 'N/A')} (P√°gina {r.get('page_number', '¬ø?')}): {r.get('text','')}\"\n",
    "        for r in top\n",
    "    )\n",
    "    context_len = len(context)\n",
    "\n",
    "    # Generar respuesta RAG (OpenAI >= 1.0.0)\n",
    "    rag_answer = \"‚ö†Ô∏è No se encontraron resultados para generar respuesta\"\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not results:\n",
    "        rag_answer = \"‚ö†Ô∏è No se encontraron resultados para generar respuesta\"\n",
    "    elif not openai_key:\n",
    "        rag_answer = \"‚ö†Ô∏è RAG no disponible: OpenAI API key no configurada\"\n",
    "    else:\n",
    "        try:\n",
    "            from openai import OpenAI\n",
    "            oa_client = OpenAI(api_key=openai_key)\n",
    "\n",
    "            system_prompt = (\n",
    "                \"You are an expert in costa rica philately (stamps, covers, etc). \"\n",
    "                \"Only answer based with the information provided. If there is not enough info for answer please, \"\n",
    "                \"answer with: 'I dont have information'. You must include any references about philatelic like scott catalogue references, dates, etc.\"\n",
    "            )\n",
    "\n",
    "            model = os.getenv(\"RAG_MODEL\", \"gpt-4o-mini\")\n",
    "            resp = oa_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Here is the information for your answers:\\n{context}\\n\\nAnswer this only with the information provided: {query}\"}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=1000,\n",
    "            )\n",
    "\n",
    "            rag_text = resp.choices[0].message.content if resp.choices else \"\"\n",
    "            if not rag_text:\n",
    "                rag_text = \"No se obtuvo texto de respuesta del modelo.\"\n",
    "\n",
    "            rag_answer = (\n",
    "                \"ü§ñ **Respuesta RAG:**\\n\\n\"\n",
    "                + rag_text\n",
    "                + f\"\\n\\nüìä *Basado en {len(results)} resultados de b√∫squeda*\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            rag_answer = f\"‚ùå Error generando respuesta RAG: {e}\"\n",
    "\n",
    "    metadata = {\n",
    "        \"query\": query,\n",
    "        \"total_results\": len(results),\n",
    "        \"max_results\": int(max_results),\n",
    "        \"filters_used\": filt or {},\n",
    "        \"context_length\": context_len,\n",
    "    }\n",
    "    return rag_answer, results, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "911d84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones RAG definidas\n"
     ]
    }
   ],
   "source": [
    "def get_collection_info() -> str:\n",
    "    \"\"\"\n",
    "    Obtener informaci√≥n de la colecci√≥n para mostrar en la interfaz.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return \"‚ùå Sin conexi√≥n a Weaviate\"\n",
    "    \n",
    "    try:\n",
    "        stats = get_collection_stats(client, \"Oxcart\")\n",
    "        if stats:\n",
    "            info = f\"üìä **Estad√≠sticas de la Colecci√≥n Oxcart:**\\n\\n\"\n",
    "            info += f\"üì¶ **Total chunks:** {stats['total_chunks']:,}\\n\"\n",
    "            info += f\"üìÑ **Documentos:** {stats['total_documents']}\\n\\n\"\n",
    "            \n",
    "            if stats.get('documents'):\n",
    "                info += \"**Documentos indexados:**\\n\"\n",
    "                for doc_id, count in stats['documents'].items():\n",
    "                    info += f\"‚Ä¢ {doc_id}: {count:,} chunks\\n\"\n",
    "            \n",
    "            return info\n",
    "        else:\n",
    "            return \"‚ùå No se pudieron obtener estad√≠sticas\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ Funciones RAG definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36640970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17310"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = get_collection_stats(client, \"Oxcart\")\n",
    "stats['total_documents']\n",
    "stats['total_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f8f9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura que usan tus funciones de b√∫squeda/respuesta\n",
    "rag_system = {\n",
    "    \"success\": True,\n",
    "    \"client\": client,                    # para que search_and_answer pueda consultar\n",
    "    \"collection_name\": COLLECTION_NAME,  # nombre de la colecci√≥n\n",
    "    \"weaviate_url\": WEAVIATE_URL,        # info para la UI\n",
    "    \"total_documents\": stats['total_documents'],       # para mostrar estado\n",
    "    \"total_chunks\": stats['total_chunks'],        # opcional en la UI\n",
    "    # puedes a√±adir m√°s campos que tu search_and_answer necesite\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "launch_gradio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CREANDO INTERFAZ GRADIO\n",
      "==================================================\n",
      "‚úÖ Interfaz Gradio creada exitosamente\n",
      "\n",
      "üöÄ Lanzando interfaz...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VM-SERVER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1072: ResourceWarning: subprocess 36608 is still running\n",
      "  _warn(\"subprocess %s is still running\" % self.pid,\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from typing import Dict, Any\n",
    "\n",
    "def create_gradio_interface(rag_system: Dict[str, Any]) -> gr.Blocks:\n",
    "    \"\"\"\n",
    "    Crea la interfaz Gradio para consultas RAG.\n",
    "    \"\"\"\n",
    "\n",
    "    def gradio_search_and_answer(query, use_filters, catalog_system, chunk_type, has_varieties, max_results):\n",
    "        \"\"\"\n",
    "        Wrapper para Gradio: llama a search_and_answer y formatea salidas.\n",
    "        \"\"\"\n",
    "        if not rag_system:\n",
    "            return \"‚ùå Sistema RAG no est√° configurado\", \"No hay resultados\", \"No hay metadatos\"\n",
    "\n",
    "        # Llamada a tu funci√≥n (se asume definida en tu entorno)\n",
    "        answer, results, metadata = search_and_answer(\n",
    "            query=query,\n",
    "            rag_system=rag_system,\n",
    "            use_filters=use_filters,\n",
    "            catalog_system=catalog_system,\n",
    "            chunk_type=chunk_type,\n",
    "            has_varieties=has_varieties,\n",
    "            max_results=int(max_results),\n",
    "        )\n",
    "\n",
    "        # --- Formatear resultados de b√∫squeda ---\n",
    "        lines = []\n",
    "        if results:\n",
    "            for i, r in enumerate(results):\n",
    "                doc_id = r.get(\"doc_id\") or r.get(\"document_id\", \"N/A\")\n",
    "                chunk_type_val = r.get(\"chunk_type\", \"N/A\")\n",
    "                page_number = r.get(\"page_number\", \"N/A\")\n",
    "                catalogs = r.get(\"catalog_systems\") or []\n",
    "                scotts = r.get(\"scott_numbers\") or []\n",
    "                years = r.get(\"years\") or []\n",
    "\n",
    "                # Vista previa: usa content_preview si existe; si no, toma 'text'\n",
    "                preview = r.get(\"content_preview\")\n",
    "                if not preview:\n",
    "                    text = r.get(\"text\", \"\")\n",
    "                    preview = (text[:300] + \"...\") if len(text) > 300 else text\n",
    "\n",
    "                block = []\n",
    "                block.append(f\"**Resultado {i+1}**\")\n",
    "                block.append(f\"‚Ä¢ Documento: {doc_id}\")\n",
    "                block.append(f\"‚Ä¢ Tipo: {chunk_type_val} | P√°gina: {page_number}\")\n",
    "                if catalogs:\n",
    "                    block.append(f\"‚Ä¢ Cat√°logos: {', '.join(catalogs)}\")\n",
    "                if scotts:\n",
    "                    block.append(f\"‚Ä¢ Scott: {', '.join(scotts)}\")\n",
    "                if years:\n",
    "                    block.append(f\"‚Ä¢ A√±os: {', '.join(str(y) for y in years)}\")\n",
    "                block.append(f\"‚Ä¢ Vista previa: {preview}\")\n",
    "                block.append(\"-\" * 50)\n",
    "                lines.append(\"\\n\".join(block))\n",
    "            search_output = \"\\n\".join(lines)\n",
    "        else:\n",
    "            search_output = \"No se encontraron resultados\"\n",
    "\n",
    "        # --- Formatear metadatos ---\n",
    "        metadata = metadata or {}\n",
    "        metadata_output = (\n",
    "            \"**Metadatos de la consulta:**\\n\"\n",
    "            f\"‚Ä¢ Consulta: {metadata.get('query', 'N/A')}\\n\"\n",
    "            f\"‚Ä¢ Resultados encontrados: {metadata.get('total_results', 0)}\\n\"\n",
    "            f\"‚Ä¢ M√°ximo solicitado: {metadata.get('max_results', 'N/A')}\\n\"\n",
    "            f\"‚Ä¢ Filtros usados: {metadata.get('filters_used', {})}\\n\"\n",
    "            f\"‚Ä¢ Longitud del contexto: {metadata.get('context_length', 'N/A')} caracteres\\n\"\n",
    "        )\n",
    "\n",
    "        return answer, search_output, metadata_output\n",
    "\n",
    "    # Valores informativos del sistema\n",
    "    collection_name = rag_system.get(\"collection_name\", \"Oxcart\")\n",
    "    total_docs = rag_system.get(\"total_documents\", 0)\n",
    "    weaviate_url = rag_system.get(\"weaviate_url\") or os.getenv(\"WEAVIATE_URL\", \"http://localhost:8080\")\n",
    "\n",
    "    # --- UI ---\n",
    "    with gr.Blocks(title=\"OXCART RAG - Consultas Filat√©licas\") as interface:\n",
    "        gr.Markdown(\n",
    "            \"# üîç OXCART RAG - Sistema de Consultas Filat√©licas\\n\\n\"\n",
    "            \"Realiza consultas inteligentes sobre tu colecci√≥n de documentos filat√©licos \"\n",
    "            \"usando b√∫squeda sem√°ntica y respuestas generadas por IA.\"\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                # Input principal\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"üí≠ Tu consulta filat√©lica\",\n",
    "                    placeholder=\"Ej: ¬øQu√© sellos de Espa√±a de 1950 est√°n catalogados como Scott?\",\n",
    "                    lines=2,\n",
    "                )\n",
    "\n",
    "                # Bot√≥n de b√∫squeda\n",
    "                search_btn = gr.Button(\"üîç Buscar y Responder\", variant=\"primary\")\n",
    "\n",
    "                # Consultas de ejemplo\n",
    "                gr.Markdown(\"**üí° Consultas de ejemplo:**\")\n",
    "                example_queries = [\n",
    "                    \"¬øQu√© sellos conmemorativos de Espa√±a est√°n en la colecci√≥n?\",\n",
    "                    \"Mu√©strame informaci√≥n sobre sellos con errores de perforaci√≥n\",\n",
    "                    \"¬øCu√°les son los sellos m√°s valiosos seg√∫n el cat√°logo Michel?\",\n",
    "                    \"Informaci√≥n sobre sellos de M√©xico de la d√©cada de 1960\",\n",
    "                    \"¬øQu√© variedades filat√©licas est√°n documentadas?\",\n",
    "                ]\n",
    "                # Botones que rellenan el textbox\n",
    "                for example in example_queries:\n",
    "                    gr.Button(example, variant=\"secondary\").click(\n",
    "                        fn=(lambda ex=example: ex),\n",
    "                        inputs=None,\n",
    "                        outputs=query_input,\n",
    "                    )\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                # Filtros avanzados\n",
    "                gr.Markdown(\"**üéØ Filtros Avanzados**\")\n",
    "\n",
    "                use_filters = gr.Checkbox(label=\"Usar filtros espec√≠ficos\", value=False)\n",
    "\n",
    "                catalog_system = gr.Dropdown(\n",
    "                    choices=[\"\", \"Scott\", \"Michel\", \"Yvert\", \"Stanley Gibbons\", \"Edifil\"],\n",
    "                    label=\"Sistema de cat√°logo\",\n",
    "                    value=\"\",\n",
    "                )\n",
    "\n",
    "                chunk_type = gr.Dropdown(\n",
    "                    choices=[\"\", \"text\", \"table\", \"figure\", \"title\", \"header\"],\n",
    "                    label=\"Tipo de contenido\",\n",
    "                    value=\"\",\n",
    "                )\n",
    "\n",
    "                has_varieties = gr.Checkbox(label=\"Solo documentos con variedades\", value=False)\n",
    "\n",
    "                max_results = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=100,\n",
    "                    value=5,\n",
    "                    step=1,\n",
    "                    label=\"M√°ximo resultados\",\n",
    "                )\n",
    "\n",
    "        # Outputs\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"## ü§ñ Respuesta IA\")\n",
    "                answer_output = gr.Textbox(label=\"Respuesta generada\", lines=8, interactive=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"## üìÑ Documentos Encontrados\")\n",
    "                search_output = gr.Textbox(label=\"Resultados de b√∫squeda\", lines=12, interactive=False)\n",
    "\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"## üìä Metadatos\")\n",
    "                metadata_output = gr.Textbox(label=\"Informaci√≥n de la consulta\", lines=10, interactive=False)\n",
    "\n",
    "        # Eventos\n",
    "        search_btn.click(\n",
    "            fn=gradio_search_and_answer,\n",
    "            inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "            outputs=[answer_output, search_output, metadata_output],\n",
    "        )\n",
    "\n",
    "        query_input.submit(\n",
    "            fn=gradio_search_and_answer,\n",
    "            inputs=[query_input, use_filters, catalog_system, chunk_type, has_varieties, max_results],\n",
    "            outputs=[answer_output, search_output, metadata_output],\n",
    "        )\n",
    "\n",
    "        # Informaci√≥n del sistema\n",
    "        gr.Markdown(\n",
    "            \"---\\n\"\n",
    "            f\"**üìä Estado del Sistema:**\\n\"\n",
    "            f\"‚Ä¢ Colecci√≥n: {collection_name}\\n\"\n",
    "            f\"‚Ä¢ Documentos indexados: {total_docs:,}\\n\"\n",
    "            f\"‚Ä¢ Weaviate URL: {weaviate_url}\\n\"\n",
    "            \"‚Ä¢ Estado: ‚úÖ Operativo\\n\"\n",
    "        )\n",
    "\n",
    "    return interface\n",
    "\n",
    "\n",
    "# ---- Lanzador (opcional) ----\n",
    "if rag_system and rag_system.get(\"success\", False):\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CREANDO INTERFAZ GRADIO\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    gradio_app = create_gradio_interface(rag_system)\n",
    "\n",
    "    print(\"‚úÖ Interfaz Gradio creada exitosamente\")\n",
    "    print(\"\\nüöÄ Lanzando interfaz...\")\n",
    "\n",
    "    GRADIO_PORT = int(os.getenv(\"GRADIO_PORT\", 7860))\n",
    "    GRADIO_SHARE = os.getenv(\"GRADIO_SHARE\", \"false\").lower() == \"true\"\n",
    "\n",
    "    gradio_app.launch(\n",
    "        server_port=GRADIO_PORT,\n",
    "        share=GRADIO_SHARE,\n",
    "        inbrowser=True,\n",
    "        show_error=True,  # si tu versi√≥n de Gradio no lo soporta, qu√≠talo sin problema\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No se puede crear la interfaz Gradio:\")\n",
    "    if not rag_system:\n",
    "        print(\"   ‚Ä¢ Sistema RAG no est√° configurado\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Error en RAG: {rag_system.get('error', 'Error desconocido')}\")\n",
    "    print(\"\\nüîß Para solucionar:\")\n",
    "    print(\"   1. Verifica que Weaviate est√© corriendo (puerto seg√∫n tu .env)\")\n",
    "    print(\"   2. Configura OPENAI_API_KEY en .env\")\n",
    "    print(\"   3. Ejecuta la indexaci√≥n de documentos\")\n",
    "    print(\"   4. Reinicia este notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7384fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "# gr.close_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion_section",
   "metadata": {},
   "source": [
    "## 8. Resumen y Pr√≥ximos Pasos\n",
    "\n",
    "Sistema RAG completo para documentos filat√©licos implementado exitosamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "final_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ OXCART PHILATELIC RAG SYSTEM\n",
      "============================================================\n",
      "üîó Weaviate: ‚úÖ Conectado\n",
      "ü§ñ OpenAI: ‚úÖ Configurado\n",
      "üåê Gradio: ‚úÖ Disponible\n",
      "\n",
      "üìä DATOS DISPONIBLES:\n",
      "   üìÑ Documentos: 81\n",
      "   üì¶ Chunks: 17,636\n",
      "   ‚úÖ Indexados: 17,310\n",
      "   üìà Cobertura: 98.2%\n",
      "\n",
      "üöÄ FUNCIONALIDADES:\n",
      "   üìÑ Indexaci√≥n autom√°tica de JSONs philatelic\n",
      "   üîç B√∫squeda sem√°ntica avanzada\n",
      "   üéõÔ∏è Filtros especializados (cat√°logos, tipos, variedades)\n",
      "   ü§ñ RAG con respuestas de LLM\n",
      "   üåê Interfaz web interactiva\n",
      "   üìä Estad√≠sticas y validaci√≥n\n",
      "\n",
      "üîÆ PR√ìXIMOS PASOS:\n",
      "   ‚Ä¢ Probar b√∫squedas en la interfaz Gradio\n",
      "   ‚Ä¢ Agregar m√°s documentos al sistema\n",
      "   ‚Ä¢ Ajustar filtros y consultas\n",
      "\n",
      "üí° RECURSOS:\n",
      "   üìö Documentaci√≥n: philatelic_chunk_schema.py\n",
      "   üîß Configuraci√≥n: .env.example\n",
      "   üê≥ Docker: docker-compose.yml\n",
      "   üåê Interfaz: http://localhost:7860\n",
      "\n",
      "‚ú® ¬°Sistema OXCART RAG listo para usar!\n"
     ]
    }
   ],
   "source": [
    "# Resumen final del sistema\n",
    "print(\"üéâ OXCART PHILATELIC RAG SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estado del sistema\n",
    "weaviate_status = \"‚úÖ Conectado\" if client else \"‚ùå Desconectado\"\n",
    "openai_status = \"‚úÖ Configurado\" if openai_available else \"‚ùå No configurado\"\n",
    "gradio_status = \"‚úÖ Disponible\" if gradio_available else \"‚ùå No instalado\"\n",
    "\n",
    "print(f\"üîó Weaviate: {weaviate_status}\")\n",
    "print(f\"ü§ñ OpenAI: {openai_status}\")\n",
    "print(f\"üåê Gradio: {gradio_status}\")\n",
    "\n",
    "# Estad√≠sticas de datos\n",
    "if discovered_files:\n",
    "    total_docs = len(discovered_files)\n",
    "    total_chunks = sum(f[\"chunks_count\"] for f in discovered_files)\n",
    "    print(f\"\\nüìä DATOS DISPONIBLES:\")\n",
    "    print(f\"   üìÑ Documentos: {total_docs}\")\n",
    "    print(f\"   üì¶ Chunks: {total_chunks:,}\")\n",
    "    \n",
    "    if client:\n",
    "        current_stats = get_collection_stats(client, \"Oxcart\")\n",
    "        if current_stats:\n",
    "            indexed_chunks = current_stats['total_chunks']\n",
    "            print(f\"   ‚úÖ Indexados: {indexed_chunks:,}\")\n",
    "            if indexed_chunks > 0:\n",
    "                coverage = (indexed_chunks / total_chunks) * 100\n",
    "                print(f\"   üìà Cobertura: {coverage:.1f}%\")\n",
    "\n",
    "# Funcionalidades disponibles\n",
    "print(f\"\\nüöÄ FUNCIONALIDADES:\")\n",
    "print(f\"   üìÑ Indexaci√≥n autom√°tica de JSONs philatelic\")\n",
    "print(f\"   üîç B√∫squeda sem√°ntica avanzada\")\n",
    "print(f\"   üéõÔ∏è Filtros especializados (cat√°logos, tipos, variedades)\")\n",
    "if openai_available:\n",
    "    print(f\"   ü§ñ RAG con respuestas de LLM\")\n",
    "if gradio_available:\n",
    "    print(f\"   üåê Interfaz web interactiva\")\n",
    "print(f\"   üìä Estad√≠sticas y validaci√≥n\")\n",
    "\n",
    "# Pr√≥ximos pasos\n",
    "print(f\"\\nüîÆ PR√ìXIMOS PASOS:\")\n",
    "if not client:\n",
    "    print(f\"   1. Configurar Weaviate: docker-compose up -d\")\n",
    "if not openai_available:\n",
    "    print(f\"   2. Configurar OpenAI API key en .env\")\n",
    "if not gradio_available:\n",
    "    print(f\"   3. Instalar Gradio: pip install gradio\")\n",
    "\n",
    "if client and discovered_files:\n",
    "    current_stats = get_collection_stats(client, \"Oxcart\")\n",
    "    if not current_stats or current_stats.get('total_chunks', 0) == 0:\n",
    "        print(f\"   ‚Ä¢ Ejecutar indexaci√≥n de documentos\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Probar b√∫squedas en la interfaz Gradio\")\n",
    "        print(f\"   ‚Ä¢ Agregar m√°s documentos al sistema\")\n",
    "        print(f\"   ‚Ä¢ Ajustar filtros y consultas\")\n",
    "\n",
    "print(f\"\\nüí° RECURSOS:\")\n",
    "print(f\"   üìö Documentaci√≥n: philatelic_chunk_schema.py\")\n",
    "print(f\"   üîß Configuraci√≥n: .env.example\")\n",
    "print(f\"   üê≥ Docker: docker-compose.yml\")\n",
    "print(f\"   üåê Interfaz: http://localhost:{os.getenv('GRADIO_PORT', 7860)}\")\n",
    "\n",
    "print(\"\\n‚ú® ¬°Sistema OXCART RAG listo para usar!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-clean (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
